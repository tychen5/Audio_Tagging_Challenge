{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "from math import log, floor\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils import *\n",
    "from keras.layers.advanced_activations import *\n",
    "# from keras.layers.advanced_activations import *\n",
    "from keras import *\n",
    "from keras.engine.topology import *\n",
    "from keras.optimizers import *\n",
    "import keras\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import sklearn\n",
    "import pickle\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "# importing dependencies\n",
    "import pandas as pd # data frame\n",
    "import numpy as np # matrix math\n",
    "from scipy.io import wavfile # reading the wavfile\n",
    "from sklearn.utils import shuffle # shuffling of data\n",
    "from random import sample # random selection\n",
    "from tqdm import tqdm # progress bar\n",
    "import matplotlib.pyplot as plt # to view graphs\n",
    "import wave\n",
    "from math import log, floor\n",
    "# audio processing\n",
    "from scipy import signal # audio processing\n",
    "from scipy.fftpack import dct\n",
    "import librosa # library for audio processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.cluster import KMeans\n",
    "import sys, os\n",
    "import random,math\n",
    "from tqdm import tqdm ##\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils import shuffle # shuffling of data\n",
    "from random import sample # random selection\n",
    "from tqdm import tqdm # progress bar\n",
    "# audio processing\n",
    "from scipy import signal # audio processing\n",
    "from scipy.fftpack import dct\n",
    "import librosa # library for audio processing\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "from keras.utils import *\n",
    "from sklearn.ensemble import *\n",
    "import pickle\n",
    "from bayes_opt import BayesianOptimization\n",
    "from logHandler import Logger\n",
    "from utils import readCSV, getPath, writePickle,readPickle\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import History ,ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001ca53d.wav' '0033e230.wav' '00353774.wav' ... 'ffd6b26c.wav'\n",
      " 'ffda1d2b.wav' 'fff81f55.wav']\n",
      "Saving fold 1\n",
      "X.shape: (371, 64, 431, 1)\n",
      "y.shape: (371, 41)\n",
      "fname.shape: (371,)\n",
      "Saving fold 2\n",
      "X.shape: (371, 64, 431, 1)\n",
      "y.shape: (371, 41)\n",
      "fname.shape: (371,)\n",
      "Saving fold 3\n",
      "X.shape: (371, 64, 431, 1)\n",
      "y.shape: (371, 41)\n",
      "fname.shape: (371,)\n",
      "Saving fold 4\n",
      "X.shape: (371, 64, 431, 1)\n",
      "y.shape: (371, 41)\n",
      "fname.shape: (371,)\n",
      "Saving fold 5\n",
      "X.shape: (371, 64, 431, 1)\n",
      "y.shape: (371, 41)\n",
      "fname.shape: (371,)\n",
      "Saving fold 6\n",
      "X.shape: (371, 64, 431, 1)\n",
      "y.shape: (371, 41)\n",
      "fname.shape: (371,)\n",
      "Saving fold 7\n",
      "X.shape: (371, 64, 431, 1)\n",
      "y.shape: (371, 41)\n",
      "fname.shape: (371,)\n",
      "Saving fold 8\n",
      "X.shape: (371, 64, 431, 1)\n",
      "y.shape: (371, 41)\n",
      "fname.shape: (371,)\n",
      "Saving fold 9\n",
      "X.shape: (371, 64, 431, 1)\n",
      "y.shape: (371, 41)\n",
      "fname.shape: (371,)\n",
      "Saving fold 10\n",
      "X.shape: (371, 64, 431, 1)\n",
      "y.shape: (371, 41)\n",
      "fname.shape: (371,)\n"
     ]
    }
   ],
   "source": [
    "# map_path = path of 'map.pkl'\n",
    "map_path = 'data/map.pkl'#sys.argv[1]\n",
    "\n",
    "# base_path = directory of all the data (train_label.csv, X_train.npy)\n",
    "base_path = 'feature/mfcc6/'#sys.argv[2]\n",
    "\n",
    "# num_fold\n",
    "num_fold = 10#int(sys.argv[3])\n",
    "\n",
    "with open(map_path, 'rb') as f:\n",
    "    map_dict = pickle.load(f)\n",
    "\n",
    "verified = []\n",
    "\n",
    "train_label_path = os.path.join(base_path, 'train_label.csv')\n",
    "Y_train = pd.read_csv(train_label_path)\n",
    "\n",
    "for i in range(len(Y_train)):\n",
    "    if Y_train['manually_verified'][i] == 1:\n",
    "        verified.append(i)\n",
    "\n",
    "Y_train = Y_train.loc[verified,:]\n",
    "\n",
    "fname_all = Y_train['fname']\n",
    "fname_all = np.array(fname_all)\n",
    "print(fname_all)\n",
    "\n",
    "Y_dict = Y_train['label'].map(map_dict)\n",
    "Y_dict = np.array(Y_dict)\n",
    "\n",
    "Y_all = []\n",
    "for i in Y_dict:\n",
    "    Y_all.append(to_categorical(i, num_classes=41))\n",
    "Y_all = np.array(Y_all)\n",
    "\n",
    "X_train_path = os.path.join(base_path, 'X_train.npy')\n",
    "X_all = np.load(X_train_path)\n",
    "\n",
    "X_all = X_all[verified, :]\n",
    "\n",
    "idx = list(range(X_all.shape[0]))\n",
    "random.shuffle(idx)\n",
    "\n",
    "xSize = math.ceil(X_all.shape[0] / num_fold)\n",
    "\n",
    "split_X_path = os.path.join(base_path, 'X')\n",
    "split_y_path = os.path.join(base_path, 'y')\n",
    "split_fname_path = os.path.join(base_path, 'fname')\n",
    "\n",
    "if not os.path.exists(split_X_path):\n",
    "    os.makedirs(split_X_path)\n",
    "if not os.path.exists(split_y_path):\n",
    "    os.makedirs(split_y_path)\n",
    "if not os.path.exists(split_fname_path):\n",
    "    os.makedirs(split_fname_path)\n",
    "\n",
    "for i in range(num_fold):\n",
    "    X = X_all[idx[i*xSize:i*xSize+xSize]]\n",
    "    y = Y_all[idx[i*xSize:i*xSize+xSize]]\n",
    "    fname = fname_all[idx[i*xSize:i*xSize+xSize]]\n",
    "    print('Saving fold {}'.format(i+1))\n",
    "    print('X.shape:', X.shape)\n",
    "    print('y.shape:', y.shape)\n",
    "    print('fname.shape:', fname.shape)\n",
    "    filename = os.path.join(split_X_path, 'X' + str(i+1) + '.npy')\n",
    "    np.save(filename, X)\n",
    "    filename = os.path.join(split_y_path, 'y' + str(i+1) + '.npy')\n",
    "    np.save(filename, y)\n",
    "    filename = os.path.join(split_fname_path, 'fname' + str(i+1) + '.npy')\n",
    "    np.save(filename, fname)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3710, 64, 431, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('feature/mfcc6/X_test.npy')\n",
    "X_all = np.load('feature/mfcc6/X_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18873, 64, 88, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18873, 64, 431, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((X_all, X_test))\n",
    "print(X.shape)\n",
    "min_ = np.min(X,axis=0)\n",
    "max_ = np.max(X,axis=0)\n",
    "range_ = max_ - min_\n",
    "mean = np.mean(X,axis=0)\n",
    "std = np.std(X,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_ = np.min(X)\n",
    "# max_ = np.max(X)\n",
    "# range_ = max_ - min_\n",
    "# mean = np.mean(X)\n",
    "# std = np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1242.64826948],\n",
       "        [1242.88633185],\n",
       "        [1268.99798239],\n",
       "        ...,\n",
       "        [1258.79215497],\n",
       "        [1258.82903343],\n",
       "        [1263.02693244]],\n",
       "\n",
       "       [[ 536.15501748],\n",
       "        [ 544.35516655],\n",
       "        [ 559.40674493],\n",
       "        ...,\n",
       "        [ 484.62245785],\n",
       "        [ 479.73208684],\n",
       "        [ 487.09957474]],\n",
       "\n",
       "       [[ 292.23504265],\n",
       "        [ 324.76049577],\n",
       "        [ 367.94273228],\n",
       "        ...,\n",
       "        [ 360.20881248],\n",
       "        [ 350.13738414],\n",
       "        [ 312.37433088]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  39.71060807],\n",
       "        [  43.65924078],\n",
       "        [  73.29228141],\n",
       "        ...,\n",
       "        [  63.80741587],\n",
       "        [  62.02384328],\n",
       "        [  41.14892323]],\n",
       "\n",
       "       [[  30.48704827],\n",
       "        [  37.14012634],\n",
       "        [  54.69477386],\n",
       "        ...,\n",
       "        [  52.11433432],\n",
       "        [  53.96625904],\n",
       "        [  36.98807019]],\n",
       "\n",
       "       [[  37.32372715],\n",
       "        [  38.14258725],\n",
       "        [  58.57843169],\n",
       "        ...,\n",
       "        [  57.55608584],\n",
       "        [  53.18481054],\n",
       "        [  31.01495625]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18873, 128, 1034, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = (X - mean)/std\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('feature/mfcc6/mean.npy',mean)\n",
    "np.save('feature/mfcc6/std.npy',std)\n",
    "np.save('feature/mfcc6/min.npy',min_)\n",
    "np.save('feature/mfcc6/range.npy',range_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi: fbank4 + mfcc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_path = path of 'map.pkl'\n",
    "map_path = 'data/map.pkl'#sys.argv[1]\n",
    "\n",
    "# base_path = directory of all the data (train_label.csv, X_train.npy)\n",
    "base_path = 'feature/mfcc6/'#sys.argv[2]\n",
    "\n",
    "\n",
    "with open(map_path, 'rb') as f:\n",
    "    map_dict = pickle.load(f)\n",
    "\n",
    "verified = []\n",
    "unverified = []\n",
    "\n",
    "train_label_path = os.path.join(base_path, 'train_label.csv')\n",
    "Y_train = pd.read_csv(train_label_path)\n",
    "\n",
    "for i in range(len(Y_train)):\n",
    "    if Y_train['manually_verified'][i] == 1:\n",
    "        verified.append(i)\n",
    "    else:\n",
    "        unverified.append(i)\n",
    "\n",
    "Y_un = Y_train.loc[unverified,:]\n",
    "\n",
    "fname_all = Y_un['fname']\n",
    "fname_all = np.array(fname_all)\n",
    "\n",
    "Y_dict = Y_un['label'].map(map_dict)\n",
    "Y_dict = np.array(Y_dict)\n",
    "\n",
    "Y_all = []\n",
    "for i in Y_dict:\n",
    "    Y_all.append(to_categorical(i, num_classes=41))\n",
    "Y_all = np.array(Y_all)\n",
    "\n",
    "filename = os.path.join(base_path, 'fname_unverified.npy')\n",
    "np.save(filename, fname_all)\n",
    "\n",
    "filename = os.path.join(base_path, 'y_unverified.npy')\n",
    "np.save(filename, Y_all)\n",
    "\n",
    "X_train_path = os.path.join(base_path, 'X_train.npy')\n",
    "X_all = np.load(X_train_path)\n",
    "\n",
    "X_un = X_all[unverified, :]\n",
    "filename = os.path.join(base_path, 'X_unverified.npy')\n",
    "np.save(filename, X_un)\n",
    "\n",
    "X_ver = X_all[verified, :]\n",
    "train_label_path = os.path.join(base_path, 'train_label.csv')\n",
    "Y_ver = pd.read_csv(train_label_path)\n",
    "Y_ver = Y_ver.loc[verified,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_list = np.load('feature/mfcc6/semi/fbank4/X_un_ver_list.pkl')\n",
    "X_un_ver = X_un[take_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 64, 431, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.load('feature/mfcc6/X_test.npy')\n",
    "take_list = np.load('feature/mfcc6/semi/fbank4/X_test_ver_list.pkl')\n",
    "X_test_ver = X_test[take_list]\n",
    "X_test_ver.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 64, 431, 1) (41, 64, 431, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_un_ver.shape,X_test_ver.shape)\n",
    "np.save('feature/mfcc6/semi/fbank4/X_test_ver.npy',X_test_ver)\n",
    "np.save('feature/mfcc6/semi/fbank4/X_un_ver.npy',X_un_ver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
