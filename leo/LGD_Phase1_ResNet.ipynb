{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "from math import log, floor\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils import *\n",
    "from keras.layers.advanced_activations import *\n",
    "from collections import Counter\n",
    "from keras import *\n",
    "from keras.engine.topology import *\n",
    "from keras.optimizers import *\n",
    "import keras\n",
    "# import pandas as pd\n",
    "import glob\n",
    "from sklearn.semi_supervised import *\n",
    "import pickle\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "import pandas as pd # data frame\n",
    "import numpy as np # matrix math\n",
    "from scipy.io import wavfile # reading the wavfile\n",
    "from sklearn.utils import shuffle # shuffling of data\n",
    "from random import sample # random selection\n",
    "from tqdm import tqdm # progress bar\n",
    "import matplotlib.pyplot as plt # to view graphs\n",
    "import wave\n",
    "from math import log, floor\n",
    "# audio processing\n",
    "from scipy import signal # audio processing\n",
    "from scipy.fftpack import dct\n",
    "import librosa # library for audio processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.cluster import KMeans\n",
    "import sys, os\n",
    "import random,math\n",
    "from tqdm import tqdm ##\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils import shuffle # shuffling of data\n",
    "from random import sample # random selection\n",
    "from tqdm import tqdm # progress bar\n",
    "# audio processing\n",
    "from scipy import signal # audio processing\n",
    "from scipy.fftpack import dct\n",
    "import librosa # library for audio processing\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "from keras.utils import *\n",
    "from sklearn.ensemble import *\n",
    "import pickle\n",
    "from bayes_opt import BayesianOptimization\n",
    "from logHandler import Logger\n",
    "from utils import readCSV, getPath, writePickle,readPickle\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import History ,ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shuffle(X, Y):\n",
    "    randomize = np.arange(len(X))\n",
    "    np.random.shuffle(randomize)\n",
    "#     print(X.shape, Y.shape)\n",
    "    return (X[randomize], Y[randomize])\n",
    "\n",
    "def getTrainData():\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(num_fold):\n",
    "        fileX = os.path.join(base_data_path, 'X/X' + str(i+1) + '.npy')\n",
    "        fileY = os.path.join(base_data_path, 'y/y' + str(i+1) + '.npy')\n",
    "        \n",
    "        X.append(np.load(fileX))\n",
    "        y.append(np.load(fileY))\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y, idx):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    for i in range(num_fold):\n",
    "        if i == idx:\n",
    "            X_val = X[i]\n",
    "            y_val = y[i]\n",
    "            continue\n",
    "        if X_train == []:\n",
    "            X_train = X[i]\n",
    "            y_train = y[i]\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, X[i]))\n",
    "            y_train = np.concatenate((y_train, y[i]))\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "def normalize(X_train, X_val):\n",
    "    X_train = (X_train - mean)/(std)\n",
    "#     X_train = (X_train - min_)/range_\n",
    "    X_val = (X_val - mean)/(std)\n",
    "#     X_val = (X_val - min_)/range_\n",
    "\n",
    "    return X_train, X_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# min_ = np.swapaxes(min_,0,1)\n",
    "# mean = np.swapaxes(mean,0,1)\n",
    "# range_ = np.swapaxes(range_,0,1)\n",
    "# std = np.swapaxes(std,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_valid(X_train,Y_train,X_valid,Y_valid,fold):\n",
    "    model = [resnet.ResnetBuilder.build_resnet_18((1, X_train.shape[1], X_train.shape[2]), 41),\n",
    "             resnet.ResnetBuilder.build_resnet_34((1,X_train.shape[1], X_train.shape[2]), 41),\n",
    "             resnet.ResnetBuilder.build_resnet_50((1, X_train.shape[1], X_train.shape[2]), 41) ,\n",
    "             resnet.ResnetBuilder.build_resnet_101((1, X_train.shape[1], X_train.shape[2]), 41),\n",
    "             resnet.ResnetBuilder.build_resnet_152((1, X_train.shape[1], X_train.shape[2]), 41)]\n",
    "    kk = random.randint(0, 4)\n",
    "    model = model[kk]\n",
    "    model.summary()\n",
    "    if kk>2:\n",
    "        batchSize=[32,64]#,128,256]\n",
    "    elif kk==2:\n",
    "        batchSize=[32,64,128]\n",
    "    else:\n",
    "        batchSize=[32,64,128,256]\n",
    "    \n",
    "    batchSize = random.choice(batchSize)\n",
    "    patien=100\n",
    "    epoch=3000\n",
    "    saveD = 'model/'+feature_type+'/'\n",
    "    if not os.path.exists(saveD):\n",
    "        os.makedirs(saveD)\n",
    "    opt = Adam()#Nadam() #Adam(lr=2e-3,decay=1e-20)\n",
    "\n",
    "    model.compile(loss=['categorical_crossentropy'],optimizer=opt, metrics=['acc']) \n",
    "    logD = './logs/mfcc6/'\n",
    "    print('using resnet model: '+str(kk))\n",
    "    if not os.path.exists(logD):\n",
    "        os.makedirs(logD)\n",
    "    history = History()\n",
    "    callback=[\n",
    "    #     ReduceLROnPlateau(monitor='loss', factor=0.5, patience=int(patien/2),\n",
    "    #                                   min_lr=1e-4,mode='min', cooldown=1 ),\n",
    "        EarlyStopping(patience=patien,monitor='val_loss',verbose=1,\n",
    "                      mode='min'),\n",
    "        ModelCheckpoint(saveD+'LGD_fold'+str(fold)+'_resnet'+str(kk)+'-.h5',\n",
    "                        monitor='val_acc',verbose=1,save_best_only=True, \n",
    "                        save_weights_only=False,mode='max'),\n",
    "        TensorBoard(log_dir=logD+'LGD_fold'+str(fold)+'_resnet'+str(kk)),\n",
    "        history#,batch_size=batch_size, write_graph=True, write_grads=False, write_images=True)\n",
    "    ]\n",
    "\n",
    "    model.fit(X_train,Y_train,\n",
    "              shuffle=True,\n",
    "              callbacks=callback, \n",
    "              class_weight='auto',\n",
    "              validation_data=(X_valid,Y_valid),\n",
    "              batch_size=batchSize,\n",
    "              epochs=epoch)\n",
    "    return model,kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semi_data(X_train,Y_train):\n",
    "    X_un_ver = np.load('feature/mfcc6/semi/fbank4/X_un_ver.npy')\n",
    "    X_test_ver = np.load('feature/mfcc6/semi/fbank4/X_test_ver.npy')\n",
    "    X = np.concatenate((X_un_ver,X_test_ver))\n",
    "    Y_un_ver = np.load('feature/mfcc6/semi/fbank4/Y_un_ver.npy')\n",
    "    Y_test_ver = np.load('feature/mfcc6/semi/fbank4/Y_test_ver.npy')\n",
    "    Y = np.concatenate((Y_un_ver,Y_test_ver))\n",
    "    Y = to_categorical(Y,num_classes=41)\n",
    "    X_semi = np.concatenate((X_train,X))\n",
    "    Y_semi = np.concatenate((Y_train,Y))\n",
    "    X_semi , Y_semi = _shuffle(X_semi,Y_semi)\n",
    "    print(X_semi.shape , Y_semi.shape)\n",
    "    return X_semi , Y_semi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = resnet.ResnetBuilder.build_resnet_50((1, 64, 431), 41)\n",
    "# model.summary()\n",
    "def train_unverified(model,X_semi,Y_semi,fold,kk):\n",
    "    name = glob.glob('model/'+feature_type+'/'+'LGD_fold'+str(fold)+'_resnet'+str(kk)+'-**')[0]\n",
    "    print('semi loading: '+ name)\n",
    "    model = load_model(name)\n",
    "    if kk>2:\n",
    "        batchSize=[32,64]#,128,256]\n",
    "    elif kk==2:\n",
    "        batchSize=[32,64,128]\n",
    "    else:\n",
    "        batchSize=[32,64,128,256]\n",
    "    batchSize = random.choice(batchSize)\n",
    "    patien=100\n",
    "    epoch=3000\n",
    "    saveD = 'model/'+feature_type+'/'\n",
    "    opt = Adam(lr=0.0001,decay=1e-6)#Nadam() #Adam(lr=2e-3,decay=1e-20)\n",
    "\n",
    "    model.compile(loss=['categorical_crossentropy'],optimizer=opt, metrics=['acc']) \n",
    "    logD = './logs/mfcc6/'\n",
    "    history = History()\n",
    "    callback=[\n",
    "        ReduceLROnPlateau(monitor='loss', factor=0.2, patience=int(patien/20),min_lr=1e-6,\n",
    "                          mode='min', cooldown=1,verbose=1 ),\n",
    "        EarlyStopping(patience=patien,monitor='val_loss',verbose=1,\n",
    "                      mode='min'),\n",
    "        ModelCheckpoint(saveD+'LGD_semi_fold'+str(fold)+'_resnet'+str(kk)+'.h5',\n",
    "                        monitor='val_acc',verbose=1,save_best_only=True, \n",
    "                        save_weights_only=False,\n",
    "                        mode='max'),\n",
    "        TensorBoard(log_dir=logD+'LGD_semi_fold'+str(fold)+'_resnet'+str(kk)),\n",
    "        history\n",
    "    ]\n",
    "\n",
    "    model.fit(X_semi,Y_semi,\n",
    "              shuffle=True,\n",
    "              callbacks=callback, \n",
    "              class_weight='auto',\n",
    "              validation_data=(X_valid,Y_valid),\n",
    "              batch_size=batchSize,\n",
    "              epochs=epoch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type = 'mfcc6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.load('feature/'+feature_type+'/mean.npy')\n",
    "std = np.load('feature/'+feature_type+'/std.npy')\n",
    "min_ = np.load('feature/'+feature_type+'/min.npy')\n",
    "range_ = np.load('feature/'+feature_type+'/range.npy')\n",
    "\n",
    "\n",
    "base_path = 'feature/'+feature_type+'/'#'/tmp2/b03902110/newphase1'\n",
    "base_data_path = 'feature/'+feature_type+'/'#os.path.join(base_path, 'data')\n",
    "num_fold = 10\n",
    "\n",
    "val_set_num = [2,3,4,5,6,7,8,9]#str(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:32: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3339, 64, 431, 1) (3339, 41)\n",
      "===train verified_2===\n",
      "using resnet model: 3\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 64, 431, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 32, 216, 64)  3200        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 32, 216, 64)  256         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 32, 216, 64)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 108, 64)  0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 108, 64)  4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 108, 64)  256         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 108, 64)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 108, 64)  36928       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 16, 108, 64)  256         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 108, 64)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 108, 256) 16640       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 108, 256) 16640       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 16, 108, 256) 0           conv2d_114[0][0]                 \n",
      "                                                                 conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 108, 256) 1024        add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 108, 256) 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 108, 64)  16448       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 108, 64)  256         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 108, 64)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 108, 64)  36928       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 108, 64)  256         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 108, 64)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 108, 256) 16640       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 16, 108, 256) 0           add_41[0][0]                     \n",
      "                                                                 conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 108, 256) 1024        add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 108, 256) 0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 108, 64)  16448       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, 108, 64)  256         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 108, 64)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 108, 64)  36928       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 108, 64)  256         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 108, 64)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 16, 108, 256) 16640       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 16, 108, 256) 0           add_42[0][0]                     \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, 108, 256) 1024        add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 108, 256) 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, 54, 128)   32896       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 8, 54, 128)   512         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 8, 54, 128)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 54, 128)   147584      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 8, 54, 128)   512         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 8, 54, 128)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 8, 54, 512)   131584      add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 54, 512)   66048       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 8, 54, 512)   0           conv2d_124[0][0]                 \n",
      "                                                                 conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 8, 54, 512)   2048        add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 8, 54, 512)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 8, 54, 128)   65664       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 8, 54, 128)   512         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 8, 54, 128)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 8, 54, 128)   147584      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 8, 54, 128)   512         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 8, 54, 128)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 8, 54, 512)   66048       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 8, 54, 512)   0           add_44[0][0]                     \n",
      "                                                                 conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, 54, 512)   2048        add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 8, 54, 512)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 8, 54, 128)   65664       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 54, 128)   512         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 8, 54, 128)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 54, 128)   147584      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 54, 128)   512         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 8, 54, 128)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 8, 54, 512)   66048       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 8, 54, 512)   0           add_45[0][0]                     \n",
      "                                                                 conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 54, 512)   2048        add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 8, 54, 512)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 8, 54, 128)   65664       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 54, 128)   512         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 8, 54, 128)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 8, 54, 128)   147584      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, 54, 128)   512         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 8, 54, 128)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 8, 54, 512)   66048       activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 8, 54, 512)   0           add_46[0][0]                     \n",
      "                                                                 conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 8, 54, 512)   2048        add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 8, 54, 512)   0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 4, 27, 256)   131328      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 4, 27, 256)   1024        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 4, 27, 256)   0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 4, 27, 256)   590080      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 4, 27, 256)   1024        conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 4, 27, 256)   0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 4, 27, 1024)  525312      add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 4, 27, 1024)  263168      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 4, 27, 1024)  0           conv2d_137[0][0]                 \n",
      "                                                                 conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 4, 27, 1024)  4096        add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 4, 27, 256)   262400      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 4, 27, 256)   1024        conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 4, 27, 256)   0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 4, 27, 256)   590080      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 4, 27, 256)   1024        conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 4, 27, 256)   0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 4, 27, 1024)  263168      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 4, 27, 1024)  0           add_48[0][0]                     \n",
      "                                                                 conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 4, 27, 1024)  4096        add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 4, 27, 256)   262400      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 4, 27, 256)   1024        conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 4, 27, 256)   0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 4, 27, 256)   590080      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 4, 27, 256)   1024        conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 4, 27, 256)   0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 4, 27, 1024)  263168      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 4, 27, 1024)  0           add_49[0][0]                     \n",
      "                                                                 conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 4, 27, 1024)  4096        add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 4, 27, 256)   262400      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 4, 27, 256)   1024        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 4, 27, 256)   0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 4, 27, 256)   590080      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 4, 27, 256)   1024        conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 4, 27, 256)   0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 4, 27, 1024)  263168      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 4, 27, 1024)  0           add_50[0][0]                     \n",
      "                                                                 conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 4, 27, 1024)  4096        add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 4, 27, 256)   262400      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 4, 27, 256)   1024        conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 4, 27, 256)   0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 4, 27, 256)   590080      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 4, 27, 256)   1024        conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 4, 27, 256)   0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 4, 27, 1024)  263168      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 4, 27, 1024)  0           add_51[0][0]                     \n",
      "                                                                 conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 4, 27, 1024)  4096        add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 4, 27, 256)   262400      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 4, 27, 256)   1024        conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 4, 27, 256)   0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 4, 27, 256)   590080      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 4, 27, 256)   1024        conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 4, 27, 256)   0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 4, 27, 1024)  263168      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 4, 27, 1024)  0           add_52[0][0]                     \n",
      "                                                                 conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 4, 27, 1024)  4096        add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 4, 27, 256)   262400      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 4, 27, 256)   1024        conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 4, 27, 256)   0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 4, 27, 256)   590080      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 4, 27, 256)   1024        conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 4, 27, 256)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 4, 27, 1024)  263168      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 4, 27, 1024)  0           add_53[0][0]                     \n",
      "                                                                 conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 4, 27, 1024)  4096        add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 4, 27, 256)   262400      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 4, 27, 256)   1024        conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 4, 27, 256)   0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 4, 27, 256)   590080      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 4, 27, 256)   1024        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 4, 27, 256)   0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 4, 27, 1024)  263168      activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 4, 27, 1024)  0           add_54[0][0]                     \n",
      "                                                                 conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 4, 27, 1024)  4096        add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 4, 27, 256)   262400      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 4, 27, 256)   1024        conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 4, 27, 256)   0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 4, 27, 256)   590080      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 4, 27, 256)   1024        conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 4, 27, 256)   0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 4, 27, 1024)  263168      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 4, 27, 1024)  0           add_55[0][0]                     \n",
      "                                                                 conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 4, 27, 1024)  4096        add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 4, 27, 256)   262400      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 4, 27, 256)   1024        conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 4, 27, 256)   0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 4, 27, 256)   590080      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 4, 27, 256)   1024        conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 4, 27, 256)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 4, 27, 1024)  263168      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 4, 27, 1024)  0           add_56[0][0]                     \n",
      "                                                                 conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 4, 27, 1024)  4096        add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 4, 27, 256)   262400      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 4, 27, 256)   1024        conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 4, 27, 256)   0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 4, 27, 256)   590080      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 4, 27, 256)   1024        conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 4, 27, 256)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 4, 27, 1024)  263168      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 4, 27, 1024)  0           add_57[0][0]                     \n",
      "                                                                 conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 4, 27, 1024)  4096        add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 4, 27, 256)   262400      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 4, 27, 256)   1024        conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 4, 27, 256)   0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 4, 27, 256)   590080      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 4, 27, 256)   1024        conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 4, 27, 256)   0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 4, 27, 1024)  263168      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 4, 27, 1024)  0           add_58[0][0]                     \n",
      "                                                                 conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 4, 27, 1024)  4096        add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 4, 27, 256)   262400      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 4, 27, 256)   1024        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 4, 27, 256)   0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 4, 27, 256)   590080      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 4, 27, 256)   1024        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 4, 27, 256)   0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 4, 27, 1024)  263168      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 4, 27, 1024)  0           add_59[0][0]                     \n",
      "                                                                 conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 4, 27, 1024)  4096        add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 4, 27, 256)   262400      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 4, 27, 256)   1024        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 4, 27, 256)   0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 4, 27, 256)   590080      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 4, 27, 256)   1024        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 4, 27, 256)   0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 4, 27, 1024)  263168      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 4, 27, 1024)  0           add_60[0][0]                     \n",
      "                                                                 conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 4, 27, 1024)  4096        add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 4, 27, 256)   262400      activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 4, 27, 256)   1024        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 4, 27, 256)   0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 4, 27, 256)   590080      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 4, 27, 256)   1024        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 4, 27, 256)   0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 4, 27, 1024)  263168      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 4, 27, 1024)  0           add_61[0][0]                     \n",
      "                                                                 conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 4, 27, 1024)  4096        add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 4, 27, 256)   262400      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 4, 27, 256)   1024        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 4, 27, 256)   0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 4, 27, 256)   590080      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 4, 27, 256)   1024        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 4, 27, 256)   0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 4, 27, 1024)  263168      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 4, 27, 1024)  0           add_62[0][0]                     \n",
      "                                                                 conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 4, 27, 1024)  4096        add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 4, 27, 256)   262400      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 4, 27, 256)   1024        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 4, 27, 256)   0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 4, 27, 256)   590080      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 4, 27, 256)   1024        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 4, 27, 256)   0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 4, 27, 1024)  263168      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 4, 27, 1024)  0           add_63[0][0]                     \n",
      "                                                                 conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 4, 27, 1024)  4096        add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 4, 27, 256)   262400      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 4, 27, 256)   1024        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 4, 27, 256)   0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 4, 27, 256)   590080      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 4, 27, 256)   1024        conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 4, 27, 256)   0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 4, 27, 1024)  263168      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 4, 27, 1024)  0           add_64[0][0]                     \n",
      "                                                                 conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 4, 27, 1024)  4096        add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 4, 27, 256)   262400      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 4, 27, 256)   1024        conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 4, 27, 256)   0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 4, 27, 256)   590080      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 4, 27, 256)   1024        conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 4, 27, 256)   0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 4, 27, 1024)  263168      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 4, 27, 1024)  0           add_65[0][0]                     \n",
      "                                                                 conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 4, 27, 1024)  4096        add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 4, 27, 256)   262400      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 4, 27, 256)   1024        conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 4, 27, 256)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 4, 27, 256)   590080      activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 4, 27, 256)   1024        conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 4, 27, 256)   0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 4, 27, 1024)  263168      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 4, 27, 1024)  0           add_66[0][0]                     \n",
      "                                                                 conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 4, 27, 1024)  4096        add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 4, 27, 256)   262400      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 4, 27, 256)   1024        conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 4, 27, 256)   0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 4, 27, 256)   590080      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 4, 27, 256)   1024        conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 4, 27, 256)   0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 4, 27, 1024)  263168      activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 4, 27, 1024)  0           add_67[0][0]                     \n",
      "                                                                 conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 4, 27, 1024)  4096        add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 4, 27, 256)   262400      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 4, 27, 256)   1024        conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 4, 27, 256)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 4, 27, 256)   590080      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 4, 27, 256)   1024        conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 4, 27, 256)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 4, 27, 1024)  263168      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 4, 27, 1024)  0           add_68[0][0]                     \n",
      "                                                                 conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 4, 27, 1024)  4096        add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 4, 27, 256)   262400      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 4, 27, 256)   1024        conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 4, 27, 256)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 4, 27, 256)   590080      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 4, 27, 256)   1024        conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 4, 27, 256)   0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 4, 27, 1024)  263168      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 4, 27, 1024)  0           add_69[0][0]                     \n",
      "                                                                 conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 4, 27, 1024)  4096        add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 4, 27, 1024)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 2, 14, 512)   524800      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 2, 14, 512)   2048        conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 2, 14, 512)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 2, 14, 512)   2359808     activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 2, 14, 512)   2048        conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 2, 14, 512)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 2, 14, 2048)  2099200     add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 2, 14, 2048)  1050624     activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 2, 14, 2048)  0           conv2d_207[0][0]                 \n",
      "                                                                 conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 2, 14, 2048)  8192        add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 2, 14, 2048)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 2, 14, 512)   1049088     activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 2, 14, 512)   2048        conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 2, 14, 512)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 2, 14, 512)   2359808     activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 2, 14, 512)   2048        conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 2, 14, 512)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 2, 14, 2048)  1050624     activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 2, 14, 2048)  0           add_71[0][0]                     \n",
      "                                                                 conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 2, 14, 2048)  8192        add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 2, 14, 2048)  0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 2, 14, 512)   1049088     activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 2, 14, 512)   2048        conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 2, 14, 512)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 2, 14, 512)   2359808     activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 2, 14, 512)   2048        conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 2, 14, 512)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 2, 14, 2048)  1050624     activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 2, 14, 2048)  0           add_72[0][0]                     \n",
      "                                                                 conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 2, 14, 2048)  8192        add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 2, 14, 2048)  0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 2048)   0           activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1, 1, 2048)   0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2048)         0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 54)           110646      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 54)           216         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 54)           0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 41)           2255        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 42,749,661\n",
      "Trainable params: 42,651,889\n",
      "Non-trainable params: 97,772\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3339 samples, validate on 371 samples\n",
      "Epoch 1/3000\n",
      "3339/3339 [==============================] - 34s 10ms/step - loss: 13.1016 - acc: 0.2402 - val_loss: 13.1823 - val_acc: 0.1806\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.18059, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 2/3000\n",
      "3339/3339 [==============================] - 20s 6ms/step - loss: 10.9475 - acc: 0.4028 - val_loss: 11.2230 - val_acc: 0.2372\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.18059 to 0.23720, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 3/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 9.1486 - acc: 0.5055 - val_loss: 8.8818 - val_acc: 0.3854\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.23720 to 0.38544, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 4/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 7.7450 - acc: 0.5627 - val_loss: 8.2251 - val_acc: 0.3827\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.38544\n",
      "Epoch 5/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 6.5520 - acc: 0.6229 - val_loss: 6.7761 - val_acc: 0.4690\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.38544 to 0.46900, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 6/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 5.5623 - acc: 0.6894 - val_loss: 5.6097 - val_acc: 0.5768\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.46900 to 0.57682, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 7/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 4.8330 - acc: 0.7167 - val_loss: 5.4716 - val_acc: 0.4501\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.57682\n",
      "Epoch 8/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 4.2699 - acc: 0.7409 - val_loss: 4.7836 - val_acc: 0.5795\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.57682 to 0.57951, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 9/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 3.8445 - acc: 0.7538 - val_loss: 4.2957 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.57951\n",
      "Epoch 10/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 3.4021 - acc: 0.7751 - val_loss: 4.0779 - val_acc: 0.6011\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.57951 to 0.60108, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 11/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 3.0954 - acc: 0.8086 - val_loss: 4.0464 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.60108\n",
      "Epoch 12/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 2.7730 - acc: 0.8287 - val_loss: 3.4268 - val_acc: 0.6173\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.60108 to 0.61725, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 13/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 2.5464 - acc: 0.8407 - val_loss: 3.1135 - val_acc: 0.6550\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.61725 to 0.65499, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 14/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 2.3504 - acc: 0.8446 - val_loss: 3.1729 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.65499\n",
      "Epoch 15/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 2.1293 - acc: 0.8739 - val_loss: 2.8542 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.65499 to 0.69811, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 16/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 2.0381 - acc: 0.8721 - val_loss: 2.8375 - val_acc: 0.6792\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.69811\n",
      "Epoch 17/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.9778 - acc: 0.8568 - val_loss: 2.7975 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.69811\n",
      "Epoch 18/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.8357 - acc: 0.8790 - val_loss: 3.6257 - val_acc: 0.5256\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.69811\n",
      "Epoch 19/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.9162 - acc: 0.8386 - val_loss: 2.8176 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.69811\n",
      "Epoch 20/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.6901 - acc: 0.8883 - val_loss: 2.4849 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.69811\n",
      "Epoch 21/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.8232 - acc: 0.8284 - val_loss: 2.4908 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.69811\n",
      "Epoch 22/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.6146 - acc: 0.8853 - val_loss: 2.2524 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.69811 to 0.72237, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 23/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.3630 - acc: 0.9392 - val_loss: 1.9877 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.72237 to 0.77358, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 24/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.2919 - acc: 0.9440 - val_loss: 2.2165 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.77358\n",
      "Epoch 25/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.3824 - acc: 0.9093 - val_loss: 2.9353 - val_acc: 0.5418\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.77358\n",
      "Epoch 26/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.3277 - acc: 0.9188 - val_loss: 2.4534 - val_acc: 0.6307\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.77358\n",
      "Epoch 27/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.2294 - acc: 0.9323 - val_loss: 2.5804 - val_acc: 0.5822\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.77358\n",
      "Epoch 28/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.3483 - acc: 0.8958 - val_loss: 2.0839 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.77358\n",
      "Epoch 29/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.2957 - acc: 0.9099 - val_loss: 2.6507 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.77358\n",
      "Epoch 30/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.2903 - acc: 0.9057 - val_loss: 2.5491 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.77358\n",
      "Epoch 31/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.1439 - acc: 0.9407 - val_loss: 2.1098 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.77358\n",
      "Epoch 32/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.0009 - acc: 0.9706 - val_loss: 2.0438 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.77358\n",
      "Epoch 33/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9799 - acc: 0.9650 - val_loss: 1.9160 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.77358\n",
      "Epoch 34/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.0868 - acc: 0.9284 - val_loss: 2.1869 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.77358\n",
      "Epoch 35/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.0556 - acc: 0.9368 - val_loss: 2.0095 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.77358\n",
      "Epoch 36/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9482 - acc: 0.9557 - val_loss: 1.8717 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.77358\n",
      "Epoch 37/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9213 - acc: 0.9623 - val_loss: 1.9517 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.77358\n",
      "Epoch 38/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9790 - acc: 0.9422 - val_loss: 2.0727 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.77358\n",
      "Epoch 39/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8853 - acc: 0.9659 - val_loss: 2.1081 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.77358\n",
      "Epoch 40/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8746 - acc: 0.9620 - val_loss: 1.9425 - val_acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_acc did not improve from 0.77358\n",
      "Epoch 41/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8898 - acc: 0.9536 - val_loss: 3.5644 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.77358\n",
      "Epoch 42/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9418 - acc: 0.9428 - val_loss: 2.1860 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.77358\n",
      "Epoch 43/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.1336 - acc: 0.8958 - val_loss: 9.4080 - val_acc: 0.1833\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.77358\n",
      "Epoch 44/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.0610 - acc: 0.9179 - val_loss: 2.7602 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.77358\n",
      "Epoch 45/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9209 - acc: 0.9512 - val_loss: 1.9580 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.77358\n",
      "Epoch 46/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8822 - acc: 0.9563 - val_loss: 1.8038 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.77358\n",
      "Epoch 47/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7901 - acc: 0.9739 - val_loss: 1.6199 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.77358 to 0.77898, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 48/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7432 - acc: 0.9790 - val_loss: 1.7168 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.77898\n",
      "Epoch 49/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8161 - acc: 0.9611 - val_loss: 2.1751 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.77898\n",
      "Epoch 50/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8097 - acc: 0.9605 - val_loss: 2.0089 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.77898\n",
      "Epoch 51/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7454 - acc: 0.9766 - val_loss: 1.8644 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.77898\n",
      "Epoch 52/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7872 - acc: 0.9590 - val_loss: 4.5761 - val_acc: 0.4043\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.77898\n",
      "Epoch 53/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7882 - acc: 0.9614 - val_loss: 1.9661 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.77898\n",
      "Epoch 54/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7328 - acc: 0.9704 - val_loss: 1.9869 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.77898\n",
      "Epoch 55/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7720 - acc: 0.9554 - val_loss: 2.8950 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.77898\n",
      "Epoch 56/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7714 - acc: 0.9599 - val_loss: 2.2367 - val_acc: 0.6873\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.77898\n",
      "Epoch 57/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8152 - acc: 0.9491 - val_loss: 2.9156 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.77898\n",
      "Epoch 58/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8224 - acc: 0.9437 - val_loss: 2.1870 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.77898\n",
      "Epoch 59/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7864 - acc: 0.9509 - val_loss: 4.1267 - val_acc: 0.4394\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.77898\n",
      "Epoch 60/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8266 - acc: 0.9467 - val_loss: 1.9868 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.77898\n",
      "Epoch 61/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7919 - acc: 0.9506 - val_loss: 2.6388 - val_acc: 0.6092\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.77898\n",
      "Epoch 62/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7595 - acc: 0.9560 - val_loss: 2.0833 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.77898\n",
      "Epoch 63/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6770 - acc: 0.9796 - val_loss: 1.8101 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.77898\n",
      "Epoch 64/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7232 - acc: 0.9611 - val_loss: 2.0065 - val_acc: 0.6792\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.77898\n",
      "Epoch 65/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7248 - acc: 0.9706 - val_loss: 1.9393 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.77898\n",
      "Epoch 66/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6777 - acc: 0.9715 - val_loss: 1.9783 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.77898\n",
      "Epoch 67/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8234 - acc: 0.9311 - val_loss: 3.6368 - val_acc: 0.4501\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.77898\n",
      "Epoch 68/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8322 - acc: 0.9335 - val_loss: 4.8336 - val_acc: 0.3881\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.77898\n",
      "Epoch 69/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7571 - acc: 0.9581 - val_loss: 2.1350 - val_acc: 0.6792\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.77898\n",
      "Epoch 70/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8503 - acc: 0.9416 - val_loss: 3.6193 - val_acc: 0.4528\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.77898\n",
      "Epoch 71/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8220 - acc: 0.9533 - val_loss: 2.6156 - val_acc: 0.6146\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.77898\n",
      "Epoch 72/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8071 - acc: 0.9536 - val_loss: 2.1410 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.77898\n",
      "Epoch 73/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 1.0020 - acc: 0.8973 - val_loss: 2.7344 - val_acc: 0.6253\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.77898\n",
      "Epoch 74/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7927 - acc: 0.9614 - val_loss: 1.9639 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.77898\n",
      "Epoch 75/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6743 - acc: 0.9817 - val_loss: 1.5050 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.77898 to 0.77898, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 76/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6106 - acc: 0.9922 - val_loss: 1.5979 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.77898\n",
      "Epoch 77/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6064 - acc: 0.9883 - val_loss: 1.7180 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.77898\n",
      "Epoch 78/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8916 - acc: 0.9287 - val_loss: 3.7568 - val_acc: 0.4987\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.77898\n",
      "Epoch 79/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8756 - acc: 0.9359 - val_loss: 2.0854 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.77898\n",
      "Epoch 80/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9167 - acc: 0.9224 - val_loss: 2.7471 - val_acc: 0.6388\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.77898\n",
      "Epoch 81/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7093 - acc: 0.9730 - val_loss: 1.6644 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.77898\n",
      "Epoch 82/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6859 - acc: 0.9727 - val_loss: 2.0925 - val_acc: 0.6765\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.77898\n",
      "Epoch 83/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6143 - acc: 0.9877 - val_loss: 1.6163 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.77898\n",
      "Epoch 84/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5952 - acc: 0.9889 - val_loss: 1.8689 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.77898\n",
      "Epoch 85/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5737 - acc: 0.9895 - val_loss: 1.5584 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.77898\n",
      "Epoch 86/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5200 - acc: 0.9970 - val_loss: 1.5436 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.77898\n",
      "Epoch 87/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5038 - acc: 0.9973 - val_loss: 1.4791 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.77898\n",
      "Epoch 88/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4895 - acc: 0.9973 - val_loss: 1.6372 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.77898\n",
      "Epoch 89/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4783 - acc: 0.9964 - val_loss: 1.6477 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.77898\n",
      "Epoch 90/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6335 - acc: 0.9704 - val_loss: 15.5235 - val_acc: 0.0404\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.77898\n",
      "Epoch 91/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7119 - acc: 0.9503 - val_loss: 4.0287 - val_acc: 0.4852\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.77898\n",
      "Epoch 92/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7614 - acc: 0.9344 - val_loss: 3.4451 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.77898\n",
      "Epoch 93/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8699 - acc: 0.9134 - val_loss: 2.4314 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.77898\n",
      "Epoch 94/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8472 - acc: 0.9236 - val_loss: 2.8142 - val_acc: 0.6469\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.77898\n",
      "Epoch 95/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6791 - acc: 0.9671 - val_loss: 1.7915 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.77898\n",
      "Epoch 96/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6038 - acc: 0.9799 - val_loss: 1.6386 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.77898\n",
      "Epoch 97/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5820 - acc: 0.9790 - val_loss: 1.7594 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.77898\n",
      "Epoch 98/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5516 - acc: 0.9901 - val_loss: 1.7129 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.77898\n",
      "Epoch 99/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5238 - acc: 0.9922 - val_loss: 1.5618 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.77898\n",
      "Epoch 100/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5048 - acc: 0.9925 - val_loss: 1.4768 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.77898\n",
      "Epoch 101/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4852 - acc: 0.9949 - val_loss: 1.3805 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.77898 to 0.79784, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 102/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4596 - acc: 0.9976 - val_loss: 1.5872 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.79784\n",
      "Epoch 103/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4489 - acc: 0.9976 - val_loss: 1.6956 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.79784\n",
      "Epoch 104/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4552 - acc: 0.9940 - val_loss: 3.3646 - val_acc: 0.4501\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.79784\n",
      "Epoch 105/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5282 - acc: 0.9781 - val_loss: 4.2932 - val_acc: 0.4070\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.79784\n",
      "Epoch 106/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9663 - acc: 0.8814 - val_loss: 15.3897 - val_acc: 0.0404\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.79784\n",
      "Epoch 107/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9726 - acc: 0.8991 - val_loss: 5.2088 - val_acc: 0.3854\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.79784\n",
      "Epoch 108/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8368 - acc: 0.9260 - val_loss: 2.3544 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.79784\n",
      "Epoch 109/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6643 - acc: 0.9668 - val_loss: 1.9331 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.79784\n",
      "Epoch 110/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5916 - acc: 0.9796 - val_loss: 1.6630 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.79784\n",
      "Epoch 111/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5511 - acc: 0.9850 - val_loss: 1.5793 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.79784\n",
      "Epoch 112/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5408 - acc: 0.9865 - val_loss: 1.5609 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.79784\n",
      "Epoch 113/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4956 - acc: 0.9940 - val_loss: 1.4375 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.79784\n",
      "Epoch 114/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4782 - acc: 0.9928 - val_loss: 1.4870 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.79784\n",
      "Epoch 115/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5005 - acc: 0.9880 - val_loss: 1.6329 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.79784\n",
      "Epoch 116/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8830 - acc: 0.8961 - val_loss: 10.4142 - val_acc: 0.1321\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.79784\n",
      "Epoch 117/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7668 - acc: 0.9395 - val_loss: 2.2737 - val_acc: 0.6765\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.79784\n",
      "Epoch 118/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6014 - acc: 0.9724 - val_loss: 1.9443 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.79784\n",
      "Epoch 119/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6091 - acc: 0.9629 - val_loss: 1.8526 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.79784\n",
      "Epoch 120/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5616 - acc: 0.9799 - val_loss: 1.6717 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.79784\n",
      "Epoch 121/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4954 - acc: 0.9916 - val_loss: 1.5773 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.79784\n",
      "Epoch 122/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4626 - acc: 0.9964 - val_loss: 1.3047 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.79784\n",
      "Epoch 123/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4629 - acc: 0.9940 - val_loss: 1.9831 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.79784\n",
      "Epoch 124/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4804 - acc: 0.9868 - val_loss: 5.9080 - val_acc: 0.3073\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.79784\n",
      "Epoch 125/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5766 - acc: 0.9620 - val_loss: 2.6713 - val_acc: 0.6092\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.79784\n",
      "Epoch 126/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6265 - acc: 0.9554 - val_loss: 2.4707 - val_acc: 0.6253\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.79784\n",
      "Epoch 127/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7157 - acc: 0.9449 - val_loss: 3.6120 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.79784\n",
      "Epoch 128/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6419 - acc: 0.9614 - val_loss: 2.5611 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.79784\n",
      "Epoch 129/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6615 - acc: 0.9512 - val_loss: 2.4616 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.79784\n",
      "Epoch 130/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6080 - acc: 0.9698 - val_loss: 2.5130 - val_acc: 0.6765\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.79784\n",
      "Epoch 131/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6669 - acc: 0.9572 - val_loss: 2.1706 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.79784\n",
      "Epoch 132/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5569 - acc: 0.9817 - val_loss: 1.6897 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.79784\n",
      "Epoch 133/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6073 - acc: 0.9757 - val_loss: 2.2425 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.79784\n",
      "Epoch 134/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5785 - acc: 0.9781 - val_loss: 2.0886 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.79784\n",
      "Epoch 135/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5050 - acc: 0.9880 - val_loss: 1.5723 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.79784\n",
      "Epoch 136/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5447 - acc: 0.9784 - val_loss: 1.9630 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.79784\n",
      "Epoch 137/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6202 - acc: 0.9581 - val_loss: 2.4226 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.79784\n",
      "Epoch 138/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5413 - acc: 0.9775 - val_loss: 1.5846 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.79784\n",
      "Epoch 139/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4847 - acc: 0.9910 - val_loss: 1.7324 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.79784\n",
      "Epoch 140/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4428 - acc: 0.9976 - val_loss: 1.5209 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.79784\n",
      "Epoch 141/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4218 - acc: 0.9982 - val_loss: 1.4098 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.79784\n",
      "Epoch 142/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4046 - acc: 0.9994 - val_loss: 1.3814 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.79784\n",
      "Epoch 143/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3900 - acc: 0.9997 - val_loss: 1.3557 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.79784\n",
      "Epoch 144/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3850 - acc: 0.9985 - val_loss: 1.5272 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.79784\n",
      "Epoch 145/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5825 - acc: 0.9566 - val_loss: 6.9478 - val_acc: 0.2615\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.79784\n",
      "Epoch 146/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7356 - acc: 0.9308 - val_loss: 6.3699 - val_acc: 0.3720\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.79784\n",
      "Epoch 147/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9807 - acc: 0.8820 - val_loss: 4.8530 - val_acc: 0.4663\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.79784\n",
      "Epoch 148/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7722 - acc: 0.9428 - val_loss: 2.3230 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.79784\n",
      "Epoch 149/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5980 - acc: 0.9763 - val_loss: 1.8576 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.79784\n",
      "Epoch 150/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5353 - acc: 0.9841 - val_loss: 2.1466 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.79784\n",
      "Epoch 151/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5348 - acc: 0.9811 - val_loss: 1.6760 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.79784\n",
      "Epoch 152/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4835 - acc: 0.9898 - val_loss: 1.4477 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.79784\n",
      "Epoch 153/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4529 - acc: 0.9958 - val_loss: 1.5986 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.79784\n",
      "Epoch 154/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4402 - acc: 0.9946 - val_loss: 1.6219 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.79784\n",
      "Epoch 155/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4996 - acc: 0.9790 - val_loss: 1.7860 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.79784\n",
      "Epoch 156/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5909 - acc: 0.9644 - val_loss: 3.4016 - val_acc: 0.5499\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.79784\n",
      "Epoch 157/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5029 - acc: 0.9826 - val_loss: 1.9323 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.79784\n",
      "Epoch 158/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5829 - acc: 0.9659 - val_loss: 1.7581 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.79784\n",
      "Epoch 159/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6419 - acc: 0.9506 - val_loss: 2.7523 - val_acc: 0.6011\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.79784\n",
      "Epoch 160/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6098 - acc: 0.9599 - val_loss: 1.8291 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.79784\n",
      "Epoch 161/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5590 - acc: 0.9701 - val_loss: 1.8725 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.79784\n",
      "Epoch 162/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6437 - acc: 0.9560 - val_loss: 1.9615 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.79784\n",
      "Epoch 163/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6339 - acc: 0.9578 - val_loss: 1.9480 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.79784\n",
      "Epoch 164/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5867 - acc: 0.9712 - val_loss: 2.1501 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.79784\n",
      "Epoch 165/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4823 - acc: 0.9919 - val_loss: 1.5309 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.79784\n",
      "Epoch 166/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4379 - acc: 0.9976 - val_loss: 1.4852 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.79784\n",
      "Epoch 167/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4213 - acc: 0.9982 - val_loss: 1.4560 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.79784\n",
      "Epoch 168/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4094 - acc: 0.9976 - val_loss: 1.4648 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.79784\n",
      "Epoch 169/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4167 - acc: 0.9946 - val_loss: 1.7182 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.79784\n",
      "Epoch 170/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4098 - acc: 0.9949 - val_loss: 1.4594 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.79784\n",
      "Epoch 171/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4594 - acc: 0.9817 - val_loss: 1.9993 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.79784\n",
      "Epoch 172/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5376 - acc: 0.9647 - val_loss: 2.0075 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.79784\n",
      "Epoch 173/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4689 - acc: 0.9775 - val_loss: 1.9481 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.79784\n",
      "Epoch 174/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4945 - acc: 0.9727 - val_loss: 2.0438 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.79784\n",
      "Epoch 175/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5517 - acc: 0.9626 - val_loss: 2.5791 - val_acc: 0.6388\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.79784\n",
      "Epoch 176/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6043 - acc: 0.9551 - val_loss: 2.3720 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.79784\n",
      "Epoch 177/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5742 - acc: 0.9644 - val_loss: 1.7374 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.79784\n",
      "Epoch 178/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5820 - acc: 0.9653 - val_loss: 2.5491 - val_acc: 0.6469\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.79784\n",
      "Epoch 179/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5039 - acc: 0.9826 - val_loss: 1.7238 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.79784\n",
      "Epoch 180/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4304 - acc: 0.9955 - val_loss: 1.3215 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.79784\n",
      "Epoch 181/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4081 - acc: 0.9970 - val_loss: 1.4791 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.79784\n",
      "Epoch 182/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4187 - acc: 0.9952 - val_loss: 1.3350 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.79784\n",
      "Epoch 183/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4057 - acc: 0.9931 - val_loss: 1.5078 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.79784\n",
      "Epoch 184/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4624 - acc: 0.9820 - val_loss: 2.0966 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.79784\n",
      "Epoch 185/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4690 - acc: 0.9769 - val_loss: 2.2767 - val_acc: 0.6765\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.79784\n",
      "Epoch 186/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7253 - acc: 0.9134 - val_loss: 3.7589 - val_acc: 0.4960\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.79784\n",
      "Epoch 187/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7384 - acc: 0.9227 - val_loss: 3.0430 - val_acc: 0.5660\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.79784\n",
      "Epoch 188/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5706 - acc: 0.9680 - val_loss: 1.7904 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.79784\n",
      "Epoch 189/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4860 - acc: 0.9859 - val_loss: 1.8841 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.79784\n",
      "Epoch 190/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4575 - acc: 0.9916 - val_loss: 1.6788 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.79784\n",
      "Epoch 191/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4373 - acc: 0.9898 - val_loss: 1.6592 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.79784\n",
      "Epoch 192/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4442 - acc: 0.9883 - val_loss: 1.4494 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.79784\n",
      "Epoch 193/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4469 - acc: 0.9862 - val_loss: 1.6182 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.79784\n",
      "Epoch 194/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4351 - acc: 0.9868 - val_loss: 1.4451 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.79784\n",
      "Epoch 195/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4062 - acc: 0.9940 - val_loss: 1.5872 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.79784\n",
      "Epoch 196/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3828 - acc: 0.9961 - val_loss: 1.3145 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.79784\n",
      "Epoch 197/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3792 - acc: 0.9958 - val_loss: 1.4213 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.79784\n",
      "Epoch 198/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3650 - acc: 0.9973 - val_loss: 1.4001 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.79784\n",
      "Epoch 199/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3603 - acc: 0.9970 - val_loss: 1.3443 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.79784\n",
      "Epoch 200/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3445 - acc: 0.9988 - val_loss: 1.3630 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.79784\n",
      "Epoch 201/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3411 - acc: 0.9982 - val_loss: 1.2177 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.79784\n",
      "Epoch 202/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3276 - acc: 0.9997 - val_loss: 1.4003 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.79784\n",
      "Epoch 203/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3189 - acc: 0.9994 - val_loss: 1.2920 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.79784\n",
      "Epoch 204/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3142 - acc: 0.9982 - val_loss: 1.3449 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.79784\n",
      "Epoch 205/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3094 - acc: 0.9991 - val_loss: 1.4412 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.79784\n",
      "Epoch 206/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.7457 - acc: 0.9102 - val_loss: 16.2779 - val_acc: 0.0135\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.79784\n",
      "Epoch 207/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9176 - acc: 0.8916 - val_loss: 6.7809 - val_acc: 0.3181\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.79784\n",
      "Epoch 208/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.8227 - acc: 0.9087 - val_loss: 2.9190 - val_acc: 0.6469\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.79784\n",
      "Epoch 209/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5785 - acc: 0.9656 - val_loss: 2.2075 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.79784\n",
      "Epoch 210/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5479 - acc: 0.9709 - val_loss: 2.1425 - val_acc: 0.6765\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.79784\n",
      "Epoch 211/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5507 - acc: 0.9665 - val_loss: 1.6690 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.79784\n",
      "Epoch 212/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4578 - acc: 0.9877 - val_loss: 1.5741 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.79784\n",
      "Epoch 213/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5796 - acc: 0.9560 - val_loss: 1.9107 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.79784\n",
      "Epoch 214/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6452 - acc: 0.9398 - val_loss: 2.3916 - val_acc: 0.6658\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.79784\n",
      "Epoch 215/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6991 - acc: 0.9239 - val_loss: 2.2733 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.79784\n",
      "Epoch 216/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5046 - acc: 0.9763 - val_loss: 1.6012 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.79784\n",
      "Epoch 217/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4640 - acc: 0.9859 - val_loss: 1.5597 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.79784\n",
      "Epoch 218/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4330 - acc: 0.9907 - val_loss: 1.4607 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.79784\n",
      "Epoch 219/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4149 - acc: 0.9943 - val_loss: 1.4775 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.79784\n",
      "Epoch 220/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4649 - acc: 0.9808 - val_loss: 1.6190 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.79784\n",
      "Epoch 221/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4159 - acc: 0.9901 - val_loss: 1.4924 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.79784\n",
      "Epoch 222/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4022 - acc: 0.9913 - val_loss: 1.3441 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00222: val_acc improved from 0.79784 to 0.80323, saving model to model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Epoch 223/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3857 - acc: 0.9964 - val_loss: 1.3263 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.80323\n",
      "Epoch 224/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4104 - acc: 0.9877 - val_loss: 1.4096 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.80323\n",
      "Epoch 225/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3827 - acc: 0.9934 - val_loss: 1.5072 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.80323\n",
      "Epoch 226/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3672 - acc: 0.9931 - val_loss: 1.5425 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.80323\n",
      "Epoch 227/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3626 - acc: 0.9943 - val_loss: 1.5058 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.80323\n",
      "Epoch 228/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3937 - acc: 0.9868 - val_loss: 1.7896 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.80323\n",
      "Epoch 229/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3693 - acc: 0.9904 - val_loss: 1.4973 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.80323\n",
      "Epoch 230/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3385 - acc: 0.9979 - val_loss: 1.3697 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.80323\n",
      "Epoch 231/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3231 - acc: 1.0000 - val_loss: 1.3236 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.80323\n",
      "Epoch 232/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3226 - acc: 0.9976 - val_loss: 1.3958 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.80323\n",
      "Epoch 233/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3214 - acc: 0.9961 - val_loss: 1.4749 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.80323\n",
      "Epoch 234/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3330 - acc: 0.9949 - val_loss: 1.5743 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.80323\n",
      "Epoch 235/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3232 - acc: 0.9940 - val_loss: 1.8599 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.80323\n",
      "Epoch 236/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3594 - acc: 0.9871 - val_loss: 2.3790 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.80323\n",
      "Epoch 237/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4039 - acc: 0.9787 - val_loss: 2.4203 - val_acc: 0.6792\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.80323\n",
      "Epoch 238/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4932 - acc: 0.9629 - val_loss: 2.3295 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.80323\n",
      "Epoch 239/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6104 - acc: 0.9377 - val_loss: 3.6230 - val_acc: 0.5499\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.80323\n",
      "Epoch 240/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6013 - acc: 0.9482 - val_loss: 2.6846 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.80323\n",
      "Epoch 241/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5158 - acc: 0.9665 - val_loss: 2.6576 - val_acc: 0.6604\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.80323\n",
      "Epoch 242/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4916 - acc: 0.9727 - val_loss: 1.7576 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.80323\n",
      "Epoch 243/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4543 - acc: 0.9760 - val_loss: 1.7348 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.80323\n",
      "Epoch 244/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4643 - acc: 0.9748 - val_loss: 2.0798 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.80323\n",
      "Epoch 245/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4800 - acc: 0.9656 - val_loss: 1.9781 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.80323\n",
      "Epoch 246/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4326 - acc: 0.9805 - val_loss: 1.7276 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.80323\n",
      "Epoch 247/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3836 - acc: 0.9925 - val_loss: 1.5492 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.80323\n",
      "Epoch 248/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3675 - acc: 0.9940 - val_loss: 1.4850 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.80323\n",
      "Epoch 249/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4369 - acc: 0.9733 - val_loss: 2.4978 - val_acc: 0.6523\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.80323\n",
      "Epoch 250/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6085 - acc: 0.9335 - val_loss: 2.2437 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.80323\n",
      "Epoch 251/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4806 - acc: 0.9715 - val_loss: 2.0864 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.80323\n",
      "Epoch 252/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4103 - acc: 0.9904 - val_loss: 1.5058 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.80323\n",
      "Epoch 253/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3737 - acc: 0.9964 - val_loss: 1.4292 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.80323\n",
      "Epoch 254/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3659 - acc: 0.9946 - val_loss: 1.3418 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.80323\n",
      "Epoch 255/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3518 - acc: 0.9958 - val_loss: 1.5209 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.80323\n",
      "Epoch 256/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3462 - acc: 0.9970 - val_loss: 1.4482 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.80323\n",
      "Epoch 257/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3506 - acc: 0.9910 - val_loss: 1.6772 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.80323\n",
      "Epoch 258/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3425 - acc: 0.9937 - val_loss: 1.5598 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.80323\n",
      "Epoch 259/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3545 - acc: 0.9877 - val_loss: 1.6617 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.80323\n",
      "Epoch 260/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3649 - acc: 0.9853 - val_loss: 1.8287 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.80323\n",
      "Epoch 261/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4719 - acc: 0.9605 - val_loss: 2.0040 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.80323\n",
      "Epoch 262/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5047 - acc: 0.9605 - val_loss: 2.7812 - val_acc: 0.5876\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.80323\n",
      "Epoch 263/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4470 - acc: 0.9778 - val_loss: 2.0130 - val_acc: 0.7116\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.80323\n",
      "Epoch 264/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5515 - acc: 0.9551 - val_loss: 2.5716 - val_acc: 0.6604\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.80323\n",
      "Epoch 265/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5605 - acc: 0.9542 - val_loss: 2.2246 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.80323\n",
      "Epoch 266/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4292 - acc: 0.9865 - val_loss: 1.5018 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.80323\n",
      "Epoch 267/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3779 - acc: 0.9949 - val_loss: 1.6086 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.80323\n",
      "Epoch 268/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3716 - acc: 0.9937 - val_loss: 1.4745 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.80323\n",
      "Epoch 269/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3785 - acc: 0.9886 - val_loss: 1.6525 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.80323\n",
      "Epoch 270/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3547 - acc: 0.9937 - val_loss: 1.5470 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00270: val_acc did not improve from 0.80323\n",
      "Epoch 271/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3422 - acc: 0.9937 - val_loss: 1.5823 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00271: val_acc did not improve from 0.80323\n",
      "Epoch 272/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3824 - acc: 0.9862 - val_loss: 1.6154 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00272: val_acc did not improve from 0.80323\n",
      "Epoch 273/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3677 - acc: 0.9880 - val_loss: 1.7920 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00273: val_acc did not improve from 0.80323\n",
      "Epoch 274/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3330 - acc: 0.9958 - val_loss: 1.5302 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00274: val_acc did not improve from 0.80323\n",
      "Epoch 275/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3252 - acc: 0.9958 - val_loss: 1.3489 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00275: val_acc did not improve from 0.80323\n",
      "Epoch 276/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3125 - acc: 0.9973 - val_loss: 1.4053 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00276: val_acc did not improve from 0.80323\n",
      "Epoch 277/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.2970 - acc: 1.0000 - val_loss: 1.3129 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00277: val_acc did not improve from 0.80323\n",
      "Epoch 278/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.2880 - acc: 1.0000 - val_loss: 1.3174 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00278: val_acc did not improve from 0.80323\n",
      "Epoch 279/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.2863 - acc: 0.9994 - val_loss: 1.2885 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00279: val_acc did not improve from 0.80323\n",
      "Epoch 280/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.2810 - acc: 0.9991 - val_loss: 1.2764 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00280: val_acc did not improve from 0.80323\n",
      "Epoch 281/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.2732 - acc: 0.9994 - val_loss: 1.2830 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00281: val_acc did not improve from 0.80323\n",
      "Epoch 282/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3503 - acc: 0.9787 - val_loss: 2.1995 - val_acc: 0.6307\n",
      "\n",
      "Epoch 00282: val_acc did not improve from 0.80323\n",
      "Epoch 283/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5232 - acc: 0.9431 - val_loss: 8.1558 - val_acc: 0.2264\n",
      "\n",
      "Epoch 00283: val_acc did not improve from 0.80323\n",
      "Epoch 284/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.9583 - acc: 0.8673 - val_loss: 5.8788 - val_acc: 0.3261\n",
      "\n",
      "Epoch 00284: val_acc did not improve from 0.80323\n",
      "Epoch 285/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.6790 - acc: 0.9413 - val_loss: 2.4436 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00285: val_acc did not improve from 0.80323\n",
      "Epoch 286/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.5226 - acc: 0.9706 - val_loss: 1.7164 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00286: val_acc did not improve from 0.80323\n",
      "Epoch 287/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4333 - acc: 0.9874 - val_loss: 1.4967 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00287: val_acc did not improve from 0.80323\n",
      "Epoch 288/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3961 - acc: 0.9937 - val_loss: 1.7493 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00288: val_acc did not improve from 0.80323\n",
      "Epoch 289/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4223 - acc: 0.9823 - val_loss: 1.7465 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00289: val_acc did not improve from 0.80323\n",
      "Epoch 290/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3720 - acc: 0.9913 - val_loss: 1.3196 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00290: val_acc did not improve from 0.80323\n",
      "Epoch 291/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3679 - acc: 0.9928 - val_loss: 1.3101 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00291: val_acc did not improve from 0.80323\n",
      "Epoch 292/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4001 - acc: 0.9808 - val_loss: 1.5253 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00292: val_acc did not improve from 0.80323\n",
      "Epoch 293/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3729 - acc: 0.9856 - val_loss: 2.0142 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00293: val_acc did not improve from 0.80323\n",
      "Epoch 294/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.4862 - acc: 0.9653 - val_loss: 2.4530 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00294: val_acc did not improve from 0.80323\n",
      "Epoch 295/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3907 - acc: 0.9832 - val_loss: 1.7175 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00295: val_acc did not improve from 0.80323\n",
      "Epoch 296/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3404 - acc: 0.9940 - val_loss: 1.3183 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00296: val_acc did not improve from 0.80323\n",
      "Epoch 297/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3870 - acc: 0.9802 - val_loss: 1.5837 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00297: val_acc did not improve from 0.80323\n",
      "Epoch 298/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3774 - acc: 0.9859 - val_loss: 1.6588 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00298: val_acc did not improve from 0.80323\n",
      "Epoch 299/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3872 - acc: 0.9802 - val_loss: 1.7122 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00299: val_acc did not improve from 0.80323\n",
      "Epoch 300/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3732 - acc: 0.9856 - val_loss: 1.4483 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00300: val_acc did not improve from 0.80323\n",
      "Epoch 301/3000\n",
      "3339/3339 [==============================] - 21s 6ms/step - loss: 0.3327 - acc: 0.9955 - val_loss: 1.5268 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00301: val_acc did not improve from 0.80323\n",
      "Epoch 00301: early stopping\n",
      "(3418, 64, 431, 1) (3418, 41)\n",
      "===train semi_2===\n",
      "semi loading: model/mfcc6/LGD_fold2_resnet3-.h5\n",
      "Train on 3418 samples, validate on 371 samples\n",
      "Epoch 1/3000\n",
      "3418/3418 [==============================] - 38s 11ms/step - loss: 0.6890 - acc: 0.9745 - val_loss: 1.4279 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80863, saving model to model/mfcc6/LGD_semi_fold2_resnet3.h5\n",
      "Epoch 2/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.5966 - acc: 0.9710 - val_loss: 1.5393 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.80863\n",
      "Epoch 3/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.5235 - acc: 0.9766 - val_loss: 1.6069 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.80863\n",
      "Epoch 4/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.5005 - acc: 0.9748 - val_loss: 1.5877 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.80863\n",
      "Epoch 5/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.4822 - acc: 0.9760 - val_loss: 1.5517 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.80863\n",
      "Epoch 6/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.4513 - acc: 0.9842 - val_loss: 1.5160 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.80863\n",
      "Epoch 7/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.4465 - acc: 0.9845 - val_loss: 1.5132 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.80863\n",
      "Epoch 8/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.4409 - acc: 0.9819 - val_loss: 1.5255 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.80863\n",
      "Epoch 9/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.4275 - acc: 0.9857 - val_loss: 1.5070 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.80863\n",
      "Epoch 10/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.4173 - acc: 0.9868 - val_loss: 1.5247 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.80863\n",
      "Epoch 11/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.4077 - acc: 0.9883 - val_loss: 1.5123 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.80863\n",
      "Epoch 12/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3959 - acc: 0.9909 - val_loss: 1.5111 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.80863\n",
      "Epoch 13/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3821 - acc: 0.9933 - val_loss: 1.4959 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.80863\n",
      "Epoch 14/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3781 - acc: 0.9927 - val_loss: 1.5124 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.80863\n",
      "Epoch 15/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3760 - acc: 0.9930 - val_loss: 1.4958 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.80863\n",
      "Epoch 16/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3740 - acc: 0.9912 - val_loss: 1.5108 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.80863\n",
      "Epoch 17/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3628 - acc: 0.9939 - val_loss: 1.5222 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.80863\n",
      "Epoch 18/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3519 - acc: 0.9959 - val_loss: 1.5369 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.80863\n",
      "Epoch 19/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3441 - acc: 0.9974 - val_loss: 1.4874 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.80863\n",
      "Epoch 20/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3435 - acc: 0.9950 - val_loss: 1.4877 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.80863\n",
      "Epoch 21/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3452 - acc: 0.9950 - val_loss: 1.4759 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80863\n",
      "Epoch 22/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3418 - acc: 0.9956 - val_loss: 1.5510 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80863\n",
      "Epoch 23/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3356 - acc: 0.9959 - val_loss: 1.5235 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.80863\n",
      "Epoch 24/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3274 - acc: 0.9982 - val_loss: 1.4904 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.80863\n",
      "Epoch 25/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3237 - acc: 0.9985 - val_loss: 1.4540 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.80863\n",
      "Epoch 26/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3257 - acc: 0.9962 - val_loss: 1.5295 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.80863\n",
      "Epoch 27/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3212 - acc: 0.9980 - val_loss: 1.4885 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.80863\n",
      "Epoch 28/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3164 - acc: 0.9982 - val_loss: 1.4471 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.80863\n",
      "Epoch 29/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3146 - acc: 0.9988 - val_loss: 1.4779 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.80863\n",
      "Epoch 30/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3133 - acc: 0.9982 - val_loss: 1.4899 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.80863\n",
      "Epoch 31/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3081 - acc: 0.9991 - val_loss: 1.5043 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.80863\n",
      "Epoch 32/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3064 - acc: 0.9991 - val_loss: 1.5127 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.80863\n",
      "Epoch 33/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3044 - acc: 0.9994 - val_loss: 1.5003 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.80863\n",
      "Epoch 34/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3024 - acc: 0.9991 - val_loss: 1.4582 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.80863\n",
      "Epoch 35/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3034 - acc: 0.9985 - val_loss: 1.4400 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.80863 to 0.80863, saving model to model/mfcc6/LGD_semi_fold2_resnet3.h5\n",
      "Epoch 36/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.3038 - acc: 0.9985 - val_loss: 1.4919 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.80863\n",
      "Epoch 37/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2976 - acc: 0.9991 - val_loss: 1.4567 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.80863\n",
      "Epoch 38/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2950 - acc: 0.9980 - val_loss: 1.4400 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.80863\n",
      "Epoch 39/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2923 - acc: 0.9988 - val_loss: 1.4515 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.80863\n",
      "Epoch 40/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2894 - acc: 0.9994 - val_loss: 1.4483 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.80863\n",
      "Epoch 41/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2876 - acc: 0.9991 - val_loss: 1.4214 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.80863\n",
      "Epoch 42/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2922 - acc: 0.9974 - val_loss: 1.5003 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.80863\n",
      "Epoch 43/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2969 - acc: 0.9965 - val_loss: 1.4823 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.80863\n",
      "Epoch 44/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2871 - acc: 0.9974 - val_loss: 1.4387 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.80863\n",
      "Epoch 45/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2852 - acc: 0.9982 - val_loss: 1.4932 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.80863\n",
      "Epoch 46/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2860 - acc: 0.9974 - val_loss: 1.4677 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.80863\n",
      "Epoch 47/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2825 - acc: 0.9988 - val_loss: 1.5398 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.80863\n",
      "Epoch 48/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2821 - acc: 0.9974 - val_loss: 1.5090 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.80863\n",
      "Epoch 49/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2748 - acc: 0.9997 - val_loss: 1.4363 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.80863\n",
      "Epoch 50/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2706 - acc: 1.0000 - val_loss: 1.3935 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.80863\n",
      "Epoch 51/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2691 - acc: 0.9997 - val_loss: 1.4039 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.80863\n",
      "Epoch 52/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2660 - acc: 1.0000 - val_loss: 1.4085 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.80863\n",
      "Epoch 53/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2642 - acc: 0.9997 - val_loss: 1.4252 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.80863\n",
      "Epoch 54/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2624 - acc: 1.0000 - val_loss: 1.4176 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.80863\n",
      "Epoch 55/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2614 - acc: 0.9994 - val_loss: 1.3766 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.80863\n",
      "Epoch 56/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2590 - acc: 0.9994 - val_loss: 1.4098 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.80863\n",
      "Epoch 57/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2570 - acc: 0.9997 - val_loss: 1.3894 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.80863\n",
      "Epoch 58/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2567 - acc: 0.9991 - val_loss: 1.3819 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.80863\n",
      "Epoch 59/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2577 - acc: 0.9982 - val_loss: 1.3770 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.80863\n",
      "Epoch 60/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2602 - acc: 0.9980 - val_loss: 1.5975 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.80863\n",
      "Epoch 61/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2550 - acc: 0.9982 - val_loss: 1.5019 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.80863\n",
      "Epoch 62/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2506 - acc: 0.9997 - val_loss: 1.4608 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.80863\n",
      "Epoch 63/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2472 - acc: 0.9994 - val_loss: 1.4105 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.80863\n",
      "Epoch 64/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2525 - acc: 0.9977 - val_loss: 1.4788 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.80863\n",
      "Epoch 65/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2593 - acc: 0.9959 - val_loss: 1.5850 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.80863\n",
      "Epoch 66/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2523 - acc: 0.9985 - val_loss: 1.4249 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.80863\n",
      "Epoch 67/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2433 - acc: 0.9997 - val_loss: 1.4642 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.80863\n",
      "Epoch 68/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2423 - acc: 0.9994 - val_loss: 1.4502 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.80863\n",
      "Epoch 69/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2397 - acc: 0.9994 - val_loss: 1.3868 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.80863\n",
      "Epoch 70/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2375 - acc: 1.0000 - val_loss: 1.3977 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.80863\n",
      "Epoch 71/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2382 - acc: 0.9994 - val_loss: 1.4418 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.80863\n",
      "Epoch 72/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2341 - acc: 0.9994 - val_loss: 1.4596 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.80863\n",
      "Epoch 73/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2316 - acc: 1.0000 - val_loss: 1.4231 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.80863\n",
      "Epoch 74/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2298 - acc: 1.0000 - val_loss: 1.4405 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.80863\n",
      "Epoch 75/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2282 - acc: 1.0000 - val_loss: 1.4577 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.80863\n",
      "Epoch 76/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2264 - acc: 1.0000 - val_loss: 1.4299 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.80863\n",
      "Epoch 77/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2296 - acc: 0.9985 - val_loss: 1.4895 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.80863\n",
      "Epoch 78/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2283 - acc: 0.9985 - val_loss: 1.3896 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.80863\n",
      "Epoch 79/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2264 - acc: 0.9991 - val_loss: 1.4185 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.80863\n",
      "Epoch 80/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2219 - acc: 0.9997 - val_loss: 1.4162 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.80863\n",
      "Epoch 81/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2211 - acc: 0.9994 - val_loss: 1.4255 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.80863\n",
      "Epoch 82/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2259 - acc: 0.9982 - val_loss: 1.4463 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.80863\n",
      "Epoch 83/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2269 - acc: 0.9968 - val_loss: 1.4584 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.80863\n",
      "Epoch 84/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2178 - acc: 0.9997 - val_loss: 1.3432 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.80863 to 0.81941, saving model to model/mfcc6/LGD_semi_fold2_resnet3.h5\n",
      "Epoch 85/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2156 - acc: 0.9994 - val_loss: 1.3688 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.81941\n",
      "Epoch 86/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2131 - acc: 1.0000 - val_loss: 1.3675 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.81941\n",
      "Epoch 87/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2112 - acc: 1.0000 - val_loss: 1.3718 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.81941\n",
      "Epoch 88/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2114 - acc: 0.9991 - val_loss: 1.3871 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.81941\n",
      "Epoch 89/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2097 - acc: 1.0000 - val_loss: 1.4216 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.81941\n",
      "Epoch 90/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2090 - acc: 0.9988 - val_loss: 1.4276 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.81941\n",
      "Epoch 91/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2102 - acc: 0.9991 - val_loss: 1.3964 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.81941\n",
      "Epoch 92/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2122 - acc: 0.9991 - val_loss: 1.4711 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.81941\n",
      "Epoch 93/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2057 - acc: 0.9994 - val_loss: 1.3836 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.81941\n",
      "Epoch 94/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2081 - acc: 0.9988 - val_loss: 1.4340 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.81941\n",
      "Epoch 95/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2081 - acc: 0.9980 - val_loss: 1.5120 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.81941\n",
      "Epoch 96/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2078 - acc: 0.9974 - val_loss: 1.5507 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.81941\n",
      "Epoch 97/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2073 - acc: 0.9980 - val_loss: 1.5916 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.81941\n",
      "Epoch 98/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2139 - acc: 0.9965 - val_loss: 1.6287 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.81941\n",
      "Epoch 99/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2073 - acc: 0.9991 - val_loss: 1.4723 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.81941\n",
      "Epoch 100/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2040 - acc: 0.9988 - val_loss: 1.4919 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.81941\n",
      "Epoch 101/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2010 - acc: 0.9994 - val_loss: 1.4473 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.81941\n",
      "Epoch 102/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.2001 - acc: 0.9994 - val_loss: 1.4351 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.81941\n",
      "Epoch 103/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1993 - acc: 0.9997 - val_loss: 1.4202 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.81941\n",
      "Epoch 104/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1996 - acc: 0.9994 - val_loss: 1.4633 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.81941\n",
      "Epoch 105/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1981 - acc: 0.9997 - val_loss: 1.4220 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.81941\n",
      "Epoch 106/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1969 - acc: 1.0000 - val_loss: 1.4144 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.81941\n",
      "Epoch 107/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1959 - acc: 1.0000 - val_loss: 1.4144 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.81941\n",
      "Epoch 108/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1953 - acc: 0.9997 - val_loss: 1.4043 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.81941\n",
      "Epoch 109/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1944 - acc: 1.0000 - val_loss: 1.4109 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.81941\n",
      "Epoch 110/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1940 - acc: 1.0000 - val_loss: 1.3993 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.81941\n",
      "Epoch 111/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1932 - acc: 1.0000 - val_loss: 1.3725 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.81941\n",
      "Epoch 112/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1924 - acc: 1.0000 - val_loss: 1.3870 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.81941\n",
      "Epoch 113/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1917 - acc: 1.0000 - val_loss: 1.3805 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.81941\n",
      "Epoch 114/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1910 - acc: 1.0000 - val_loss: 1.3777 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.81941\n",
      "Epoch 115/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1907 - acc: 1.0000 - val_loss: 1.4129 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.81941\n",
      "Epoch 116/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1895 - acc: 0.9997 - val_loss: 1.4174 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.81941\n",
      "Epoch 117/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1887 - acc: 1.0000 - val_loss: 1.4173 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.81941\n",
      "Epoch 118/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1879 - acc: 1.0000 - val_loss: 1.4450 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.81941\n",
      "Epoch 119/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1868 - acc: 1.0000 - val_loss: 1.4381 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.81941\n",
      "Epoch 120/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1861 - acc: 1.0000 - val_loss: 1.4316 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.81941\n",
      "Epoch 121/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1853 - acc: 1.0000 - val_loss: 1.3936 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.81941\n",
      "Epoch 122/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1849 - acc: 0.9997 - val_loss: 1.4129 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.81941\n",
      "Epoch 123/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1839 - acc: 1.0000 - val_loss: 1.3870 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.81941\n",
      "Epoch 124/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1829 - acc: 1.0000 - val_loss: 1.3934 - val_acc: 0.8086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00124: val_acc did not improve from 0.81941\n",
      "Epoch 125/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1827 - acc: 1.0000 - val_loss: 1.4278 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.81941\n",
      "Epoch 126/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1809 - acc: 1.0000 - val_loss: 1.4016 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.81941\n",
      "Epoch 127/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1803 - acc: 0.9997 - val_loss: 1.4451 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.81941\n",
      "Epoch 128/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1790 - acc: 1.0000 - val_loss: 1.4171 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.81941\n",
      "Epoch 129/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1786 - acc: 0.9994 - val_loss: 1.4290 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.81941\n",
      "Epoch 130/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1771 - acc: 1.0000 - val_loss: 1.3568 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.81941\n",
      "Epoch 131/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1772 - acc: 0.9997 - val_loss: 1.4292 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.81941\n",
      "Epoch 132/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1767 - acc: 0.9994 - val_loss: 1.4670 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.81941\n",
      "Epoch 133/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1759 - acc: 0.9994 - val_loss: 1.4015 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.81941\n",
      "Epoch 134/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1742 - acc: 1.0000 - val_loss: 1.3903 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.81941\n",
      "Epoch 135/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1736 - acc: 0.9997 - val_loss: 1.3873 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.81941\n",
      "Epoch 136/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1764 - acc: 0.9982 - val_loss: 1.5217 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.81941\n",
      "Epoch 137/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1734 - acc: 0.9994 - val_loss: 1.4030 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.81941\n",
      "Epoch 138/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1717 - acc: 1.0000 - val_loss: 1.3635 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.81941\n",
      "Epoch 139/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1708 - acc: 1.0000 - val_loss: 1.3538 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.81941\n",
      "Epoch 140/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1713 - acc: 0.9994 - val_loss: 1.3655 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.81941\n",
      "Epoch 141/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1696 - acc: 1.0000 - val_loss: 1.3447 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.81941\n",
      "Epoch 142/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1686 - acc: 1.0000 - val_loss: 1.3830 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.81941\n",
      "Epoch 143/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1684 - acc: 0.9997 - val_loss: 1.5231 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.81941\n",
      "Epoch 144/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1684 - acc: 0.9997 - val_loss: 1.4280 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.81941\n",
      "Epoch 145/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1667 - acc: 1.0000 - val_loss: 1.3966 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.81941\n",
      "Epoch 146/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1659 - acc: 1.0000 - val_loss: 1.3748 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.81941\n",
      "Epoch 147/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1656 - acc: 0.9997 - val_loss: 1.4009 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.81941\n",
      "Epoch 148/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1647 - acc: 1.0000 - val_loss: 1.3979 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.81941\n",
      "Epoch 149/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1651 - acc: 0.9997 - val_loss: 1.3780 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.81941\n",
      "Epoch 150/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1638 - acc: 0.9997 - val_loss: 1.3956 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.81941\n",
      "Epoch 151/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1637 - acc: 0.9997 - val_loss: 1.3934 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.81941\n",
      "Epoch 152/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1619 - acc: 1.0000 - val_loss: 1.3683 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.81941\n",
      "Epoch 153/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1614 - acc: 1.0000 - val_loss: 1.4108 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.81941\n",
      "Epoch 154/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1608 - acc: 0.9997 - val_loss: 1.3503 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.81941\n",
      "Epoch 155/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1630 - acc: 0.9988 - val_loss: 1.3879 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.81941\n",
      "Epoch 156/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1617 - acc: 0.9982 - val_loss: 1.4315 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.81941\n",
      "Epoch 157/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1608 - acc: 0.9994 - val_loss: 1.3739 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.81941\n",
      "Epoch 158/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1607 - acc: 0.9991 - val_loss: 1.3324 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.81941\n",
      "Epoch 159/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1606 - acc: 0.9991 - val_loss: 1.3365 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.81941\n",
      "Epoch 160/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1583 - acc: 1.0000 - val_loss: 1.3448 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.81941\n",
      "Epoch 161/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1579 - acc: 1.0000 - val_loss: 1.3392 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.81941\n",
      "Epoch 162/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1569 - acc: 1.0000 - val_loss: 1.3034 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.81941\n",
      "Epoch 163/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1561 - acc: 1.0000 - val_loss: 1.3084 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.81941\n",
      "Epoch 164/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1560 - acc: 0.9997 - val_loss: 1.2906 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.81941\n",
      "Epoch 165/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1562 - acc: 0.9997 - val_loss: 1.3143 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.81941\n",
      "Epoch 166/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1556 - acc: 0.9997 - val_loss: 1.3248 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.81941\n",
      "Epoch 167/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1545 - acc: 1.0000 - val_loss: 1.3035 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.81941\n",
      "Epoch 168/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1537 - acc: 1.0000 - val_loss: 1.3002 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.81941\n",
      "Epoch 169/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1534 - acc: 1.0000 - val_loss: 1.2872 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.81941\n",
      "Epoch 170/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1532 - acc: 1.0000 - val_loss: 1.3125 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.81941\n",
      "Epoch 171/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1521 - acc: 1.0000 - val_loss: 1.3248 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.81941\n",
      "Epoch 172/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1518 - acc: 0.9997 - val_loss: 1.3427 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.81941\n",
      "Epoch 173/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1515 - acc: 0.9997 - val_loss: 1.3671 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.81941\n",
      "Epoch 174/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1506 - acc: 1.0000 - val_loss: 1.3428 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.81941\n",
      "Epoch 175/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1499 - acc: 1.0000 - val_loss: 1.3160 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.81941\n",
      "Epoch 176/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1492 - acc: 1.0000 - val_loss: 1.3292 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.81941\n",
      "Epoch 177/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1483 - acc: 1.0000 - val_loss: 1.3730 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.81941\n",
      "Epoch 178/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1480 - acc: 1.0000 - val_loss: 1.3433 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.81941\n",
      "Epoch 179/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1472 - acc: 1.0000 - val_loss: 1.3429 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.81941\n",
      "Epoch 180/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1463 - acc: 1.0000 - val_loss: 1.3493 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.81941\n",
      "Epoch 181/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1455 - acc: 1.0000 - val_loss: 1.3489 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.81941\n",
      "Epoch 182/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1446 - acc: 1.0000 - val_loss: 1.3383 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.81941\n",
      "Epoch 183/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1464 - acc: 0.9991 - val_loss: 1.3674 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.81941\n",
      "Epoch 184/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1466 - acc: 0.9994 - val_loss: 1.3900 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.81941\n",
      "Epoch 185/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1466 - acc: 0.9988 - val_loss: 1.4535 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.81941\n",
      "Epoch 186/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1457 - acc: 0.9991 - val_loss: 1.4799 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.81941\n",
      "Epoch 187/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1440 - acc: 0.9997 - val_loss: 1.5636 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.81941\n",
      "Epoch 188/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1439 - acc: 0.9997 - val_loss: 1.4601 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.81941\n",
      "Epoch 189/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1443 - acc: 0.9991 - val_loss: 1.4519 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.81941\n",
      "Epoch 190/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1465 - acc: 0.9991 - val_loss: 1.3994 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.81941\n",
      "Epoch 191/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1425 - acc: 0.9994 - val_loss: 1.4198 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.81941\n",
      "Epoch 192/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1420 - acc: 0.9997 - val_loss: 1.3585 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.81941\n",
      "Epoch 193/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1412 - acc: 0.9994 - val_loss: 1.3447 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.81941\n",
      "Epoch 194/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1416 - acc: 0.9991 - val_loss: 1.3951 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.81941\n",
      "Epoch 195/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1404 - acc: 1.0000 - val_loss: 1.3644 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.81941\n",
      "Epoch 196/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1397 - acc: 1.0000 - val_loss: 1.3940 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.81941\n",
      "Epoch 197/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1393 - acc: 0.9997 - val_loss: 1.3974 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.81941\n",
      "Epoch 198/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1388 - acc: 1.0000 - val_loss: 1.3753 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.81941\n",
      "Epoch 199/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1383 - acc: 1.0000 - val_loss: 1.3572 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.81941\n",
      "Epoch 200/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1378 - acc: 1.0000 - val_loss: 1.3524 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.81941\n",
      "Epoch 201/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1390 - acc: 0.9994 - val_loss: 1.3517 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.81941\n",
      "Epoch 202/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1381 - acc: 0.9997 - val_loss: 1.3596 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.81941\n",
      "Epoch 203/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1377 - acc: 0.9997 - val_loss: 1.4195 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.81941\n",
      "Epoch 204/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1389 - acc: 0.9991 - val_loss: 1.4745 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.81941\n",
      "Epoch 205/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1451 - acc: 0.9991 - val_loss: 1.3362 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.81941\n",
      "Epoch 206/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1407 - acc: 0.9997 - val_loss: 1.3663 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.81941\n",
      "Epoch 207/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1407 - acc: 0.9988 - val_loss: 1.4230 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.81941\n",
      "Epoch 208/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1382 - acc: 0.9994 - val_loss: 1.4197 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.81941\n",
      "Epoch 209/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1370 - acc: 0.9997 - val_loss: 1.3820 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.81941\n",
      "Epoch 210/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1361 - acc: 0.9997 - val_loss: 1.3734 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.81941\n",
      "Epoch 211/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1354 - acc: 1.0000 - val_loss: 1.3507 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.81941\n",
      "Epoch 212/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1358 - acc: 1.0000 - val_loss: 1.3543 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.81941\n",
      "Epoch 213/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1350 - acc: 1.0000 - val_loss: 1.3634 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.81941\n",
      "Epoch 214/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1352 - acc: 1.0000 - val_loss: 1.3928 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.81941\n",
      "Epoch 215/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1348 - acc: 1.0000 - val_loss: 1.3991 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.81941\n",
      "Epoch 216/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1344 - acc: 1.0000 - val_loss: 1.3637 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.81941\n",
      "Epoch 217/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1341 - acc: 1.0000 - val_loss: 1.3649 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.81941\n",
      "Epoch 218/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1340 - acc: 1.0000 - val_loss: 1.3679 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.81941\n",
      "Epoch 219/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1339 - acc: 1.0000 - val_loss: 1.3565 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.81941\n",
      "Epoch 220/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1336 - acc: 1.0000 - val_loss: 1.3480 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.81941\n",
      "Epoch 221/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1334 - acc: 1.0000 - val_loss: 1.3587 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.81941\n",
      "Epoch 222/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1331 - acc: 1.0000 - val_loss: 1.3669 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.81941\n",
      "Epoch 223/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1327 - acc: 1.0000 - val_loss: 1.3499 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.81941\n",
      "Epoch 224/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1325 - acc: 1.0000 - val_loss: 1.3614 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.81941\n",
      "Epoch 225/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1322 - acc: 1.0000 - val_loss: 1.3294 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.81941\n",
      "Epoch 226/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1320 - acc: 1.0000 - val_loss: 1.3459 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.81941\n",
      "Epoch 227/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1315 - acc: 1.0000 - val_loss: 1.3545 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.81941\n",
      "Epoch 228/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1314 - acc: 1.0000 - val_loss: 1.3336 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.81941\n",
      "Epoch 229/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1314 - acc: 0.9997 - val_loss: 1.3481 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.81941\n",
      "Epoch 230/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1310 - acc: 1.0000 - val_loss: 1.3439 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.81941\n",
      "Epoch 231/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1317 - acc: 0.9997 - val_loss: 1.3653 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.81941\n",
      "Epoch 232/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1312 - acc: 0.9997 - val_loss: 1.3590 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.81941\n",
      "Epoch 233/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1302 - acc: 1.0000 - val_loss: 1.3505 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.81941\n",
      "Epoch 234/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1298 - acc: 1.0000 - val_loss: 1.3461 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.81941\n",
      "Epoch 235/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1299 - acc: 0.9997 - val_loss: 1.3527 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.81941\n",
      "Epoch 236/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1295 - acc: 1.0000 - val_loss: 1.3147 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.81941\n",
      "Epoch 237/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1289 - acc: 1.0000 - val_loss: 1.3093 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.81941\n",
      "Epoch 238/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1288 - acc: 1.0000 - val_loss: 1.3176 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.81941\n",
      "Epoch 239/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1285 - acc: 1.0000 - val_loss: 1.3237 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.81941\n",
      "Epoch 240/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1283 - acc: 1.0000 - val_loss: 1.3403 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.81941\n",
      "Epoch 241/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1280 - acc: 1.0000 - val_loss: 1.3404 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.81941\n",
      "Epoch 242/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1276 - acc: 1.0000 - val_loss: 1.3398 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.81941\n",
      "Epoch 243/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1273 - acc: 1.0000 - val_loss: 1.3356 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.81941\n",
      "Epoch 244/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1269 - acc: 1.0000 - val_loss: 1.3372 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.81941\n",
      "Epoch 245/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1273 - acc: 0.9994 - val_loss: 1.3693 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.81941\n",
      "Epoch 246/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1263 - acc: 1.0000 - val_loss: 1.3500 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.81941\n",
      "Epoch 247/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1262 - acc: 1.0000 - val_loss: 1.3327 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.81941\n",
      "Epoch 248/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1258 - acc: 1.0000 - val_loss: 1.3311 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.81941\n",
      "Epoch 249/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1254 - acc: 1.0000 - val_loss: 1.3279 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.81941\n",
      "Epoch 250/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1251 - acc: 1.0000 - val_loss: 1.3503 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.81941\n",
      "Epoch 251/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1247 - acc: 1.0000 - val_loss: 1.3501 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.81941\n",
      "Epoch 252/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1243 - acc: 1.0000 - val_loss: 1.3486 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.81941\n",
      "Epoch 253/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1273 - acc: 0.9994 - val_loss: 1.3978 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.81941\n",
      "Epoch 254/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1241 - acc: 1.0000 - val_loss: 1.3511 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.81941\n",
      "Epoch 255/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1241 - acc: 1.0000 - val_loss: 1.3768 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.81941\n",
      "Epoch 256/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1234 - acc: 1.0000 - val_loss: 1.3675 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.81941\n",
      "Epoch 257/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1231 - acc: 1.0000 - val_loss: 1.3604 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.81941\n",
      "Epoch 258/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1225 - acc: 1.0000 - val_loss: 1.3582 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.81941\n",
      "Epoch 259/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1222 - acc: 1.0000 - val_loss: 1.3642 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.81941\n",
      "Epoch 260/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1220 - acc: 1.0000 - val_loss: 1.3743 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.81941\n",
      "Epoch 261/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1220 - acc: 0.9997 - val_loss: 1.3488 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.81941\n",
      "Epoch 262/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1215 - acc: 1.0000 - val_loss: 1.3586 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.81941\n",
      "Epoch 263/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1211 - acc: 1.0000 - val_loss: 1.3390 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.81941\n",
      "Epoch 264/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1206 - acc: 1.0000 - val_loss: 1.3333 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.81941\n",
      "Epoch 265/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1204 - acc: 1.0000 - val_loss: 1.3365 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.81941\n",
      "Epoch 266/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1199 - acc: 1.0000 - val_loss: 1.3459 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.81941\n",
      "Epoch 267/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1196 - acc: 1.0000 - val_loss: 1.3415 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.81941\n",
      "Epoch 268/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1191 - acc: 1.0000 - val_loss: 1.3407 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.81941\n",
      "Epoch 269/3000\n",
      "3418/3418 [==============================] - 25s 7ms/step - loss: 0.1191 - acc: 1.0000 - val_loss: 1.3213 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.81941\n",
      "Epoch 00269: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:32: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3339, 64, 431, 1) (3339, 41)\n",
      "===train verified_3===\n",
      "using resnet model: 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 64, 431, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 32, 216, 64)  3200        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 32, 216, 64)  256         conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 32, 216, 64)  0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 108, 64)  0           activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 16, 108, 64)  36928       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 16, 108, 64)  256         conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 16, 108, 64)  0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, 16, 108, 64)  36928       activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_132 (Add)                   (None, 16, 108, 64)  0           max_pooling2d_7[0][0]            \n",
      "                                                                 conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 16, 108, 64)  256         add_132[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 16, 108, 64)  0           batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, 16, 108, 64)  36928       activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, 16, 108, 64)  256         conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 16, 108, 64)  0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, 16, 108, 64)  36928       activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_133 (Add)                   (None, 16, 108, 64)  0           add_132[0][0]                    \n",
      "                                                                 conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, 16, 108, 64)  256         add_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 16, 108, 64)  0           batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 16, 108, 64)  36928       activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, 16, 108, 64)  256         conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 16, 108, 64)  0           batch_normalization_379[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 16, 108, 64)  36928       activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_134 (Add)                   (None, 16, 108, 64)  0           add_133[0][0]                    \n",
      "                                                                 conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_380 (BatchN (None, 16, 108, 64)  256         add_134[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 16, 108, 64)  0           batch_normalization_380[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 8, 54, 128)   73856       activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_381 (BatchN (None, 8, 54, 128)   512         conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 8, 54, 128)   0           batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 8, 54, 128)   8320        add_134[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 8, 54, 128)   147584      activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_135 (Add)                   (None, 8, 54, 128)   0           conv2d_398[0][0]                 \n",
      "                                                                 conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_382 (BatchN (None, 8, 54, 128)   512         add_135[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 8, 54, 128)   0           batch_normalization_382[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, 8, 54, 128)   147584      activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_383 (BatchN (None, 8, 54, 128)   512         conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 8, 54, 128)   0           batch_normalization_383[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, 8, 54, 128)   147584      activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_136 (Add)                   (None, 8, 54, 128)   0           add_135[0][0]                    \n",
      "                                                                 conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_384 (BatchN (None, 8, 54, 128)   512         add_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 8, 54, 128)   0           batch_normalization_384[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, 8, 54, 128)   147584      activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchN (None, 8, 54, 128)   512         conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 8, 54, 128)   0           batch_normalization_385[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, 8, 54, 128)   147584      activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_137 (Add)                   (None, 8, 54, 128)   0           add_136[0][0]                    \n",
      "                                                                 conv2d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchN (None, 8, 54, 128)   512         add_137[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 8, 54, 128)   0           batch_normalization_386[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, 8, 54, 128)   147584      activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_387 (BatchN (None, 8, 54, 128)   512         conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 8, 54, 128)   0           batch_normalization_387[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, 8, 54, 128)   147584      activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_138 (Add)                   (None, 8, 54, 128)   0           add_137[0][0]                    \n",
      "                                                                 conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, 8, 54, 128)   512         add_138[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 8, 54, 128)   0           batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 4, 27, 256)   295168      activation_382[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, 4, 27, 256)   1024        conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 4, 27, 256)   0           batch_normalization_389[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 4, 27, 256)   33024       add_138[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 4, 27, 256)   590080      activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_139 (Add)                   (None, 4, 27, 256)   0           conv2d_407[0][0]                 \n",
      "                                                                 conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 4, 27, 256)   1024        add_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 4, 27, 256)   0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 4, 27, 256)   590080      activation_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 4, 27, 256)   1024        conv2d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 4, 27, 256)   0           batch_normalization_391[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, 4, 27, 256)   590080      activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_140 (Add)                   (None, 4, 27, 256)   0           add_139[0][0]                    \n",
      "                                                                 conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, 4, 27, 256)   1024        add_140[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 4, 27, 256)   0           batch_normalization_392[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, 4, 27, 256)   590080      activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, 4, 27, 256)   1024        conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 4, 27, 256)   0           batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_411 (Conv2D)             (None, 4, 27, 256)   590080      activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_141 (Add)                   (None, 4, 27, 256)   0           add_140[0][0]                    \n",
      "                                                                 conv2d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, 4, 27, 256)   1024        add_141[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 4, 27, 256)   0           batch_normalization_394[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, 4, 27, 256)   590080      activation_388[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_395 (BatchN (None, 4, 27, 256)   1024        conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 4, 27, 256)   0           batch_normalization_395[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, 4, 27, 256)   590080      activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_142 (Add)                   (None, 4, 27, 256)   0           add_141[0][0]                    \n",
      "                                                                 conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_396 (BatchN (None, 4, 27, 256)   1024        add_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 4, 27, 256)   0           batch_normalization_396[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, 4, 27, 256)   590080      activation_390[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_397 (BatchN (None, 4, 27, 256)   1024        conv2d_414[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 4, 27, 256)   0           batch_normalization_397[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, 4, 27, 256)   590080      activation_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_143 (Add)                   (None, 4, 27, 256)   0           add_142[0][0]                    \n",
      "                                                                 conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, 4, 27, 256)   1024        add_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 4, 27, 256)   0           batch_normalization_398[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, 4, 27, 256)   590080      activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, 4, 27, 256)   1024        conv2d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, 4, 27, 256)   0           batch_normalization_399[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, 4, 27, 256)   590080      activation_393[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_144 (Add)                   (None, 4, 27, 256)   0           add_143[0][0]                    \n",
      "                                                                 conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, 4, 27, 256)   1024        add_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, 4, 27, 256)   0           batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, 2, 14, 512)   1180160     activation_394[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, 2, 14, 512)   2048        conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_395 (Activation)     (None, 2, 14, 512)   0           batch_normalization_401[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, 2, 14, 512)   131584      add_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, 2, 14, 512)   2359808     activation_395[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_145 (Add)                   (None, 2, 14, 512)   0           conv2d_420[0][0]                 \n",
      "                                                                 conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 2, 14, 512)   2048        add_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, 2, 14, 512)   0           batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, 2, 14, 512)   2359808     activation_396[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 2, 14, 512)   2048        conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, 2, 14, 512)   0           batch_normalization_403[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, 2, 14, 512)   2359808     activation_397[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_146 (Add)                   (None, 2, 14, 512)   0           add_145[0][0]                    \n",
      "                                                                 conv2d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 2, 14, 512)   2048        add_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_398 (Activation)     (None, 2, 14, 512)   0           batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_423 (Conv2D)             (None, 2, 14, 512)   2359808     activation_398[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 2, 14, 512)   2048        conv2d_423[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_399 (Activation)     (None, 2, 14, 512)   0           batch_normalization_405[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_424 (Conv2D)             (None, 2, 14, 512)   2359808     activation_399[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_147 (Add)                   (None, 2, 14, 512)   0           add_146[0][0]                    \n",
      "                                                                 conv2d_424[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 2, 14, 512)   2048        add_147[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_400 (Activation)     (None, 2, 14, 512)   0           batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 1, 1, 512)    0           activation_400[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1, 1, 512)    0           average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 512)          0           dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 49)           25137       flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 49)           196         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 49)           0           batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 41)           2050        dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,327,735\n",
      "Trainable params: 21,312,405\n",
      "Non-trainable params: 15,330\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3339 samples, validate on 371 samples\n",
      "Epoch 1/3000\n",
      "3339/3339 [==============================] - 14s 4ms/step - loss: 4.7362 - acc: 0.2046 - val_loss: 4.8582 - val_acc: 0.1509\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.15094, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 2/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 3.8787 - acc: 0.3255 - val_loss: 4.1540 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.15094 to 0.28571, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 3/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 3.3178 - acc: 0.4331 - val_loss: 4.0222 - val_acc: 0.2722\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.28571\n",
      "Epoch 4/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 2.8834 - acc: 0.4951 - val_loss: 3.2404 - val_acc: 0.3666\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.28571 to 0.36658, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 5/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 2.5520 - acc: 0.5654 - val_loss: 2.6065 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.36658 to 0.50943, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 6/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 2.3033 - acc: 0.6068 - val_loss: 2.6037 - val_acc: 0.5364\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.50943 to 0.53639, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 7/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 2.0784 - acc: 0.6433 - val_loss: 2.7039 - val_acc: 0.4717\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.53639\n",
      "Epoch 8/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.9029 - acc: 0.6703 - val_loss: 2.3789 - val_acc: 0.5768\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.53639 to 0.57682, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 9/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.7117 - acc: 0.7212 - val_loss: 2.0127 - val_acc: 0.6307\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.57682 to 0.63073, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 10/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.5782 - acc: 0.7418 - val_loss: 1.7072 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.63073 to 0.71698, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 11/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.5191 - acc: 0.7442 - val_loss: 2.6502 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.71698\n",
      "Epoch 12/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.4245 - acc: 0.7766 - val_loss: 1.6697 - val_acc: 0.6658\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.71698\n",
      "Epoch 13/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.3163 - acc: 0.7966 - val_loss: 1.5316 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.71698 to 0.73854, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 14/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.3021 - acc: 0.7829 - val_loss: 1.9065 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.73854\n",
      "Epoch 15/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.2048 - acc: 0.8149 - val_loss: 1.7363 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.73854\n",
      "Epoch 16/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.2306 - acc: 0.8047 - val_loss: 1.7388 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.73854\n",
      "Epoch 17/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.1930 - acc: 0.8155 - val_loss: 1.4463 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.73854 to 0.76550, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 18/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.1038 - acc: 0.8335 - val_loss: 1.5971 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.76550\n",
      "Epoch 19/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.0455 - acc: 0.8482 - val_loss: 1.6995 - val_acc: 0.6604\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.76550\n",
      "Epoch 20/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 1.0343 - acc: 0.8494 - val_loss: 1.4891 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.76550\n",
      "Epoch 21/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.9690 - acc: 0.8691 - val_loss: 1.9722 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.76550\n",
      "Epoch 22/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.9703 - acc: 0.8625 - val_loss: 1.4390 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.76550\n",
      "Epoch 23/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.9358 - acc: 0.8673 - val_loss: 1.4552 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.76550\n",
      "Epoch 24/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.8746 - acc: 0.8886 - val_loss: 1.4139 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.76550\n",
      "Epoch 25/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.8496 - acc: 0.8955 - val_loss: 1.4489 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.76550\n",
      "Epoch 26/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.8543 - acc: 0.8991 - val_loss: 1.3387 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.76550 to 0.79515, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 27/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.8265 - acc: 0.9015 - val_loss: 1.4142 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.79515\n",
      "Epoch 28/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.8851 - acc: 0.8799 - val_loss: 1.5271 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.79515\n",
      "Epoch 29/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.8130 - acc: 0.8997 - val_loss: 1.2863 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.79515\n",
      "Epoch 30/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.7802 - acc: 0.9084 - val_loss: 1.3476 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.79515\n",
      "Epoch 31/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.7486 - acc: 0.9182 - val_loss: 1.3052 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.79515\n",
      "Epoch 32/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.7183 - acc: 0.9275 - val_loss: 1.5235 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.79515\n",
      "Epoch 33/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.7302 - acc: 0.9176 - val_loss: 1.5988 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.79515\n",
      "Epoch 34/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.8232 - acc: 0.9027 - val_loss: 1.8868 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.79515\n",
      "Epoch 35/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.7176 - acc: 0.9239 - val_loss: 1.7453 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.79515\n",
      "Epoch 36/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.7181 - acc: 0.9224 - val_loss: 1.4537 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.79515\n",
      "Epoch 37/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6755 - acc: 0.9371 - val_loss: 1.4281 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.79515\n",
      "Epoch 38/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6671 - acc: 0.9362 - val_loss: 1.3878 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.79515\n",
      "Epoch 39/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6969 - acc: 0.9305 - val_loss: 1.5026 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.79515\n",
      "Epoch 40/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6150 - acc: 0.9464 - val_loss: 1.4839 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.79515\n",
      "Epoch 41/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6224 - acc: 0.9437 - val_loss: 1.2579 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.79515\n",
      "Epoch 42/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6213 - acc: 0.9479 - val_loss: 1.5772 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.79515\n",
      "Epoch 43/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6637 - acc: 0.9272 - val_loss: 1.7157 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.79515\n",
      "Epoch 44/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.7510 - acc: 0.9096 - val_loss: 1.6332 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.79515\n",
      "Epoch 45/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.7114 - acc: 0.9215 - val_loss: 1.3916 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.79515\n",
      "Epoch 46/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6580 - acc: 0.9359 - val_loss: 1.4731 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.79515\n",
      "Epoch 47/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5660 - acc: 0.9602 - val_loss: 1.2707 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.79515\n",
      "Epoch 48/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5241 - acc: 0.9656 - val_loss: 1.1444 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.79515 to 0.82210, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 49/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5047 - acc: 0.9674 - val_loss: 1.4976 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.82210\n",
      "Epoch 50/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6207 - acc: 0.9377 - val_loss: 1.4354 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.82210\n",
      "Epoch 51/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5496 - acc: 0.9554 - val_loss: 1.5213 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.82210\n",
      "Epoch 52/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5463 - acc: 0.9605 - val_loss: 1.4351 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.82210\n",
      "Epoch 53/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5591 - acc: 0.9518 - val_loss: 1.8724 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.82210\n",
      "Epoch 54/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6053 - acc: 0.9401 - val_loss: 1.6660 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.82210\n",
      "Epoch 55/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.7248 - acc: 0.9119 - val_loss: 1.6823 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.82210\n",
      "Epoch 56/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6026 - acc: 0.9488 - val_loss: 1.3081 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.82210\n",
      "Epoch 57/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5108 - acc: 0.9692 - val_loss: 1.5640 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.82210\n",
      "Epoch 58/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4985 - acc: 0.9704 - val_loss: 1.2612 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.82210\n",
      "Epoch 59/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5442 - acc: 0.9503 - val_loss: 1.7042 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.82210\n",
      "Epoch 60/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6155 - acc: 0.9356 - val_loss: 1.9055 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.82210\n",
      "Epoch 61/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5290 - acc: 0.9638 - val_loss: 1.4791 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.82210\n",
      "Epoch 62/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4848 - acc: 0.9706 - val_loss: 1.4715 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.82210\n",
      "Epoch 63/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4752 - acc: 0.9709 - val_loss: 1.6790 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.82210\n",
      "Epoch 64/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5518 - acc: 0.9494 - val_loss: 1.6456 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.82210\n",
      "Epoch 65/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5243 - acc: 0.9560 - val_loss: 1.5492 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.82210\n",
      "Epoch 66/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4608 - acc: 0.9751 - val_loss: 1.4329 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.82210\n",
      "Epoch 67/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4973 - acc: 0.9581 - val_loss: 1.8950 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.82210\n",
      "Epoch 68/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5255 - acc: 0.9530 - val_loss: 1.8664 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.82210\n",
      "Epoch 69/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5521 - acc: 0.9464 - val_loss: 1.2245 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.82210\n",
      "Epoch 70/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4968 - acc: 0.9656 - val_loss: 1.3983 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.82210\n",
      "Epoch 71/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5095 - acc: 0.9554 - val_loss: 1.8703 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.82210\n",
      "Epoch 72/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4582 - acc: 0.9745 - val_loss: 1.3402 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.82210\n",
      "Epoch 73/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4547 - acc: 0.9706 - val_loss: 1.5049 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.82210\n",
      "Epoch 74/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5656 - acc: 0.9371 - val_loss: 1.4018 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.82210\n",
      "Epoch 75/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4995 - acc: 0.9605 - val_loss: 2.4556 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.82210\n",
      "Epoch 76/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4505 - acc: 0.9730 - val_loss: 1.2485 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.82210 to 0.82480, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 77/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4084 - acc: 0.9841 - val_loss: 1.2690 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.82480\n",
      "Epoch 78/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4432 - acc: 0.9683 - val_loss: 1.3191 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.82480\n",
      "Epoch 79/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4870 - acc: 0.9557 - val_loss: 1.7220 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.82480\n",
      "Epoch 80/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4671 - acc: 0.9662 - val_loss: 1.3914 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.82480\n",
      "Epoch 81/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4453 - acc: 0.9727 - val_loss: 1.3850 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.82480\n",
      "Epoch 82/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4496 - acc: 0.9659 - val_loss: 2.0668 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.82480\n",
      "Epoch 83/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.6438 - acc: 0.9197 - val_loss: 2.2117 - val_acc: 0.6765\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.82480\n",
      "Epoch 84/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5259 - acc: 0.9518 - val_loss: 1.4771 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.82480\n",
      "Epoch 85/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5043 - acc: 0.9581 - val_loss: 1.5460 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.82480\n",
      "Epoch 86/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4443 - acc: 0.9757 - val_loss: 1.3151 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.82480\n",
      "Epoch 87/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4139 - acc: 0.9811 - val_loss: 1.2071 - val_acc: 0.8329\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.82480 to 0.83288, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 88/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4000 - acc: 0.9805 - val_loss: 1.2514 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.83288\n",
      "Epoch 89/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4145 - acc: 0.9745 - val_loss: 1.6382 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.83288\n",
      "Epoch 90/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4334 - acc: 0.9689 - val_loss: 1.6058 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.83288\n",
      "Epoch 91/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4346 - acc: 0.9698 - val_loss: 1.6231 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.83288\n",
      "Epoch 92/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4194 - acc: 0.9745 - val_loss: 1.3680 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.83288\n",
      "Epoch 93/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4048 - acc: 0.9745 - val_loss: 1.6421 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.83288\n",
      "Epoch 94/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4682 - acc: 0.9563 - val_loss: 1.5635 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.83288\n",
      "Epoch 95/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5944 - acc: 0.9305 - val_loss: 1.8134 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.83288\n",
      "Epoch 96/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4700 - acc: 0.9626 - val_loss: 1.4952 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.83288\n",
      "Epoch 97/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4024 - acc: 0.9829 - val_loss: 1.2859 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.83288\n",
      "Epoch 98/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3843 - acc: 0.9844 - val_loss: 1.4349 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.83288\n",
      "Epoch 99/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3798 - acc: 0.9829 - val_loss: 1.4250 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.83288\n",
      "Epoch 100/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3687 - acc: 0.9841 - val_loss: 1.4603 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.83288\n",
      "Epoch 101/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4271 - acc: 0.9686 - val_loss: 1.5742 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.83288\n",
      "Epoch 102/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4240 - acc: 0.9662 - val_loss: 1.4668 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.83288\n",
      "Epoch 103/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4201 - acc: 0.9680 - val_loss: 1.5068 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.83288\n",
      "Epoch 104/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4620 - acc: 0.9575 - val_loss: 1.8558 - val_acc: 0.7116\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.83288\n",
      "Epoch 105/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4523 - acc: 0.9617 - val_loss: 1.5663 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.83288\n",
      "Epoch 106/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4271 - acc: 0.9724 - val_loss: 1.4703 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.83288\n",
      "Epoch 107/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4075 - acc: 0.9745 - val_loss: 1.2417 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.83288\n",
      "Epoch 108/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4341 - acc: 0.9709 - val_loss: 2.0587 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.83288\n",
      "Epoch 109/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4381 - acc: 0.9653 - val_loss: 1.4753 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.83288\n",
      "Epoch 110/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4589 - acc: 0.9596 - val_loss: 1.5369 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.83288\n",
      "Epoch 111/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4199 - acc: 0.9724 - val_loss: 1.3364 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.83288\n",
      "Epoch 112/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3999 - acc: 0.9775 - val_loss: 1.2600 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.83288\n",
      "Epoch 113/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3706 - acc: 0.9850 - val_loss: 1.2926 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.83288\n",
      "Epoch 114/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3738 - acc: 0.9814 - val_loss: 1.5148 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.83288\n",
      "Epoch 115/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3396 - acc: 0.9886 - val_loss: 1.2918 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.83288\n",
      "Epoch 116/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3226 - acc: 0.9922 - val_loss: 1.5137 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.83288\n",
      "Epoch 117/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3536 - acc: 0.9775 - val_loss: 1.4437 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.83288\n",
      "Epoch 118/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4237 - acc: 0.9650 - val_loss: 1.8658 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.83288\n",
      "Epoch 119/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5016 - acc: 0.9434 - val_loss: 1.7652 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.83288\n",
      "Epoch 120/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.5188 - acc: 0.9416 - val_loss: 1.3181 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.83288\n",
      "Epoch 121/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4604 - acc: 0.9593 - val_loss: 1.4261 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.83288\n",
      "Epoch 122/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4269 - acc: 0.9656 - val_loss: 1.4993 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.83288\n",
      "Epoch 123/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3690 - acc: 0.9838 - val_loss: 1.5593 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.83288\n",
      "Epoch 124/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3628 - acc: 0.9865 - val_loss: 1.3763 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.83288\n",
      "Epoch 125/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4041 - acc: 0.9730 - val_loss: 1.7062 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.83288\n",
      "Epoch 126/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3708 - acc: 0.9823 - val_loss: 1.3982 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.83288\n",
      "Epoch 127/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3236 - acc: 0.9937 - val_loss: 1.1976 - val_acc: 0.8410\n",
      "\n",
      "Epoch 00127: val_acc improved from 0.83288 to 0.84097, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 128/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3650 - acc: 0.9778 - val_loss: 1.4904 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.84097\n",
      "Epoch 129/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4319 - acc: 0.9557 - val_loss: 2.0435 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.84097\n",
      "Epoch 130/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4392 - acc: 0.9614 - val_loss: 1.3291 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.84097\n",
      "Epoch 131/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4450 - acc: 0.9536 - val_loss: 1.5374 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.84097\n",
      "Epoch 132/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3688 - acc: 0.9787 - val_loss: 1.4963 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.84097\n",
      "Epoch 133/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3922 - acc: 0.9757 - val_loss: 1.5816 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.84097\n",
      "Epoch 134/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3528 - acc: 0.9847 - val_loss: 1.1528 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00134: val_acc improved from 0.84097 to 0.85984, saving model to model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Epoch 135/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3345 - acc: 0.9862 - val_loss: 1.3340 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.85984\n",
      "Epoch 136/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3924 - acc: 0.9674 - val_loss: 1.5036 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.85984\n",
      "Epoch 137/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4315 - acc: 0.9587 - val_loss: 2.2050 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.85984\n",
      "Epoch 138/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3845 - acc: 0.9766 - val_loss: 1.5938 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.85984\n",
      "Epoch 139/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3563 - acc: 0.9811 - val_loss: 1.3676 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.85984\n",
      "Epoch 140/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3298 - acc: 0.9895 - val_loss: 1.2619 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.85984\n",
      "Epoch 141/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3158 - acc: 0.9904 - val_loss: 1.3231 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.85984\n",
      "Epoch 142/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.2932 - acc: 0.9967 - val_loss: 1.2275 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.85984\n",
      "Epoch 143/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3529 - acc: 0.9766 - val_loss: 2.1242 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.85984\n",
      "Epoch 144/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4456 - acc: 0.9530 - val_loss: 3.3282 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.85984\n",
      "Epoch 145/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4602 - acc: 0.9503 - val_loss: 1.5086 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.85984\n",
      "Epoch 146/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.4182 - acc: 0.9692 - val_loss: 1.5196 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.85984\n",
      "Epoch 147/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3739 - acc: 0.9775 - val_loss: 1.2585 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.85984\n",
      "Epoch 148/3000\n",
      "3339/3339 [==============================] - 10s 3ms/step - loss: 0.3369 - acc: 0.9829 - val_loss: 1.1964 - val_acc: 0.8356\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.85984\n",
      "Epoch 00148: early stopping\n",
      "(4480, 64, 431, 1) (4480, 41)\n",
      "===train semi_3===\n",
      "semi loading: model/mfcc6/LGD_fold3_resnet1-.h5\n",
      "Train on 4480 samples, validate on 371 samples\n",
      "Epoch 1/3000\n",
      "4480/4480 [==============================] - 15s 3ms/step - loss: 1.4079 - acc: 0.8458 - val_loss: 1.5681 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74394, saving model to model/mfcc6/LGD_semi_fold3_resnet1.h5\n",
      "Epoch 2/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.8675 - acc: 0.8783 - val_loss: 1.4703 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.74394 to 0.74663, saving model to model/mfcc6/LGD_semi_fold3_resnet1.h5\n",
      "Epoch 3/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.7332 - acc: 0.8904 - val_loss: 1.4200 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.74663 to 0.74933, saving model to model/mfcc6/LGD_semi_fold3_resnet1.h5\n",
      "Epoch 4/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.6664 - acc: 0.8975 - val_loss: 1.3558 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.74933 to 0.75472, saving model to model/mfcc6/LGD_semi_fold3_resnet1.h5\n",
      "Epoch 5/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.5974 - acc: 0.9165 - val_loss: 1.3493 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75472\n",
      "Epoch 6/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.5682 - acc: 0.9107 - val_loss: 1.3245 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75472\n",
      "Epoch 7/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.5393 - acc: 0.9188 - val_loss: 1.2920 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.75472 to 0.77089, saving model to model/mfcc6/LGD_semi_fold3_resnet1.h5\n",
      "Epoch 8/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.5001 - acc: 0.9250 - val_loss: 1.2748 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.77089\n",
      "Epoch 9/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.4864 - acc: 0.9324 - val_loss: 1.2670 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.77089\n",
      "Epoch 10/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.4673 - acc: 0.9384 - val_loss: 1.2592 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.77089\n",
      "Epoch 11/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.4353 - acc: 0.9433 - val_loss: 1.2570 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.77089 to 0.77628, saving model to model/mfcc6/LGD_semi_fold3_resnet1.h5\n",
      "Epoch 12/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.4312 - acc: 0.9498 - val_loss: 1.2950 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.77628\n",
      "Epoch 13/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.4245 - acc: 0.9493 - val_loss: 1.3240 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.77628\n",
      "Epoch 14/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.4034 - acc: 0.9607 - val_loss: 1.2980 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.77628\n",
      "Epoch 15/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.4018 - acc: 0.9603 - val_loss: 1.2819 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.77628\n",
      "Epoch 16/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3858 - acc: 0.9661 - val_loss: 1.2959 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.77628\n",
      "Epoch 17/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3695 - acc: 0.9701 - val_loss: 1.2615 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.77628\n",
      "Epoch 18/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3628 - acc: 0.9730 - val_loss: 1.3411 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.77628\n",
      "Epoch 19/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3550 - acc: 0.9770 - val_loss: 1.3270 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.77628\n",
      "Epoch 20/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3598 - acc: 0.9741 - val_loss: 1.3674 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.77628\n",
      "Epoch 21/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3454 - acc: 0.9799 - val_loss: 1.3347 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.77628\n",
      "Epoch 22/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3329 - acc: 0.9853 - val_loss: 1.3325 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.77628\n",
      "Epoch 23/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3322 - acc: 0.9842 - val_loss: 1.3751 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.77628\n",
      "Epoch 24/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3259 - acc: 0.9877 - val_loss: 1.3851 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.77628\n",
      "Epoch 25/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3242 - acc: 0.9875 - val_loss: 1.4038 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.77628\n",
      "Epoch 26/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3162 - acc: 0.9902 - val_loss: 1.3923 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.77628\n",
      "Epoch 27/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3076 - acc: 0.9935 - val_loss: 1.3754 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.77628\n",
      "Epoch 28/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3084 - acc: 0.9917 - val_loss: 1.3804 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.77628\n",
      "Epoch 29/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.3049 - acc: 0.9926 - val_loss: 1.4379 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.77628\n",
      "Epoch 30/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2980 - acc: 0.9949 - val_loss: 1.4080 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.77628\n",
      "Epoch 31/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2974 - acc: 0.9931 - val_loss: 1.4177 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.77628\n",
      "Epoch 32/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2905 - acc: 0.9969 - val_loss: 1.4693 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.77628\n",
      "Epoch 33/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2886 - acc: 0.9967 - val_loss: 1.4085 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.77628\n",
      "Epoch 34/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2861 - acc: 0.9975 - val_loss: 1.4152 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.77628\n",
      "Epoch 35/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2830 - acc: 0.9971 - val_loss: 1.4469 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.77628\n",
      "Epoch 36/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2814 - acc: 0.9978 - val_loss: 1.3647 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.77628 to 0.78437, saving model to model/mfcc6/LGD_semi_fold3_resnet1.h5\n",
      "Epoch 37/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2802 - acc: 0.9973 - val_loss: 1.4431 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.78437\n",
      "Epoch 38/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2779 - acc: 0.9980 - val_loss: 1.4242 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.78437\n",
      "Epoch 39/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2785 - acc: 0.9969 - val_loss: 1.4447 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.78437\n",
      "Epoch 40/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2747 - acc: 0.9980 - val_loss: 1.5240 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.78437\n",
      "Epoch 41/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2726 - acc: 0.9987 - val_loss: 1.5021 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.78437\n",
      "Epoch 42/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2698 - acc: 0.9991 - val_loss: 1.4934 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.78437\n",
      "Epoch 43/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2679 - acc: 0.9991 - val_loss: 1.5009 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.78437\n",
      "Epoch 44/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2670 - acc: 0.9989 - val_loss: 1.4136 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.78437\n",
      "Epoch 45/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2685 - acc: 0.9962 - val_loss: 1.4950 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.78437\n",
      "Epoch 46/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2691 - acc: 0.9969 - val_loss: 1.5657 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.78437\n",
      "Epoch 47/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2608 - acc: 0.9980 - val_loss: 1.4575 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.78437\n",
      "Epoch 48/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2576 - acc: 0.9991 - val_loss: 1.4081 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.78437\n",
      "Epoch 49/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2554 - acc: 0.9993 - val_loss: 1.5620 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.78437\n",
      "Epoch 50/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2554 - acc: 0.9980 - val_loss: 1.5446 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.78437\n",
      "Epoch 51/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2526 - acc: 0.9987 - val_loss: 1.4925 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.78437\n",
      "Epoch 52/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2618 - acc: 0.9967 - val_loss: 1.4993 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.78437\n",
      "Epoch 53/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2582 - acc: 0.9964 - val_loss: 1.5330 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.78437\n",
      "Epoch 54/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2520 - acc: 0.9980 - val_loss: 1.4877 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.78437\n",
      "Epoch 55/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2464 - acc: 0.9996 - val_loss: 1.6193 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.78437\n",
      "Epoch 56/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2465 - acc: 0.9993 - val_loss: 1.5447 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.78437\n",
      "Epoch 57/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2425 - acc: 1.0000 - val_loss: 1.4978 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.78437\n",
      "Epoch 58/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2414 - acc: 0.9996 - val_loss: 1.5989 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.78437\n",
      "Epoch 59/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2396 - acc: 0.9996 - val_loss: 1.6121 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.78437\n",
      "Epoch 60/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2380 - acc: 0.9996 - val_loss: 1.6213 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.78437\n",
      "Epoch 61/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2432 - acc: 0.9991 - val_loss: 1.4250 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.78437\n",
      "Epoch 62/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2356 - acc: 0.9993 - val_loss: 1.5303 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.78437\n",
      "Epoch 63/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2329 - acc: 0.9998 - val_loss: 1.6541 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.78437\n",
      "Epoch 64/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2309 - acc: 1.0000 - val_loss: 1.6530 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.78437\n",
      "Epoch 65/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2312 - acc: 0.9996 - val_loss: 1.5365 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.78437\n",
      "Epoch 66/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2399 - acc: 0.9973 - val_loss: 1.5480 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.78437\n",
      "Epoch 67/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2580 - acc: 0.9906 - val_loss: 1.6870 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.78437\n",
      "Epoch 68/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2474 - acc: 0.9922 - val_loss: 1.4852 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.78437\n",
      "Epoch 69/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2343 - acc: 0.9971 - val_loss: 1.6198 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.78437\n",
      "Epoch 70/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2278 - acc: 0.9989 - val_loss: 1.5971 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.78437\n",
      "Epoch 71/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2264 - acc: 0.9996 - val_loss: 1.5782 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.78437\n",
      "Epoch 72/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2242 - acc: 1.0000 - val_loss: 1.5767 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.78437\n",
      "Epoch 73/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2243 - acc: 0.9993 - val_loss: 1.5839 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.78437\n",
      "Epoch 74/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2231 - acc: 1.0000 - val_loss: 1.5590 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.78437\n",
      "Epoch 75/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2237 - acc: 0.9991 - val_loss: 1.5461 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.78437\n",
      "Epoch 76/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2217 - acc: 0.9996 - val_loss: 1.5685 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.78437\n",
      "Epoch 77/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2210 - acc: 0.9998 - val_loss: 1.6067 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.78437\n",
      "Epoch 78/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2193 - acc: 1.0000 - val_loss: 1.5875 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.78437\n",
      "Epoch 79/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2191 - acc: 0.9998 - val_loss: 1.5542 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.78437\n",
      "Epoch 80/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2180 - acc: 1.0000 - val_loss: 1.5548 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.78437\n",
      "Epoch 81/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2178 - acc: 0.9996 - val_loss: 1.5938 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.78437\n",
      "Epoch 82/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2163 - acc: 1.0000 - val_loss: 1.5867 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.78437\n",
      "Epoch 83/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2154 - acc: 1.0000 - val_loss: 1.5920 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.78437\n",
      "Epoch 84/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2151 - acc: 0.9998 - val_loss: 1.6198 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.78437\n",
      "Epoch 85/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2149 - acc: 0.9996 - val_loss: 1.5447 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.78437\n",
      "Epoch 86/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2134 - acc: 1.0000 - val_loss: 1.5066 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.78437\n",
      "Epoch 87/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2130 - acc: 0.9998 - val_loss: 1.5044 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.78437\n",
      "Epoch 88/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2116 - acc: 1.0000 - val_loss: 1.6351 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.78437\n",
      "Epoch 89/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2102 - acc: 1.0000 - val_loss: 1.5969 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.78437\n",
      "Epoch 90/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2107 - acc: 0.9993 - val_loss: 1.6395 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.78437\n",
      "Epoch 91/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2090 - acc: 0.9998 - val_loss: 1.6419 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.78437\n",
      "Epoch 92/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2081 - acc: 0.9996 - val_loss: 1.6300 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.78437\n",
      "Epoch 93/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2070 - acc: 1.0000 - val_loss: 1.6122 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.78437\n",
      "Epoch 94/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2059 - acc: 1.0000 - val_loss: 1.5695 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.78437\n",
      "Epoch 95/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2052 - acc: 0.9998 - val_loss: 1.5667 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.78437\n",
      "Epoch 96/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2037 - acc: 1.0000 - val_loss: 1.5853 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.78437\n",
      "Epoch 97/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2030 - acc: 1.0000 - val_loss: 1.5614 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.78437\n",
      "Epoch 98/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2015 - acc: 1.0000 - val_loss: 1.5644 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.78437\n",
      "Epoch 99/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2009 - acc: 0.9996 - val_loss: 1.6248 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.78437\n",
      "Epoch 100/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.1996 - acc: 1.0000 - val_loss: 1.6051 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.78437\n",
      "Epoch 101/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.1989 - acc: 0.9998 - val_loss: 1.5452 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.78437\n",
      "Epoch 102/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.2006 - acc: 0.9991 - val_loss: 1.5941 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.78437\n",
      "Epoch 103/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.1972 - acc: 1.0000 - val_loss: 1.6266 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.78437\n",
      "Epoch 104/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.1959 - acc: 1.0000 - val_loss: 1.5803 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.78437\n",
      "Epoch 105/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.1943 - acc: 1.0000 - val_loss: 1.5908 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.78437\n",
      "Epoch 106/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.1935 - acc: 1.0000 - val_loss: 1.6519 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.78437\n",
      "Epoch 107/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.1920 - acc: 1.0000 - val_loss: 1.6529 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.78437\n",
      "Epoch 108/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.1914 - acc: 0.9998 - val_loss: 1.6187 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.78437\n",
      "Epoch 109/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.1903 - acc: 0.9998 - val_loss: 1.6611 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.78437\n",
      "Epoch 110/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.1896 - acc: 0.9996 - val_loss: 1.5787 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.78437\n",
      "Epoch 111/3000\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 0.1880 - acc: 1.0000 - val_loss: 1.5915 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.78437\n",
      "Epoch 00111: early stopping\n",
      "(3339, 64, 431, 1) (3339, 41)\n",
      "===train verified_4===\n",
      "using resnet model: 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 64, 431, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_757 (Conv2D)             (None, 32, 216, 64)  3200        input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_729 (BatchN (None, 32, 216, 64)  256         conv2d_757[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_718 (Activation)     (None, 32, 216, 64)  0           batch_normalization_729[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 16, 108, 64)  0           activation_718[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_758 (Conv2D)             (None, 16, 108, 64)  36928       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_730 (BatchN (None, 16, 108, 64)  256         conv2d_758[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_719 (Activation)     (None, 16, 108, 64)  0           batch_normalization_730[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_759 (Conv2D)             (None, 16, 108, 64)  36928       activation_719[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_255 (Add)                   (None, 16, 108, 64)  0           max_pooling2d_12[0][0]           \n",
      "                                                                 conv2d_759[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_731 (BatchN (None, 16, 108, 64)  256         add_255[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_720 (Activation)     (None, 16, 108, 64)  0           batch_normalization_731[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_760 (Conv2D)             (None, 16, 108, 64)  36928       activation_720[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_732 (BatchN (None, 16, 108, 64)  256         conv2d_760[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_721 (Activation)     (None, 16, 108, 64)  0           batch_normalization_732[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_761 (Conv2D)             (None, 16, 108, 64)  36928       activation_721[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_256 (Add)                   (None, 16, 108, 64)  0           add_255[0][0]                    \n",
      "                                                                 conv2d_761[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_733 (BatchN (None, 16, 108, 64)  256         add_256[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_722 (Activation)     (None, 16, 108, 64)  0           batch_normalization_733[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_762 (Conv2D)             (None, 16, 108, 64)  36928       activation_722[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_734 (BatchN (None, 16, 108, 64)  256         conv2d_762[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_723 (Activation)     (None, 16, 108, 64)  0           batch_normalization_734[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_763 (Conv2D)             (None, 16, 108, 64)  36928       activation_723[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_257 (Add)                   (None, 16, 108, 64)  0           add_256[0][0]                    \n",
      "                                                                 conv2d_763[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_735 (BatchN (None, 16, 108, 64)  256         add_257[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_724 (Activation)     (None, 16, 108, 64)  0           batch_normalization_735[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_764 (Conv2D)             (None, 8, 54, 128)   73856       activation_724[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_736 (BatchN (None, 8, 54, 128)   512         conv2d_764[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_725 (Activation)     (None, 8, 54, 128)   0           batch_normalization_736[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_766 (Conv2D)             (None, 8, 54, 128)   8320        add_257[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_765 (Conv2D)             (None, 8, 54, 128)   147584      activation_725[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_258 (Add)                   (None, 8, 54, 128)   0           conv2d_766[0][0]                 \n",
      "                                                                 conv2d_765[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_737 (BatchN (None, 8, 54, 128)   512         add_258[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_726 (Activation)     (None, 8, 54, 128)   0           batch_normalization_737[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_767 (Conv2D)             (None, 8, 54, 128)   147584      activation_726[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_738 (BatchN (None, 8, 54, 128)   512         conv2d_767[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_727 (Activation)     (None, 8, 54, 128)   0           batch_normalization_738[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_768 (Conv2D)             (None, 8, 54, 128)   147584      activation_727[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_259 (Add)                   (None, 8, 54, 128)   0           add_258[0][0]                    \n",
      "                                                                 conv2d_768[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_739 (BatchN (None, 8, 54, 128)   512         add_259[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_728 (Activation)     (None, 8, 54, 128)   0           batch_normalization_739[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_769 (Conv2D)             (None, 8, 54, 128)   147584      activation_728[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_740 (BatchN (None, 8, 54, 128)   512         conv2d_769[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_729 (Activation)     (None, 8, 54, 128)   0           batch_normalization_740[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_770 (Conv2D)             (None, 8, 54, 128)   147584      activation_729[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_260 (Add)                   (None, 8, 54, 128)   0           add_259[0][0]                    \n",
      "                                                                 conv2d_770[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_741 (BatchN (None, 8, 54, 128)   512         add_260[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_730 (Activation)     (None, 8, 54, 128)   0           batch_normalization_741[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_771 (Conv2D)             (None, 8, 54, 128)   147584      activation_730[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_742 (BatchN (None, 8, 54, 128)   512         conv2d_771[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_731 (Activation)     (None, 8, 54, 128)   0           batch_normalization_742[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_772 (Conv2D)             (None, 8, 54, 128)   147584      activation_731[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_261 (Add)                   (None, 8, 54, 128)   0           add_260[0][0]                    \n",
      "                                                                 conv2d_772[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_743 (BatchN (None, 8, 54, 128)   512         add_261[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_732 (Activation)     (None, 8, 54, 128)   0           batch_normalization_743[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_773 (Conv2D)             (None, 4, 27, 256)   295168      activation_732[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_744 (BatchN (None, 4, 27, 256)   1024        conv2d_773[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_733 (Activation)     (None, 4, 27, 256)   0           batch_normalization_744[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_775 (Conv2D)             (None, 4, 27, 256)   33024       add_261[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_774 (Conv2D)             (None, 4, 27, 256)   590080      activation_733[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_262 (Add)                   (None, 4, 27, 256)   0           conv2d_775[0][0]                 \n",
      "                                                                 conv2d_774[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_745 (BatchN (None, 4, 27, 256)   1024        add_262[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_734 (Activation)     (None, 4, 27, 256)   0           batch_normalization_745[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_776 (Conv2D)             (None, 4, 27, 256)   590080      activation_734[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_746 (BatchN (None, 4, 27, 256)   1024        conv2d_776[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_735 (Activation)     (None, 4, 27, 256)   0           batch_normalization_746[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_777 (Conv2D)             (None, 4, 27, 256)   590080      activation_735[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_263 (Add)                   (None, 4, 27, 256)   0           add_262[0][0]                    \n",
      "                                                                 conv2d_777[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_747 (BatchN (None, 4, 27, 256)   1024        add_263[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_736 (Activation)     (None, 4, 27, 256)   0           batch_normalization_747[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_778 (Conv2D)             (None, 4, 27, 256)   590080      activation_736[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_748 (BatchN (None, 4, 27, 256)   1024        conv2d_778[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_737 (Activation)     (None, 4, 27, 256)   0           batch_normalization_748[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_779 (Conv2D)             (None, 4, 27, 256)   590080      activation_737[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_264 (Add)                   (None, 4, 27, 256)   0           add_263[0][0]                    \n",
      "                                                                 conv2d_779[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_749 (BatchN (None, 4, 27, 256)   1024        add_264[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_738 (Activation)     (None, 4, 27, 256)   0           batch_normalization_749[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_780 (Conv2D)             (None, 4, 27, 256)   590080      activation_738[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_750 (BatchN (None, 4, 27, 256)   1024        conv2d_780[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_739 (Activation)     (None, 4, 27, 256)   0           batch_normalization_750[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_781 (Conv2D)             (None, 4, 27, 256)   590080      activation_739[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_265 (Add)                   (None, 4, 27, 256)   0           add_264[0][0]                    \n",
      "                                                                 conv2d_781[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_751 (BatchN (None, 4, 27, 256)   1024        add_265[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_740 (Activation)     (None, 4, 27, 256)   0           batch_normalization_751[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_782 (Conv2D)             (None, 4, 27, 256)   590080      activation_740[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_752 (BatchN (None, 4, 27, 256)   1024        conv2d_782[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_741 (Activation)     (None, 4, 27, 256)   0           batch_normalization_752[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_783 (Conv2D)             (None, 4, 27, 256)   590080      activation_741[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_266 (Add)                   (None, 4, 27, 256)   0           add_265[0][0]                    \n",
      "                                                                 conv2d_783[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_753 (BatchN (None, 4, 27, 256)   1024        add_266[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_742 (Activation)     (None, 4, 27, 256)   0           batch_normalization_753[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_784 (Conv2D)             (None, 4, 27, 256)   590080      activation_742[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_754 (BatchN (None, 4, 27, 256)   1024        conv2d_784[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_743 (Activation)     (None, 4, 27, 256)   0           batch_normalization_754[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_785 (Conv2D)             (None, 4, 27, 256)   590080      activation_743[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_267 (Add)                   (None, 4, 27, 256)   0           add_266[0][0]                    \n",
      "                                                                 conv2d_785[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_755 (BatchN (None, 4, 27, 256)   1024        add_267[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_744 (Activation)     (None, 4, 27, 256)   0           batch_normalization_755[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_786 (Conv2D)             (None, 2, 14, 512)   1180160     activation_744[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_756 (BatchN (None, 2, 14, 512)   2048        conv2d_786[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_745 (Activation)     (None, 2, 14, 512)   0           batch_normalization_756[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_788 (Conv2D)             (None, 2, 14, 512)   131584      add_267[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_787 (Conv2D)             (None, 2, 14, 512)   2359808     activation_745[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_268 (Add)                   (None, 2, 14, 512)   0           conv2d_788[0][0]                 \n",
      "                                                                 conv2d_787[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_757 (BatchN (None, 2, 14, 512)   2048        add_268[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_746 (Activation)     (None, 2, 14, 512)   0           batch_normalization_757[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_789 (Conv2D)             (None, 2, 14, 512)   2359808     activation_746[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_758 (BatchN (None, 2, 14, 512)   2048        conv2d_789[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_747 (Activation)     (None, 2, 14, 512)   0           batch_normalization_758[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_790 (Conv2D)             (None, 2, 14, 512)   2359808     activation_747[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_269 (Add)                   (None, 2, 14, 512)   0           add_268[0][0]                    \n",
      "                                                                 conv2d_790[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_759 (BatchN (None, 2, 14, 512)   2048        add_269[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_748 (Activation)     (None, 2, 14, 512)   0           batch_normalization_759[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_791 (Conv2D)             (None, 2, 14, 512)   2359808     activation_748[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_760 (BatchN (None, 2, 14, 512)   2048        conv2d_791[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_749 (Activation)     (None, 2, 14, 512)   0           batch_normalization_760[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_792 (Conv2D)             (None, 2, 14, 512)   2359808     activation_749[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_270 (Add)                   (None, 2, 14, 512)   0           add_269[0][0]                    \n",
      "                                                                 conv2d_792[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_761 (BatchN (None, 2, 14, 512)   2048        add_270[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_750 (Activation)     (None, 2, 14, 512)   0           batch_normalization_761[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 1, 1, 512)    0           activation_750[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1, 1, 512)    0           average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 512)          0           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 58)           29754       flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_762 (BatchN (None, 58)           232         dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 58)           0           batch_normalization_762[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 41)           2419        dropout_24[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,332,757\n",
      "Trainable params: 21,317,409\n",
      "Non-trainable params: 15,348\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3339 samples, validate on 371 samples\n",
      "Epoch 1/3000\n",
      "3339/3339 [==============================] - 12s 4ms/step - loss: 4.8841 - acc: 0.1836 - val_loss: 5.6297 - val_acc: 0.1995\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.19946, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 2/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 4.0700 - acc: 0.3453 - val_loss: 4.1519 - val_acc: 0.3100\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.19946 to 0.30997, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 3/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 3.7413 - acc: 0.4241 - val_loss: 4.3918 - val_acc: 0.3019\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.30997\n",
      "Epoch 4/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 3.3293 - acc: 0.4972 - val_loss: 3.7672 - val_acc: 0.3612\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.30997 to 0.36119, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 5/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 3.0248 - acc: 0.5714 - val_loss: 3.6710 - val_acc: 0.3693\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.36119 to 0.36927, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 6/3000\n",
      "3339/3339 [==============================] - 6s 2ms/step - loss: 2.8316 - acc: 0.5960 - val_loss: 3.1082 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.36927 to 0.50135, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 7/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 2.6161 - acc: 0.6559 - val_loss: 3.2810 - val_acc: 0.4825\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.50135\n",
      "Epoch 8/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 2.4784 - acc: 0.6751 - val_loss: 3.0115 - val_acc: 0.5418\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.50135 to 0.54178, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 9/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 2.2307 - acc: 0.7308 - val_loss: 2.7076 - val_acc: 0.6119\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.54178 to 0.61186, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 10/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 2.0213 - acc: 0.7649 - val_loss: 3.1269 - val_acc: 0.4906\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.61186\n",
      "Epoch 11/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 2.0154 - acc: 0.7628 - val_loss: 3.2618 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.61186\n",
      "Epoch 12/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.8461 - acc: 0.7984 - val_loss: 2.9182 - val_acc: 0.5849\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.61186\n",
      "Epoch 13/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.8740 - acc: 0.7778 - val_loss: 2.7372 - val_acc: 0.5795\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.61186\n",
      "Epoch 14/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.6914 - acc: 0.8164 - val_loss: 2.6643 - val_acc: 0.5984\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.61186\n",
      "Epoch 15/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.9050 - acc: 0.7538 - val_loss: 3.4218 - val_acc: 0.4582\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.61186\n",
      "Epoch 16/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.6825 - acc: 0.8110 - val_loss: 3.0605 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.61186\n",
      "Epoch 17/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.5561 - acc: 0.8461 - val_loss: 2.3836 - val_acc: 0.6550\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.61186 to 0.65499, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 18/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.4024 - acc: 0.8706 - val_loss: 2.3153 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.65499 to 0.65768, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 19/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.5769 - acc: 0.8185 - val_loss: 2.3862 - val_acc: 0.6226\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.65768\n",
      "Epoch 20/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.3477 - acc: 0.8757 - val_loss: 2.3215 - val_acc: 0.6388\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.65768\n",
      "Epoch 21/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.4845 - acc: 0.8323 - val_loss: 2.3261 - val_acc: 0.6604\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.65768 to 0.66038, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 22/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.5154 - acc: 0.8305 - val_loss: 2.2082 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.66038\n",
      "Epoch 23/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.2571 - acc: 0.8988 - val_loss: 1.9381 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.66038 to 0.71429, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 24/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.1626 - acc: 0.9167 - val_loss: 1.8956 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.71429 to 0.71968, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 25/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.1039 - acc: 0.9197 - val_loss: 1.6241 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.71968 to 0.77358, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 26/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.2360 - acc: 0.8784 - val_loss: 2.4993 - val_acc: 0.5957\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.77358\n",
      "Epoch 27/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.2957 - acc: 0.8616 - val_loss: 2.1392 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.77358\n",
      "Epoch 28/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.1915 - acc: 0.8880 - val_loss: 1.9988 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.77358\n",
      "Epoch 29/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.0755 - acc: 0.9137 - val_loss: 1.7406 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.77358\n",
      "Epoch 30/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.9755 - acc: 0.9437 - val_loss: 1.8482 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.77358\n",
      "Epoch 31/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.9082 - acc: 0.9533 - val_loss: 1.6780 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.77358\n",
      "Epoch 32/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.9085 - acc: 0.9461 - val_loss: 2.7575 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.77358\n",
      "Epoch 33/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.4977 - acc: 0.7829 - val_loss: 3.6764 - val_acc: 0.3801\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.77358\n",
      "Epoch 34/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.2660 - acc: 0.8509 - val_loss: 2.4080 - val_acc: 0.6011\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.77358\n",
      "Epoch 35/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.0578 - acc: 0.9081 - val_loss: 2.4266 - val_acc: 0.6523\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.77358\n",
      "Epoch 36/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.9871 - acc: 0.9293 - val_loss: 1.9956 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.77358\n",
      "Epoch 37/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.9415 - acc: 0.9365 - val_loss: 1.6812 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.77358\n",
      "Epoch 38/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.9067 - acc: 0.9416 - val_loss: 1.6144 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.77358\n",
      "Epoch 39/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8579 - acc: 0.9518 - val_loss: 1.5349 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.77358 to 0.77358, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 40/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8058 - acc: 0.9608 - val_loss: 1.4468 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.77358 to 0.78706, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 41/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7553 - acc: 0.9701 - val_loss: 1.5572 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.78706\n",
      "Epoch 42/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7560 - acc: 0.9665 - val_loss: 1.4484 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.78706\n",
      "Epoch 43/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7240 - acc: 0.9730 - val_loss: 1.4151 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.78706\n",
      "Epoch 44/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6954 - acc: 0.9775 - val_loss: 1.6073 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.78706\n",
      "Epoch 45/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7151 - acc: 0.9695 - val_loss: 1.4914 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.78706\n",
      "Epoch 46/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7467 - acc: 0.9527 - val_loss: 1.5085 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.78706 to 0.78706, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 47/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6893 - acc: 0.9689 - val_loss: 1.7188 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.78706\n",
      "Epoch 48/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.9164 - acc: 0.9087 - val_loss: 1.9560 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.78706\n",
      "Epoch 49/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8954 - acc: 0.9087 - val_loss: 1.7549 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.78706\n",
      "Epoch 50/3000\n",
      "3339/3339 [==============================] - 6s 2ms/step - loss: 0.8614 - acc: 0.9245 - val_loss: 1.8500 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.78706\n",
      "Epoch 51/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8357 - acc: 0.9335 - val_loss: 1.8465 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.78706\n",
      "Epoch 52/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7920 - acc: 0.9416 - val_loss: 1.8095 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.78706\n",
      "Epoch 53/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8509 - acc: 0.9284 - val_loss: 2.0093 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.78706\n",
      "Epoch 54/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7377 - acc: 0.9590 - val_loss: 1.6355 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.78706\n",
      "Epoch 55/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6674 - acc: 0.9742 - val_loss: 1.4732 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.78706\n",
      "Epoch 56/3000\n",
      "3339/3339 [==============================] - 6s 2ms/step - loss: 0.6738 - acc: 0.9739 - val_loss: 1.4963 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.78706 to 0.79515, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 57/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6004 - acc: 0.9889 - val_loss: 1.6595 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.79515\n",
      "Epoch 58/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8035 - acc: 0.9335 - val_loss: 2.1610 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.79515\n",
      "Epoch 59/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6984 - acc: 0.9599 - val_loss: 1.5988 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.79515\n",
      "Epoch 60/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7117 - acc: 0.9512 - val_loss: 2.1010 - val_acc: 0.6792\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.79515\n",
      "Epoch 61/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8647 - acc: 0.9191 - val_loss: 2.0854 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.79515\n",
      "Epoch 62/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7117 - acc: 0.9563 - val_loss: 1.6937 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.79515\n",
      "Epoch 63/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5995 - acc: 0.9862 - val_loss: 1.5404 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.79515\n",
      "Epoch 64/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5734 - acc: 0.9901 - val_loss: 1.3477 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.79515 to 0.79515, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 65/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5453 - acc: 0.9916 - val_loss: 1.4914 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.79515\n",
      "Epoch 66/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5801 - acc: 0.9808 - val_loss: 1.4500 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.79515\n",
      "Epoch 67/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5758 - acc: 0.9772 - val_loss: 1.6550 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.79515\n",
      "Epoch 68/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8755 - acc: 0.8970 - val_loss: 2.5816 - val_acc: 0.5930\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.79515\n",
      "Epoch 69/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.9596 - acc: 0.8820 - val_loss: 2.6340 - val_acc: 0.5903\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.79515\n",
      "Epoch 70/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.9097 - acc: 0.9063 - val_loss: 2.6158 - val_acc: 0.6038\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.79515\n",
      "Epoch 71/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.0892 - acc: 0.8604 - val_loss: 3.3920 - val_acc: 0.5418\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.79515\n",
      "Epoch 72/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8580 - acc: 0.9245 - val_loss: 2.0193 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.79515\n",
      "Epoch 73/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8059 - acc: 0.9341 - val_loss: 1.7696 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.79515\n",
      "Epoch 74/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7067 - acc: 0.9620 - val_loss: 2.1826 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.79515\n",
      "Epoch 75/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7911 - acc: 0.9341 - val_loss: 1.8893 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.79515\n",
      "Epoch 76/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7201 - acc: 0.9551 - val_loss: 1.7402 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.79515\n",
      "Epoch 77/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8179 - acc: 0.9239 - val_loss: 2.2946 - val_acc: 0.6469\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.79515\n",
      "Epoch 78/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8864 - acc: 0.9152 - val_loss: 2.0832 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.79515\n",
      "Epoch 79/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6669 - acc: 0.9721 - val_loss: 1.7600 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.79515\n",
      "Epoch 80/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6299 - acc: 0.9775 - val_loss: 1.4946 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.79515\n",
      "Epoch 81/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5821 - acc: 0.9883 - val_loss: 1.4345 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.79515\n",
      "Epoch 82/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6019 - acc: 0.9787 - val_loss: 1.6621 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.79515\n",
      "Epoch 83/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5627 - acc: 0.9874 - val_loss: 1.4184 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.79515\n",
      "Epoch 84/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5257 - acc: 0.9940 - val_loss: 1.2615 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.79515 to 0.79784, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 85/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5230 - acc: 0.9898 - val_loss: 1.2788 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.79784 to 0.80323, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 86/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5118 - acc: 0.9901 - val_loss: 1.5178 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.80323\n",
      "Epoch 87/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4773 - acc: 0.9943 - val_loss: 1.2942 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.80323\n",
      "Epoch 88/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4819 - acc: 0.9910 - val_loss: 1.4698 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.80323\n",
      "Epoch 89/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5429 - acc: 0.9757 - val_loss: 1.8185 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.80323\n",
      "Epoch 90/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7271 - acc: 0.9323 - val_loss: 2.1805 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.80323\n",
      "Epoch 91/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6448 - acc: 0.9569 - val_loss: 1.6137 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.80323\n",
      "Epoch 92/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5994 - acc: 0.9692 - val_loss: 1.6066 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.80323\n",
      "Epoch 93/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5714 - acc: 0.9739 - val_loss: 1.5202 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.80323\n",
      "Epoch 94/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5067 - acc: 0.9892 - val_loss: 1.3749 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.80323\n",
      "Epoch 95/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5710 - acc: 0.9742 - val_loss: 1.7700 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.80323\n",
      "Epoch 96/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5131 - acc: 0.9817 - val_loss: 1.9591 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.80323\n",
      "Epoch 97/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7278 - acc: 0.9236 - val_loss: 2.5259 - val_acc: 0.6658\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.80323\n",
      "Epoch 98/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8213 - acc: 0.9099 - val_loss: 2.4558 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.80323\n",
      "Epoch 99/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8135 - acc: 0.9149 - val_loss: 2.0272 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.80323\n",
      "Epoch 100/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 1.0649 - acc: 0.8556 - val_loss: 4.2062 - val_acc: 0.5121\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.80323\n",
      "Epoch 101/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.9645 - acc: 0.8835 - val_loss: 2.2448 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.80323\n",
      "Epoch 102/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8395 - acc: 0.9248 - val_loss: 1.8333 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.80323\n",
      "Epoch 103/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7004 - acc: 0.9560 - val_loss: 1.7291 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.80323\n",
      "Epoch 104/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5863 - acc: 0.9817 - val_loss: 1.4441 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.80323\n",
      "Epoch 105/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5334 - acc: 0.9934 - val_loss: 1.2783 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.80323\n",
      "Epoch 106/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5015 - acc: 0.9979 - val_loss: 1.2398 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.80323\n",
      "Epoch 107/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4830 - acc: 0.9982 - val_loss: 1.2341 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.80323\n",
      "Epoch 108/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4683 - acc: 0.9976 - val_loss: 1.2585 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.80323\n",
      "Epoch 109/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5115 - acc: 0.9826 - val_loss: 1.5956 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.80323\n",
      "Epoch 110/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6109 - acc: 0.9557 - val_loss: 2.0169 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.80323\n",
      "Epoch 111/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5550 - acc: 0.9686 - val_loss: 1.5513 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.80323\n",
      "Epoch 112/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5418 - acc: 0.9748 - val_loss: 1.5979 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.80323\n",
      "Epoch 113/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.8176 - acc: 0.9060 - val_loss: 3.7863 - val_acc: 0.4636\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.80323\n",
      "Epoch 114/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7026 - acc: 0.9395 - val_loss: 1.8649 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.80323\n",
      "Epoch 115/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7114 - acc: 0.9404 - val_loss: 2.0185 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.80323\n",
      "Epoch 116/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7897 - acc: 0.9182 - val_loss: 1.9024 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.80323\n",
      "Epoch 117/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6018 - acc: 0.9686 - val_loss: 1.6591 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.80323\n",
      "Epoch 118/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5943 - acc: 0.9712 - val_loss: 1.5359 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.80323\n",
      "Epoch 119/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5327 - acc: 0.9808 - val_loss: 1.4992 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.80323\n",
      "Epoch 120/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6075 - acc: 0.9623 - val_loss: 1.7982 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.80323\n",
      "Epoch 121/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5332 - acc: 0.9817 - val_loss: 1.4268 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.80323\n",
      "Epoch 122/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5796 - acc: 0.9709 - val_loss: 1.7248 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.80323\n",
      "Epoch 123/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5038 - acc: 0.9856 - val_loss: 1.5080 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.80323\n",
      "Epoch 124/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6838 - acc: 0.9434 - val_loss: 1.8267 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.80323\n",
      "Epoch 125/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5523 - acc: 0.9784 - val_loss: 1.5021 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.80323\n",
      "Epoch 126/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5543 - acc: 0.9757 - val_loss: 1.5037 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.80323 to 0.80593, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 127/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5460 - acc: 0.9751 - val_loss: 1.5565 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.80593\n",
      "Epoch 128/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4954 - acc: 0.9862 - val_loss: 1.4753 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.80593\n",
      "Epoch 129/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5416 - acc: 0.9721 - val_loss: 2.1365 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.80593\n",
      "Epoch 130/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6574 - acc: 0.9452 - val_loss: 2.0369 - val_acc: 0.6792\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.80593\n",
      "Epoch 131/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5963 - acc: 0.9623 - val_loss: 2.0298 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.80593\n",
      "Epoch 132/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7150 - acc: 0.9380 - val_loss: 2.8915 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.80593\n",
      "Epoch 133/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7440 - acc: 0.9290 - val_loss: 1.9338 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.80593\n",
      "Epoch 134/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6720 - acc: 0.9518 - val_loss: 1.6469 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.80593\n",
      "Epoch 135/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6358 - acc: 0.9608 - val_loss: 1.6099 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.80593\n",
      "Epoch 136/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5864 - acc: 0.9689 - val_loss: 1.6646 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.80593\n",
      "Epoch 137/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5560 - acc: 0.9784 - val_loss: 1.6266 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.80593\n",
      "Epoch 138/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6122 - acc: 0.9635 - val_loss: 1.8346 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.80593\n",
      "Epoch 139/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7560 - acc: 0.9326 - val_loss: 1.7303 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.80593\n",
      "Epoch 140/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7113 - acc: 0.9383 - val_loss: 2.0422 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.80593\n",
      "Epoch 141/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.7091 - acc: 0.9440 - val_loss: 2.2529 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.80593\n",
      "Epoch 142/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5835 - acc: 0.9769 - val_loss: 1.4252 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.80593\n",
      "Epoch 143/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5065 - acc: 0.9925 - val_loss: 1.2822 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00143: val_acc improved from 0.80593 to 0.81132, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 144/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4661 - acc: 0.9973 - val_loss: 1.1928 - val_acc: 0.8356\n",
      "\n",
      "Epoch 00144: val_acc improved from 0.81132 to 0.83558, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 145/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4464 - acc: 0.9979 - val_loss: 1.3049 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.83558\n",
      "Epoch 146/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4403 - acc: 0.9949 - val_loss: 1.2009 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.83558\n",
      "Epoch 147/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4228 - acc: 0.9970 - val_loss: 1.2502 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.83558\n",
      "Epoch 148/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4053 - acc: 0.9994 - val_loss: 1.2008 - val_acc: 0.8437\n",
      "\n",
      "Epoch 00148: val_acc improved from 0.83558 to 0.84367, saving model to model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Epoch 149/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3936 - acc: 0.9994 - val_loss: 1.1784 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.84367\n",
      "Epoch 150/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4361 - acc: 0.9886 - val_loss: 1.5456 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.84367\n",
      "Epoch 151/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4206 - acc: 0.9940 - val_loss: 1.2787 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.84367\n",
      "Epoch 152/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3895 - acc: 0.9982 - val_loss: 1.2833 - val_acc: 0.8329\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.84367\n",
      "Epoch 153/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3767 - acc: 0.9979 - val_loss: 1.3054 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.84367\n",
      "Epoch 154/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3961 - acc: 0.9925 - val_loss: 1.4172 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.84367\n",
      "Epoch 155/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3788 - acc: 0.9964 - val_loss: 1.2209 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.84367\n",
      "Epoch 156/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3895 - acc: 0.9898 - val_loss: 1.4172 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.84367\n",
      "Epoch 157/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4324 - acc: 0.9808 - val_loss: 1.6636 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.84367\n",
      "Epoch 158/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4789 - acc: 0.9692 - val_loss: 1.8888 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.84367\n",
      "Epoch 159/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4314 - acc: 0.9790 - val_loss: 1.4213 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.84367\n",
      "Epoch 160/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4450 - acc: 0.9784 - val_loss: 1.4740 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.84367\n",
      "Epoch 161/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6768 - acc: 0.9257 - val_loss: 2.1726 - val_acc: 0.6765\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.84367\n",
      "Epoch 162/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6283 - acc: 0.9455 - val_loss: 1.9176 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.84367\n",
      "Epoch 163/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6163 - acc: 0.9473 - val_loss: 2.1162 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.84367\n",
      "Epoch 164/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5152 - acc: 0.9718 - val_loss: 1.5234 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.84367\n",
      "Epoch 165/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4877 - acc: 0.9736 - val_loss: 1.7802 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.84367\n",
      "Epoch 166/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4817 - acc: 0.9772 - val_loss: 1.4369 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.84367\n",
      "Epoch 167/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4589 - acc: 0.9811 - val_loss: 1.2510 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.84367\n",
      "Epoch 168/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4469 - acc: 0.9844 - val_loss: 1.3780 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.84367\n",
      "Epoch 169/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6066 - acc: 0.9458 - val_loss: 4.9982 - val_acc: 0.4636\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.84367\n",
      "Epoch 170/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4886 - acc: 0.9739 - val_loss: 1.7841 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.84367\n",
      "Epoch 171/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4492 - acc: 0.9835 - val_loss: 1.5321 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.84367\n",
      "Epoch 172/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4149 - acc: 0.9895 - val_loss: 1.2212 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.84367\n",
      "Epoch 173/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4698 - acc: 0.9784 - val_loss: 1.3249 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.84367\n",
      "Epoch 174/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4973 - acc: 0.9668 - val_loss: 1.9114 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.84367\n",
      "Epoch 175/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4188 - acc: 0.9919 - val_loss: 1.4820 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.84367\n",
      "Epoch 176/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4040 - acc: 0.9916 - val_loss: 1.4242 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.84367\n",
      "Epoch 177/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3926 - acc: 0.9919 - val_loss: 1.3461 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.84367\n",
      "Epoch 178/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3705 - acc: 0.9967 - val_loss: 1.3854 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.84367\n",
      "Epoch 179/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4609 - acc: 0.9704 - val_loss: 1.7884 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.84367\n",
      "Epoch 180/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4262 - acc: 0.9820 - val_loss: 1.5339 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.84367\n",
      "Epoch 181/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5362 - acc: 0.9563 - val_loss: 2.1021 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.84367\n",
      "Epoch 182/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4538 - acc: 0.9766 - val_loss: 1.8753 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.84367\n",
      "Epoch 183/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5719 - acc: 0.9452 - val_loss: 2.1428 - val_acc: 0.6792\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.84367\n",
      "Epoch 184/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5334 - acc: 0.9614 - val_loss: 2.7755 - val_acc: 0.5957\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.84367\n",
      "Epoch 185/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4783 - acc: 0.9757 - val_loss: 1.4368 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.84367\n",
      "Epoch 186/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4359 - acc: 0.9814 - val_loss: 1.5859 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.84367\n",
      "Epoch 187/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3913 - acc: 0.9937 - val_loss: 1.2136 - val_acc: 0.8329\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.84367\n",
      "Epoch 188/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3969 - acc: 0.9913 - val_loss: 1.5992 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.84367\n",
      "Epoch 189/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4020 - acc: 0.9865 - val_loss: 1.2529 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.84367\n",
      "Epoch 190/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3760 - acc: 0.9922 - val_loss: 1.3184 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.84367\n",
      "Epoch 191/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3597 - acc: 0.9943 - val_loss: 1.4488 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.84367\n",
      "Epoch 192/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3548 - acc: 0.9922 - val_loss: 1.2697 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.84367\n",
      "Epoch 193/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3325 - acc: 0.9976 - val_loss: 1.2871 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.84367\n",
      "Epoch 194/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4124 - acc: 0.9757 - val_loss: 2.1203 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.84367\n",
      "Epoch 195/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4425 - acc: 0.9704 - val_loss: 1.8205 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.84367\n",
      "Epoch 196/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4509 - acc: 0.9692 - val_loss: 1.6368 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.84367\n",
      "Epoch 197/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4029 - acc: 0.9829 - val_loss: 1.3583 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.84367\n",
      "Epoch 198/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4943 - acc: 0.9557 - val_loss: 1.5791 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.84367\n",
      "Epoch 199/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4476 - acc: 0.9763 - val_loss: 2.5980 - val_acc: 0.6226\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.84367\n",
      "Epoch 200/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4301 - acc: 0.9781 - val_loss: 1.5690 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.84367\n",
      "Epoch 201/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3945 - acc: 0.9853 - val_loss: 1.6429 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.84367\n",
      "Epoch 202/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5580 - acc: 0.9572 - val_loss: 2.8840 - val_acc: 0.6038\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.84367\n",
      "Epoch 203/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5805 - acc: 0.9362 - val_loss: 2.2890 - val_acc: 0.6280\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.84367\n",
      "Epoch 204/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4401 - acc: 0.9760 - val_loss: 1.5724 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.84367\n",
      "Epoch 205/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3757 - acc: 0.9970 - val_loss: 1.2262 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.84367\n",
      "Epoch 206/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3741 - acc: 0.9934 - val_loss: 1.3749 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.84367\n",
      "Epoch 207/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5002 - acc: 0.9617 - val_loss: 1.9496 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.84367\n",
      "Epoch 208/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5258 - acc: 0.9575 - val_loss: 1.8763 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.84367\n",
      "Epoch 209/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4245 - acc: 0.9835 - val_loss: 1.3648 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.84367\n",
      "Epoch 210/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4711 - acc: 0.9683 - val_loss: 1.4554 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.84367\n",
      "Epoch 211/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4637 - acc: 0.9706 - val_loss: 1.8846 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.84367\n",
      "Epoch 212/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4937 - acc: 0.9641 - val_loss: 1.6135 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.84367\n",
      "Epoch 213/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4089 - acc: 0.9886 - val_loss: 1.4311 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.84367\n",
      "Epoch 214/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4177 - acc: 0.9817 - val_loss: 1.4554 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.84367\n",
      "Epoch 215/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4212 - acc: 0.9820 - val_loss: 1.8950 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.84367\n",
      "Epoch 216/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4335 - acc: 0.9742 - val_loss: 1.7008 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.84367\n",
      "Epoch 217/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4939 - acc: 0.9587 - val_loss: 1.5771 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.84367\n",
      "Epoch 218/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4536 - acc: 0.9751 - val_loss: 1.9163 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.84367\n",
      "Epoch 219/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3706 - acc: 0.9946 - val_loss: 1.3319 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.84367\n",
      "Epoch 220/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3416 - acc: 0.9997 - val_loss: 1.1557 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.84367\n",
      "Epoch 221/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3476 - acc: 0.9937 - val_loss: 1.4683 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.84367\n",
      "Epoch 222/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4526 - acc: 0.9745 - val_loss: 2.0954 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.84367\n",
      "Epoch 223/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4419 - acc: 0.9718 - val_loss: 1.6976 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.84367\n",
      "Epoch 224/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3625 - acc: 0.9952 - val_loss: 1.3478 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.84367\n",
      "Epoch 225/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3392 - acc: 0.9961 - val_loss: 1.2573 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.84367\n",
      "Epoch 226/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3725 - acc: 0.9850 - val_loss: 1.6342 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.84367\n",
      "Epoch 227/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5114 - acc: 0.9557 - val_loss: 1.5437 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.84367\n",
      "Epoch 228/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5006 - acc: 0.9578 - val_loss: 2.4058 - val_acc: 0.6361\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.84367\n",
      "Epoch 229/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4687 - acc: 0.9698 - val_loss: 1.7152 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.84367\n",
      "Epoch 230/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4111 - acc: 0.9826 - val_loss: 1.4978 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.84367\n",
      "Epoch 231/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4997 - acc: 0.9611 - val_loss: 1.8321 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.84367\n",
      "Epoch 232/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4663 - acc: 0.9689 - val_loss: 1.5545 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.84367\n",
      "Epoch 233/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4964 - acc: 0.9620 - val_loss: 1.8295 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.84367\n",
      "Epoch 234/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4156 - acc: 0.9787 - val_loss: 1.5399 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.84367\n",
      "Epoch 235/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3901 - acc: 0.9874 - val_loss: 1.3916 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.84367\n",
      "Epoch 236/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3799 - acc: 0.9892 - val_loss: 1.4411 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.84367\n",
      "Epoch 237/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3607 - acc: 0.9931 - val_loss: 1.6146 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.84367\n",
      "Epoch 238/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3860 - acc: 0.9820 - val_loss: 1.3822 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.84367\n",
      "Epoch 239/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4362 - acc: 0.9736 - val_loss: 1.6155 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.84367\n",
      "Epoch 240/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4176 - acc: 0.9766 - val_loss: 1.6766 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.84367\n",
      "Epoch 241/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4389 - acc: 0.9718 - val_loss: 1.8724 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.84367\n",
      "Epoch 242/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4251 - acc: 0.9766 - val_loss: 1.5250 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.84367\n",
      "Epoch 243/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3992 - acc: 0.9850 - val_loss: 1.5893 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.84367\n",
      "Epoch 244/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3501 - acc: 0.9940 - val_loss: 1.2495 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.84367\n",
      "Epoch 245/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3276 - acc: 0.9991 - val_loss: 1.2052 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.84367\n",
      "Epoch 246/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3166 - acc: 0.9994 - val_loss: 1.2415 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.84367\n",
      "Epoch 247/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3076 - acc: 0.9991 - val_loss: 1.1858 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.84367\n",
      "Epoch 248/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3120 - acc: 0.9958 - val_loss: 1.2062 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.84367\n",
      "Epoch 249/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3062 - acc: 0.9964 - val_loss: 1.2050 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.84367\n",
      "Epoch 250/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4531 - acc: 0.9653 - val_loss: 2.7659 - val_acc: 0.5822\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.84367\n",
      "Epoch 251/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4500 - acc: 0.9635 - val_loss: 2.9033 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.84367\n",
      "Epoch 252/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.6647 - acc: 0.9170 - val_loss: 3.5717 - val_acc: 0.5795\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.84367\n",
      "Epoch 253/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4540 - acc: 0.9674 - val_loss: 1.7744 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.84367\n",
      "Epoch 254/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4649 - acc: 0.9644 - val_loss: 1.9649 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.84367\n",
      "Epoch 255/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3753 - acc: 0.9889 - val_loss: 1.4359 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.84367\n",
      "Epoch 256/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3973 - acc: 0.9793 - val_loss: 1.7556 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.84367\n",
      "Epoch 257/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3498 - acc: 0.9931 - val_loss: 1.6074 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.84367\n",
      "Epoch 258/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4487 - acc: 0.9665 - val_loss: 2.0774 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.84367\n",
      "Epoch 259/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3887 - acc: 0.9829 - val_loss: 1.6132 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.84367\n",
      "Epoch 260/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3960 - acc: 0.9811 - val_loss: 1.7640 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.84367\n",
      "Epoch 261/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3578 - acc: 0.9877 - val_loss: 1.4754 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.84367\n",
      "Epoch 262/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3545 - acc: 0.9889 - val_loss: 1.4108 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.84367\n",
      "Epoch 263/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3230 - acc: 0.9949 - val_loss: 1.2771 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.84367\n",
      "Epoch 264/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3108 - acc: 0.9964 - val_loss: 1.2500 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.84367\n",
      "Epoch 265/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3557 - acc: 0.9823 - val_loss: 1.5174 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.84367\n",
      "Epoch 266/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3821 - acc: 0.9772 - val_loss: 1.6997 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.84367\n",
      "Epoch 267/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3901 - acc: 0.9751 - val_loss: 1.6052 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.84367\n",
      "Epoch 268/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3323 - acc: 0.9907 - val_loss: 1.2386 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.84367\n",
      "Epoch 269/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3095 - acc: 0.9964 - val_loss: 1.3248 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.84367\n",
      "Epoch 270/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3033 - acc: 0.9958 - val_loss: 1.2859 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00270: val_acc did not improve from 0.84367\n",
      "Epoch 271/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3687 - acc: 0.9775 - val_loss: 1.4197 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00271: val_acc did not improve from 0.84367\n",
      "Epoch 272/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3432 - acc: 0.9868 - val_loss: 1.4399 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00272: val_acc did not improve from 0.84367\n",
      "Epoch 273/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3633 - acc: 0.9787 - val_loss: 1.8387 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00273: val_acc did not improve from 0.84367\n",
      "Epoch 274/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4443 - acc: 0.9638 - val_loss: 1.9709 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00274: val_acc did not improve from 0.84367\n",
      "Epoch 275/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4070 - acc: 0.9742 - val_loss: 1.7511 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00275: val_acc did not improve from 0.84367\n",
      "Epoch 276/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3601 - acc: 0.9856 - val_loss: 1.6599 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00276: val_acc did not improve from 0.84367\n",
      "Epoch 277/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3239 - acc: 0.9940 - val_loss: 1.3101 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00277: val_acc did not improve from 0.84367\n",
      "Epoch 278/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3043 - acc: 0.9982 - val_loss: 1.2386 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00278: val_acc did not improve from 0.84367\n",
      "Epoch 279/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3179 - acc: 0.9931 - val_loss: 1.5001 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00279: val_acc did not improve from 0.84367\n",
      "Epoch 280/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3011 - acc: 0.9958 - val_loss: 1.3839 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00280: val_acc did not improve from 0.84367\n",
      "Epoch 281/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2941 - acc: 0.9961 - val_loss: 1.2984 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00281: val_acc did not improve from 0.84367\n",
      "Epoch 282/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2805 - acc: 0.9988 - val_loss: 1.2350 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00282: val_acc did not improve from 0.84367\n",
      "Epoch 283/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3876 - acc: 0.9763 - val_loss: 2.2846 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00283: val_acc did not improve from 0.84367\n",
      "Epoch 284/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5047 - acc: 0.9428 - val_loss: 2.9359 - val_acc: 0.6146\n",
      "\n",
      "Epoch 00284: val_acc did not improve from 0.84367\n",
      "Epoch 285/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3782 - acc: 0.9799 - val_loss: 1.9747 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00285: val_acc did not improve from 0.84367\n",
      "Epoch 286/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4737 - acc: 0.9557 - val_loss: 2.0382 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00286: val_acc did not improve from 0.84367\n",
      "Epoch 287/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5112 - acc: 0.9464 - val_loss: 2.1815 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00287: val_acc did not improve from 0.84367\n",
      "Epoch 288/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5012 - acc: 0.9491 - val_loss: 1.8478 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00288: val_acc did not improve from 0.84367\n",
      "Epoch 289/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3794 - acc: 0.9823 - val_loss: 1.5432 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00289: val_acc did not improve from 0.84367\n",
      "Epoch 290/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3408 - acc: 0.9931 - val_loss: 1.4077 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00290: val_acc did not improve from 0.84367\n",
      "Epoch 291/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3264 - acc: 0.9955 - val_loss: 1.4250 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00291: val_acc did not improve from 0.84367\n",
      "Epoch 292/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3881 - acc: 0.9766 - val_loss: 1.6416 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00292: val_acc did not improve from 0.84367\n",
      "Epoch 293/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4760 - acc: 0.9566 - val_loss: 1.9900 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00293: val_acc did not improve from 0.84367\n",
      "Epoch 294/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5547 - acc: 0.9401 - val_loss: 2.7651 - val_acc: 0.6550\n",
      "\n",
      "Epoch 00294: val_acc did not improve from 0.84367\n",
      "Epoch 295/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4846 - acc: 0.9608 - val_loss: 1.7880 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00295: val_acc did not improve from 0.84367\n",
      "Epoch 296/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4833 - acc: 0.9596 - val_loss: 1.8696 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00296: val_acc did not improve from 0.84367\n",
      "Epoch 297/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5613 - acc: 0.9353 - val_loss: 2.2644 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00297: val_acc did not improve from 0.84367\n",
      "Epoch 298/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4066 - acc: 0.9793 - val_loss: 1.5459 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00298: val_acc did not improve from 0.84367\n",
      "Epoch 299/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5119 - acc: 0.9593 - val_loss: 1.6683 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00299: val_acc did not improve from 0.84367\n",
      "Epoch 300/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4746 - acc: 0.9659 - val_loss: 1.8552 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00300: val_acc did not improve from 0.84367\n",
      "Epoch 301/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3727 - acc: 0.9928 - val_loss: 1.1924 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00301: val_acc did not improve from 0.84367\n",
      "Epoch 302/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3451 - acc: 0.9973 - val_loss: 1.1122 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00302: val_acc did not improve from 0.84367\n",
      "Epoch 303/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3288 - acc: 0.9985 - val_loss: 1.1213 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00303: val_acc did not improve from 0.84367\n",
      "Epoch 304/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3184 - acc: 0.9991 - val_loss: 1.1196 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00304: val_acc did not improve from 0.84367\n",
      "Epoch 305/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3214 - acc: 0.9970 - val_loss: 1.2093 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00305: val_acc did not improve from 0.84367\n",
      "Epoch 306/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3055 - acc: 0.9994 - val_loss: 1.1557 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00306: val_acc did not improve from 0.84367\n",
      "Epoch 307/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2994 - acc: 0.9991 - val_loss: 1.0970 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00307: val_acc did not improve from 0.84367\n",
      "Epoch 308/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2932 - acc: 0.9994 - val_loss: 1.0902 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00308: val_acc did not improve from 0.84367\n",
      "Epoch 309/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2853 - acc: 0.9997 - val_loss: 1.1951 - val_acc: 0.8329\n",
      "\n",
      "Epoch 00309: val_acc did not improve from 0.84367\n",
      "Epoch 310/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2864 - acc: 0.9985 - val_loss: 1.1837 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00310: val_acc did not improve from 0.84367\n",
      "Epoch 311/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2873 - acc: 0.9961 - val_loss: 1.2226 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00311: val_acc did not improve from 0.84367\n",
      "Epoch 312/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2756 - acc: 0.9988 - val_loss: 1.1023 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00312: val_acc did not improve from 0.84367\n",
      "Epoch 313/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2690 - acc: 0.9994 - val_loss: 1.1224 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00313: val_acc did not improve from 0.84367\n",
      "Epoch 314/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2634 - acc: 1.0000 - val_loss: 1.1078 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00314: val_acc did not improve from 0.84367\n",
      "Epoch 315/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2582 - acc: 1.0000 - val_loss: 1.0845 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00315: val_acc did not improve from 0.84367\n",
      "Epoch 316/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2539 - acc: 1.0000 - val_loss: 1.0705 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00316: val_acc did not improve from 0.84367\n",
      "Epoch 317/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2519 - acc: 0.9994 - val_loss: 1.1271 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00317: val_acc did not improve from 0.84367\n",
      "Epoch 318/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2486 - acc: 0.9994 - val_loss: 1.1078 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00318: val_acc did not improve from 0.84367\n",
      "Epoch 319/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2967 - acc: 0.9844 - val_loss: 1.8447 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00319: val_acc did not improve from 0.84367\n",
      "Epoch 320/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2820 - acc: 0.9919 - val_loss: 1.4568 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00320: val_acc did not improve from 0.84367\n",
      "Epoch 321/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2695 - acc: 0.9958 - val_loss: 1.3287 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00321: val_acc did not improve from 0.84367\n",
      "Epoch 322/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2641 - acc: 0.9955 - val_loss: 1.3321 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00322: val_acc did not improve from 0.84367\n",
      "Epoch 323/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2484 - acc: 0.9991 - val_loss: 1.2336 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00323: val_acc did not improve from 0.84367\n",
      "Epoch 324/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2481 - acc: 0.9973 - val_loss: 1.2134 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00324: val_acc did not improve from 0.84367\n",
      "Epoch 325/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2442 - acc: 0.9976 - val_loss: 1.6075 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00325: val_acc did not improve from 0.84367\n",
      "Epoch 326/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5372 - acc: 0.9149 - val_loss: 3.4342 - val_acc: 0.5553\n",
      "\n",
      "Epoch 00326: val_acc did not improve from 0.84367\n",
      "Epoch 327/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4956 - acc: 0.9374 - val_loss: 3.8069 - val_acc: 0.5606\n",
      "\n",
      "Epoch 00327: val_acc did not improve from 0.84367\n",
      "Epoch 328/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3740 - acc: 0.9748 - val_loss: 2.1327 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00328: val_acc did not improve from 0.84367\n",
      "Epoch 329/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4323 - acc: 0.9587 - val_loss: 2.1333 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00329: val_acc did not improve from 0.84367\n",
      "Epoch 330/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5189 - acc: 0.9416 - val_loss: 2.7328 - val_acc: 0.6469\n",
      "\n",
      "Epoch 00330: val_acc did not improve from 0.84367\n",
      "Epoch 331/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3680 - acc: 0.9820 - val_loss: 1.8145 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00331: val_acc did not improve from 0.84367\n",
      "Epoch 332/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3389 - acc: 0.9874 - val_loss: 1.7753 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00332: val_acc did not improve from 0.84367\n",
      "Epoch 333/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3231 - acc: 0.9925 - val_loss: 1.6259 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00333: val_acc did not improve from 0.84367\n",
      "Epoch 334/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3055 - acc: 0.9937 - val_loss: 1.6510 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00334: val_acc did not improve from 0.84367\n",
      "Epoch 335/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3523 - acc: 0.9793 - val_loss: 1.8065 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00335: val_acc did not improve from 0.84367\n",
      "Epoch 336/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3898 - acc: 0.9701 - val_loss: 1.7686 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00336: val_acc did not improve from 0.84367\n",
      "Epoch 337/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3642 - acc: 0.9787 - val_loss: 1.8480 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00337: val_acc did not improve from 0.84367\n",
      "Epoch 338/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3828 - acc: 0.9733 - val_loss: 1.6669 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00338: val_acc did not improve from 0.84367\n",
      "Epoch 339/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3263 - acc: 0.9883 - val_loss: 1.4538 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00339: val_acc did not improve from 0.84367\n",
      "Epoch 340/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3037 - acc: 0.9928 - val_loss: 1.3973 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00340: val_acc did not improve from 0.84367\n",
      "Epoch 341/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2929 - acc: 0.9964 - val_loss: 1.2639 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00341: val_acc did not improve from 0.84367\n",
      "Epoch 342/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2759 - acc: 0.9976 - val_loss: 1.2112 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00342: val_acc did not improve from 0.84367\n",
      "Epoch 343/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2675 - acc: 0.9994 - val_loss: 1.1352 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00343: val_acc did not improve from 0.84367\n",
      "Epoch 344/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2601 - acc: 0.9997 - val_loss: 1.1073 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00344: val_acc did not improve from 0.84367\n",
      "Epoch 345/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2540 - acc: 1.0000 - val_loss: 1.0912 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00345: val_acc did not improve from 0.84367\n",
      "Epoch 346/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2500 - acc: 0.9994 - val_loss: 1.0797 - val_acc: 0.8329\n",
      "\n",
      "Epoch 00346: val_acc did not improve from 0.84367\n",
      "Epoch 347/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2465 - acc: 0.9994 - val_loss: 1.1105 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00347: val_acc did not improve from 0.84367\n",
      "Epoch 348/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2417 - acc: 0.9997 - val_loss: 1.0847 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00348: val_acc did not improve from 0.84367\n",
      "Epoch 349/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2371 - acc: 0.9997 - val_loss: 1.1118 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00349: val_acc did not improve from 0.84367\n",
      "Epoch 350/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3605 - acc: 0.9724 - val_loss: 3.0091 - val_acc: 0.6038\n",
      "\n",
      "Epoch 00350: val_acc did not improve from 0.84367\n",
      "Epoch 351/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5312 - acc: 0.9251 - val_loss: 3.0854 - val_acc: 0.6146\n",
      "\n",
      "Epoch 00351: val_acc did not improve from 0.84367\n",
      "Epoch 352/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4670 - acc: 0.9488 - val_loss: 2.6539 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00352: val_acc did not improve from 0.84367\n",
      "Epoch 353/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5125 - acc: 0.9347 - val_loss: 3.8934 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00353: val_acc did not improve from 0.84367\n",
      "Epoch 354/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4457 - acc: 0.9539 - val_loss: 1.9286 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00354: val_acc did not improve from 0.84367\n",
      "Epoch 355/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3536 - acc: 0.9859 - val_loss: 1.5219 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00355: val_acc did not improve from 0.84367\n",
      "Epoch 356/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4586 - acc: 0.9554 - val_loss: 5.3161 - val_acc: 0.4852\n",
      "\n",
      "Epoch 00356: val_acc did not improve from 0.84367\n",
      "Epoch 357/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3657 - acc: 0.9796 - val_loss: 1.3028 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00357: val_acc did not improve from 0.84367\n",
      "Epoch 358/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3761 - acc: 0.9757 - val_loss: 1.5935 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00358: val_acc did not improve from 0.84367\n",
      "Epoch 359/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4835 - acc: 0.9476 - val_loss: 1.9520 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00359: val_acc did not improve from 0.84367\n",
      "Epoch 360/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4087 - acc: 0.9730 - val_loss: 1.7262 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00360: val_acc did not improve from 0.84367\n",
      "Epoch 361/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4212 - acc: 0.9677 - val_loss: 1.9463 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00361: val_acc did not improve from 0.84367\n",
      "Epoch 362/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4312 - acc: 0.9680 - val_loss: 1.6843 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00362: val_acc did not improve from 0.84367\n",
      "Epoch 363/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3758 - acc: 0.9796 - val_loss: 1.7141 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00363: val_acc did not improve from 0.84367\n",
      "Epoch 364/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3202 - acc: 0.9958 - val_loss: 1.4128 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00364: val_acc did not improve from 0.84367\n",
      "Epoch 365/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3307 - acc: 0.9889 - val_loss: 1.2592 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00365: val_acc did not improve from 0.84367\n",
      "Epoch 366/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3928 - acc: 0.9769 - val_loss: 1.4155 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00366: val_acc did not improve from 0.84367\n",
      "Epoch 367/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3667 - acc: 0.9796 - val_loss: 1.4092 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00367: val_acc did not improve from 0.84367\n",
      "Epoch 368/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3892 - acc: 0.9760 - val_loss: 1.4991 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00368: val_acc did not improve from 0.84367\n",
      "Epoch 369/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3376 - acc: 0.9883 - val_loss: 1.3522 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00369: val_acc did not improve from 0.84367\n",
      "Epoch 370/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4278 - acc: 0.9608 - val_loss: 1.6971 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00370: val_acc did not improve from 0.84367\n",
      "Epoch 371/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3601 - acc: 0.9835 - val_loss: 1.7484 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00371: val_acc did not improve from 0.84367\n",
      "Epoch 372/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3801 - acc: 0.9802 - val_loss: 1.5922 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00372: val_acc did not improve from 0.84367\n",
      "Epoch 373/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3298 - acc: 0.9919 - val_loss: 1.4654 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00373: val_acc did not improve from 0.84367\n",
      "Epoch 374/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3639 - acc: 0.9802 - val_loss: 1.6104 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00374: val_acc did not improve from 0.84367\n",
      "Epoch 375/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3637 - acc: 0.9841 - val_loss: 1.7145 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00375: val_acc did not improve from 0.84367\n",
      "Epoch 376/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3445 - acc: 0.9844 - val_loss: 1.6045 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00376: val_acc did not improve from 0.84367\n",
      "Epoch 377/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3420 - acc: 0.9847 - val_loss: 1.4099 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00377: val_acc did not improve from 0.84367\n",
      "Epoch 378/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4156 - acc: 0.9677 - val_loss: 1.9366 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00378: val_acc did not improve from 0.84367\n",
      "Epoch 379/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3907 - acc: 0.9712 - val_loss: 1.8569 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00379: val_acc did not improve from 0.84367\n",
      "Epoch 380/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3563 - acc: 0.9808 - val_loss: 1.5723 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00380: val_acc did not improve from 0.84367\n",
      "Epoch 381/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3582 - acc: 0.9847 - val_loss: 1.5962 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00381: val_acc did not improve from 0.84367\n",
      "Epoch 382/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3028 - acc: 0.9964 - val_loss: 1.3960 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00382: val_acc did not improve from 0.84367\n",
      "Epoch 383/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3910 - acc: 0.9715 - val_loss: 2.2160 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00383: val_acc did not improve from 0.84367\n",
      "Epoch 384/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3562 - acc: 0.9823 - val_loss: 1.6135 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00384: val_acc did not improve from 0.84367\n",
      "Epoch 385/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3220 - acc: 0.9925 - val_loss: 1.6760 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00385: val_acc did not improve from 0.84367\n",
      "Epoch 386/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3266 - acc: 0.9904 - val_loss: 1.5314 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00386: val_acc did not improve from 0.84367\n",
      "Epoch 387/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3028 - acc: 0.9943 - val_loss: 1.3864 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00387: val_acc did not improve from 0.84367\n",
      "Epoch 388/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2884 - acc: 0.9979 - val_loss: 1.3134 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00388: val_acc did not improve from 0.84367\n",
      "Epoch 389/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3916 - acc: 0.9724 - val_loss: 1.5847 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00389: val_acc did not improve from 0.84367\n",
      "Epoch 390/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4479 - acc: 0.9539 - val_loss: 1.7016 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00390: val_acc did not improve from 0.84367\n",
      "Epoch 391/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3864 - acc: 0.9730 - val_loss: 1.5130 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00391: val_acc did not improve from 0.84367\n",
      "Epoch 392/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3134 - acc: 0.9931 - val_loss: 1.4140 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00392: val_acc did not improve from 0.84367\n",
      "Epoch 393/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2978 - acc: 0.9967 - val_loss: 1.3615 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00393: val_acc did not improve from 0.84367\n",
      "Epoch 394/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3564 - acc: 0.9835 - val_loss: 1.8145 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00394: val_acc did not improve from 0.84367\n",
      "Epoch 395/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.5327 - acc: 0.9419 - val_loss: 2.7883 - val_acc: 0.6604\n",
      "\n",
      "Epoch 00395: val_acc did not improve from 0.84367\n",
      "Epoch 396/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4166 - acc: 0.9635 - val_loss: 1.4916 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00396: val_acc did not improve from 0.84367\n",
      "Epoch 397/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3263 - acc: 0.9904 - val_loss: 1.3081 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00397: val_acc did not improve from 0.84367\n",
      "Epoch 398/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3517 - acc: 0.9844 - val_loss: 1.7291 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00398: val_acc did not improve from 0.84367\n",
      "Epoch 399/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4533 - acc: 0.9614 - val_loss: 1.6899 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00399: val_acc did not improve from 0.84367\n",
      "Epoch 400/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3465 - acc: 0.9838 - val_loss: 1.5178 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00400: val_acc did not improve from 0.84367\n",
      "Epoch 401/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3169 - acc: 0.9934 - val_loss: 1.3605 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00401: val_acc did not improve from 0.84367\n",
      "Epoch 402/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2970 - acc: 0.9961 - val_loss: 1.3153 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00402: val_acc did not improve from 0.84367\n",
      "Epoch 403/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3439 - acc: 0.9817 - val_loss: 1.4834 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00403: val_acc did not improve from 0.84367\n",
      "Epoch 404/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.4089 - acc: 0.9695 - val_loss: 1.7251 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00404: val_acc did not improve from 0.84367\n",
      "Epoch 405/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3162 - acc: 0.9919 - val_loss: 1.6166 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00405: val_acc did not improve from 0.84367\n",
      "Epoch 406/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2987 - acc: 0.9961 - val_loss: 1.3525 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00406: val_acc did not improve from 0.84367\n",
      "Epoch 407/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2853 - acc: 0.9976 - val_loss: 1.2620 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00407: val_acc did not improve from 0.84367\n",
      "Epoch 408/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3372 - acc: 0.9817 - val_loss: 1.5685 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00408: val_acc did not improve from 0.84367\n",
      "Epoch 409/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3454 - acc: 0.9826 - val_loss: 1.4260 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00409: val_acc did not improve from 0.84367\n",
      "Epoch 410/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3446 - acc: 0.9844 - val_loss: 1.6186 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00410: val_acc did not improve from 0.84367\n",
      "Epoch 411/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3023 - acc: 0.9937 - val_loss: 1.4311 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00411: val_acc did not improve from 0.84367\n",
      "Epoch 412/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3754 - acc: 0.9709 - val_loss: 1.9254 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00412: val_acc did not improve from 0.84367\n",
      "Epoch 413/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3274 - acc: 0.9865 - val_loss: 1.6560 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00413: val_acc did not improve from 0.84367\n",
      "Epoch 414/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.3162 - acc: 0.9892 - val_loss: 1.4283 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00414: val_acc did not improve from 0.84367\n",
      "Epoch 415/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2883 - acc: 0.9955 - val_loss: 1.3644 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00415: val_acc did not improve from 0.84367\n",
      "Epoch 416/3000\n",
      "3339/3339 [==============================] - 7s 2ms/step - loss: 0.2872 - acc: 0.9931 - val_loss: 1.3499 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00416: val_acc did not improve from 0.84367\n",
      "Epoch 00416: early stopping\n",
      "(3712, 64, 431, 1) (3712, 41)\n",
      "===train semi_4===\n",
      "semi loading: model/mfcc6/LGD_fold4_resnet1-.h5\n",
      "Train on 3712 samples, validate on 371 samples\n",
      "Epoch 1/3000\n",
      "3712/3712 [==============================] - 17s 5ms/step - loss: 0.7813 - acc: 0.9267 - val_loss: 1.5259 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77358, saving model to model/mfcc6/LGD_semi_fold4_resnet1.h5\n",
      "Epoch 2/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.6015 - acc: 0.9413 - val_loss: 1.4055 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.77358 to 0.78976, saving model to model/mfcc6/LGD_semi_fold4_resnet1.h5\n",
      "Epoch 3/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.5575 - acc: 0.9499 - val_loss: 1.4752 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.78976\n",
      "Epoch 4/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.5203 - acc: 0.9545 - val_loss: 1.3914 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.78976 to 0.80323, saving model to model/mfcc6/LGD_semi_fold4_resnet1.h5\n",
      "Epoch 5/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.5076 - acc: 0.9593 - val_loss: 1.4595 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.80323\n",
      "Epoch 6/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.4766 - acc: 0.9685 - val_loss: 1.3845 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.80323\n",
      "Epoch 7/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.4748 - acc: 0.9669 - val_loss: 1.4299 - val_acc: 0.8059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_acc improved from 0.80323 to 0.80593, saving model to model/mfcc6/LGD_semi_fold4_resnet1.h5\n",
      "Epoch 8/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.4657 - acc: 0.9706 - val_loss: 1.3840 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.80593\n",
      "Epoch 9/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.4491 - acc: 0.9733 - val_loss: 1.4076 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.80593\n",
      "Epoch 10/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.4442 - acc: 0.9758 - val_loss: 1.4697 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.80593\n",
      "Epoch 11/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.4354 - acc: 0.9728 - val_loss: 1.5116 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.80593\n",
      "Epoch 12/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.4146 - acc: 0.9820 - val_loss: 1.3732 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.80593\n",
      "Epoch 13/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.4117 - acc: 0.9806 - val_loss: 1.5361 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.80593\n",
      "Epoch 14/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3955 - acc: 0.9871 - val_loss: 1.4465 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.80593\n",
      "Epoch 15/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3788 - acc: 0.9916 - val_loss: 1.4501 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.80593\n",
      "Epoch 16/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3894 - acc: 0.9863 - val_loss: 1.5121 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.80593\n",
      "Epoch 17/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3813 - acc: 0.9868 - val_loss: 1.4429 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.80593\n",
      "Epoch 18/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3753 - acc: 0.9919 - val_loss: 1.5601 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.80593\n",
      "Epoch 19/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3725 - acc: 0.9881 - val_loss: 1.5509 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.80593\n",
      "Epoch 20/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3736 - acc: 0.9879 - val_loss: 1.5770 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.80593\n",
      "Epoch 21/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3610 - acc: 0.9930 - val_loss: 1.5648 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80593\n",
      "Epoch 22/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3659 - acc: 0.9898 - val_loss: 1.5720 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80593\n",
      "Epoch 23/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3589 - acc: 0.9887 - val_loss: 1.5454 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.80593\n",
      "Epoch 24/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3611 - acc: 0.9903 - val_loss: 1.5809 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.80593\n",
      "Epoch 25/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3510 - acc: 0.9908 - val_loss: 1.4797 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.80593\n",
      "Epoch 26/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3537 - acc: 0.9914 - val_loss: 1.5289 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.80593\n",
      "Epoch 27/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3382 - acc: 0.9943 - val_loss: 1.3875 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.80593 to 0.81132, saving model to model/mfcc6/LGD_semi_fold4_resnet1.h5\n",
      "Epoch 28/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3387 - acc: 0.9933 - val_loss: 1.4885 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.81132\n",
      "Epoch 29/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3416 - acc: 0.9930 - val_loss: 1.5262 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.81132\n",
      "Epoch 30/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3361 - acc: 0.9925 - val_loss: 1.6265 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.81132\n",
      "Epoch 31/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3302 - acc: 0.9919 - val_loss: 1.5340 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.81132\n",
      "Epoch 32/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3182 - acc: 0.9968 - val_loss: 1.4472 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.81132\n",
      "Epoch 33/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3198 - acc: 0.9952 - val_loss: 1.5783 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.81132\n",
      "Epoch 34/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3158 - acc: 0.9976 - val_loss: 1.4544 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.81132\n",
      "Epoch 35/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3241 - acc: 0.9933 - val_loss: 1.5185 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.81132\n",
      "Epoch 36/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3090 - acc: 0.9970 - val_loss: 1.4116 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.81132\n",
      "Epoch 37/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3136 - acc: 0.9941 - val_loss: 1.5350 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.81132\n",
      "Epoch 38/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3025 - acc: 0.9978 - val_loss: 1.4674 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.81132\n",
      "Epoch 39/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3002 - acc: 0.9976 - val_loss: 1.6052 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.81132\n",
      "Epoch 40/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3051 - acc: 0.9957 - val_loss: 1.6271 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.81132\n",
      "Epoch 41/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3041 - acc: 0.9943 - val_loss: 1.7546 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.81132\n",
      "Epoch 42/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3077 - acc: 0.9930 - val_loss: 1.5427 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.81132\n",
      "Epoch 43/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3041 - acc: 0.9952 - val_loss: 1.5408 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.81132\n",
      "Epoch 44/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.3003 - acc: 0.9949 - val_loss: 1.4889 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.81132\n",
      "Epoch 45/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2887 - acc: 0.9978 - val_loss: 1.4469 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.81132\n",
      "Epoch 46/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2823 - acc: 0.9984 - val_loss: 1.4484 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.81132\n",
      "Epoch 47/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2790 - acc: 0.9997 - val_loss: 1.4505 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.81132\n",
      "Epoch 48/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2768 - acc: 1.0000 - val_loss: 1.4389 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.81132\n",
      "Epoch 49/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2758 - acc: 0.9997 - val_loss: 1.5171 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.81132\n",
      "Epoch 50/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2774 - acc: 0.9989 - val_loss: 1.5001 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.81132\n",
      "Epoch 51/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2751 - acc: 0.9989 - val_loss: 1.4596 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.81132\n",
      "Epoch 52/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2717 - acc: 0.9997 - val_loss: 1.4693 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.81132\n",
      "Epoch 53/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2722 - acc: 0.9992 - val_loss: 1.5316 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.81132\n",
      "Epoch 54/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2678 - acc: 1.0000 - val_loss: 1.4752 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.81132\n",
      "Epoch 55/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2659 - acc: 0.9997 - val_loss: 1.5293 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.81132\n",
      "Epoch 56/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2652 - acc: 0.9989 - val_loss: 1.5869 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.81132\n",
      "Epoch 57/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2654 - acc: 0.9989 - val_loss: 1.6229 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.81132\n",
      "Epoch 58/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2610 - acc: 1.0000 - val_loss: 1.5896 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.81132\n",
      "Epoch 59/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2619 - acc: 0.9992 - val_loss: 1.5916 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.81132\n",
      "Epoch 60/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2611 - acc: 0.9984 - val_loss: 1.5440 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.81132\n",
      "Epoch 61/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2604 - acc: 0.9987 - val_loss: 1.4731 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.81132\n",
      "Epoch 62/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2561 - acc: 0.9995 - val_loss: 1.4783 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.81132\n",
      "Epoch 63/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2543 - acc: 0.9995 - val_loss: 1.3873 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.81132\n",
      "Epoch 64/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2511 - acc: 1.0000 - val_loss: 1.4521 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.81132\n",
      "Epoch 65/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2499 - acc: 0.9997 - val_loss: 1.4028 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.81132\n",
      "Epoch 66/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2500 - acc: 0.9995 - val_loss: 1.4442 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.81132\n",
      "Epoch 67/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2527 - acc: 0.9984 - val_loss: 1.6071 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.81132\n",
      "Epoch 68/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2470 - acc: 0.9995 - val_loss: 1.4414 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.81132\n",
      "Epoch 69/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2444 - acc: 0.9997 - val_loss: 1.4486 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.81132\n",
      "Epoch 70/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2422 - acc: 0.9995 - val_loss: 1.4710 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.81132\n",
      "Epoch 71/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2407 - acc: 1.0000 - val_loss: 1.5776 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.81132\n",
      "Epoch 72/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2386 - acc: 1.0000 - val_loss: 1.5104 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.81132\n",
      "Epoch 73/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2383 - acc: 0.9995 - val_loss: 1.5357 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.81132\n",
      "Epoch 74/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2464 - acc: 0.9965 - val_loss: 1.5558 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.81132\n",
      "Epoch 75/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2500 - acc: 0.9949 - val_loss: 1.6104 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.81132\n",
      "Epoch 76/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2429 - acc: 0.9962 - val_loss: 1.5429 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.81132\n",
      "Epoch 77/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2365 - acc: 0.9987 - val_loss: 1.5163 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.81132\n",
      "Epoch 78/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2364 - acc: 0.9989 - val_loss: 1.4619 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.81132\n",
      "Epoch 79/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2322 - acc: 0.9997 - val_loss: 1.5462 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.81132\n",
      "Epoch 80/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2300 - acc: 0.9997 - val_loss: 1.5289 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.81132\n",
      "Epoch 81/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2290 - acc: 1.0000 - val_loss: 1.5663 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.81132\n",
      "Epoch 82/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2276 - acc: 0.9997 - val_loss: 1.4871 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.81132\n",
      "Epoch 83/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2253 - acc: 1.0000 - val_loss: 1.5171 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.81132\n",
      "Epoch 84/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2236 - acc: 1.0000 - val_loss: 1.4618 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.81132\n",
      "Epoch 85/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2290 - acc: 0.9981 - val_loss: 1.5572 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.81132\n",
      "Epoch 86/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2268 - acc: 0.9978 - val_loss: 1.4621 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.81132\n",
      "Epoch 87/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2282 - acc: 0.9973 - val_loss: 1.4936 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.81132\n",
      "Epoch 88/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2312 - acc: 0.9962 - val_loss: 1.6446 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.81132\n",
      "Epoch 89/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2215 - acc: 0.9995 - val_loss: 1.4880 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.81132\n",
      "Epoch 90/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2192 - acc: 1.0000 - val_loss: 1.4272 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.81132\n",
      "Epoch 91/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2181 - acc: 0.9989 - val_loss: 1.4809 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.81132\n",
      "Epoch 92/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2161 - acc: 0.9997 - val_loss: 1.4467 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.81132\n",
      "Epoch 93/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2154 - acc: 0.9997 - val_loss: 1.3861 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.81132\n",
      "Epoch 94/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2140 - acc: 1.0000 - val_loss: 1.4525 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.81132\n",
      "Epoch 95/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2155 - acc: 0.9989 - val_loss: 1.5491 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.81132\n",
      "Epoch 96/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2141 - acc: 0.9995 - val_loss: 1.5059 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.81132\n",
      "Epoch 97/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2113 - acc: 0.9997 - val_loss: 1.3838 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.81132\n",
      "Epoch 98/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2130 - acc: 0.9992 - val_loss: 1.5165 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.81132\n",
      "Epoch 99/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2178 - acc: 0.9970 - val_loss: 1.7758 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.81132\n",
      "Epoch 100/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2167 - acc: 0.9976 - val_loss: 1.4752 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.81132\n",
      "Epoch 101/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2259 - acc: 0.9949 - val_loss: 1.7093 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.81132\n",
      "Epoch 102/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2173 - acc: 0.9976 - val_loss: 1.6107 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.81132\n",
      "Epoch 103/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2102 - acc: 0.9995 - val_loss: 1.5384 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.81132\n",
      "Epoch 104/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2071 - acc: 1.0000 - val_loss: 1.4605 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.81132\n",
      "Epoch 105/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2068 - acc: 0.9997 - val_loss: 1.4392 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.81132\n",
      "Epoch 106/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2057 - acc: 1.0000 - val_loss: 1.4523 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.81132\n",
      "Epoch 107/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2051 - acc: 0.9997 - val_loss: 1.4206 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.81132\n",
      "Epoch 108/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2053 - acc: 0.9995 - val_loss: 1.4545 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.81132\n",
      "Epoch 109/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2034 - acc: 1.0000 - val_loss: 1.4418 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.81132\n",
      "Epoch 110/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2028 - acc: 1.0000 - val_loss: 1.4286 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.81132\n",
      "Epoch 111/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2020 - acc: 1.0000 - val_loss: 1.4403 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.81132\n",
      "Epoch 112/3000\n",
      "3712/3712 [==============================] - 11s 3ms/step - loss: 0.2022 - acc: 0.9997 - val_loss: 1.4456 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.81132\n",
      "Epoch 00112: early stopping\n",
      "(3339, 64, 431, 1) (3339, 41)\n",
      "===train verified_5===\n",
      "using resnet model: 3\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 64, 431, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1214 (Conv2D)            (None, 32, 216, 64)  3200        input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1168 (Batch (None, 32, 216, 64)  256         conv2d_1214[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1150 (Activation)    (None, 32, 216, 64)  0           batch_normalization_1168[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 16, 108, 64)  0           activation_1150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1215 (Conv2D)            (None, 16, 108, 64)  4160        max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1169 (Batch (None, 16, 108, 64)  256         conv2d_1215[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1151 (Activation)    (None, 16, 108, 64)  0           batch_normalization_1169[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1216 (Conv2D)            (None, 16, 108, 64)  36928       activation_1151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1170 (Batch (None, 16, 108, 64)  256         conv2d_1216[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1152 (Activation)    (None, 16, 108, 64)  0           batch_normalization_1170[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1218 (Conv2D)            (None, 16, 108, 256) 16640       max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1217 (Conv2D)            (None, 16, 108, 256) 16640       activation_1152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_410 (Add)                   (None, 16, 108, 256) 0           conv2d_1218[0][0]                \n",
      "                                                                 conv2d_1217[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1171 (Batch (None, 16, 108, 256) 1024        add_410[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1153 (Activation)    (None, 16, 108, 256) 0           batch_normalization_1171[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1219 (Conv2D)            (None, 16, 108, 64)  16448       activation_1153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1172 (Batch (None, 16, 108, 64)  256         conv2d_1219[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1154 (Activation)    (None, 16, 108, 64)  0           batch_normalization_1172[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1220 (Conv2D)            (None, 16, 108, 64)  36928       activation_1154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1173 (Batch (None, 16, 108, 64)  256         conv2d_1220[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1155 (Activation)    (None, 16, 108, 64)  0           batch_normalization_1173[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1221 (Conv2D)            (None, 16, 108, 256) 16640       activation_1155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_411 (Add)                   (None, 16, 108, 256) 0           add_410[0][0]                    \n",
      "                                                                 conv2d_1221[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1174 (Batch (None, 16, 108, 256) 1024        add_411[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1156 (Activation)    (None, 16, 108, 256) 0           batch_normalization_1174[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1222 (Conv2D)            (None, 16, 108, 64)  16448       activation_1156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1175 (Batch (None, 16, 108, 64)  256         conv2d_1222[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1157 (Activation)    (None, 16, 108, 64)  0           batch_normalization_1175[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1223 (Conv2D)            (None, 16, 108, 64)  36928       activation_1157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1176 (Batch (None, 16, 108, 64)  256         conv2d_1223[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1158 (Activation)    (None, 16, 108, 64)  0           batch_normalization_1176[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1224 (Conv2D)            (None, 16, 108, 256) 16640       activation_1158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_412 (Add)                   (None, 16, 108, 256) 0           add_411[0][0]                    \n",
      "                                                                 conv2d_1224[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1177 (Batch (None, 16, 108, 256) 1024        add_412[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1159 (Activation)    (None, 16, 108, 256) 0           batch_normalization_1177[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1225 (Conv2D)            (None, 8, 54, 128)   32896       activation_1159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1178 (Batch (None, 8, 54, 128)   512         conv2d_1225[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1160 (Activation)    (None, 8, 54, 128)   0           batch_normalization_1178[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1226 (Conv2D)            (None, 8, 54, 128)   147584      activation_1160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1179 (Batch (None, 8, 54, 128)   512         conv2d_1226[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1161 (Activation)    (None, 8, 54, 128)   0           batch_normalization_1179[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1228 (Conv2D)            (None, 8, 54, 512)   131584      add_412[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1227 (Conv2D)            (None, 8, 54, 512)   66048       activation_1161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_413 (Add)                   (None, 8, 54, 512)   0           conv2d_1228[0][0]                \n",
      "                                                                 conv2d_1227[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1180 (Batch (None, 8, 54, 512)   2048        add_413[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1162 (Activation)    (None, 8, 54, 512)   0           batch_normalization_1180[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1229 (Conv2D)            (None, 8, 54, 128)   65664       activation_1162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1181 (Batch (None, 8, 54, 128)   512         conv2d_1229[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1163 (Activation)    (None, 8, 54, 128)   0           batch_normalization_1181[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1230 (Conv2D)            (None, 8, 54, 128)   147584      activation_1163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1182 (Batch (None, 8, 54, 128)   512         conv2d_1230[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1164 (Activation)    (None, 8, 54, 128)   0           batch_normalization_1182[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1231 (Conv2D)            (None, 8, 54, 512)   66048       activation_1164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_414 (Add)                   (None, 8, 54, 512)   0           add_413[0][0]                    \n",
      "                                                                 conv2d_1231[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1183 (Batch (None, 8, 54, 512)   2048        add_414[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1165 (Activation)    (None, 8, 54, 512)   0           batch_normalization_1183[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1232 (Conv2D)            (None, 8, 54, 128)   65664       activation_1165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1184 (Batch (None, 8, 54, 128)   512         conv2d_1232[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1166 (Activation)    (None, 8, 54, 128)   0           batch_normalization_1184[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1233 (Conv2D)            (None, 8, 54, 128)   147584      activation_1166[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1185 (Batch (None, 8, 54, 128)   512         conv2d_1233[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1167 (Activation)    (None, 8, 54, 128)   0           batch_normalization_1185[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1234 (Conv2D)            (None, 8, 54, 512)   66048       activation_1167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_415 (Add)                   (None, 8, 54, 512)   0           add_414[0][0]                    \n",
      "                                                                 conv2d_1234[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1186 (Batch (None, 8, 54, 512)   2048        add_415[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1168 (Activation)    (None, 8, 54, 512)   0           batch_normalization_1186[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1235 (Conv2D)            (None, 8, 54, 128)   65664       activation_1168[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1187 (Batch (None, 8, 54, 128)   512         conv2d_1235[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1169 (Activation)    (None, 8, 54, 128)   0           batch_normalization_1187[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1236 (Conv2D)            (None, 8, 54, 128)   147584      activation_1169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1188 (Batch (None, 8, 54, 128)   512         conv2d_1236[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1170 (Activation)    (None, 8, 54, 128)   0           batch_normalization_1188[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1237 (Conv2D)            (None, 8, 54, 512)   66048       activation_1170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_416 (Add)                   (None, 8, 54, 512)   0           add_415[0][0]                    \n",
      "                                                                 conv2d_1237[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1189 (Batch (None, 8, 54, 512)   2048        add_416[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1171 (Activation)    (None, 8, 54, 512)   0           batch_normalization_1189[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1238 (Conv2D)            (None, 4, 27, 256)   131328      activation_1171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1190 (Batch (None, 4, 27, 256)   1024        conv2d_1238[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1172 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1190[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1239 (Conv2D)            (None, 4, 27, 256)   590080      activation_1172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1191 (Batch (None, 4, 27, 256)   1024        conv2d_1239[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1173 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1191[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1241 (Conv2D)            (None, 4, 27, 1024)  525312      add_416[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1240 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_417 (Add)                   (None, 4, 27, 1024)  0           conv2d_1241[0][0]                \n",
      "                                                                 conv2d_1240[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1192 (Batch (None, 4, 27, 1024)  4096        add_417[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1174 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1192[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1242 (Conv2D)            (None, 4, 27, 256)   262400      activation_1174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1193 (Batch (None, 4, 27, 256)   1024        conv2d_1242[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1175 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1193[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1243 (Conv2D)            (None, 4, 27, 256)   590080      activation_1175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1194 (Batch (None, 4, 27, 256)   1024        conv2d_1243[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1176 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1194[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1244 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_418 (Add)                   (None, 4, 27, 1024)  0           add_417[0][0]                    \n",
      "                                                                 conv2d_1244[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1195 (Batch (None, 4, 27, 1024)  4096        add_418[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1177 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1195[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1245 (Conv2D)            (None, 4, 27, 256)   262400      activation_1177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1196 (Batch (None, 4, 27, 256)   1024        conv2d_1245[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1178 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1196[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1246 (Conv2D)            (None, 4, 27, 256)   590080      activation_1178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1197 (Batch (None, 4, 27, 256)   1024        conv2d_1246[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1179 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1197[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1247 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_419 (Add)                   (None, 4, 27, 1024)  0           add_418[0][0]                    \n",
      "                                                                 conv2d_1247[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1198 (Batch (None, 4, 27, 1024)  4096        add_419[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1180 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1198[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1248 (Conv2D)            (None, 4, 27, 256)   262400      activation_1180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1199 (Batch (None, 4, 27, 256)   1024        conv2d_1248[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1181 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1199[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1249 (Conv2D)            (None, 4, 27, 256)   590080      activation_1181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1200 (Batch (None, 4, 27, 256)   1024        conv2d_1249[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1182 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1200[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1250 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_420 (Add)                   (None, 4, 27, 1024)  0           add_419[0][0]                    \n",
      "                                                                 conv2d_1250[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1201 (Batch (None, 4, 27, 1024)  4096        add_420[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1183 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1201[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1251 (Conv2D)            (None, 4, 27, 256)   262400      activation_1183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1202 (Batch (None, 4, 27, 256)   1024        conv2d_1251[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1184 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1202[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1252 (Conv2D)            (None, 4, 27, 256)   590080      activation_1184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1203 (Batch (None, 4, 27, 256)   1024        conv2d_1252[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1185 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1203[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1253 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_421 (Add)                   (None, 4, 27, 1024)  0           add_420[0][0]                    \n",
      "                                                                 conv2d_1253[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1204 (Batch (None, 4, 27, 1024)  4096        add_421[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1186 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1204[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1254 (Conv2D)            (None, 4, 27, 256)   262400      activation_1186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1205 (Batch (None, 4, 27, 256)   1024        conv2d_1254[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1187 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1205[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1255 (Conv2D)            (None, 4, 27, 256)   590080      activation_1187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1206 (Batch (None, 4, 27, 256)   1024        conv2d_1255[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1188 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1206[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1256 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1188[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_422 (Add)                   (None, 4, 27, 1024)  0           add_421[0][0]                    \n",
      "                                                                 conv2d_1256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1207 (Batch (None, 4, 27, 1024)  4096        add_422[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1189 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1207[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1257 (Conv2D)            (None, 4, 27, 256)   262400      activation_1189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1208 (Batch (None, 4, 27, 256)   1024        conv2d_1257[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1190 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1208[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1258 (Conv2D)            (None, 4, 27, 256)   590080      activation_1190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1209 (Batch (None, 4, 27, 256)   1024        conv2d_1258[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1191 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1209[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1259 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_423 (Add)                   (None, 4, 27, 1024)  0           add_422[0][0]                    \n",
      "                                                                 conv2d_1259[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1210 (Batch (None, 4, 27, 1024)  4096        add_423[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1192 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1210[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1260 (Conv2D)            (None, 4, 27, 256)   262400      activation_1192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1211 (Batch (None, 4, 27, 256)   1024        conv2d_1260[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1193 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1211[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1261 (Conv2D)            (None, 4, 27, 256)   590080      activation_1193[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1212 (Batch (None, 4, 27, 256)   1024        conv2d_1261[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1194 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1212[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1262 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1194[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_424 (Add)                   (None, 4, 27, 1024)  0           add_423[0][0]                    \n",
      "                                                                 conv2d_1262[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1213 (Batch (None, 4, 27, 1024)  4096        add_424[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1195 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1213[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1263 (Conv2D)            (None, 4, 27, 256)   262400      activation_1195[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1214 (Batch (None, 4, 27, 256)   1024        conv2d_1263[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1196 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1214[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1264 (Conv2D)            (None, 4, 27, 256)   590080      activation_1196[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1215 (Batch (None, 4, 27, 256)   1024        conv2d_1264[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1197 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1215[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1265 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1197[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_425 (Add)                   (None, 4, 27, 1024)  0           add_424[0][0]                    \n",
      "                                                                 conv2d_1265[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1216 (Batch (None, 4, 27, 1024)  4096        add_425[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1198 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1216[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1266 (Conv2D)            (None, 4, 27, 256)   262400      activation_1198[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1217 (Batch (None, 4, 27, 256)   1024        conv2d_1266[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1199 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1217[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1267 (Conv2D)            (None, 4, 27, 256)   590080      activation_1199[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1218 (Batch (None, 4, 27, 256)   1024        conv2d_1267[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1200 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1218[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1268 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1200[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_426 (Add)                   (None, 4, 27, 1024)  0           add_425[0][0]                    \n",
      "                                                                 conv2d_1268[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1219 (Batch (None, 4, 27, 1024)  4096        add_426[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1201 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1219[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1269 (Conv2D)            (None, 4, 27, 256)   262400      activation_1201[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1220 (Batch (None, 4, 27, 256)   1024        conv2d_1269[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1202 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1220[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1270 (Conv2D)            (None, 4, 27, 256)   590080      activation_1202[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1221 (Batch (None, 4, 27, 256)   1024        conv2d_1270[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1203 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1221[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1271 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1203[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_427 (Add)                   (None, 4, 27, 1024)  0           add_426[0][0]                    \n",
      "                                                                 conv2d_1271[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1222 (Batch (None, 4, 27, 1024)  4096        add_427[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1204 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1222[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1272 (Conv2D)            (None, 4, 27, 256)   262400      activation_1204[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1223 (Batch (None, 4, 27, 256)   1024        conv2d_1272[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1205 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1223[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1273 (Conv2D)            (None, 4, 27, 256)   590080      activation_1205[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1224 (Batch (None, 4, 27, 256)   1024        conv2d_1273[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1206 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1224[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1274 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1206[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_428 (Add)                   (None, 4, 27, 1024)  0           add_427[0][0]                    \n",
      "                                                                 conv2d_1274[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1225 (Batch (None, 4, 27, 1024)  4096        add_428[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1207 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1225[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1275 (Conv2D)            (None, 4, 27, 256)   262400      activation_1207[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1226 (Batch (None, 4, 27, 256)   1024        conv2d_1275[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1208 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1226[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1276 (Conv2D)            (None, 4, 27, 256)   590080      activation_1208[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1227 (Batch (None, 4, 27, 256)   1024        conv2d_1276[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1209 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1227[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1277 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1209[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_429 (Add)                   (None, 4, 27, 1024)  0           add_428[0][0]                    \n",
      "                                                                 conv2d_1277[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1228 (Batch (None, 4, 27, 1024)  4096        add_429[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1210 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1228[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1278 (Conv2D)            (None, 4, 27, 256)   262400      activation_1210[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1229 (Batch (None, 4, 27, 256)   1024        conv2d_1278[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1211 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1229[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1279 (Conv2D)            (None, 4, 27, 256)   590080      activation_1211[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1230 (Batch (None, 4, 27, 256)   1024        conv2d_1279[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1212 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1230[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1280 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1212[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_430 (Add)                   (None, 4, 27, 1024)  0           add_429[0][0]                    \n",
      "                                                                 conv2d_1280[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1231 (Batch (None, 4, 27, 1024)  4096        add_430[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1213 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1231[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1281 (Conv2D)            (None, 4, 27, 256)   262400      activation_1213[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1232 (Batch (None, 4, 27, 256)   1024        conv2d_1281[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1214 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1232[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1282 (Conv2D)            (None, 4, 27, 256)   590080      activation_1214[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1233 (Batch (None, 4, 27, 256)   1024        conv2d_1282[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1215 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1233[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1283 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1215[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_431 (Add)                   (None, 4, 27, 1024)  0           add_430[0][0]                    \n",
      "                                                                 conv2d_1283[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1234 (Batch (None, 4, 27, 1024)  4096        add_431[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1216 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1234[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1284 (Conv2D)            (None, 4, 27, 256)   262400      activation_1216[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1235 (Batch (None, 4, 27, 256)   1024        conv2d_1284[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1217 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1235[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1285 (Conv2D)            (None, 4, 27, 256)   590080      activation_1217[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1236 (Batch (None, 4, 27, 256)   1024        conv2d_1285[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1218 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1236[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1286 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1218[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_432 (Add)                   (None, 4, 27, 1024)  0           add_431[0][0]                    \n",
      "                                                                 conv2d_1286[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1237 (Batch (None, 4, 27, 1024)  4096        add_432[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1219 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1237[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1287 (Conv2D)            (None, 4, 27, 256)   262400      activation_1219[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1238 (Batch (None, 4, 27, 256)   1024        conv2d_1287[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1220 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1238[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1288 (Conv2D)            (None, 4, 27, 256)   590080      activation_1220[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1239 (Batch (None, 4, 27, 256)   1024        conv2d_1288[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1221 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1239[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1289 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1221[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_433 (Add)                   (None, 4, 27, 1024)  0           add_432[0][0]                    \n",
      "                                                                 conv2d_1289[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1240 (Batch (None, 4, 27, 1024)  4096        add_433[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1222 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1240[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1290 (Conv2D)            (None, 4, 27, 256)   262400      activation_1222[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1241 (Batch (None, 4, 27, 256)   1024        conv2d_1290[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1223 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1241[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1291 (Conv2D)            (None, 4, 27, 256)   590080      activation_1223[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1242 (Batch (None, 4, 27, 256)   1024        conv2d_1291[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1224 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1242[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1292 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1224[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_434 (Add)                   (None, 4, 27, 1024)  0           add_433[0][0]                    \n",
      "                                                                 conv2d_1292[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1243 (Batch (None, 4, 27, 1024)  4096        add_434[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1225 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1243[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1293 (Conv2D)            (None, 4, 27, 256)   262400      activation_1225[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1244 (Batch (None, 4, 27, 256)   1024        conv2d_1293[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1226 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1244[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1294 (Conv2D)            (None, 4, 27, 256)   590080      activation_1226[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1245 (Batch (None, 4, 27, 256)   1024        conv2d_1294[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1227 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1245[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1295 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1227[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_435 (Add)                   (None, 4, 27, 1024)  0           add_434[0][0]                    \n",
      "                                                                 conv2d_1295[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1246 (Batch (None, 4, 27, 1024)  4096        add_435[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1228 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1246[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1296 (Conv2D)            (None, 4, 27, 256)   262400      activation_1228[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1247 (Batch (None, 4, 27, 256)   1024        conv2d_1296[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1229 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1247[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1297 (Conv2D)            (None, 4, 27, 256)   590080      activation_1229[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1248 (Batch (None, 4, 27, 256)   1024        conv2d_1297[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1230 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1248[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1298 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1230[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_436 (Add)                   (None, 4, 27, 1024)  0           add_435[0][0]                    \n",
      "                                                                 conv2d_1298[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1249 (Batch (None, 4, 27, 1024)  4096        add_436[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1231 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1249[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1299 (Conv2D)            (None, 4, 27, 256)   262400      activation_1231[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1250 (Batch (None, 4, 27, 256)   1024        conv2d_1299[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1232 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1250[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1300 (Conv2D)            (None, 4, 27, 256)   590080      activation_1232[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1251 (Batch (None, 4, 27, 256)   1024        conv2d_1300[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1233 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1251[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1301 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1233[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_437 (Add)                   (None, 4, 27, 1024)  0           add_436[0][0]                    \n",
      "                                                                 conv2d_1301[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1252 (Batch (None, 4, 27, 1024)  4096        add_437[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1234 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1252[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1302 (Conv2D)            (None, 4, 27, 256)   262400      activation_1234[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1253 (Batch (None, 4, 27, 256)   1024        conv2d_1302[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1235 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1253[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1303 (Conv2D)            (None, 4, 27, 256)   590080      activation_1235[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1254 (Batch (None, 4, 27, 256)   1024        conv2d_1303[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1236 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1254[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1304 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1236[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_438 (Add)                   (None, 4, 27, 1024)  0           add_437[0][0]                    \n",
      "                                                                 conv2d_1304[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1255 (Batch (None, 4, 27, 1024)  4096        add_438[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1237 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1255[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1305 (Conv2D)            (None, 4, 27, 256)   262400      activation_1237[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1256 (Batch (None, 4, 27, 256)   1024        conv2d_1305[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1238 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1256[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1306 (Conv2D)            (None, 4, 27, 256)   590080      activation_1238[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1257 (Batch (None, 4, 27, 256)   1024        conv2d_1306[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1239 (Activation)    (None, 4, 27, 256)   0           batch_normalization_1257[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1307 (Conv2D)            (None, 4, 27, 1024)  263168      activation_1239[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_439 (Add)                   (None, 4, 27, 1024)  0           add_438[0][0]                    \n",
      "                                                                 conv2d_1307[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1258 (Batch (None, 4, 27, 1024)  4096        add_439[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1240 (Activation)    (None, 4, 27, 1024)  0           batch_normalization_1258[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1308 (Conv2D)            (None, 2, 14, 512)   524800      activation_1240[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1259 (Batch (None, 2, 14, 512)   2048        conv2d_1308[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1241 (Activation)    (None, 2, 14, 512)   0           batch_normalization_1259[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1309 (Conv2D)            (None, 2, 14, 512)   2359808     activation_1241[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1260 (Batch (None, 2, 14, 512)   2048        conv2d_1309[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1242 (Activation)    (None, 2, 14, 512)   0           batch_normalization_1260[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1311 (Conv2D)            (None, 2, 14, 2048)  2099200     add_439[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1310 (Conv2D)            (None, 2, 14, 2048)  1050624     activation_1242[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_440 (Add)                   (None, 2, 14, 2048)  0           conv2d_1311[0][0]                \n",
      "                                                                 conv2d_1310[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1261 (Batch (None, 2, 14, 2048)  8192        add_440[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1243 (Activation)    (None, 2, 14, 2048)  0           batch_normalization_1261[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1312 (Conv2D)            (None, 2, 14, 512)   1049088     activation_1243[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1262 (Batch (None, 2, 14, 512)   2048        conv2d_1312[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1244 (Activation)    (None, 2, 14, 512)   0           batch_normalization_1262[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1313 (Conv2D)            (None, 2, 14, 512)   2359808     activation_1244[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1263 (Batch (None, 2, 14, 512)   2048        conv2d_1313[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1245 (Activation)    (None, 2, 14, 512)   0           batch_normalization_1263[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1314 (Conv2D)            (None, 2, 14, 2048)  1050624     activation_1245[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_441 (Add)                   (None, 2, 14, 2048)  0           add_440[0][0]                    \n",
      "                                                                 conv2d_1314[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1264 (Batch (None, 2, 14, 2048)  8192        add_441[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1246 (Activation)    (None, 2, 14, 2048)  0           batch_normalization_1264[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1315 (Conv2D)            (None, 2, 14, 512)   1049088     activation_1246[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1265 (Batch (None, 2, 14, 512)   2048        conv2d_1315[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1247 (Activation)    (None, 2, 14, 512)   0           batch_normalization_1265[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1316 (Conv2D)            (None, 2, 14, 512)   2359808     activation_1247[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1266 (Batch (None, 2, 14, 512)   2048        conv2d_1316[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1248 (Activation)    (None, 2, 14, 512)   0           batch_normalization_1266[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1317 (Conv2D)            (None, 2, 14, 2048)  1050624     activation_1248[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_442 (Add)                   (None, 2, 14, 2048)  0           add_441[0][0]                    \n",
      "                                                                 conv2d_1317[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1267 (Batch (None, 2, 14, 2048)  8192        add_442[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1249 (Activation)    (None, 2, 14, 2048)  0           batch_normalization_1267[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 1, 1, 2048)   0           activation_1249[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1, 1, 2048)   0           average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 2048)         0           dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 56)           114744      flatten_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1268 (Batch (None, 56)           224         dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 56)           0           batch_normalization_1268[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 41)           2337        dropout_38[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,753,849\n",
      "Trainable params: 42,656,073\n",
      "Non-trainable params: 97,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3339 samples, validate on 371 samples\n",
      "Epoch 1/3000\n",
      "3339/3339 [==============================] - 39s 12ms/step - loss: 12.8225 - acc: 0.2120 - val_loss: 12.0754 - val_acc: 0.2749\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.27493, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 2/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 9.8491 - acc: 0.3726 - val_loss: 10.7888 - val_acc: 0.2156\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.27493\n",
      "Epoch 3/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 7.6752 - acc: 0.4385 - val_loss: 6.8343 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.27493 to 0.42588, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 4/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 6.0639 - acc: 0.5049 - val_loss: 5.4618 - val_acc: 0.5606\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.42588 to 0.56065, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 5/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 4.9040 - acc: 0.5678 - val_loss: 5.0033 - val_acc: 0.4744\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.56065\n",
      "Epoch 6/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 4.1122 - acc: 0.5897 - val_loss: 4.6378 - val_acc: 0.3774\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.56065\n",
      "Epoch 7/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 3.5183 - acc: 0.6199 - val_loss: 3.6519 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.56065 to 0.56873, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 8/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 3.0940 - acc: 0.6496 - val_loss: 3.5832 - val_acc: 0.5633\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.56873\n",
      "Epoch 9/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 2.7508 - acc: 0.6789 - val_loss: 3.2842 - val_acc: 0.5606\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.56873\n",
      "Epoch 10/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 2.5067 - acc: 0.6945 - val_loss: 3.0159 - val_acc: 0.5445\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.56873\n",
      "Epoch 11/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 2.3544 - acc: 0.7002 - val_loss: 2.9514 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.56873\n",
      "Epoch 12/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 2.1267 - acc: 0.7394 - val_loss: 2.7965 - val_acc: 0.5768\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.56873 to 0.57682, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 13/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 2.0496 - acc: 0.7347 - val_loss: 2.4672 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.57682 to 0.64151, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 14/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.9224 - acc: 0.7478 - val_loss: 2.1994 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.64151 to 0.67385, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 15/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.7691 - acc: 0.7751 - val_loss: 2.5013 - val_acc: 0.6119\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.67385\n",
      "Epoch 16/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.6848 - acc: 0.7874 - val_loss: 2.2806 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.67385\n",
      "Epoch 17/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.5789 - acc: 0.8107 - val_loss: 2.4068 - val_acc: 0.6361\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.67385\n",
      "Epoch 18/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.5700 - acc: 0.8044 - val_loss: 2.5512 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.67385\n",
      "Epoch 19/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.4643 - acc: 0.8215 - val_loss: 2.1990 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.67385\n",
      "Epoch 20/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.4641 - acc: 0.8116 - val_loss: 2.3816 - val_acc: 0.6226\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.67385\n",
      "Epoch 21/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.3818 - acc: 0.8305 - val_loss: 2.0408 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.67385 to 0.69542, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 22/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.3041 - acc: 0.8473 - val_loss: 1.9795 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.69542 to 0.71968, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 23/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.2183 - acc: 0.8631 - val_loss: 2.0519 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.71968\n",
      "Epoch 24/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.2972 - acc: 0.8434 - val_loss: 1.8414 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.71968 to 0.75472, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 25/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.2521 - acc: 0.8509 - val_loss: 1.9361 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.75472\n",
      "Epoch 26/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.2390 - acc: 0.8515 - val_loss: 1.7882 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.75472\n",
      "Epoch 27/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.1068 - acc: 0.8811 - val_loss: 1.9458 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.75472\n",
      "Epoch 28/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.0185 - acc: 0.9078 - val_loss: 1.8196 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.75472\n",
      "Epoch 29/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.0446 - acc: 0.8907 - val_loss: 2.1429 - val_acc: 0.6307\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.75472\n",
      "Epoch 30/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.0488 - acc: 0.8865 - val_loss: 3.1627 - val_acc: 0.5202\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.75472\n",
      "Epoch 31/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.0325 - acc: 0.8883 - val_loss: 2.5033 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.75472\n",
      "Epoch 32/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.0044 - acc: 0.8955 - val_loss: 1.7579 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.75472 to 0.75741, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 33/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.9881 - acc: 0.9030 - val_loss: 1.9323 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.75741\n",
      "Epoch 34/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.9556 - acc: 0.9042 - val_loss: 2.1879 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.75741\n",
      "Epoch 35/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.9254 - acc: 0.9122 - val_loss: 1.9212 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.75741\n",
      "Epoch 36/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.9005 - acc: 0.9236 - val_loss: 1.9477 - val_acc: 0.7116\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.75741\n",
      "Epoch 37/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8524 - acc: 0.9356 - val_loss: 2.2979 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.75741\n",
      "Epoch 38/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.9130 - acc: 0.9078 - val_loss: 1.8843 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.75741\n",
      "Epoch 39/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 1.0103 - acc: 0.8814 - val_loss: 1.7882 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.75741 to 0.76011, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 40/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.9518 - acc: 0.8994 - val_loss: 1.9340 - val_acc: 0.7439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_acc did not improve from 0.76011\n",
      "Epoch 41/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8681 - acc: 0.9302 - val_loss: 2.3168 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.76011\n",
      "Epoch 42/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8063 - acc: 0.9416 - val_loss: 1.8517 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.76011\n",
      "Epoch 43/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.9255 - acc: 0.9125 - val_loss: 5.1845 - val_acc: 0.4232\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.76011\n",
      "Epoch 44/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.9730 - acc: 0.9093 - val_loss: 2.4239 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.76011\n",
      "Epoch 45/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8739 - acc: 0.9233 - val_loss: 1.7954 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.76011\n",
      "Epoch 46/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8123 - acc: 0.9407 - val_loss: 1.6172 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.76011 to 0.77628, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 47/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8041 - acc: 0.9458 - val_loss: 1.7821 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.77628\n",
      "Epoch 48/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7889 - acc: 0.9440 - val_loss: 1.7763 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.77628\n",
      "Epoch 49/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7442 - acc: 0.9509 - val_loss: 1.6069 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.77628\n",
      "Epoch 50/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7336 - acc: 0.9551 - val_loss: 2.0261 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.77628\n",
      "Epoch 51/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8530 - acc: 0.9218 - val_loss: 2.8920 - val_acc: 0.6253\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.77628\n",
      "Epoch 52/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8691 - acc: 0.9188 - val_loss: 2.0715 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.77628\n",
      "Epoch 53/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7778 - acc: 0.9506 - val_loss: 1.6924 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.77628\n",
      "Epoch 54/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8207 - acc: 0.9347 - val_loss: 3.7221 - val_acc: 0.4555\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.77628\n",
      "Epoch 55/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8477 - acc: 0.9350 - val_loss: 2.2231 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.77628\n",
      "Epoch 56/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8096 - acc: 0.9344 - val_loss: 2.0754 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.77628\n",
      "Epoch 57/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7815 - acc: 0.9443 - val_loss: 1.9038 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.77628\n",
      "Epoch 58/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7701 - acc: 0.9485 - val_loss: 1.8027 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.77628\n",
      "Epoch 59/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7058 - acc: 0.9620 - val_loss: 1.5038 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.77628\n",
      "Epoch 60/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7103 - acc: 0.9539 - val_loss: 1.9518 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.77628\n",
      "Epoch 61/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7948 - acc: 0.9341 - val_loss: 2.4034 - val_acc: 0.6523\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.77628\n",
      "Epoch 62/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8503 - acc: 0.9284 - val_loss: 2.6669 - val_acc: 0.6092\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.77628\n",
      "Epoch 63/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.9381 - acc: 0.9105 - val_loss: 2.1086 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.77628\n",
      "Epoch 64/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7115 - acc: 0.9614 - val_loss: 1.8084 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.77628\n",
      "Epoch 65/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7066 - acc: 0.9533 - val_loss: 1.5239 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.77628\n",
      "Epoch 66/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6880 - acc: 0.9623 - val_loss: 1.9552 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.77628\n",
      "Epoch 67/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6728 - acc: 0.9665 - val_loss: 1.7147 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.77628\n",
      "Epoch 68/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6165 - acc: 0.9724 - val_loss: 1.6216 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.77628\n",
      "Epoch 69/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6475 - acc: 0.9611 - val_loss: 1.5775 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.77628\n",
      "Epoch 70/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5993 - acc: 0.9769 - val_loss: 1.5569 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.77628 to 0.79515, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 71/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6816 - acc: 0.9542 - val_loss: 2.0207 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.79515\n",
      "Epoch 72/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8879 - acc: 0.9117 - val_loss: 4.7560 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.79515\n",
      "Epoch 73/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8729 - acc: 0.9206 - val_loss: 1.8488 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.79515\n",
      "Epoch 74/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7356 - acc: 0.9491 - val_loss: 1.8490 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.79515\n",
      "Epoch 75/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6318 - acc: 0.9721 - val_loss: 1.6514 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.79515\n",
      "Epoch 76/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6564 - acc: 0.9605 - val_loss: 1.8515 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.79515\n",
      "Epoch 77/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6388 - acc: 0.9668 - val_loss: 1.8094 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.79515\n",
      "Epoch 78/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5802 - acc: 0.9769 - val_loss: 1.5314 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.79515\n",
      "Epoch 79/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5728 - acc: 0.9751 - val_loss: 1.9678 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.79515\n",
      "Epoch 80/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6297 - acc: 0.9617 - val_loss: 2.0426 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.79515\n",
      "Epoch 81/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6841 - acc: 0.9527 - val_loss: 1.7231 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.79515\n",
      "Epoch 82/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6794 - acc: 0.9500 - val_loss: 1.9023 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.79515\n",
      "Epoch 83/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6882 - acc: 0.9467 - val_loss: 1.6420 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.79515\n",
      "Epoch 84/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6898 - acc: 0.9509 - val_loss: 1.8378 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.79515\n",
      "Epoch 85/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6363 - acc: 0.9644 - val_loss: 1.7653 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.79515\n",
      "Epoch 86/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5994 - acc: 0.9695 - val_loss: 1.8493 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.79515\n",
      "Epoch 87/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6220 - acc: 0.9596 - val_loss: 1.9512 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.79515\n",
      "Epoch 88/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6517 - acc: 0.9593 - val_loss: 2.1034 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.79515\n",
      "Epoch 89/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7603 - acc: 0.9302 - val_loss: 1.9125 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.79515\n",
      "Epoch 90/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7067 - acc: 0.9464 - val_loss: 1.8549 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.79515\n",
      "Epoch 91/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7162 - acc: 0.9485 - val_loss: 1.7752 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.79515\n",
      "Epoch 92/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6130 - acc: 0.9665 - val_loss: 2.1623 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.79515\n",
      "Epoch 93/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6158 - acc: 0.9638 - val_loss: 1.6591 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.79515\n",
      "Epoch 94/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5688 - acc: 0.9775 - val_loss: 1.7591 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.79515\n",
      "Epoch 95/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5383 - acc: 0.9829 - val_loss: 1.9368 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.79515\n",
      "Epoch 96/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6764 - acc: 0.9485 - val_loss: 2.2481 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.79515\n",
      "Epoch 97/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6260 - acc: 0.9626 - val_loss: 1.8908 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.79515\n",
      "Epoch 98/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5857 - acc: 0.9701 - val_loss: 1.5920 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.79515\n",
      "Epoch 99/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6121 - acc: 0.9614 - val_loss: 1.8368 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.79515\n",
      "Epoch 100/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7021 - acc: 0.9431 - val_loss: 2.0211 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.79515\n",
      "Epoch 101/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6176 - acc: 0.9662 - val_loss: 1.9792 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.79515\n",
      "Epoch 102/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5975 - acc: 0.9674 - val_loss: 1.6959 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.79515\n",
      "Epoch 103/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5648 - acc: 0.9724 - val_loss: 1.6394 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.79515\n",
      "Epoch 104/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5505 - acc: 0.9754 - val_loss: 1.5054 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.79515\n",
      "Epoch 105/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5086 - acc: 0.9826 - val_loss: 1.4339 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.79515 to 0.80593, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 106/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4937 - acc: 0.9832 - val_loss: 1.4999 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.80593\n",
      "Epoch 107/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5564 - acc: 0.9680 - val_loss: 2.0633 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.80593\n",
      "Epoch 108/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6376 - acc: 0.9461 - val_loss: 2.0440 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.80593\n",
      "Epoch 109/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7833 - acc: 0.9245 - val_loss: 2.2074 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.80593\n",
      "Epoch 110/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6738 - acc: 0.9527 - val_loss: 1.7341 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.80593\n",
      "Epoch 111/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6215 - acc: 0.9626 - val_loss: 1.9468 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.80593\n",
      "Epoch 112/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6550 - acc: 0.9491 - val_loss: 1.6788 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.80593\n",
      "Epoch 113/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7003 - acc: 0.9380 - val_loss: 1.7731 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.80593\n",
      "Epoch 114/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5950 - acc: 0.9683 - val_loss: 1.5413 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.80593\n",
      "Epoch 115/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5248 - acc: 0.9856 - val_loss: 1.5562 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.80593\n",
      "Epoch 116/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4935 - acc: 0.9880 - val_loss: 1.4338 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.80593\n",
      "Epoch 117/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4900 - acc: 0.9856 - val_loss: 1.7283 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.80593\n",
      "Epoch 118/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5096 - acc: 0.9799 - val_loss: 1.7764 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.80593\n",
      "Epoch 119/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5210 - acc: 0.9733 - val_loss: 2.1834 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.80593\n",
      "Epoch 120/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5816 - acc: 0.9593 - val_loss: 2.1772 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.80593\n",
      "Epoch 121/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5757 - acc: 0.9644 - val_loss: 1.8374 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.80593\n",
      "Epoch 122/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6162 - acc: 0.9554 - val_loss: 2.2343 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.80593\n",
      "Epoch 123/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5464 - acc: 0.9772 - val_loss: 2.0679 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.80593\n",
      "Epoch 124/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5511 - acc: 0.9721 - val_loss: 1.7353 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.80593\n",
      "Epoch 125/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5371 - acc: 0.9778 - val_loss: 1.5511 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.80593\n",
      "Epoch 126/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5075 - acc: 0.9793 - val_loss: 1.7081 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.80593\n",
      "Epoch 127/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6496 - acc: 0.9437 - val_loss: 2.3301 - val_acc: 0.6065\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.80593\n",
      "Epoch 128/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6383 - acc: 0.9449 - val_loss: 2.0459 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.80593\n",
      "Epoch 129/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5728 - acc: 0.9668 - val_loss: 1.9770 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.80593\n",
      "Epoch 130/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5174 - acc: 0.9829 - val_loss: 1.6266 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.80593\n",
      "Epoch 131/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5108 - acc: 0.9778 - val_loss: 1.8250 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.80593\n",
      "Epoch 132/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4843 - acc: 0.9856 - val_loss: 1.9606 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.80593\n",
      "Epoch 133/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5942 - acc: 0.9569 - val_loss: 2.8284 - val_acc: 0.5606\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.80593\n",
      "Epoch 134/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6128 - acc: 0.9584 - val_loss: 1.9429 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.80593\n",
      "Epoch 135/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5310 - acc: 0.9778 - val_loss: 2.0274 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.80593\n",
      "Epoch 136/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5201 - acc: 0.9763 - val_loss: 2.1127 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.80593\n",
      "Epoch 137/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5299 - acc: 0.9751 - val_loss: 1.9061 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.80593\n",
      "Epoch 138/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5897 - acc: 0.9593 - val_loss: 1.8118 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.80593\n",
      "Epoch 139/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5059 - acc: 0.9796 - val_loss: 1.5546 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.80593\n",
      "Epoch 140/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4742 - acc: 0.9841 - val_loss: 1.6813 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.80593\n",
      "Epoch 141/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5738 - acc: 0.9554 - val_loss: 2.1325 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.80593\n",
      "Epoch 142/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5393 - acc: 0.9733 - val_loss: 1.6234 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.80593\n",
      "Epoch 143/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5578 - acc: 0.9647 - val_loss: 2.1490 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.80593\n",
      "Epoch 144/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5019 - acc: 0.9787 - val_loss: 1.6564 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.80593\n",
      "Epoch 145/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5411 - acc: 0.9665 - val_loss: 2.2555 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.80593\n",
      "Epoch 146/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5952 - acc: 0.9560 - val_loss: 2.6058 - val_acc: 0.6469\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.80593\n",
      "Epoch 147/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5558 - acc: 0.9671 - val_loss: 1.7895 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.80593\n",
      "Epoch 148/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5393 - acc: 0.9733 - val_loss: 1.7286 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.80593\n",
      "Epoch 149/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5082 - acc: 0.9790 - val_loss: 1.6445 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.80593\n",
      "Epoch 150/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4529 - acc: 0.9877 - val_loss: 1.3838 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00150: val_acc improved from 0.80593 to 0.80863, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 151/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4401 - acc: 0.9895 - val_loss: 1.4729 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.80863\n",
      "Epoch 152/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4571 - acc: 0.9817 - val_loss: 1.8775 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.80863\n",
      "Epoch 153/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4965 - acc: 0.9692 - val_loss: 1.8033 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.80863\n",
      "Epoch 154/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5232 - acc: 0.9698 - val_loss: 2.5343 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.80863\n",
      "Epoch 155/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5786 - acc: 0.9587 - val_loss: 2.1581 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.80863\n",
      "Epoch 156/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5599 - acc: 0.9659 - val_loss: 2.0950 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.80863\n",
      "Epoch 157/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5487 - acc: 0.9671 - val_loss: 2.0647 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.80863\n",
      "Epoch 158/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5678 - acc: 0.9638 - val_loss: 1.9176 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.80863\n",
      "Epoch 159/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5744 - acc: 0.9590 - val_loss: 2.1156 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.80863\n",
      "Epoch 160/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4893 - acc: 0.9793 - val_loss: 1.6537 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.80863\n",
      "Epoch 161/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4499 - acc: 0.9874 - val_loss: 1.6654 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.80863\n",
      "Epoch 162/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4438 - acc: 0.9883 - val_loss: 1.7196 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.80863\n",
      "Epoch 163/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4202 - acc: 0.9916 - val_loss: 1.6431 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.80863\n",
      "Epoch 164/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3923 - acc: 0.9958 - val_loss: 1.4330 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.80863\n",
      "Epoch 165/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3779 - acc: 0.9979 - val_loss: 1.2433 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00165: val_acc improved from 0.80863 to 0.81941, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 166/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4957 - acc: 0.9659 - val_loss: 2.7713 - val_acc: 0.6280\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.81941\n",
      "Epoch 167/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7657 - acc: 0.9075 - val_loss: 9.8364 - val_acc: 0.1536\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.81941\n",
      "Epoch 168/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8968 - acc: 0.9039 - val_loss: 2.4413 - val_acc: 0.6604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00168: val_acc did not improve from 0.81941\n",
      "Epoch 169/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6936 - acc: 0.9494 - val_loss: 2.2586 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.81941\n",
      "Epoch 170/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5595 - acc: 0.9775 - val_loss: 1.6497 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.81941\n",
      "Epoch 171/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5009 - acc: 0.9838 - val_loss: 1.6883 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.81941\n",
      "Epoch 172/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4708 - acc: 0.9892 - val_loss: 1.5850 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.81941\n",
      "Epoch 173/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4490 - acc: 0.9889 - val_loss: 1.4590 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.81941\n",
      "Epoch 174/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4396 - acc: 0.9874 - val_loss: 1.5422 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.81941\n",
      "Epoch 175/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4053 - acc: 0.9952 - val_loss: 1.4767 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.81941\n",
      "Epoch 176/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4722 - acc: 0.9724 - val_loss: 1.7510 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.81941\n",
      "Epoch 177/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4266 - acc: 0.9850 - val_loss: 1.4346 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.81941\n",
      "Epoch 178/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4387 - acc: 0.9829 - val_loss: 2.1385 - val_acc: 0.7116\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.81941\n",
      "Epoch 179/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4857 - acc: 0.9677 - val_loss: 2.2588 - val_acc: 0.6873\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.81941\n",
      "Epoch 180/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5859 - acc: 0.9470 - val_loss: 1.8473 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.81941\n",
      "Epoch 181/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5250 - acc: 0.9641 - val_loss: 2.1836 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.81941\n",
      "Epoch 182/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4553 - acc: 0.9832 - val_loss: 1.4986 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.81941\n",
      "Epoch 183/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4200 - acc: 0.9898 - val_loss: 1.4903 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.81941\n",
      "Epoch 184/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4152 - acc: 0.9880 - val_loss: 1.9069 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.81941\n",
      "Epoch 185/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4429 - acc: 0.9769 - val_loss: 1.6663 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.81941\n",
      "Epoch 186/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5104 - acc: 0.9686 - val_loss: 2.1249 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.81941\n",
      "Epoch 187/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6491 - acc: 0.9356 - val_loss: 2.3454 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.81941\n",
      "Epoch 188/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6352 - acc: 0.9479 - val_loss: 2.3859 - val_acc: 0.6765\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.81941\n",
      "Epoch 189/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5080 - acc: 0.9763 - val_loss: 2.2851 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.81941\n",
      "Epoch 190/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4776 - acc: 0.9808 - val_loss: 1.5416 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.81941\n",
      "Epoch 191/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4549 - acc: 0.9838 - val_loss: 1.5244 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.81941\n",
      "Epoch 192/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4208 - acc: 0.9883 - val_loss: 1.5537 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.81941\n",
      "Epoch 193/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4069 - acc: 0.9904 - val_loss: 1.5403 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.81941\n",
      "Epoch 194/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3828 - acc: 0.9949 - val_loss: 1.3658 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.81941\n",
      "Epoch 195/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4118 - acc: 0.9865 - val_loss: 1.7550 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.81941\n",
      "Epoch 196/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4519 - acc: 0.9757 - val_loss: 2.1946 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.81941\n",
      "Epoch 197/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4873 - acc: 0.9668 - val_loss: 2.2757 - val_acc: 0.6658\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.81941\n",
      "Epoch 198/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5854 - acc: 0.9491 - val_loss: 4.9058 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.81941\n",
      "Epoch 199/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6176 - acc: 0.9518 - val_loss: 2.0036 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.81941\n",
      "Epoch 200/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5032 - acc: 0.9769 - val_loss: 2.5263 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.81941\n",
      "Epoch 201/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5180 - acc: 0.9695 - val_loss: 1.8512 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.81941\n",
      "Epoch 202/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4739 - acc: 0.9802 - val_loss: 1.8211 - val_acc: 0.7871\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.81941\n",
      "Epoch 203/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4574 - acc: 0.9823 - val_loss: 1.8790 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.81941\n",
      "Epoch 204/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4366 - acc: 0.9832 - val_loss: 1.9927 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.81941\n",
      "Epoch 205/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4900 - acc: 0.9683 - val_loss: 1.8075 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.81941\n",
      "Epoch 206/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4485 - acc: 0.9832 - val_loss: 1.5711 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.81941\n",
      "Epoch 207/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4214 - acc: 0.9853 - val_loss: 1.9060 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.81941\n",
      "Epoch 208/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4128 - acc: 0.9892 - val_loss: 1.5129 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.81941\n",
      "Epoch 209/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3911 - acc: 0.9907 - val_loss: 1.8059 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.81941\n",
      "Epoch 210/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4418 - acc: 0.9775 - val_loss: 1.8434 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.81941\n",
      "Epoch 211/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4854 - acc: 0.9701 - val_loss: 3.0826 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.81941\n",
      "Epoch 212/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5542 - acc: 0.9554 - val_loss: 2.7605 - val_acc: 0.5957\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.81941\n",
      "Epoch 213/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5690 - acc: 0.9635 - val_loss: 3.0807 - val_acc: 0.6038\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.81941\n",
      "Epoch 214/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5309 - acc: 0.9674 - val_loss: 1.8411 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.81941\n",
      "Epoch 215/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5080 - acc: 0.9686 - val_loss: 1.8077 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.81941\n",
      "Epoch 216/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5036 - acc: 0.9668 - val_loss: 2.3968 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.81941\n",
      "Epoch 217/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5014 - acc: 0.9727 - val_loss: 2.1020 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.81941\n",
      "Epoch 218/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4666 - acc: 0.9760 - val_loss: 1.4508 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.81941\n",
      "Epoch 219/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4187 - acc: 0.9868 - val_loss: 1.5332 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.81941\n",
      "Epoch 220/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4307 - acc: 0.9844 - val_loss: 1.4424 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.81941\n",
      "Epoch 221/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4153 - acc: 0.9838 - val_loss: 1.5375 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.81941\n",
      "Epoch 222/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3785 - acc: 0.9931 - val_loss: 1.3594 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.81941\n",
      "Epoch 223/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4006 - acc: 0.9871 - val_loss: 1.3785 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.81941\n",
      "Epoch 224/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4149 - acc: 0.9820 - val_loss: 2.2635 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.81941\n",
      "Epoch 225/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4529 - acc: 0.9772 - val_loss: 1.8372 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.81941\n",
      "Epoch 226/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4658 - acc: 0.9718 - val_loss: 2.2686 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.81941\n",
      "Epoch 227/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4673 - acc: 0.9775 - val_loss: 1.6322 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.81941\n",
      "Epoch 228/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4271 - acc: 0.9838 - val_loss: 1.6505 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.81941\n",
      "Epoch 229/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4274 - acc: 0.9820 - val_loss: 1.8220 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.81941\n",
      "Epoch 230/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4545 - acc: 0.9724 - val_loss: 1.7448 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.81941\n",
      "Epoch 231/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4619 - acc: 0.9724 - val_loss: 2.5947 - val_acc: 0.6199\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.81941\n",
      "Epoch 232/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6561 - acc: 0.9308 - val_loss: 4.0097 - val_acc: 0.4960\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.81941\n",
      "Epoch 233/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6758 - acc: 0.9449 - val_loss: 2.3748 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.81941\n",
      "Epoch 234/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5144 - acc: 0.9775 - val_loss: 1.5459 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.81941\n",
      "Epoch 235/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4698 - acc: 0.9814 - val_loss: 1.6436 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.81941\n",
      "Epoch 236/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4500 - acc: 0.9829 - val_loss: 1.4509 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.81941\n",
      "Epoch 237/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3998 - acc: 0.9937 - val_loss: 1.3384 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00237: val_acc improved from 0.81941 to 0.82749, saving model to model/mfcc6/LGD_fold5_resnet3-.h5\n",
      "Epoch 238/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3819 - acc: 0.9937 - val_loss: 1.3166 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.82749\n",
      "Epoch 239/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3585 - acc: 0.9982 - val_loss: 1.4002 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.82749\n",
      "Epoch 240/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3452 - acc: 0.9985 - val_loss: 1.3085 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.82749\n",
      "Epoch 241/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3328 - acc: 0.9994 - val_loss: 1.4133 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.82749\n",
      "Epoch 242/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3343 - acc: 0.9970 - val_loss: 1.3956 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.82749\n",
      "Epoch 243/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4036 - acc: 0.9778 - val_loss: 2.8178 - val_acc: 0.6226\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.82749\n",
      "Epoch 244/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.7906 - acc: 0.8940 - val_loss: 6.1253 - val_acc: 0.3854\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.82749\n",
      "Epoch 245/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.8850 - acc: 0.9033 - val_loss: 2.0626 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.82749\n",
      "Epoch 246/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.6139 - acc: 0.9548 - val_loss: 1.7650 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.82749\n",
      "Epoch 247/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5085 - acc: 0.9781 - val_loss: 1.5601 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.82749\n",
      "Epoch 248/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4744 - acc: 0.9820 - val_loss: 1.4746 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.82749\n",
      "Epoch 249/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4219 - acc: 0.9907 - val_loss: 1.3851 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.82749\n",
      "Epoch 250/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3897 - acc: 0.9958 - val_loss: 1.4075 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.82749\n",
      "Epoch 251/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3745 - acc: 0.9955 - val_loss: 1.4605 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.82749\n",
      "Epoch 252/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3690 - acc: 0.9961 - val_loss: 1.3959 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.82749\n",
      "Epoch 253/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3474 - acc: 0.9982 - val_loss: 1.3134 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.82749\n",
      "Epoch 254/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3420 - acc: 0.9973 - val_loss: 1.5225 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.82749\n",
      "Epoch 255/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3788 - acc: 0.9859 - val_loss: 1.7973 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.82749\n",
      "Epoch 256/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4489 - acc: 0.9635 - val_loss: 1.9986 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.82749\n",
      "Epoch 257/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4449 - acc: 0.9736 - val_loss: 1.4816 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.82749\n",
      "Epoch 258/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4779 - acc: 0.9662 - val_loss: 1.7589 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.82749\n",
      "Epoch 259/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.5630 - acc: 0.9497 - val_loss: 1.8421 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.82749\n",
      "Epoch 260/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4697 - acc: 0.9742 - val_loss: 1.6584 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.82749\n",
      "Epoch 261/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4151 - acc: 0.9877 - val_loss: 1.8142 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.82749\n",
      "Epoch 262/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4000 - acc: 0.9865 - val_loss: 1.5348 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.82749\n",
      "Epoch 263/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4071 - acc: 0.9868 - val_loss: 1.5488 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.82749\n",
      "Epoch 264/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.4039 - acc: 0.9832 - val_loss: 1.7170 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.82749\n",
      "Epoch 265/3000\n",
      "3339/3339 [==============================] - 26s 8ms/step - loss: 0.3711 - acc: 0.9913 - val_loss: 1.5723 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.82749\n",
      "Epoch 00265: early stopping\n",
      "(3418, 64, 431, 1) (3418, 41)\n",
      "===train semi_5===\n",
      "semi loading: model/mfcc6/LGD_fold5_resnet3-.h5\n"
     ]
    }
   ],
   "source": [
    "# fold=0\n",
    "for fold in val_set_num:\n",
    "    X, y = getTrainData()\n",
    "    # X = np.swapaxes(X,2,3)\n",
    "    X_train, Y_train, X_valid, Y_valid = split_data(X, y, fold) #fold\n",
    "    # X_train, X_valid = normalize(X_train, X_valid)\n",
    "    print(X_train.shape, Y_train.shape)\n",
    "\n",
    "    # X_train = np.swapaxes(X_train,1,3)\n",
    "    # X_valid = np.swapaxes(X_valid,1,3)\n",
    "    print(\"===train verified_\"+str(fold)+'===')\n",
    "    model,model_num = train_valid(X_train,Y_train,X_valid,Y_valid,fold)\n",
    "    X_semi , Y_semi = get_semi_data(X_train,Y_train)\n",
    "    print('===train semi_'+str(fold)+'===')\n",
    "    model_semi = train_unverified(model,X_semi,Y_semi,fold,model_num)\n",
    "# 0=> 0.81941 (not semi)\n",
    "# 1=>0.83019 (semi)\n",
    "# 2=>0.81941 (semi)\n",
    "# 3=>0.85984 (resnet1_not semi)0.78437\n",
    "# 4=>0.84367 (renet1_not semi)0.81132\n",
    "# 5=>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
