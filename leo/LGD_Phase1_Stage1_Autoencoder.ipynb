{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "from math import log, floor\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils import *\n",
    "from keras.layers.advanced_activations import *\n",
    "# from keras.layers.advanced_activations import *\n",
    "from keras import *\n",
    "from keras.engine.topology import *\n",
    "from keras.optimizers import *\n",
    "import keras\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import sklearn\n",
    "import pickle\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "import pandas as pd # data frame\n",
    "import numpy as np # matrix math\n",
    "from scipy.io import wavfile # reading the wavfile\n",
    "from sklearn.utils import shuffle # shuffling of data\n",
    "from random import sample # random selection\n",
    "from tqdm import tqdm # progress bar\n",
    "import matplotlib.pyplot as plt # to view graphs\n",
    "import wave\n",
    "from math import log, floor\n",
    "# audio processing\n",
    "from scipy import signal # audio processing\n",
    "from scipy.fftpack import dct\n",
    "import librosa # library for audio processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.cluster import KMeans\n",
    "import sys, os\n",
    "import random,math\n",
    "from tqdm import tqdm ##\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils import shuffle # shuffling of data\n",
    "from random import sample # random selection\n",
    "from tqdm import tqdm # progress bar\n",
    "# audio processing\n",
    "from scipy import signal # audio processing\n",
    "from scipy.fftpack import dct\n",
    "import librosa # library for audio processing\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "from keras.utils import *\n",
    "from sklearn.ensemble import *\n",
    "import pickle\n",
    "from bayes_opt import BayesianOptimization\n",
    "from logHandler import Logger\n",
    "from utils import readCSV, getPath, writePickle,readPickle\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import History ,ModelCheckpoint, EarlyStopping\n",
    "from sklearn.semi_supervised import LabelSpreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18873, 128, 63, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean = np.load('feature/fbank2/mean.npy')\n",
    "# std = np.load('feature/fbank2/std.npy')\n",
    "min_ = np.load('feature/fbank2/min.npy')\n",
    "range_ = np.load('feature/fbank2/range.npy')\n",
    "X_test = np.load('feature/fbank2/X_test.npy')\n",
    "X_train = np.load('feature/fbank2/X_train.npy')\n",
    "X_train = np.concatenate((X_train,X_test))\n",
    "# X_train = (X_train - mean)/std\n",
    "# X_train = (X_train - min_)/range_\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "laten_dim = 32\n",
    "ker_si = 2\n",
    "filters = 32\n",
    "loss_fn = 'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
    "# then z = z_mean + sqrt(var)*eps\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 63, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 63, 32)  160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 258048)       0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         264242176   flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 32)           32800       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 32)           32800       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 32)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 264,307,936\n",
      "Trainable params: 264,307,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 258048)            8515584   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 128, 63, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 128, 63, 32)       4128      \n",
      "_________________________________________________________________\n",
      "decoder_output (Conv2DTransp (None, 128, 63, 1)        129       \n",
      "=================================================================\n",
      "Total params: 8,519,841\n",
      "Trainable params: 8,519,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(X_train.shape[1],X_train.shape[2],1))\n",
    "\n",
    "x = Conv2D(filters,kernel_size=ker_si,padding='same')(input_img)\n",
    "# x = Conv2D(filters*2,(2,2),padding='same',activation='relu')(x)\n",
    "# x = Conv2D(filters*4,(2,2),padding='same',activation='relu')(x)\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(laten_dim*32,activation='selu')(x)\n",
    "z_mean = Dense(laten_dim,name='z_mean')(x)\n",
    "z_log_var = Dense(laten_dim,name='z_log_var')(x)\n",
    "z = Lambda(sampling, output_shape=(laten_dim,),name='z')([z_mean,z_log_var])\n",
    "\n",
    "encoder = Model(input_img,[z_mean,z_log_var,z],name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "latent_inputs = Input(shape=(laten_dim,), name='z_sampling')\n",
    "x = Dense(shape[1] * shape[2] * shape[3], activation='selu')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "# x = Conv2DTranspose(filters=filters*4,kernel_size=ker_si,activation='relu',padding='same')(x)\n",
    "# x = Conv2DTranspose(filters=filters*2,kernel_size=ker_si,activation='relu',padding='same')(x)\n",
    "x = Conv2DTranspose(filters=filters,kernel_size=ker_si,activation='selu',padding='same')(x)\n",
    "outputs = Conv2DTranspose(filters=1,kernel_size=ker_si,activation='sigmoid',padding='same',name='decoder_output')(x)\n",
    "decoder = Model(latent_inputs,outputs,name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "outputs = decoder(encoder(input_img)[2])\n",
    "vae = Model(input_img,outputs,name='vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 63, 1)        0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 32), (None, 32),  264307936 \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 128, 63, 1)        8519841   \n",
      "=================================================================\n",
      "Total params: 272,827,777\n",
      "Trainable params: 272,827,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if loss_fn == 'mse':\n",
    "    reconstruction_loss = mse(K.flatten(input_img), K.flatten(outputs))\n",
    "else:\n",
    "    reconstruction_loss = binary_crossentropy(K.flatten(input_img),K.flatten(outputs))\n",
    "# reconstruction_loss *= X_train.shape[1] * X_train.shape[2]\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer=Nadam())\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 1088/18873 [>.............................] - ETA: 2:10 - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-59077529c618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# vae.fit_generator(batch_generator(X_train,X_train,2),samples_per_epoch=len(X_train)//2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae.fit(X_train,epochs=50 ,shuffle=True,batch_size=64)\n",
    "# vae.fit_generator(batch_generator(X_train,X_train,2),samples_per_epoch=len(X_train)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_data_random(x, y, batch_size):\n",
    "    \"\"\"逐步提取batch数据到显存，降低对显存的占用\"\"\"\n",
    "    ylen = len(y)\n",
    "    loopcount = ylen // batch_size\n",
    "    while (True):\n",
    "        i = random.randint(0,loopcount)\n",
    "        yield x[i * batch_size:(i + 1) * batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X_gen,Y_gen,batch_size):\n",
    "        while True: \n",
    "          yield(X_gen[batch_size],Y_gen[batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 128, 63, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 63, 64)       1856      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 128, 63, 32)       57376     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 63, 1)        897       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8064)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8064)              65036160  \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 128, 63, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 128, 63, 64)       1856      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 128, 63, 1)        1793      \n",
      "=================================================================\n",
      "Total params: 65,099,938\n",
      "Trainable params: 65,099,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(X_train.shape[1],X_train.shape[2],1))\n",
    "\n",
    "x = Conv2D(64,(4,7),activation='selu',padding='same')(input_img)\n",
    "x = Conv2D(32,(4,7),activation='selu',padding='same')(x)\n",
    "x = Conv2D(1,(4,7),activation='selu',padding='same')(x)\n",
    "shape3 = K.int_shape(x)\n",
    "# x = MaxPool2D((4,11))(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "shape = K.int_shape(x)\n",
    "x = Flatten()(x)\n",
    "encoder = Dense(int(shape[1]*shape[2]*shape[3]),activation='selu')(x)\n",
    "\n",
    "# x = Dense(int(shape[1]*shape[2]*shape[3]/5),activation='relu')(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "# encoder = Dense(shape[1]*shape[2],activation='relu')(x)\n",
    "# x = Dense(int(shape[1]*shape[2]*shape[3]/5),activation='relu')(encoder)\n",
    "# x = Dropout(0.25)(x)\n",
    "# x = Dense(int(shape[1]*shape[2]*shape[3]),activation='relu')(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "# x = Reshape((shape[1],shape[2],shape[3]))(x)\n",
    "\n",
    "x = Reshape((shape[1],shape[2],shape[3]))(encoder)\n",
    "# decoder = UpSampling2D((4,11))(x)\n",
    "decoder = Conv2DTranspose(64,(4,7),padding='same',activation='selu')(x)\n",
    "decoder = Conv2DTranspose(1,(4,7),padding='same',activation='linear')(decoder)\n",
    "shape2 = K.int_shape(decoder)\n",
    "autoencoder = Model(input_img,decoder)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.68515982e-08],\n",
       "         [6.10931256e-11],\n",
       "         [1.00922095e-11],\n",
       "         ...,\n",
       "         [4.49030556e-13],\n",
       "         [6.76089206e-12],\n",
       "         [9.87279343e-13]],\n",
       "\n",
       "        [[3.24172773e-08],\n",
       "         [4.59462553e-11],\n",
       "         [6.33367303e-12],\n",
       "         ...,\n",
       "         [7.08938122e-13],\n",
       "         [6.00601911e-12],\n",
       "         [1.19238179e-12]],\n",
       "\n",
       "        [[2.60941008e-08],\n",
       "         [1.63177358e-12],\n",
       "         [3.09327118e-12],\n",
       "         ...,\n",
       "         [2.38984187e-13],\n",
       "         [4.88358964e-13],\n",
       "         [4.62261430e-14]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[3.66533340e-06],\n",
       "         [2.05469828e-09],\n",
       "         [7.67199874e-10],\n",
       "         ...,\n",
       "         [5.44710123e-10],\n",
       "         [2.93064888e-10],\n",
       "         [8.86016748e-11]],\n",
       "\n",
       "        [[4.55876436e-06],\n",
       "         [1.22505689e-09],\n",
       "         [5.18232166e-10],\n",
       "         ...,\n",
       "         [3.36411521e-10],\n",
       "         [1.90237547e-10],\n",
       "         [8.66972960e-11]],\n",
       "\n",
       "        [[3.56051742e-06],\n",
       "         [1.24054068e-10],\n",
       "         [2.76616126e-11],\n",
       "         ...,\n",
       "         [5.03232592e-11],\n",
       "         [1.10913391e-10],\n",
       "         [9.08708757e-12]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.77869978e-06],\n",
       "         [6.49183950e-09],\n",
       "         [6.87095681e-09],\n",
       "         ...,\n",
       "         [7.94671206e-09],\n",
       "         [3.22516151e-09],\n",
       "         [1.01319082e-08]],\n",
       "\n",
       "        [[3.69770429e-06],\n",
       "         [3.87558602e-09],\n",
       "         [4.35268536e-09],\n",
       "         ...,\n",
       "         [2.45381408e-09],\n",
       "         [2.09480188e-09],\n",
       "         [6.32038217e-09]],\n",
       "\n",
       "        [[2.99811450e-06],\n",
       "         [3.93119513e-11],\n",
       "         [6.24407166e-11],\n",
       "         ...,\n",
       "         [1.18547672e-10],\n",
       "         [2.44584465e-10],\n",
       "         [1.42989016e-10]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00],\n",
       "         [0.00000000e+00]]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "18873/18873 [==============================] - 10730s 569ms/step - loss: 4.3904e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff70fff6940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0313\n",
      "Epoch 2/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0200\n",
      "Epoch 3/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0138\n",
      "Epoch 4/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0105\n",
      "Epoch 5/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0085\n",
      "Epoch 6/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0068\n",
      "Epoch 7/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0048\n",
      "Epoch 8/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0040\n",
      "Epoch 9/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0035\n",
      "Epoch 10/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0029\n",
      "Epoch 11/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0022\n",
      "Epoch 12/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0019\n",
      "Epoch 13/500\n",
      "18873/18873 [==============================] - 33s 2ms/step - loss: 0.0019\n",
      "Epoch 14/500\n",
      "  512/18873 [..............................] - ETA: 32s - loss: 0.0015"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7fb85fe544ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# autoencoder.compile(optimizer=Nadam(), loss='mse')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=10, min_lr=1e-4)\n",
    "# autoencoder.compile(optimizer=Nadam(), loss='mse')\n",
    "autoencoder.compile(optimizer=Adam(lr=0.002), loss='mse')\n",
    "autoencoder.fit(X_train,X_train, epochs=500,shuffle=True,batch_size=256,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 62.9312\n",
      "Epoch 2/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 1.5340\n",
      "Epoch 3/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.9289\n",
      "Epoch 4/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.6724\n",
      "Epoch 5/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.5248\n",
      "Epoch 6/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.4282\n",
      "Epoch 7/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.3583\n",
      "Epoch 8/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.3062\n",
      "Epoch 9/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.2658\n",
      "Epoch 10/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.2336\n",
      "Epoch 11/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.2077\n",
      "Epoch 12/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1859\n",
      "Epoch 13/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1678\n",
      "Epoch 14/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1528\n",
      "Epoch 15/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1398\n",
      "Epoch 16/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1289\n",
      "Epoch 17/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1196\n",
      "Epoch 18/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1116\n",
      "Epoch 19/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1049\n",
      "Epoch 20/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0989\n",
      "Epoch 21/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0934\n",
      "Epoch 22/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0888\n",
      "Epoch 23/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0848\n",
      "Epoch 24/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0813\n",
      "Epoch 25/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0782\n",
      "Epoch 26/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0754\n",
      "Epoch 27/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0729\n",
      "Epoch 28/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0706\n",
      "Epoch 29/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0685\n",
      "Epoch 30/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0666\n",
      "Epoch 31/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0648\n",
      "Epoch 32/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0633\n",
      "Epoch 33/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0618\n",
      "Epoch 34/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0606\n",
      "Epoch 35/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0598\n",
      "Epoch 36/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0587\n",
      "Epoch 37/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0584\n",
      "Epoch 38/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0585\n",
      "Epoch 39/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0677\n",
      "Epoch 40/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.2604\n",
      "Epoch 41/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.4501\n",
      "Epoch 42/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0714\n",
      "Epoch 43/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0565\n",
      "Epoch 44/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0545\n",
      "Epoch 45/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0541\n",
      "Epoch 46/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0538\n",
      "Epoch 47/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0537\n",
      "Epoch 48/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0534\n",
      "Epoch 49/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0534\n",
      "Epoch 50/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0533\n",
      "Epoch 51/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0573\n",
      "Epoch 52/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1588\n",
      "Epoch 53/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0538\n",
      "Epoch 54/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1740\n",
      "Epoch 55/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0531\n",
      "Epoch 56/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1679\n",
      "Epoch 57/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0647\n",
      "Epoch 58/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1750\n",
      "Epoch 59/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0588\n",
      "Epoch 60/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.1646\n",
      "Epoch 61/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0536\n",
      "Epoch 62/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0519\n",
      "Epoch 63/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0518\n",
      "Epoch 64/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0517\n",
      "Epoch 65/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0516\n",
      "Epoch 66/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0515\n",
      "Epoch 67/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0515\n",
      "Epoch 68/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0514\n",
      "Epoch 69/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0515\n",
      "Epoch 70/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0515\n",
      "Epoch 71/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0528\n",
      "Epoch 72/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0521\n",
      "Epoch 73/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0511\n",
      "Epoch 74/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0510\n",
      "Epoch 75/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0511\n",
      "Epoch 76/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0511\n",
      "Epoch 77/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0511\n",
      "Epoch 78/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0513\n",
      "Epoch 79/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0510\n",
      "Epoch 80/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0510\n",
      "Epoch 81/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0512\n",
      "Epoch 82/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0515\n",
      "Epoch 83/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0516\n",
      "Epoch 84/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0553\n",
      "Epoch 85/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0512\n",
      "Epoch 86/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0613\n",
      "Epoch 87/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0519\n",
      "Epoch 88/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0572\n",
      "Epoch 89/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0526\n",
      "Epoch 90/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0514\n",
      "Epoch 91/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0575\n",
      "Epoch 92/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0576\n",
      "Epoch 93/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0552\n",
      "Epoch 94/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0584\n",
      "Epoch 95/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0565\n",
      "Epoch 96/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0512\n",
      "Epoch 97/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0540\n",
      "Epoch 98/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0539\n",
      "Epoch 99/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0518\n",
      "Epoch 100/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0565\n",
      "Epoch 101/500\n",
      "18873/18873 [==============================] - 32s 2ms/step - loss: 0.0510\n",
      "Epoch 102/500\n",
      "  256/18873 [..............................] - ETA: 31s - loss: 0.0421"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d864da18dfd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreduce_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=2e-4)\n",
    "autoencoder.compile(optimizer=Adamax(decay=1e-6), loss='mse')\n",
    "autoencoder.fit(X_train,X_train, epochs=500,shuffle=True,batch_size=256,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('model/lgd_dense_AE3.h5')\n",
    "# encoder.save('model/lgd_dense_enc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Spreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nexit()\\nX_all = X_all[verified, :]\\nidx = list(range(X_all.shape[0]))\\nrandom.shuffle(idx)\\nxSize = math.ceil(X_all.shape[0] / num_fold)\\nsplit_X_path = os.path.join(base_path, 'X')\\nsplit_y_path = os.path.join(base_path, 'y')\\nif not os.path.exists(split_X_path):\\n    os.makedirs(split_X_path)\\nif not os.path.exists(split_y_path):\\n    os.makedirs(split_y_path)\\nfor i in range(num_fold):\\n    X = X_all[idx[i*xSize:i*xSize+xSize]]\\n    y = Y_all[idx[i*xSize:i*xSize+xSize]]\\n    print('Saving fold {}'.format(i+1))\\n    print('X.shape:', X.shape)\\n    print('y.shape:', y.shape)\\n    filename = os.path.join(split_X_path, 'X' + str(i+1) + '.npy')\\n    np.save(filename, X)\\n    filename = os.path.join(split_y_path, 'y' + str(i+1) + '.npy')\\n    np.save(filename, y)\\n    time.sleep(1)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map_path = path of 'map.pkl'\n",
    "map_path = 'data/map.pkl'#sys.argv[1]\n",
    "\n",
    "# base_path = directory of all the data (train_label.csv, X_train.npy)\n",
    "base_path = 'feature/fbank2/'#sys.argv[2]\n",
    "\n",
    "\n",
    "with open(map_path, 'rb') as f:\n",
    "    map_dict = pickle.load(f)\n",
    "\n",
    "verified = []\n",
    "unverified = []\n",
    "\n",
    "train_label_path = os.path.join(base_path, 'train_label.csv')\n",
    "Y_train = pd.read_csv(train_label_path)\n",
    "\n",
    "for i in range(len(Y_train)):\n",
    "    if Y_train['manually_verified'][i] == 1:\n",
    "        verified.append(i)\n",
    "    else:\n",
    "        unverified.append(i)\n",
    "\n",
    "Y_un = Y_train.loc[unverified,:]\n",
    "\n",
    "fname_all = Y_un['fname']\n",
    "fname_all = np.array(fname_all)\n",
    "\n",
    "Y_dict = Y_un['label'].map(map_dict)\n",
    "Y_dict = np.array(Y_dict)\n",
    "\n",
    "Y_all = []\n",
    "for i in Y_dict:\n",
    "    Y_all.append(to_categorical(i, num_classes=41))\n",
    "Y_all = np.array(Y_all)\n",
    "\n",
    "filename = os.path.join(base_path, 'fname_unverified.npy')\n",
    "np.save(filename, fname_all)\n",
    "\n",
    "filename = os.path.join(base_path, 'y_unverified.npy')\n",
    "np.save(filename, Y_all)\n",
    "\n",
    "X_train_path = os.path.join(base_path, 'X_train.npy')\n",
    "X_all = np.load(X_train_path)\n",
    "\n",
    "X_un = X_all[unverified, :]\n",
    "filename = os.path.join(base_path, 'X_unverified.npy')\n",
    "np.save(filename, X_un)\n",
    "\n",
    "X_ver = X_all[verified, :]\n",
    "train_label_path = os.path.join(base_path, 'train_label.csv')\n",
    "Y_ver = pd.read_csv(train_label_path)\n",
    "Y_ver = Y_ver.loc[verified,:]\n",
    "'''\n",
    "exit()\n",
    "X_all = X_all[verified, :]\n",
    "idx = list(range(X_all.shape[0]))\n",
    "random.shuffle(idx)\n",
    "xSize = math.ceil(X_all.shape[0] / num_fold)\n",
    "split_X_path = os.path.join(base_path, 'X')\n",
    "split_y_path = os.path.join(base_path, 'y')\n",
    "if not os.path.exists(split_X_path):\n",
    "    os.makedirs(split_X_path)\n",
    "if not os.path.exists(split_y_path):\n",
    "    os.makedirs(split_y_path)\n",
    "for i in range(num_fold):\n",
    "    X = X_all[idx[i*xSize:i*xSize+xSize]]\n",
    "    y = Y_all[idx[i*xSize:i*xSize+xSize]]\n",
    "    print('Saving fold {}'.format(i+1))\n",
    "    print('X.shape:', X.shape)\n",
    "    print('y.shape:', y.shape)\n",
    "    filename = os.path.join(split_X_path, 'X' + str(i+1) + '.npy')\n",
    "    np.save(filename, X)\n",
    "    filename = os.path.join(split_y_path, 'y' + str(i+1) + '.npy')\n",
    "    np.save(filename, y)\n",
    "    time.sleep(1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5763, 128, 63, 1), (3710, 128, 63, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_un.shape , X_ver.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5763,), (3710,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_ver = Y_ver['label'].map(map_dict)\n",
    "Y_ver = np.array(Y_ver)\n",
    "Y_un = Y_un['label'].map(map_dict)\n",
    "Y_un = np.array(Y_un)\n",
    "Y_un.shape , Y_ver.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 128, 63, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 63, 64)       1856      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 128, 63, 32)       57376     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 63, 1)        897       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8064)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8064)              65036160  \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 128, 63, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 128, 63, 64)       1856      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 128, 63, 1)        1793      \n",
      "=================================================================\n",
      "Total params: 65,099,938\n",
      "Trainable params: 65,099,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 128, 63, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 63, 64)       1856      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 128, 63, 32)       57376     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 63, 1)        897       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8064)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8064)              65036160  \n",
      "=================================================================\n",
      "Total params: 65,096,289\n",
      "Trainable params: 65,096,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# enc = \n",
    "autoencoder.summary()\n",
    "model = Model(input = autoencoder.layers[0].input, output = autoencoder.layers[5].output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3710, 128, 63, 1) (5763, 128, 63, 1)\n"
     ]
    }
   ],
   "source": [
    "X_ver_dense = model.predict(X_ver)\n",
    "X_un_dense = model.predict(X_un)\n",
    "print(X_ver.shape , X_un.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('feature/fbank2/X_test.npy')\n",
    "X_test_dense = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3710, 128, 63, 1) 3710\n"
     ]
    }
   ],
   "source": [
    "print(X_ver.shape, len(Y_ver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09620187,  0.2492431 ,  0.24759266, ...,  0.04647778,\n",
       "        -0.02873544,  0.03930053],\n",
       "       [ 0.09247909,  0.24535836,  0.24525653, ...,  0.04525119,\n",
       "        -0.02469481,  0.03752303],\n",
       "       [-0.3769405 , -1.7127558 , -0.18668665, ..., -0.6169543 ,\n",
       "         0.46726173, -0.41674918],\n",
       "       ...,\n",
       "       [ 0.05762236,  0.24217416,  0.24650599, ...,  0.04710196,\n",
       "        -0.00618235,  0.03439311],\n",
       "       [-1.00396   ,  0.120268  ,  0.8185499 , ...,  0.02463336,\n",
       "         0.09405316, -0.20394024],\n",
       "       [ 0.09200265,  0.24472915,  0.24133763, ...,  0.04494386,\n",
       "        -0.02631949,  0.03843198]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9400, 8064)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelSpreading(alpha=0.2, gamma=20, kernel='knn', max_iter=30, n_jobs=-1,\n",
       "        n_neighbors=7, tol=0.001)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_model = LabelSpreading(kernel='knn',n_jobs=-1)#,n_neighbors=3,alpha=0.05)#, max_iter=50, gamma=10, alpha=0.1,tol=0.0001)\n",
    "lp_model.fit(X_ver_dense,Y_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0, 40,  7, ..., 15,  2, 39]), array([26, 39, 29, ...,  7, 21, 40]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_ans = lp_model.predict(X_un_dense)\n",
    "test_ans = lp_model.predict(X_test_dense)\n",
    "un_ans, test_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save semi data and re-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5763, 8064)\n"
     ]
    }
   ],
   "source": [
    "print(X_un_dense.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('feature/fbank2/semi/X_un_dense.npy',X_un_dense)\n",
    "np.save('feature/fbank2/semi/Y_un_dense.npy',un_ans)\n",
    "np.save('feature/fbank2/semi/X_test_dense.npy',X_test_dense)\n",
    "np.save('feature/fbank2/semi/Y_test_dense.npy',test_ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
