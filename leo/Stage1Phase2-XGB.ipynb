{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "from math import log, floor\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils import *\n",
    "from keras.layers.advanced_activations import *\n",
    "# from keras.layers.advanced_activations import *\n",
    "from keras import *\n",
    "from keras.engine.topology import *\n",
    "from keras.optimizers import *\n",
    "import keras\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import sklearn\n",
    "import pickle\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "# importing dependencies\n",
    "import pandas as pd # data frame\n",
    "import numpy as np # matrix math\n",
    "from scipy.io import wavfile # reading the wavfile\n",
    "from sklearn.utils import shuffle # shuffling of data\n",
    "from random import sample # random selection\n",
    "from tqdm import tqdm # progress bar\n",
    "import matplotlib.pyplot as plt # to view graphs\n",
    "import wave\n",
    "from math import log, floor\n",
    "# audio processing\n",
    "from scipy import signal # audio processing\n",
    "from scipy.fftpack import dct\n",
    "import librosa # library for audio processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.cluster import KMeans\n",
    "import sys, os\n",
    "import tqdm ##\n",
    "from tqdm import * ##\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils import shuffle # shuffling of data\n",
    "from random import sample # random selection\n",
    "from tqdm import tqdm # progress bar\n",
    "# audio processing\n",
    "from scipy import signal # audio processing\n",
    "from scipy.fftpack import dct\n",
    "import librosa # library for audio processing\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "from keras.utils import *\n",
    "from sklearn.ensemble import *\n",
    "import pickle\n",
    "from bayes_opt import BayesianOptimization\n",
    "from logHandler import Logger\n",
    "from utils import readCSV, getPath, writePickle,readPickle\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3710, 41)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = 'data/10fold_stacking/' #共同predict對stacling verified data的結果\n",
    "\n",
    "acc_df = pd.read_csv('data/ens_unverified/validation_ACC_P1S1.csv') #accuracy csv\n",
    "acc_df.columns = ['model','csv_name','acc']\n",
    "acc_df = acc_df.filter(['csv_name','acc'])\n",
    "acc_df['csv_name'] = acc_df['csv_name'].str.replace('_unverified_','_')\n",
    "files = os.listdir(folder)\n",
    "\n",
    "ratio_all=0\n",
    "\n",
    "df_dict = {}\n",
    "for i,csv in enumerate(files):\n",
    "    df_name = csv[:csv.rfind('_')]\n",
    "#     print(df_name)\n",
    "    if csv.startswith('validation_ACC'):\n",
    "        continue\n",
    "    \n",
    "    ratio = acc_df[acc_df['csv_name'] == csv]['acc'].values[0]\n",
    "    ratio_all += ratio\n",
    "    if not (df_name in df_dict.keys()):\n",
    "        df_dict[df_name] = pd.read_csv(os.path.join(folder,csv))\n",
    "        df1_ = df_dict[df_name].drop('fname',axis=1)\n",
    "        df1_ = np.array(df1_) * ratio\n",
    "        df1_ = pd.DataFrame(df1_)\n",
    "        df1_['acc'] = ratio\n",
    "#         print(len(df1_))\n",
    "        df_dict[df_name] = df_dict[df_name].filter(['fname'])\n",
    "        df_dict[df_name] = pd.merge(df_dict[df_name],df1_,how='inner',right_index=True,left_index=True)\n",
    "    else:\n",
    "        df1_name = pd.read_csv(os.path.join(folder,csv))\n",
    "        df1_ = df1_name.drop('fname',axis=1)\n",
    "        df1_ = np.array(df1_) * ratio\n",
    "        df1_ = pd.DataFrame(df1_)\n",
    "        df1_['acc'] = ratio\n",
    "#         print(len(df1_))\n",
    "        df1_name = df1_name.filter(['fname'])\n",
    "        df1_ = pd.merge(df1_name, df1_,how='inner',right_index=True,left_index=True)\n",
    "        df_dict[df_name] = df_dict[df_name].append(df1_, ignore_index=True)\n",
    "#         print(len(df_dict[df_name]))\n",
    "#     elif csv.startswith('mike_resnet'):\n",
    "#         ratio = acc_df[acc_df['csv_name'] == csv]['acc'].values[0]\n",
    "#         if a==0:\n",
    "#             df1 = pd.read_csv(os.path.join(folder,csv))\n",
    "#             df1_ = df1.drop('fname',axis=1)\n",
    "#             df1_ = np.array(df1_) * ratio\n",
    "#             df1_ = pd.DataFrame(df1_)\n",
    "#             df1 = df1.filter(['fname'])\n",
    "#             df1 = pd.merge(df1,df1_,how='inner',right_index=True,left_index=True)\n",
    "#             a+=1\n",
    "#         else:\n",
    "#             df1_name = pd.read_csv(os.path.join(folder,csv))\n",
    "#             df1_ = df1_name.drop('fname',axis=1)\n",
    "#             df1_ = np.array(df1_) * ratio\n",
    "#             df1_ = pd.DataFrame(df1_)\n",
    "#             df1_name = df1_name.filter(['fname'])\n",
    "#             df1_ = pd.merge(df1_name, df1_,how='inner',right_index=True,left_index=True)\n",
    "#             df1.append(df1_, ignore_index=True)\n",
    "#     elif csv.startswith('mike_cnn2d'):\n",
    "#         ratio = acc_df[acc_df['csv_name'] == csv]['acc'].values[0]\n",
    "#         if b==0:\n",
    "#             df2 = pd.read_csv(os.path.join(folder,csv))\n",
    "#             df2_ = df2.drop('fname',axis=1)\n",
    "#             df2_ = np.array(df1_) * ratio\n",
    "#             df2_ = pd.DataFrame(df1_)\n",
    "#             df2 = df2.filter(['fname'])\n",
    "#             df2 = pd.merge(df2,df1_,how='inner',right_index=True,left_index=True)\n",
    "#             b+=1\n",
    "#         else:\n",
    "#             df2.append(pd.read_csv(os.path.join(folder,csv)), ignore_index=True)     \n",
    "#     elif csv.startswith('mow_cnn2d'):\n",
    "#         ratio = acc_df[acc_df['csv_name'] == csv]['acc'].values[0]\n",
    "#         if c==0:\n",
    "#             df3 = pd.read_csv(os.path.join(folder,csv))\n",
    "#             c+=1\n",
    "#         else:\n",
    "#             df3.append(pd.read_csv(os.path.join(folder,csv)), ignore_index=True)     \n",
    "    \n",
    "#     else:\n",
    "#         print('unknown csv')\n",
    "#         break\n",
    "#         ratio = acc_df[acc_df['csv_name'] == csv]['acc'].values[0]\n",
    "#         print(ratio)\n",
    "#         ratio_all += ratio\n",
    "#     df = pd.read_csv(os.path.join(folder,csv),header=None)\n",
    "\n",
    "for k,v in df_dict.items():\n",
    "    df_dict[k] = v.sort_values('fname')\n",
    "\n",
    "_ = list(df_dict.keys())\n",
    "sum_ = np.zeros((len(df_dict[_[0]]), 42))\n",
    "for k,v in df_dict.items():\n",
    "    sum_ += v[v.columns[1:]].values\n",
    "ratio_ = np.tile(sum_[:, -1], (41, 1)).T\n",
    "train_X = sum_[:, :-1] / ratio_\n",
    "#     df_final = pd.DataFrame(sum_)\n",
    "# df_final\n",
    "\n",
    "#     sum_ /= ratio_all\n",
    "\n",
    "\n",
    "# df = pd.merge(df1,df2,on='fname',how='inner')\n",
    "# df = pd.merge(df,df3,on='fname',how='inner')\n",
    "# # if df.iloc[0,0] == 'fname':\n",
    "# df = df.drop('fname',axis=1)\n",
    "# # df = df.drop(0,axis=1)\n",
    "\n",
    "# df\n",
    "\n",
    "# if i==0:\n",
    "#     train_X = df.values*ratio\n",
    "# else:\n",
    "#     train_X += df.values*ratio\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label like: [ 1  3  4 ... 14  9 17] data#: 3710\n"
     ]
    }
   ],
   "source": [
    "label = pd.read_csv('data/train_label.csv',names=['fname','label','verified'],header=0)\n",
    "dicts_ = pickle.load(open('data/map.pkl','rb'))\n",
    "label['trans']=label['label'].map(dicts_)\n",
    "# label = label.drop(['ID','fname','verified','label'],axis=1)\n",
    "label = pd.merge(label,df_dict[k],on='fname',how='inner')\n",
    "label = label['trans'].values\n",
    "print('label like:',label,'data#:', len(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data to eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_valid_set(X_all, Y_all, percentage):\n",
    "    all_data_size = len(X_all)\n",
    "    valid_data_size = int(floor(all_data_size * percentage))\n",
    "\n",
    "    X_all, Y_all = _shuffle(X_all, Y_all)\n",
    "\n",
    "    X_train, Y_train = X_all[0:valid_data_size], Y_all[0:valid_data_size]\n",
    "    X_valid, Y_valid = X_all[valid_data_size:], Y_all[valid_data_size:]\n",
    "\n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shuffle(X, Y):\n",
    "    randomize = np.arange(len(X))\n",
    "    np.random.shuffle(randomize)\n",
    "#     print(X.shape, Y.shape)\n",
    "    return (X[randomize], Y[randomize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3339, 41) (3339,)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_valid, Y_valid = split_valid_set(train_X, label, 0.95)\n",
    "print(X_train.shape , Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(max_delta_step,reg_lambda,reg_alpha,n_estimators,max_depth, subsample, min_child_weight, gamma, colsample_bytree, colsample_bylevel):\n",
    "#, learning_rate\n",
    "# def train_xgb(max_delta_step,reg_lambda,n_estimators,max_depth,min_child_weight,gamma):\n",
    "    xgb_params = {\n",
    "#         'tree_method':'gpu_hist',\n",
    "#         'predictor':'gpu_predictor',\n",
    "        'nthread': 12,\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class':41,\n",
    "#         'n_estimators': int(750.6),\n",
    "#         'eta': 0.01,\n",
    "        'silent': 1,\n",
    "#         'seed': 0,\n",
    "        # for _train_internal\n",
    "        'eval_metric': ['merror'],\n",
    "        ######################\n",
    "        'max_delta_step':int(max_delta_step),\n",
    "        'reg_lambda': max(reg_lambda, 0),\n",
    "        'reg_alpha': max(reg_alpha, 0),\n",
    "        'n_estimators':int(n_estimators),\n",
    "        'max_depth': int(max_depth),\n",
    "        'subsample': max(min(subsample, 1), 0),\n",
    "        'min_child_weight': int(min_child_weight),\n",
    "#         'alpha': max(alpha, 0),\n",
    "        'gamma': max(gamma, 0),\n",
    "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "        'colsample_bylevel': max(min(colsample_bylevel, 1), 0),\n",
    "#         'learning_rate': max(min(learning_rate, 1), 0),\n",
    "    }\n",
    "    # print(dTrain)\n",
    "    score = xgb.cv(\n",
    "        xgb_params, \n",
    "        dTrain, \n",
    "        num_boost_round=1500, #2000\n",
    "        early_stopping_rounds=10, #100\n",
    "        verbose_eval=False,\n",
    "        maximize=False, #針對eval_metric\n",
    "        nfold=3, #10\n",
    "        seed=np.random.get_state()[1][0]\n",
    "    )\n",
    "    # logger.info(score)\n",
    "    return -score['test-merror-mean'].iloc[-1] #回傳給BO去maximize的，只能改中間的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "#     X, Y, testX, testFid = prepare_data()\n",
    "#     X, Y, testX = str2float(X, Y, testX)\n",
    "#     X, testX = scale_data(X, testX)\n",
    "    \n",
    "#     if args.select_feature:\n",
    "        # select feature\n",
    "#         pass\n",
    "    for iter in range(30): #the number of trying sampling，挑選幾個XGB存起來??\n",
    "        np.random.seed(iter)\n",
    "        logger.info('Iteration %2d, Current random seed: %2d' % (iter, np.random.get_state()[1][0]))\n",
    "        # sampling data\n",
    "        # trainX, trainY, validX, validY = sample_data(X, Y)\n",
    "        trainX = train_X#pca_all #train_X#X_train\n",
    "        trainY = label#label#train_Y#Y_train\n",
    "        testX = train_X#pca_all#train_X#X_valid\n",
    "        testY = label#label#train_Y#Y_valid\n",
    "        global dTrain\n",
    "        dTrain = xgb.DMatrix(trainX, label=trainY, nthread=12)\n",
    "        global dTest\n",
    "        dTest = xgb.DMatrix(testX, label=testY,nthread=12)\n",
    "\n",
    "        # bayes_opt selection\n",
    "        # parameter to be learning \n",
    "        logger.info('Setting parameters for BayesianOptimaization')       \n",
    "        params = {\n",
    "            'max_delta_step':(0,10),#(0,10), #0~10 0=>nolimit\n",
    "            'reg_lambda': (70,85), #1e-5,200 #1: 25,60\n",
    "            'reg_alpha': (0,0.3), #100 1=>0~1\n",
    "            'n_estimators':(1120,1135), #50~1600 #250~1200 #1: 365,410\n",
    "            'max_depth': (1,1),#(1, 10), #65 #不能0=>no limit #1:1,16\n",
    "            'subsample': (0.9, 1), #0~1\n",
    "            'min_child_weight': (8, 11), #30 1=>0~1\n",
    "#             'alpha': (0, 10), #等同reg_alpha\n",
    "            'gamma': (0,1), #30 1=>0~1\n",
    "            'colsample_bytree': (0.8, 1), #1e-5~1\n",
    "            'colsample_bylevel': (0.9, 1), #(1e-5,1)\n",
    "#             'learning_rate': (0.01, 1),\n",
    "        }\n",
    "        logger.info('Running BayesianOptimization')\n",
    "        xgb_bayesopt = BayesianOptimization(train_xgb, params)\n",
    "        xgb_bayesopt.maximize(init_points=6, n_iter=100) #10,50 #5 ,25\n",
    "        \n",
    "        # get the best param\n",
    "        best_params = xgb_bayesopt.res['max']['max_params']\n",
    "        logger.info('Iteration: %d, XGBoost max auc: %f' % (iter, xgb_bayesopt.res['max']['max_val']))\n",
    "        for param, val in best_params.items():\n",
    "            logger.info('Param %s: %r' % (param, val))\n",
    "        # setting xgboost param\n",
    "        logger.info('Setting best parameters for BayesianOptimization')\n",
    "        xgb_params = {\n",
    "#             'tree_method':'gpu_hist',\n",
    "#             'predictor':'gpu_predictor',\n",
    "            'nthread': 12,\n",
    "#             'n_estimators': int(750.6),\n",
    "#             'eta': 0.01,\n",
    "            'silent': 1,\n",
    "            # for _train_internal\n",
    "#             'eval_metric': ['map'],\n",
    "            ######################\n",
    "            'max_delta_step':int(best_params['max_delta_step']),\n",
    "            'reg_lambda': max(best_params['reg_lambda'], 0),\n",
    "            'reg_alpha': max(best_params['reg_alpha'], 0),\n",
    "            'n_estimators':int(best_params['n_estimators']),\n",
    "            'max_depth': int(best_params['max_depth']),\n",
    "            'subsample': max(min(best_params['subsample'], 1), 0),\n",
    "            'min_child_weight': int(best_params['min_child_weight']),\n",
    "##             'alpha': max(best_params['alpha'], 0),\n",
    "            'gamma': max(best_params['gamma'], 0),\n",
    "            'colsample_bytree': max(min(best_params['colsample_bytree'], 1), 0),\n",
    "            'colsample_bylevel': max(min(best_params['colsample_bylevel'], 1), 0),\n",
    "#             'learning_rate': max(min(best_params['learning_rate'], 1), 0),\n",
    "        }\n",
    "        # training\n",
    "        model = xgb.train(\n",
    "            xgb_params, \n",
    "            dTrain, \n",
    "            num_boost_round=1500,  #2000\n",
    "            verbose_eval=False, \n",
    "            maximize=False,\n",
    "            \n",
    "        )\n",
    "        #save XGB best model\n",
    "#         writePickle(model, os.path.join('model', 'model2_iter%d_%dfold_%f.pkl' % (iter, 3, xgb_bayesopt.res['max']['max_val'])))\n",
    "        #n_fold\n",
    "        # predict valid y\n",
    "#         predY = model.predict(dTest)\n",
    "#         result_df = pd.DataFrame(data={'y':predY})\n",
    "#         joined_df = pd.DataFrame(testFid).join(result_df)\n",
    "\n",
    "\n",
    "#         joined_df.to_csv(os.path.join('result', 'xgb_result%d_%dfold.csv' % (iter, 10)), index=False)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # re-sorted the fid because of the random splitting data\n",
    "        logger.info('----------------------------------------------------------------------\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-15 22:03:54,433 - logHandler - train - INFO - Iteration  0, Current random seed:  0\n",
      "2018-06-15 22:03:54,434 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-15 22:03:54,434 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.15310\u001b[0m | \u001b[32m             0.9050\u001b[0m | \u001b[32m            0.9756\u001b[0m | \u001b[32m   0.6188\u001b[0m | \u001b[32m          9.2569\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.7689\u001b[0m | \u001b[32m     1134.4254\u001b[0m | \u001b[32m     0.2315\u001b[0m | \u001b[32m     77.8663\u001b[0m | \u001b[32m     0.9381\u001b[0m | \n",
      "    2 | 00m02s |   -0.16145 |              0.9523 |             0.9167 |    0.8470 |           2.8036 |      1.0000 |             8.3034 |      1125.1970 |      0.1456 |      79.7392 |      0.9283 | \n",
      "    3 | 00m03s |   -0.15364 |              0.9222 |             0.9645 |    0.1923 |           3.1715 |      1.0000 |             9.8057 |      1128.2612 |      0.2244 |      84.9629 |      0.9018 | \n",
      "    4 | 00m02s |   -0.15525 |              0.9165 |             0.9138 |    0.7240 |           8.7570 |      1.0000 |             8.9257 |      1124.7412 |      0.1038 |      78.4726 |      0.9108 | \n",
      "    5 | 00m02s |   -0.15957 |              0.9754 |             0.8883 |    0.8488 |           3.0021 |      1.0000 |            10.2762 |      1129.4538 |      0.2006 |      76.3064 |      0.9053 | \n",
      "    6 | 00m02s |   -0.15391 |              0.9294 |             0.9038 |    0.6939 |           6.4355 |      1.0000 |             8.2734 |      1125.4191 |      0.0155 |      74.8675 |      0.9969 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m12s |   -0.15822 |              0.9000 |             0.9490 |    0.0000 |          10.0000 |      1.0000 |            11.0000 |      1120.0000 |      0.1201 |      70.0000 |      1.0000 | \n",
      "    8 | 00m11s |   -0.16388 |              0.9217 |             0.8750 |    0.1125 |           0.4312 |      1.0000 |             8.4131 |      1133.8291 |      0.0423 |      70.0754 |      0.9152 | \n",
      "    9 | 00m14s |   -0.15633 |              0.9678 |             0.9909 |    0.8407 |           2.1973 |      1.0000 |             8.1368 |      1134.9461 |      0.0296 |      84.9835 |      0.9200 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([6.41807405e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10 | 00m15s |   -0.16226 |              0.9507 |             0.8967 |    0.0181 |           9.9059 |      1.0000 |             8.4246 |      1134.7307 |      0.2208 |      84.8202 |      0.9345 | \n",
      "   11 | 00m13s |   -0.15580 |              0.9288 |             0.8084 |    0.9871 |           9.5536 |      1.0000 |             9.0318 |      1132.3789 |      0.1080 |      70.0325 |      0.9377 | \n",
      "   12 | 00m15s |   -0.15364 |              0.9884 |             0.9440 |    0.0116 |           9.2916 |      1.0000 |             8.1427 |      1129.4976 |      0.2449 |      75.1794 |      0.9667 | \n",
      "   13 | 00m15s |   -0.15579 |              0.9090 |             0.9923 |    0.0260 |           5.8841 |      1.0000 |            10.9649 |      1120.1556 |      0.0176 |      84.5917 |      0.9217 | \n",
      "   14 | 00m17s |   -0.16145 |              0.9279 |             0.8130 |    0.0866 |           0.5991 |      1.0000 |            10.9573 |      1134.2608 |      0.0436 |      84.9109 |      0.9804 | \n",
      "   15 | 00m17s |   -0.15876 |              0.9213 |             0.9615 |    0.0292 |           7.5427 |      1.0000 |            10.7505 |      1134.7862 |      0.0257 |      71.1274 |      0.9630 | \n",
      "   16 | 00m16s |   -0.16092 |              0.9576 |             0.9976 |    0.9792 |           8.9494 |      1.0000 |            10.9831 |      1125.4084 |      0.1010 |      84.7504 |      0.9650 | \n",
      "   17 | 00m16s |   -0.15715 |              0.9465 |             0.9749 |    0.4070 |           9.8921 |      1.0000 |             8.1178 |      1120.6787 |      0.2415 |      70.0649 |      0.9086 | \n",
      "   18 | 00m17s |   -0.15606 |              0.9252 |             0.9767 |    0.0750 |           5.7073 |      1.0000 |             8.0098 |      1134.9508 |      0.0282 |      76.8245 |      0.9591 | \n",
      "   19 | 00m17s |   -0.15768 |              0.9294 |             0.9347 |    0.1379 |           0.1302 |      1.0000 |            10.6767 |      1120.5060 |      0.2520 |      70.1147 |      0.9687 | \n",
      "   20 | 00m18s |   -0.15768 |              0.9032 |             0.8866 |    0.9878 |           0.1092 |      1.0000 |             9.6033 |      1120.1406 |      0.0101 |      84.9954 |      0.9676 | \n",
      "   21 | 00m19s |   -0.15983 |              0.9082 |             0.9351 |    0.9054 |           6.2718 |      1.0000 |            10.8051 |      1124.2991 |      0.2927 |      70.9577 |      0.9116 | \n",
      "   22 | 00m18s |   -0.15553 |              0.9445 |             0.9978 |    0.3190 |           7.0213 |      1.0000 |             8.1258 |      1120.0251 |      0.0346 |      84.8455 |      0.9895 | \n",
      "   23 | 00m19s |   -0.15822 |              0.9816 |             0.9977 |    0.9489 |           9.3442 |      1.0000 |             8.5853 |      1131.3248 |      0.0452 |      78.1113 |      0.9406 | \n",
      "   24 | 00m19s |   -0.15714 |              0.9000 |             0.8000 |    0.0000 |           2.4427 |      1.0000 |             8.0000 |      1120.0000 |      0.0000 |      70.5281 |      0.9000 | \n",
      "   25 | 00m18s |   -0.15957 |              0.9279 |             0.8446 |    0.0179 |           9.9746 |      1.0000 |             9.7982 |      1120.2690 |      0.2444 |      77.2498 |      0.9778 | \n",
      "   26 | 00m19s |   -0.15984 |              0.9305 |             0.8935 |    0.7863 |           4.2579 |      1.0000 |            10.8313 |      1134.9817 |      0.2789 |      84.7732 |      0.9777 | \n",
      "   27 | 00m20s |   -0.15876 |              0.9129 |             0.8196 |    0.1041 |           9.7830 |      1.0000 |             8.0694 |      1125.7957 |      0.0725 |      70.5148 |      0.9945 | \n",
      "   28 | 00m21s |   -0.15687 |              0.9221 |             0.9389 |    0.6514 |           9.8953 |      1.0000 |             8.3324 |      1134.6896 |      0.2925 |      73.5259 |      0.9172 | \n",
      "   29 | 00m20s |   -0.15741 |              0.9849 |             0.9390 |    0.0026 |           0.1860 |      1.0000 |             8.6766 |      1120.2604 |      0.2346 |      84.6687 |      0.9700 | \n",
      "   30 | 00m20s |   -0.15984 |              0.9270 |             0.9853 |    0.9058 |           0.6672 |      1.0000 |             8.0510 |      1125.6765 |      0.0841 |      70.1463 |      0.9316 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([6.9040687e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 | 00m21s |   -0.15499 |              0.9106 |             0.8389 |    0.3637 |           0.5482 |      1.0000 |             8.2967 |      1129.8945 |      0.2880 |      84.8842 |      0.9927 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-8.87237693e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00011208]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 00m20s |   -0.15741 |              0.9401 |             0.9940 |    0.9149 |           0.1843 |      1.0000 |             8.1696 |      1120.0887 |      0.1088 |      70.3691 |      0.9949 | \n",
      "   33 | 00m20s |   -0.15688 |              0.9273 |             0.8511 |    0.1289 |           9.9134 |      1.0000 |            10.9847 |      1132.4748 |      0.2319 |      75.4798 |      0.9311 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00062182]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 00m20s |   -0.15822 |              0.9104 |             0.9977 |    0.4705 |           3.8968 |      1.0000 |             8.1104 |      1130.5441 |      0.2986 |      70.6291 |      0.9991 | \n",
      "   35 | 00m20s |   -0.16173 |              0.9885 |             0.8474 |    0.0004 |           5.4473 |      1.0000 |             8.6861 |      1125.0647 |      0.2969 |      84.8945 |      0.9709 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00026074]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00010895]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 | 00m22s |   -0.15741 |              0.9011 |             0.9941 |    0.0112 |           0.1354 |      1.0000 |             8.2125 |      1134.8461 |      0.1392 |      81.5589 |      0.9673 | \n",
      "   37 | 00m22s |   -0.15364 |              0.9046 |             0.9859 |    0.1062 |           0.0521 |      1.0000 |             8.1843 |      1129.3384 |      0.0753 |      84.9730 |      0.9094 | \n",
      "   38 | 00m22s |   -0.15741 |              0.9606 |             0.9877 |    0.2153 |           9.7272 |      1.0000 |            10.3507 |      1120.1194 |      0.2759 |      84.6962 |      0.9942 | \n",
      "   39 | 00m20s |   -0.15876 |              0.9026 |             0.9665 |    0.0565 |           0.5847 |      1.0000 |            10.2351 |      1120.0072 |      0.0937 |      75.8572 |      0.9815 | \n",
      "   40 | 00m22s |   -0.16065 |              0.9321 |             0.9884 |    0.0139 |           6.7625 |      1.0000 |            10.8703 |      1128.8094 |      0.2663 |      78.4089 |      0.9362 | \n",
      "   41 | 00m23s |   -0.15795 |              0.9131 |             0.9987 |    0.8772 |           1.1203 |      1.0000 |            10.9535 |      1126.8457 |      0.1903 |      84.9470 |      0.9895 | \n",
      "   42 | 00m26s |   -0.15660 |              0.9033 |             0.9285 |    0.8951 |           9.6169 |      1.0000 |             8.0361 |      1126.7661 |      0.1075 |      75.1710 |      0.9050 | \n",
      "   43 | 00m24s |   -0.15822 |              0.9921 |             0.9600 |    0.9836 |           5.5599 |      1.0000 |             8.3795 |      1120.0370 |      0.2519 |      76.1928 |      0.9012 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00106451]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   44 | 00m24s |   -0.15822 |              0.9625 |             0.9949 |    0.0075 |           9.7691 |      1.0000 |            10.1309 |      1129.7467 |      0.0079 |      70.4711 |      0.9218 | \n",
      "   45 | 00m26s |   -0.15930 |              0.9772 |             0.9974 |    0.1070 |           3.7409 |      1.0000 |             8.2025 |      1131.7329 |      0.0807 |      84.0785 |      0.9968 | \n",
      "   46 | 00m23s |   -0.16011 |              0.9539 |             0.9886 |    0.9828 |           0.2362 |      1.0000 |            10.1121 |      1134.8142 |      0.2353 |      74.5593 |      0.9758 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00063477]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   47 | 00m23s |   -0.15983 |              0.9615 |             0.8920 |    0.0156 |           9.9219 |      1.0000 |            10.7146 |      1134.6776 |      0.1784 |      81.7640 |      0.9169 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00071983]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 00m25s |   -0.15580 |              0.9100 |             0.9361 |    0.0261 |           7.0197 |      1.0000 |             8.0034 |      1124.2660 |      0.2985 |      75.7967 |      0.9105 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00100308]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 00m33s |   -0.15822 |              0.9827 |             0.9500 |    0.7967 |           5.3313 |      1.0000 |            10.3357 |      1120.0476 |      0.0028 |      70.2662 |      0.9387 | \n",
      "   50 | 00m41s |   -0.15714 |              0.9118 |             0.8095 |    0.7072 |           6.9303 |      1.0000 |             8.6545 |      1129.8006 |      0.0098 |      73.5807 |      0.9311 | \n",
      "   51 | 00m40s |   -0.16226 |              0.9018 |             0.9422 |    0.0052 |           0.1656 |      1.0000 |             8.2016 |      1129.4486 |      0.2947 |      75.3622 |      0.9591 | \n",
      "   52 | 00m41s |   -0.15957 |              0.9692 |             0.9050 |    0.0389 |           9.8048 |      1.0000 |             8.8237 |      1134.5904 |      0.2026 |      70.0361 |      0.9218 | \n",
      "   53 | 00m39s |   -0.16065 |              0.9124 |             0.8553 |    0.4709 |           1.8161 |      1.0000 |            10.8404 |      1130.8423 |      0.2928 |      70.0637 |      0.9998 | \n",
      "   54 | 00m47s |   -0.15930 |              0.9228 |             0.9946 |    0.9859 |           9.8913 |      1.0000 |             8.8220 |      1120.0189 |      0.0440 |      82.3632 |      0.9521 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0014366]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   55 | 00m46s |   -0.15714 |              0.9998 |             0.9479 |    0.7755 |           6.8397 |      1.0000 |             9.7484 |      1134.8406 |      0.2986 |      75.2765 |      0.9897 | \n",
      "   56 | 00m43s |   -0.15741 |              0.9239 |             0.9319 |    0.0068 |           9.5169 |      1.0000 |             8.5627 |      1134.8917 |      0.0202 |      77.6416 |      0.9649 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00038389]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   57 | 00m42s |   -0.16415 |              0.9102 |             0.9922 |    0.9774 |           9.2888 |      1.0000 |            10.3625 |      1134.7778 |      0.1611 |      70.3200 |      0.9358 | \n",
      "   58 | 00m43s |   -0.15714 |              0.9096 |             0.9971 |    0.0532 |           2.4746 |      1.0000 |            10.0304 |      1124.0215 |      0.0272 |      74.3581 |      0.9941 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-7.74802866e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   59 | 00m44s |   -0.15741 |              0.9221 |             0.9891 |    0.0201 |           9.3286 |      1.0000 |             8.1496 |      1132.2340 |      0.2604 |      71.2338 |      0.9031 | \n",
      "   60 | 00m45s |   -0.15876 |              0.9021 |             0.8226 |    0.0610 |           1.8412 |      1.0000 |            10.7988 |      1134.8827 |      0.0151 |      78.1446 |      0.9159 | \n",
      "   61 | 00m42s |   -0.16361 |              0.9546 |             0.9669 |    0.7229 |           4.9170 |      1.0000 |            10.3001 |      1120.2181 |      0.2772 |      84.9640 |      0.9481 | \n",
      "   62 | 00m45s |   -0.15741 |              0.9018 |             0.9108 |    0.9792 |           4.4124 |      1.0000 |             8.3411 |      1134.9104 |      0.2847 |      70.0445 |      0.9456 | \n",
      "   63 | 00m43s |   -0.15984 |              0.9226 |             0.8342 |    0.0351 |           6.7791 |      1.0000 |             8.2501 |      1120.0807 |      0.0466 |      80.5303 |      0.9897 | \n",
      "   64 | 00m44s |   -0.15687 |              0.9590 |             0.8114 |    0.9086 |           4.9103 |      1.0000 |             8.1890 |      1134.9736 |      0.2327 |      80.0634 |      0.9285 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0002353]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00035622]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   65 | 00m47s |   -0.15661 |              0.9075 |             0.9061 |    0.0081 |           9.8031 |      1.0000 |             9.1472 |      1127.6574 |      0.2999 |      84.9855 |      0.9422 | \n",
      "   66 | 00m48s |   -0.15525 |              0.9510 |             0.8735 |    0.9806 |           1.9615 |      1.0000 |             8.1109 |      1134.8545 |      0.0328 |      76.9648 |      0.9940 | \n",
      "   67 | 00m49s |   -0.15580 |              0.9844 |             0.9171 |    0.1695 |           0.1606 |      1.0000 |            10.7819 |      1120.3304 |      0.0555 |      84.6961 |      0.9720 | \n",
      "   68 | 00m49s |   -0.15822 |              0.9289 |             0.8347 |    0.0291 |           2.8611 |      1.0000 |             8.6381 |      1134.9543 |      0.2129 |      73.1749 |      0.9750 | \n",
      "   69 | 00m45s |   -0.15903 |              0.9120 |             0.9606 |    0.9880 |           0.1067 |      1.0000 |            10.0501 |      1132.8140 |      0.0819 |      84.9647 |      0.9111 | \n",
      "   70 | 00m50s |   -0.16145 |              0.9019 |             0.8831 |    0.9791 |           5.0556 |      1.0000 |             8.1994 |      1121.4542 |      0.2912 |      70.2064 |      0.9919 | \n",
      "   71 | 00m52s |   -0.15876 |              0.9728 |             0.8843 |    0.9270 |           9.2774 |      1.0000 |             8.4041 |      1120.0563 |      0.0139 |      72.5633 |      0.9669 | \n",
      "   72 | 00m47s |   -0.16173 |              0.9263 |             0.8214 |    0.0359 |           9.9748 |      1.0000 |             8.1968 |      1121.3987 |      0.0851 |      84.6097 |      0.9127 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00033082]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   73 | 00m52s |   -0.15660 |              0.9218 |             0.8127 |    0.0388 |           4.2622 |      1.0000 |            10.5902 |      1127.8278 |      0.0230 |      70.0055 |      0.9917 | \n",
      "   74 | 00m53s |   -0.16280 |              0.9403 |             0.9861 |    0.2112 |           6.7603 |      1.0000 |            10.9123 |      1123.1370 |      0.0209 |      76.9868 |      0.9654 | \n",
      "   75 | 00m47s |   -0.15391 |              0.9131 |             0.9040 |    0.7431 |           9.1974 |      1.0000 |            10.9470 |      1130.7768 |      0.2746 |      84.7922 |      0.9833 | \n",
      "   76 | 00m50s |   -0.15903 |              0.9001 |             0.8172 |    0.9927 |           0.0094 |      1.0000 |            10.4504 |      1120.5046 |      0.0244 |      70.0854 |      0.9830 | \n",
      "   77 | 00m54s |   -0.16092 |              0.9338 |             0.8676 |    0.9319 |           9.8418 |      1.0000 |            10.1881 |      1134.9184 |      0.1671 |      84.6758 |      0.9881 | \n",
      "   78 | 00m59s |   -0.15768 |              0.9021 |             0.9343 |    0.0113 |           7.3438 |      1.0000 |            10.9329 |      1130.3962 |      0.2975 |      84.6039 |      0.9317 | \n",
      "   79 | 00m48s |   -0.16200 |              0.9117 |             0.9719 |    0.7749 |           5.0993 |      1.0000 |             8.0154 |      1128.1735 |      0.1849 |      77.1540 |      0.9568 | \n",
      "   80 | 00m51s |   -0.15579 |              0.9860 |             0.9436 |    0.0727 |           0.1830 |      1.0000 |             8.1065 |      1120.2159 |      0.0384 |      76.0514 |      0.9068 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00202128]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   81 | 00m56s | \u001b[35m  -0.15229\u001b[0m | \u001b[32m             0.9860\u001b[0m | \u001b[32m            0.9855\u001b[0m | \u001b[32m   0.1568\u001b[0m | \u001b[32m          0.1796\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.4935\u001b[0m | \u001b[32m     1124.4252\u001b[0m | \u001b[32m     0.0384\u001b[0m | \u001b[32m     84.9936\u001b[0m | \u001b[32m     0.9038\u001b[0m | \n",
      "   82 | 00m51s |   -0.15660 |              0.9227 |             0.9917 |    0.0289 |           9.9457 |      1.0000 |            10.2751 |      1127.8317 |      0.2798 |      78.8961 |      0.9485 | \n",
      "   83 | 00m51s |   -0.16253 |              0.9408 |             0.9443 |    0.0589 |           0.2126 |      1.0000 |             9.6789 |      1127.7261 |      0.0577 |      82.1454 |      0.9617 | \n",
      "   84 | 00m52s |   -0.15391 |              0.9707 |             0.8184 |    0.1230 |           6.8508 |      1.0000 |            10.0359 |      1133.7408 |      0.2758 |      70.0451 |      0.9128 | \n",
      "   85 | 00m54s |   -0.16038 |              0.9857 |             0.9668 |    0.8954 |           1.9547 |      1.0000 |             8.1791 |      1127.8793 |      0.0280 |      84.9868 |      0.9272 | \n",
      "   86 | 00m55s |   -0.15688 |              0.9076 |             0.9947 |    0.1212 |           1.5115 |      1.0000 |            10.0053 |      1131.3766 |      0.2588 |      84.8880 |      0.9412 | \n",
      "   87 | 00m55s |   -0.15957 |              0.9688 |             0.8165 |    0.1047 |           0.0084 |      1.0000 |             8.2605 |      1134.2559 |      0.0346 |      84.9393 |      0.9584 | \n",
      "   88 | 00m55s |   -0.15714 |              0.9143 |             0.8660 |    0.8982 |           9.9318 |      1.0000 |             9.8568 |      1130.1735 |      0.2813 |      75.5373 |      0.9750 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00036927]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   89 | 00m51s |   -0.15849 |              0.9936 |             0.9816 |    0.8587 |           6.8840 |      1.0000 |             8.0775 |      1126.9704 |      0.1804 |      70.0430 |      0.9032 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00142661]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00059278]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   90 | 01m00s |   -0.15661 |              0.9074 |             0.8178 |    0.0024 |           9.9868 |      1.0000 |            10.3856 |      1130.6317 |      0.1082 |      84.9103 |      0.9412 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00045797]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   91 | 00m51s |   -0.16307 |              0.9073 |             0.8976 |    0.9980 |           9.0224 |      1.0000 |             8.6247 |      1131.1070 |      0.2416 |      84.4698 |      0.9926 | \n",
      "   92 | 00m56s |   -0.16172 |              0.9712 |             0.9987 |    0.0558 |           9.8393 |      1.0000 |             8.0916 |      1122.0004 |      0.0570 |      76.4934 |      0.9974 | \n",
      "   93 | 00m57s |   -0.15822 |              0.9174 |             0.8165 |    0.9668 |           0.1670 |      1.0000 |             8.1220 |      1124.1256 |      0.1291 |      75.4829 |      0.9287 | \n",
      "   94 | 01m05s |   -0.16011 |              0.9924 |             0.9850 |    0.8350 |           9.7962 |      1.0000 |            10.8251 |      1134.2579 |      0.2689 |      78.2962 |      0.9605 | \n",
      "   95 | 01m01s |   -0.15876 |              0.9460 |             0.8530 |    0.0618 |           8.1142 |      1.0000 |             9.4252 |      1132.7921 |      0.2890 |      77.1737 |      0.9029 | \n",
      "   96 | 00m57s |   -0.15256 |              0.9460 |             0.9988 |    0.1211 |           0.0279 |      1.0000 |             8.2634 |      1120.0177 |      0.0510 |      80.1360 |      0.9073 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00040206]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   97 | 01m08s |   -0.15525 |              0.9143 |             0.9814 |    0.6162 |           0.1343 |      1.0000 |            10.9103 |      1126.8806 |      0.1102 |      74.4463 |      0.9310 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00036756]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00068064]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   98 | 01m08s |   -0.15364 |              0.9068 |             0.9212 |    0.2200 |           0.0431 |      1.0000 |            10.2883 |      1121.4345 |      0.0275 |      82.6794 |      0.9093 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-5.18265297e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   99 | 01m00s |   -0.15903 |              0.9125 |             0.9811 |    0.0008 |           7.9028 |      1.0000 |             8.9124 |      1120.3583 |      0.0121 |      71.4795 |      0.9774 | \n",
      "  100 | 01m00s |   -0.15715 |              0.9024 |             0.8435 |    0.0451 |           2.6932 |      1.0000 |            10.0443 |      1127.2470 |      0.2761 |      72.9397 |      0.9097 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00094775]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  101 | 01m05s |   -0.16011 |              0.9033 |             0.8514 |    0.0376 |           0.0712 |      1.0000 |             8.0086 |      1125.3122 |      0.1154 |      84.7802 |      0.9585 | \n",
      "  102 | 01m08s |   -0.16038 |              0.9341 |             0.9946 |    0.2416 |           0.1323 |      1.0000 |            10.9649 |      1124.1695 |      0.2231 |      84.9919 |      0.9236 | \n",
      "  103 | 01m12s |   -0.15418 |              0.9036 |             0.9817 |    0.1267 |           5.7143 |      1.0000 |             8.5219 |      1134.8900 |      0.2796 |      84.6918 |      0.9475 | \n",
      "  104 | 01m07s |   -0.16334 |              0.9079 |             0.9448 |    0.0273 |           2.4823 |      1.0000 |             8.6988 |      1120.0839 |      0.0205 |      81.2051 |      0.9058 | \n",
      "  105 | 01m07s |   -0.15687 |              0.9971 |             0.9769 |    0.4460 |           0.0470 |      1.0000 |            10.1656 |      1122.7458 |      0.0121 |      78.9956 |      0.9907 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00045714]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  106 | 01m13s |   -0.15849 |              0.9467 |             0.8527 |    0.9717 |           0.0929 |      1.0000 |             9.2785 |      1130.3844 |      0.0133 |      72.0566 |      0.9971 | \n",
      "2018-06-15 23:10:04,585 - logHandler - train - INFO - Iteration: 0, XGBoost max auc: -0.152290\n",
      "2018-06-15 23:10:04,587 - logHandler - train - INFO - Param max_delta_step: 0.17961999903504333\n",
      "2018-06-15 23:10:04,588 - logHandler - train - INFO - Param reg_lambda: 84.99359587205444\n",
      "2018-06-15 23:10:04,590 - logHandler - train - INFO - Param reg_alpha: 0.038381920686318426\n",
      "2018-06-15 23:10:04,591 - logHandler - train - INFO - Param n_estimators: 1124.4251936024773\n",
      "2018-06-15 23:10:04,592 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-15 23:10:04,594 - logHandler - train - INFO - Param subsample: 0.9038045842146902\n",
      "2018-06-15 23:10:04,595 - logHandler - train - INFO - Param min_child_weight: 9.493490075057935\n",
      "2018-06-15 23:10:04,596 - logHandler - train - INFO - Param gamma: 0.1567852971733722\n",
      "2018-06-15 23:10:04,597 - logHandler - train - INFO - Param colsample_bytree: 0.9854783139625078\n",
      "2018-06-15 23:10:04,599 - logHandler - train - INFO - Param colsample_bylevel: 0.9859540935205913\n",
      "2018-06-15 23:10:04,600 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-15 23:10:05,402 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-15 23:10:05,403 - logHandler - train - INFO - Iteration  1, Current random seed:  1\n",
      "2018-06-15 23:10:05,406 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-15 23:10:05,407 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.15526\u001b[0m | \u001b[32m             0.9527\u001b[0m | \u001b[32m            0.8282\u001b[0m | \u001b[32m   0.8692\u001b[0m | \u001b[32m          5.4564\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.5298\u001b[0m | \u001b[32m     1121.3953\u001b[0m | \u001b[32m     0.1819\u001b[0m | \u001b[32m     78.3397\u001b[0m | \u001b[32m     0.9057\u001b[0m | \n",
      "    2 | 00m02s |   -0.15634 |              0.9683 |             0.9263 |    0.8534 |           9.9838 |      1.0000 |             9.5734 |      1129.0158 |      0.0211 |      72.5240 |      0.9662 | \n",
      "    3 | 00m01s |   -0.16092 |              0.9525 |             0.9107 |    0.1978 |           7.8200 |      1.0000 |             9.7810 |      1134.9032 |      0.0495 |      71.9158 |      0.9015 | \n",
      "    4 | 00m02s |   -0.15687 |              0.9031 |             0.9689 |    0.8799 |           9.3532 |      1.0000 |             8.3331 |      1126.8856 |      0.2664 |      70.1343 |      0.9480 | \n",
      "    5 | 00m02s |   -0.16092 |              0.9472 |             0.8177 |    0.7186 |           6.1421 |      1.0000 |            10.5038 |      1120.3133 |      0.1136 |      83.4504 |      0.9888 | \n",
      "    6 | 00m02s |   -0.15687 |              0.9136 |             0.8721 |    0.1742 |           2.8110 |      1.0000 |             8.2573 |      1121.1897 |      0.0664 |      70.2232 |      0.9177 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.64970229e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m13s |   -0.15929 |              0.9053 |             0.9864 |    0.9788 |           0.3493 |      1.0000 |            10.9131 |      1128.2063 |      0.2540 |      70.5363 |      0.9102 | \n",
      "    8 | 00m14s |   -0.16145 |              0.9809 |             0.8997 |    0.9501 |           0.2254 |      1.0000 |             8.0071 |      1134.9735 |      0.1639 |      84.8400 |      0.9972 | \n",
      "    9 | 00m17s |   -0.15553 |              0.9522 |             0.9501 |    0.7645 |           9.8709 |      1.0000 |            10.8538 |      1120.1158 |      0.1309 |      70.9568 |      0.9638 | \n",
      "   10 | 00m17s |   -0.16065 |              0.9677 |             0.8474 |    0.9766 |           9.5919 |      1.0000 |             9.5397 |      1134.7126 |      0.2508 |      84.3384 |      0.9172 | \n",
      "   11 | 00m17s |   -0.16118 |              0.9417 |             0.8659 |    0.9342 |           0.0923 |      1.0000 |             8.0373 |      1120.0673 |      0.1032 |      76.4205 |      0.9536 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.97544723e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 00m19s |   -0.15580 |              0.9814 |             0.9941 |    0.0448 |           6.2269 |      1.0000 |            10.6806 |      1127.7220 |      0.2968 |      78.2635 |      0.9774 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.66676681e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 00m19s |   -0.15552 |              0.9542 |             0.8817 |    0.2880 |           9.8293 |      1.0000 |             8.2512 |      1121.2015 |      0.0257 |      78.1734 |      0.9953 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00010634]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 00m18s |   -0.15661 |              0.9462 |             0.8530 |    0.9619 |           5.8631 |      1.0000 |             8.1937 |      1126.7793 |      0.0167 |      75.2952 |      0.9263 | \n",
      "   15 | 00m17s |   -0.16226 |              0.9385 |             0.8155 |    0.4863 |           0.6974 |      1.0000 |            10.9949 |      1134.9638 |      0.1614 |      83.1187 |      0.9244 | \n",
      "   16 | 00m18s |   -0.15715 |              0.9567 |             0.8090 |    0.0020 |           9.5989 |      1.0000 |            10.5164 |      1125.2013 |      0.2700 |      73.0433 |      0.9297 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00010741]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 00m17s |   -0.15768 |              0.9711 |             0.9853 |    0.2070 |           2.6954 |      1.0000 |            10.9879 |      1120.9455 |      0.0148 |      72.9314 |      0.9353 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.54942832e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 47, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 | 00m19s |   -0.15552 |              0.9588 |             0.9980 |    0.9950 |           9.9346 |      1.0000 |            10.6830 |      1123.4132 |      0.0958 |      79.2943 |      0.9184 | \n",
      "   19 | 00m19s |   -0.16038 |              0.9967 |             0.9379 |    0.9903 |           7.6511 |      1.0000 |             8.0220 |      1120.0356 |      0.2112 |      73.7924 |      0.9034 | \n",
      "   20 | 00m21s |   -0.15822 |              0.9062 |             0.9824 |    0.1979 |           1.4271 |      1.0000 |             8.2509 |      1126.7905 |      0.1182 |      84.9579 |      0.9108 | \n",
      "   21 | 00m20s |   -0.15715 |              0.9154 |             0.8184 |    0.1305 |           9.8314 |      1.0000 |             8.0732 |      1127.7163 |      0.2886 |      81.6749 |      0.9610 | \n",
      "   22 | 00m20s |   -0.15822 |              0.9183 |             0.9326 |    0.7111 |           9.7719 |      1.0000 |            10.9090 |      1134.1020 |      0.0008 |      70.2327 |      0.9549 | \n",
      "   23 | 00m19s |   -0.15741 |              0.9784 |             0.9356 |    0.0409 |           0.2380 |      1.0000 |             8.7030 |      1134.6827 |      0.0753 |      70.1167 |      0.9128 | \n",
      "   24 | 00m20s |   -0.15606 |              0.9040 |             0.8090 |    0.0047 |           1.7426 |      1.0000 |            10.4744 |      1125.1056 |      0.0522 |      79.1936 |      0.9982 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-8.64776491e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 00m19s | \u001b[35m  -0.15525\u001b[0m | \u001b[32m             0.9148\u001b[0m | \u001b[32m            0.9919\u001b[0m | \u001b[32m   0.0352\u001b[0m | \u001b[32m          5.1357\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.0310\u001b[0m | \u001b[32m     1123.0225\u001b[0m | \u001b[32m     0.0219\u001b[0m | \u001b[32m     79.9508\u001b[0m | \u001b[32m     0.9397\u001b[0m | \n",
      "   26 | 00m19s |   -0.15742 |              0.9561 |             0.8379 |    0.9556 |           5.2504 |      1.0000 |            10.1179 |      1127.2324 |      0.0074 |      83.1591 |      0.9896 | \n",
      "   27 | 00m25s |   -0.15903 |              0.9015 |             0.8821 |    0.0067 |           9.7744 |      1.0000 |            10.9643 |      1120.1842 |      0.0287 |      77.0538 |      0.9225 | \n",
      "   28 | 00m18s |   -0.15687 |              0.9469 |             0.8291 |    0.9938 |           0.4901 |      1.0000 |            10.8592 |      1120.0076 |      0.1530 |      70.0204 |      0.9472 | \n",
      "   29 | 00m18s |   -0.15822 |              0.9358 |             0.9312 |    0.8791 |           6.9738 |      1.0000 |            10.9442 |      1123.0339 |      0.0874 |      70.1227 |      0.9901 | \n",
      "   30 | 00m18s |   -0.15687 |              0.9767 |             0.8490 |    0.9935 |           0.0412 |      1.0000 |             8.1364 |      1130.0563 |      0.2944 |      80.2179 |      0.9251 | \n",
      "   31 | 00m20s |   -0.15741 |              0.9120 |             0.8385 |    0.0069 |           0.8522 |      1.0000 |             8.0698 |      1127.0136 |      0.2823 |      70.1220 |      0.9824 | \n",
      "   32 | 00m19s |   -0.15633 |              0.9330 |             0.9573 |    0.9079 |           9.7751 |      1.0000 |             8.3686 |      1134.0009 |      0.2895 |      77.3688 |      0.9970 | \n",
      "   33 | 00m19s |   -0.15822 |              0.9502 |             0.9162 |    0.8728 |           9.7676 |      1.0000 |             8.2357 |      1134.6745 |      0.2884 |      70.0262 |      0.9331 | \n",
      "   34 | 00m19s |   -0.15741 |              0.9838 |             0.8598 |    0.1060 |           9.9818 |      1.0000 |             8.6957 |      1121.8021 |      0.0995 |      70.0472 |      0.9301 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00010588]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 00m20s |   -0.15930 |              0.9674 |             0.9544 |    0.9056 |           9.2812 |      1.0000 |             8.0896 |      1120.7795 |      0.2735 |      84.7628 |      0.9055 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-9.22734398e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 63, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00021603]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 | 00m22s |   -0.15930 |              0.9054 |             0.8496 |    0.9736 |           9.8041 |      1.0000 |             8.7900 |      1125.6667 |      0.2172 |      79.3762 |      0.9853 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00064248]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 00m25s |   -0.15660 |              0.9306 |             0.9583 |    0.0168 |           3.8990 |      1.0000 |             8.1020 |      1134.8181 |      0.0418 |      82.0388 |      0.9057 | \n",
      "   38 | 00m22s |   -0.16226 |              0.9868 |             0.9227 |    0.0367 |           9.4193 |      1.0000 |             8.1457 |      1134.5854 |      0.0099 |      79.9567 |      0.9317 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00020991]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00034456]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 00m22s |   -0.15687 |              0.9299 |             0.8261 |    0.9838 |           0.7237 |      1.0000 |             8.2295 |      1134.9963 |      0.2855 |      73.3234 |      0.9743 | \n",
      "   40 | 00m22s |   -0.15714 |              0.9986 |             0.8855 |    0.0186 |           9.9780 |      1.0000 |            10.5169 |      1122.8541 |      0.1943 |      84.5666 |      0.9701 | \n",
      "   41 | 00m23s |   -0.15796 |              0.9901 |             0.8035 |    0.4520 |           5.4865 |      1.0000 |             8.0246 |      1130.8500 |      0.2911 |      84.9068 |      0.9346 | \n",
      "   42 | 00m23s |   -0.15876 |              0.9885 |             0.9841 |    0.0405 |           0.4181 |      1.0000 |            10.9191 |      1121.6754 |      0.2560 |      84.0025 |      0.9435 | \n",
      "   43 | 00m24s |   -0.16200 |              0.9960 |             0.8869 |    0.9334 |           3.6756 |      1.0000 |             8.2068 |      1133.2288 |      0.2645 |      70.1164 |      0.9272 | \n",
      "   44 | 00m29s |   -0.15580 |              0.9974 |             0.9771 |    0.0143 |           0.0671 |      1.0000 |             8.1220 |      1133.4592 |      0.1761 |      76.1269 |      0.9273 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0003669]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 | 00m24s |   -0.16226 |              0.9981 |             0.9932 |    0.0049 |           0.0949 |      1.0000 |             8.3547 |      1122.2875 |      0.2416 |      70.2543 |      0.9855 | \n",
      "   46 | 00m24s |   -0.16146 |              0.9870 |             0.9921 |    0.8022 |           9.6241 |      1.0000 |            10.9977 |      1129.1197 |      0.2943 |      84.7340 |      0.9701 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00048404]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   47 | 01m04s |   -0.15983 |              0.9870 |             0.8525 |    0.9543 |           9.7507 |      1.0000 |            10.9953 |      1134.7626 |      0.1669 |      77.1554 |      0.9564 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00014057]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 00m23s |   -0.15768 |              0.9359 |             0.9988 |    0.9016 |           2.9672 |      1.0000 |            10.8503 |      1124.8173 |      0.2751 |      80.4395 |      0.9350 | \n",
      "   49 | 00m35s |   -0.16092 |              0.9248 |             0.8004 |    0.2839 |           0.8077 |      1.0000 |             8.3466 |      1120.3400 |      0.0019 |      84.3633 |      0.9208 | \n",
      "   50 | 00m41s |   -0.15795 |              0.9146 |             0.8127 |    0.0096 |           3.7337 |      1.0000 |             8.0180 |      1130.4349 |      0.2824 |      79.3051 |      0.9095 | \n",
      "   51 | 00m39s |   -0.15660 |              0.9195 |             0.9745 |    0.2314 |           9.9052 |      1.0000 |             8.1858 |      1125.7475 |      0.0890 |      84.9259 |      0.9401 | \n",
      "   52 | 00m40s |   -0.16011 |              0.9156 |             0.8329 |    0.8986 |           0.3670 |      1.0000 |            10.9793 |      1134.9949 |      0.0545 |      75.8088 |      0.9228 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.2872618e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53 | 00m40s |   -0.16307 |              0.9450 |             0.8052 |    0.0080 |           9.6408 |      1.0000 |             8.1842 |      1120.8908 |      0.0200 |      81.3255 |      0.9176 | \n",
      "   54 | 00m48s |   -0.15876 |              0.9540 |             0.9896 |    0.9489 |           0.6934 |      1.0000 |             8.6122 |      1129.7364 |      0.0100 |      73.5864 |      0.9982 | \n",
      "   55 | 00m47s |   -0.15849 |              0.9312 |             0.9445 |    0.0545 |           9.9508 |      1.0000 |            10.6919 |      1130.5739 |      0.2720 |      70.3230 |      0.9642 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00026814]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   56 | 00m45s |   -0.15957 |              0.9112 |             0.9975 |    0.1309 |           0.0758 |      1.0000 |             8.7690 |      1134.0042 |      0.2457 |      80.4176 |      0.9910 | \n",
      "   57 | 00m45s |   -0.15795 |              0.9428 |             0.9376 |    0.9551 |           0.2260 |      1.0000 |            10.5689 |      1123.8483 |      0.0467 |      84.6273 |      0.9995 | \n",
      "   58 | 00m42s |   -0.16065 |              0.9946 |             0.8080 |    0.6667 |           0.1903 |      1.0000 |            10.9265 |      1134.3697 |      0.2782 |      70.4654 |      0.9908 | \n",
      "   59 | 00m46s |   -0.16011 |              0.9685 |             0.9470 |    0.9702 |           3.5568 |      1.0000 |             8.1612 |      1134.9174 |      0.2269 |      77.5716 |      0.9923 | \n",
      "   60 | 00m48s | \u001b[35m  -0.15472\u001b[0m | \u001b[32m             0.9700\u001b[0m | \u001b[32m            0.9926\u001b[0m | \u001b[32m   0.0325\u001b[0m | \u001b[32m          9.8877\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.2635\u001b[0m | \u001b[32m     1124.2430\u001b[0m | \u001b[32m     0.2382\u001b[0m | \u001b[32m     75.6347\u001b[0m | \u001b[32m     0.9113\u001b[0m | \n",
      "   61 | 00m44s |   -0.15714 |              0.9399 |             0.9074 |    0.0422 |           4.3231 |      1.0000 |            10.9198 |      1125.1540 |      0.2933 |      84.9577 |      0.9866 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-5.12710831e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00024403]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   62 | 00m45s |   -0.16253 |              0.9638 |             0.8230 |    0.0189 |           0.0582 |      1.0000 |             8.0981 |      1125.7032 |      0.2487 |      77.2370 |      0.9131 | \n",
      "   63 | 00m48s |   -0.15579 |              0.9565 |             0.9309 |    0.0201 |           6.4042 |      1.0000 |            10.8526 |      1134.8578 |      0.2640 |      84.8120 |      0.9716 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00022867]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   64 | 00m50s |   -0.15822 |              0.9559 |             0.9624 |    0.0308 |           0.1566 |      1.0000 |            10.9510 |      1130.1161 |      0.0789 |      84.9084 |      0.9809 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.14659306e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   65 | 00m48s |   -0.15687 |              0.9794 |             0.9868 |    0.8647 |           6.8365 |      1.0000 |            10.8782 |      1123.2768 |      0.0109 |      76.4720 |      0.9782 | \n",
      "   66 | 00m53s | \u001b[35m  -0.15391\u001b[0m | \u001b[32m             0.9572\u001b[0m | \u001b[32m            0.9961\u001b[0m | \u001b[32m   0.1748\u001b[0m | \u001b[32m          6.6529\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.0669\u001b[0m | \u001b[32m     1134.9945\u001b[0m | \u001b[32m     0.2291\u001b[0m | \u001b[32m     84.9718\u001b[0m | \u001b[32m     0.9957\u001b[0m | \n",
      "   67 | 00m49s |   -0.16065 |              0.9564 |             0.8024 |    0.0113 |           3.3152 |      1.0000 |            10.8758 |      1127.2663 |      0.0042 |      70.6202 |      0.9490 | \n",
      "   68 | 00m51s |   -0.15715 |              0.9013 |             0.9307 |    0.2172 |           9.6646 |      1.0000 |             8.0190 |      1131.5439 |      0.1105 |      74.0036 |      0.9845 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00149453]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   69 | 00m46s |   -0.15984 |              0.9957 |             0.8711 |    0.9149 |           0.1687 |      1.0000 |            10.6476 |      1120.4150 |      0.0126 |      80.9277 |      0.9244 | \n",
      "   70 | 00m52s |   -0.15984 |              0.9642 |             0.9916 |    0.9851 |           3.2595 |      1.0000 |             8.0591 |      1122.8164 |      0.0355 |      70.6001 |      0.9426 | \n",
      "   71 | 00m48s |   -0.15795 |              0.9306 |             0.9273 |    0.9380 |           0.1233 |      1.0000 |             8.0614 |      1129.3893 |      0.0014 |      70.2034 |      0.9231 | \n",
      "   72 | 00m46s |   -0.15687 |              0.9250 |             0.9625 |    0.9888 |           4.2589 |      1.0000 |             9.1744 |      1134.6292 |      0.1363 |      84.9354 |      0.9309 | \n",
      "   73 | 00m50s |   -0.16092 |              0.9920 |             0.9386 |    0.1992 |           4.0064 |      1.0000 |            10.7032 |      1120.0063 |      0.0490 |      70.0218 |      0.9204 | \n",
      "   74 | 00m49s |   -0.16118 |              0.9049 |             0.9096 |    0.9726 |           9.9573 |      1.0000 |            10.8386 |      1121.9550 |      0.2089 |      70.1968 |      0.9217 | \n",
      "   75 | 00m53s |   -0.15526 |              0.9012 |             0.8413 |    0.0869 |           7.8699 |      1.0000 |             8.0663 |      1124.9963 |      0.0129 |      72.6603 |      0.9859 | \n",
      "   76 | 00m53s |   -0.15795 |              0.9008 |             0.9969 |    0.0547 |           9.8841 |      1.0000 |             9.0980 |      1120.5164 |      0.0521 |      72.5384 |      0.9725 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00036656]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   77 | 00m50s |   -0.15634 |              0.9962 |             0.8185 |    0.9587 |           0.1350 |      1.0000 |            10.9349 |      1129.5511 |      0.2856 |      77.4672 |      0.9722 | \n",
      "   78 | 00m55s |   -0.15498 |              0.9741 |             0.8165 |    0.8277 |           0.2419 |      1.0000 |            10.9582 |      1120.0646 |      0.0573 |      76.2463 |      0.9874 | \n",
      "   79 | 00m55s |   -0.16145 |              0.9999 |             0.9333 |    0.0337 |           5.2280 |      1.0000 |             8.2400 |      1121.8236 |      0.2645 |      76.8095 |      0.9979 | \n",
      "   80 | 00m53s |   -0.15822 |              0.9696 |             0.8952 |    0.7776 |           7.5915 |      1.0000 |             8.3187 |      1120.0744 |      0.0266 |      70.0003 |      0.9976 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00048535]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   81 | 00m52s |   -0.15741 |              0.9299 |             0.8066 |    0.8787 |           9.7259 |      1.0000 |            10.9159 |      1120.4525 |      0.2272 |      84.9712 |      0.9681 | \n",
      "   82 | 00m54s |   -0.15660 |              0.9136 |             0.8456 |    0.9756 |           0.0766 |      1.0000 |            10.7864 |      1123.6184 |      0.0133 |      72.7174 |      0.9821 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00032216]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00028855]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   83 | 00m50s |   -0.15633 |              0.9015 |             0.8487 |    0.0463 |           0.0227 |      1.0000 |             9.0731 |      1131.7362 |      0.1216 |      72.7024 |      0.9283 | \n",
      "   84 | 00m53s |   -0.15714 |              0.9711 |             0.9973 |    0.9700 |           1.3449 |      1.0000 |            10.6540 |      1120.0012 |      0.0041 |      84.8056 |      0.9332 | \n",
      "   85 | 00m56s |   -0.15930 |              0.9846 |             0.9603 |    0.9807 |           9.6708 |      1.0000 |             9.7040 |      1120.0550 |      0.0515 |      77.0237 |      0.9632 | \n",
      "   86 | 01m01s |   -0.15877 |              0.9813 |             0.8366 |    0.0380 |           6.2734 |      1.0000 |            10.8757 |      1123.7242 |      0.0197 |      81.3647 |      0.9009 | \n",
      "   87 | 00m59s |   -0.16065 |              0.9402 |             0.9890 |    0.9669 |           8.2008 |      1.0000 |            10.9971 |      1130.0867 |      0.2923 |      75.2332 |      0.9821 | \n",
      "   88 | 00m53s |   -0.16092 |              0.9944 |             0.8279 |    0.9747 |           4.9203 |      1.0000 |             8.0614 |      1122.4816 |      0.2647 |      84.5365 |      0.9800 | \n",
      "   89 | 00m55s | \u001b[35m  -0.15310\u001b[0m | \u001b[32m             0.9225\u001b[0m | \u001b[32m            0.9770\u001b[0m | \u001b[32m   0.0700\u001b[0m | \u001b[32m          0.1232\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.9424\u001b[0m | \u001b[32m     1128.7811\u001b[0m | \u001b[32m     0.1199\u001b[0m | \u001b[32m     81.0284\u001b[0m | \u001b[32m     0.9504\u001b[0m | \n",
      "   90 | 01m00s |   -0.15552 |              0.9341 |             0.9504 |    0.0099 |           3.1801 |      1.0000 |            10.9260 |      1129.8803 |      0.1056 |      81.4215 |      0.9943 | \n",
      "   91 | 00m51s |   -0.15741 |              0.9006 |             0.8388 |    0.9817 |           4.2955 |      1.0000 |            10.7594 |      1120.0075 |      0.1407 |      74.9255 |      0.9098 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00100818]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   92 | 01m00s |   -0.15579 |              0.9215 |             0.8505 |    0.3243 |           0.1278 |      1.0000 |            10.9703 |      1120.0514 |      0.0647 |      72.4976 |      0.9102 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.000134]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00311144]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   93 | 00m55s |   -0.15984 |              0.9987 |             0.9362 |    0.6863 |           9.9691 |      1.0000 |            10.7318 |      1134.9889 |      0.2621 |      72.0863 |      0.9969 | \n",
      "   94 | 00m58s |   -0.15660 |              0.9002 |             0.9499 |    0.9339 |           6.9835 |      1.0000 |             8.1712 |      1129.6854 |      0.0188 |      80.9689 |      0.9072 | \n",
      "   95 | 00m58s |   -0.15606 |              0.9775 |             0.9070 |    0.1711 |           9.8728 |      1.0000 |             8.1401 |      1129.1248 |      0.0419 |      70.0146 |      0.9801 | \n",
      "   96 | 00m59s |   -0.15795 |              0.9279 |             0.9997 |    0.9200 |           5.8705 |      1.0000 |             8.0702 |      1120.1828 |      0.0106 |      79.2521 |      0.9470 | \n",
      "   97 | 01m03s |   -0.15795 |              0.9006 |             0.9846 |    0.9954 |           7.9044 |      1.0000 |             8.0282 |      1122.8294 |      0.2355 |      79.1134 |      0.9028 | \n",
      "   98 | 01m02s |   -0.15768 |              0.9324 |             0.9597 |    0.0661 |           9.6107 |      1.0000 |            10.9809 |      1125.3922 |      0.0021 |      77.6237 |      0.9209 | \n",
      "   99 | 01m02s |   -0.16065 |              0.9800 |             0.9727 |    0.9919 |           6.2624 |      1.0000 |            10.5999 |      1134.7119 |      0.2944 |      81.6033 |      0.9425 | \n",
      "  100 | 01m03s |   -0.15903 |              0.9062 |             0.9205 |    0.0050 |           3.2652 |      1.0000 |             8.1176 |      1134.9347 |      0.1870 |      84.7758 |      0.9467 | \n",
      "  101 | 01m01s |   -0.16199 |              0.9087 |             0.9381 |    0.0092 |           0.0645 |      1.0000 |            10.3051 |      1128.9517 |      0.0089 |      78.5051 |      0.9193 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00064258]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  102 | 01m05s |   -0.16173 |              0.9042 |             0.8233 |    0.8568 |           0.1194 |      1.0000 |            10.9731 |      1127.1504 |      0.1014 |      83.0175 |      0.9085 | \n",
      "  103 | 01m04s |   -0.15795 |              0.9896 |             0.9699 |    0.0389 |           4.0774 |      1.0000 |             8.5680 |      1127.1420 |      0.2749 |      82.0417 |      0.9948 | \n",
      "  104 | 01m02s |   -0.16200 |              0.9857 |             0.8201 |    0.9977 |           0.0762 |      1.0000 |            10.9936 |      1132.1511 |      0.0112 |      81.4622 |      0.9892 | \n",
      "  105 | 01m02s |   -0.16173 |              0.9180 |             0.8177 |    0.9727 |           9.9895 |      1.0000 |             8.1819 |      1123.2783 |      0.1269 |      74.6016 |      0.9724 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00089996]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  106 | 01m09s |   -0.15903 |              0.9198 |             0.8156 |    0.7689 |           0.8422 |      1.0000 |             8.0718 |      1120.0164 |      0.2358 |      70.3792 |      0.9802 | \n",
      "2018-06-16 00:17:31,740 - logHandler - train - INFO - Iteration: 1, XGBoost max auc: -0.153097\n",
      "2018-06-16 00:17:31,750 - logHandler - train - INFO - Param max_delta_step: 0.12316005512685302\n",
      "2018-06-16 00:17:31,751 - logHandler - train - INFO - Param reg_lambda: 81.02842672429084\n",
      "2018-06-16 00:17:31,751 - logHandler - train - INFO - Param reg_alpha: 0.1198725215270109\n",
      "2018-06-16 00:17:31,752 - logHandler - train - INFO - Param n_estimators: 1128.781116857449\n",
      "2018-06-16 00:17:31,753 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 00:17:31,753 - logHandler - train - INFO - Param subsample: 0.9503589240114895\n",
      "2018-06-16 00:17:31,754 - logHandler - train - INFO - Param min_child_weight: 10.942364714027804\n",
      "2018-06-16 00:17:31,755 - logHandler - train - INFO - Param gamma: 0.06999772292109607\n",
      "2018-06-16 00:17:31,755 - logHandler - train - INFO - Param colsample_bytree: 0.9770005809089838\n",
      "2018-06-16 00:17:31,756 - logHandler - train - INFO - Param colsample_bylevel: 0.9225153738062474\n",
      "2018-06-16 00:17:31,756 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 00:17:32,508 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 00:17:32,509 - logHandler - train - INFO - Iteration  2, Current random seed:  2\n",
      "2018-06-16 00:17:32,539 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 00:17:32,539 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m01s | \u001b[35m  -0.16118\u001b[0m | \u001b[32m             0.9933\u001b[0m | \u001b[32m            0.8160\u001b[0m | \u001b[32m   0.8890\u001b[0m | \u001b[32m          4.8801\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.9989\u001b[0m | \u001b[32m     1131.5999\u001b[0m | \u001b[32m     0.0381\u001b[0m | \u001b[32m     82.1789\u001b[0m | \u001b[32m     0.9878\u001b[0m | \n",
      "    2 | 00m01s | \u001b[35m  -0.15957\u001b[0m | \u001b[32m             0.9554\u001b[0m | \u001b[32m            0.9075\u001b[0m | \u001b[32m   0.0042\u001b[0m | \u001b[32m          1.3144\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.2049\u001b[0m | \u001b[32m     1120.7783\u001b[0m | \u001b[32m     0.1046\u001b[0m | \u001b[32m     80.5226\u001b[0m | \u001b[32m     0.9926\u001b[0m | \n",
      "    3 | 00m02s | \u001b[35m  -0.15930\u001b[0m | \u001b[32m             0.9589\u001b[0m | \u001b[32m            0.8261\u001b[0m | \u001b[32m   0.2757\u001b[0m | \u001b[32m          4.2947\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.8218\u001b[0m | \u001b[32m     1131.0045\u001b[0m | \u001b[32m     0.2275\u001b[0m | \u001b[32m     71.2909\u001b[0m | \u001b[32m     0.9791\u001b[0m | \n",
      "    4 | 00m01s | \u001b[35m  -0.15822\u001b[0m | \u001b[32m             0.9066\u001b[0m | \u001b[32m            0.9882\u001b[0m | \u001b[32m   0.3903\u001b[0m | \u001b[32m          1.5801\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.2472\u001b[0m | \u001b[32m     1125.1739\u001b[0m | \u001b[32m     0.1691\u001b[0m | \u001b[32m     73.8623\u001b[0m | \u001b[32m     0.9095\u001b[0m | \n",
      "    5 | 00m01s |   -0.15876 |              0.9353 |             0.9826 |    0.3201 |           0.2688 |      1.0000 |             9.7142 |      1127.7150 |      0.1663 |      82.2611 |      0.9334 | \n",
      "    6 | 00m02s |   -0.15849 |              0.9793 |             0.8079 |    0.1900 |           0.6167 |      1.0000 |            10.9884 |      1122.5550 |      0.0412 |      78.0215 |      0.9107 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m15s | \u001b[35m  -0.15526\u001b[0m | \u001b[32m             0.9258\u001b[0m | \u001b[32m            0.9965\u001b[0m | \u001b[32m   0.5434\u001b[0m | \u001b[32m          0.0027\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.5894\u001b[0m | \u001b[32m     1134.6889\u001b[0m | \u001b[32m     0.2978\u001b[0m | \u001b[32m     70.2634\u001b[0m | \u001b[32m     0.9873\u001b[0m | \n",
      "    8 | 00m15s |   -0.16227 |              0.9779 |             0.8017 |    0.9920 |           0.3510 |      1.0000 |             8.2888 |      1133.9235 |      0.2144 |      70.0417 |      0.9819 | \n",
      "    9 | 00m16s |   -0.15687 |              0.9399 |             0.9518 |    0.0124 |           8.6189 |      1.0000 |            10.8311 |      1134.9674 |      0.2664 |      84.2811 |      0.9317 | \n",
      "   10 | 00m16s |   -0.16064 |              0.9544 |             0.9544 |    0.1726 |           9.6507 |      1.0000 |            10.8653 |      1132.8587 |      0.2770 |      70.0356 |      0.9999 | \n",
      "   11 | 00m17s |   -0.15929 |              0.9072 |             0.9343 |    0.0102 |           9.9624 |      1.0000 |            10.8781 |      1120.8180 |      0.2539 |      84.0836 |      0.9985 | \n",
      "   12 | 00m16s |   -0.15714 |              0.9445 |             0.9489 |    0.0220 |           0.6253 |      1.0000 |            10.7743 |      1134.8036 |      0.0505 |      79.2695 |      0.9831 | \n",
      "   13 | 00m17s |   -0.15633 |              0.9217 |             0.8193 |    0.0099 |           0.1635 |      1.0000 |            10.6351 |      1126.2420 |      0.2831 |      70.2927 |      0.9774 | \n",
      "   14 | 00m16s |   -0.16038 |              0.9508 |             0.9640 |    0.0565 |           1.2789 |      1.0000 |            10.9036 |      1131.8898 |      0.0191 |      70.8664 |      0.9020 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00021633]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 45, 'nit': 2, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 00m18s |   -0.15957 |              0.9463 |             0.9832 |    0.1257 |           0.6959 |      1.0000 |            10.8936 |      1120.2912 |      0.2755 |      84.8358 |      0.9774 | \n",
      "   16 | 00m18s |   -0.15903 |              0.9616 |             0.8700 |    0.0776 |           3.6742 |      1.0000 |            10.9249 |      1132.9052 |      0.2919 |      78.0529 |      0.9823 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00026751]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 00m18s |   -0.15795 |              0.9529 |             0.8419 |    0.2687 |           9.4746 |      1.0000 |             8.1409 |      1120.0727 |      0.0962 |      70.2481 |      0.9074 | \n",
      "   18 | 00m18s |   -0.16361 |              0.9333 |             0.8912 |    0.3141 |           0.1729 |      1.0000 |             8.6488 |      1134.7074 |      0.2860 |      84.7566 |      0.9266 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00042519]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 00m17s |   -0.16281 |              0.9123 |             0.9849 |    0.8092 |           9.8903 |      1.0000 |             8.0239 |      1133.7053 |      0.2867 |      82.7696 |      0.9506 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-9.16542704e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 00m18s |   -0.15984 |              0.9191 |             0.9744 |    0.6645 |           0.9894 |      1.0000 |             8.3855 |      1120.0398 |      0.2825 |      70.2665 |      0.9782 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00011399]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00012877]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 00m18s |   -0.15795 |              0.9074 |             0.8512 |    0.9339 |           0.2775 |      1.0000 |            10.8602 |      1134.8929 |      0.2399 |      84.2227 |      0.9976 | \n",
      "   22 | 00m19s |   -0.15876 |              0.9626 |             0.8740 |    0.0358 |           9.7388 |      1.0000 |             8.3315 |      1124.9747 |      0.2732 |      77.8239 |      0.9906 | \n",
      "   23 | 00m18s |   -0.15714 |              0.9178 |             0.9918 |    0.0909 |           6.7103 |      1.0000 |            10.5191 |      1120.1479 |      0.2202 |      70.2394 |      0.9898 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.60236882e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 00m19s |   -0.15633 |              0.9809 |             0.9137 |    0.0988 |           5.5583 |      1.0000 |            10.9408 |      1126.3996 |      0.2365 |      84.9378 |      0.9962 | \n",
      "   25 | 00m19s |   -0.15876 |              0.9787 |             0.9678 |    0.0837 |           6.9110 |      1.0000 |             8.1062 |      1123.9663 |      0.2340 |      70.2290 |      0.9978 | \n",
      "   26 | 00m19s |   -0.15822 |              0.9654 |             0.8334 |    0.9239 |           9.9267 |      1.0000 |            10.6220 |      1120.1705 |      0.2954 |      73.0091 |      0.9632 | \n",
      "   27 | 00m18s |   -0.16011 |              0.9224 |             0.8048 |    0.5735 |           9.3836 |      1.0000 |             8.1188 |      1121.2603 |      0.2411 |      84.7133 |      0.9812 | \n",
      "   28 | 00m19s |   -0.15930 |              0.9160 |             0.8451 |    0.0420 |           9.9949 |      1.0000 |            10.4538 |      1130.1712 |      0.2470 |      84.8577 |      0.9476 | \n",
      "   29 | 00m19s |   -0.15983 |              0.9068 |             0.8599 |    0.0561 |           8.4760 |      1.0000 |             8.6018 |      1134.6104 |      0.2281 |      70.2806 |      0.9324 | \n",
      "   30 | 00m17s |   -0.15822 |              0.9526 |             0.8191 |    0.9567 |           0.0447 |      1.0000 |            10.9087 |      1124.3996 |      0.2893 |      71.5171 |      0.9975 | \n",
      "   31 | 00m19s |   -0.15930 |              0.9015 |             0.9182 |    0.7565 |           3.0498 |      1.0000 |            10.6480 |      1124.2676 |      0.2890 |      81.5332 |      0.9974 | \n",
      "   32 | 00m19s |   -0.15526 |              0.9144 |             0.8764 |    0.0157 |           0.3908 |      1.0000 |            10.4355 |      1120.9773 |      0.2926 |      73.5460 |      0.9877 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00022123]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 00m19s | \u001b[35m  -0.15391\u001b[0m | \u001b[32m             0.9259\u001b[0m | \u001b[32m            0.9965\u001b[0m | \u001b[32m   0.0174\u001b[0m | \u001b[32m          3.7814\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.6694\u001b[0m | \u001b[32m     1131.5406\u001b[0m | \u001b[32m     0.0262\u001b[0m | \u001b[32m     84.9499\u001b[0m | \u001b[32m     0.9887\u001b[0m | \n",
      "   34 | 00m19s |   -0.15957 |              0.9114 |             0.9448 |    0.0101 |           1.1260 |      1.0000 |            10.9915 |      1127.4688 |      0.1779 |      84.5442 |      0.9993 | \n",
      "   35 | 00m19s |   -0.15714 |              0.9301 |             0.9963 |    0.0468 |           9.7898 |      1.0000 |             8.3034 |      1128.2224 |      0.2697 |      70.2309 |      0.9229 | \n",
      "   36 | 00m21s |   -0.15634 |              0.9053 |             0.9889 |    0.8485 |           4.7307 |      1.0000 |            10.9765 |      1134.5865 |      0.2783 |      84.7515 |      0.9921 | \n",
      "   37 | 00m21s |   -0.15903 |              0.9563 |             0.9878 |    0.0954 |           9.5017 |      1.0000 |             8.7275 |      1120.0256 |      0.2493 |      76.8615 |      0.9660 | \n",
      "   38 | 00m21s |   -0.15391 |              0.9999 |             0.9419 |    0.0353 |           0.0767 |      1.0000 |             9.2054 |      1129.0777 |      0.2634 |      74.7064 |      0.9987 | \n",
      "   39 | 00m22s |   -0.15930 |              0.9648 |             0.9920 |    0.0239 |           5.8868 |      1.0000 |             8.2875 |      1130.4168 |      0.2897 |      84.1749 |      0.9368 | \n",
      "   40 | 00m22s |   -0.15876 |              0.9723 |             0.9433 |    0.0026 |           9.8471 |      1.0000 |            10.6356 |      1120.3202 |      0.2709 |      70.3226 |      0.9997 | \n",
      "   41 | 00m22s |   -0.15984 |              0.9195 |             0.9292 |    0.8938 |           6.2302 |      1.0000 |            10.9923 |      1120.0850 |      0.0885 |      84.9488 |      0.9866 | \n",
      "   42 | 00m22s |   -0.15418 |              0.9468 |             0.8991 |    0.0213 |           0.6773 |      1.0000 |            10.9191 |      1134.1991 |      0.2988 |      84.6085 |      0.9777 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00015131]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-9.80141388e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 | 00m23s |   -0.15849 |              0.9818 |             0.9975 |    0.9157 |           9.6026 |      1.0000 |             8.2750 |      1133.5011 |      0.2875 |      73.2705 |      0.9529 | \n",
      "   44 | 00m21s |   -0.15498 |              0.9463 |             0.9583 |    0.1038 |           0.0105 |      1.0000 |            10.6708 |      1130.4672 |      0.2810 |      76.4697 |      0.9698 | \n",
      "   45 | 00m22s |   -0.15472 |              0.9610 |             0.8785 |    0.1065 |           0.0299 |      1.0000 |            10.6457 |      1120.0526 |      0.1070 |      70.0516 |      0.9165 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00052593]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46 | 00m23s |   -0.15714 |              0.9817 |             0.9880 |    0.2861 |           0.2394 |      1.0000 |            10.9833 |      1120.0841 |      0.1955 |      74.5962 |      0.9476 | \n",
      "   47 | 00m23s |   -0.15580 |              0.9164 |             0.9001 |    0.0759 |           0.1001 |      1.0000 |             8.1483 |      1126.3373 |      0.2006 |      76.9635 |      0.9989 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00065931]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 00m24s |   -0.15768 |              0.9944 |             0.9575 |    0.0551 |           0.2461 |      1.0000 |            10.8159 |      1134.7669 |      0.2846 |      71.3142 |      0.9572 | \n",
      "   49 | 00m30s |   -0.15768 |              0.9229 |             0.9936 |    0.0270 |           0.3389 |      1.0000 |            10.2540 |      1126.7267 |      0.1636 |      77.8182 |      0.9973 | \n",
      "   50 | 00m38s |   -0.15498 |              0.9287 |             0.9492 |    0.2436 |           0.2200 |      1.0000 |             8.0345 |      1130.3537 |      0.2884 |      75.2734 |      0.9271 | \n",
      "   51 | 00m39s |   -0.15822 |              0.9694 |             0.8329 |    0.0168 |           3.7732 |      1.0000 |            10.9673 |      1130.9411 |      0.1733 |      84.9539 |      0.9053 | \n",
      "   52 | 00m42s |   -0.15525 |              0.9022 |             0.9239 |    0.0202 |           7.1800 |      1.0000 |             9.3485 |      1123.9612 |      0.0041 |      84.0289 |      0.9295 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00124237]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53 | 00m41s |   -0.15930 |              0.9813 |             0.9558 |    0.9980 |           9.4507 |      1.0000 |            10.7920 |      1124.3848 |      0.0108 |      84.6320 |      0.9890 | \n",
      "   54 | 00m46s |   -0.16011 |              0.9061 |             0.9865 |    0.0071 |           9.7300 |      1.0000 |            10.7885 |      1133.9578 |      0.0787 |      77.9807 |      0.9902 | \n",
      "   55 | 00m43s | \u001b[35m  -0.15310\u001b[0m | \u001b[32m             0.9279\u001b[0m | \u001b[32m            0.9070\u001b[0m | \u001b[32m   0.0576\u001b[0m | \u001b[32m          0.0209\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.0082\u001b[0m | \u001b[32m     1126.7375\u001b[0m | \u001b[32m     0.0444\u001b[0m | \u001b[32m     72.3789\u001b[0m | \u001b[32m     0.9921\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0017794]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   56 | 00m45s |   -0.15580 |              0.9111 |             0.9119 |    0.0069 |           9.4878 |      1.0000 |             8.0899 |      1130.1294 |      0.0542 |      74.8908 |      0.9903 | \n",
      "   57 | 00m42s |   -0.15607 |              0.9155 |             0.8006 |    0.0372 |           7.1018 |      1.0000 |            10.4962 |      1120.9329 |      0.0326 |      73.3642 |      0.9918 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-4.01633442e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 2, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   58 | 00m45s |   -0.15579 |              0.9184 |             0.9560 |    0.1647 |           0.7107 |      1.0000 |            10.9236 |      1134.7584 |      0.0140 |      84.8549 |      0.9338 | \n",
      "   59 | 00m45s |   -0.15634 |              0.9449 |             0.9954 |    0.2105 |           0.0346 |      1.0000 |            10.5204 |      1132.7479 |      0.2224 |      82.7635 |      0.9998 | \n",
      "   60 | 00m41s |   -0.15930 |              0.9270 |             0.9417 |    0.9800 |           9.9414 |      1.0000 |             8.1185 |      1129.6668 |      0.0363 |      70.1046 |      0.9657 | \n",
      "   61 | 00m42s |   -0.15687 |              0.9013 |             0.9750 |    0.7612 |           0.2066 |      1.0000 |             9.5310 |      1130.6078 |      0.2293 |      73.7297 |      0.9965 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00171428]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   62 | 00m43s |   -0.15984 |              0.9327 |             0.9973 |    0.2387 |           0.4295 |      1.0000 |             8.5780 |      1122.4566 |      0.0214 |      84.9239 |      0.9995 | \n",
      "   63 | 00m43s |   -0.15525 |              0.9864 |             0.9734 |    0.0081 |           0.3649 |      1.0000 |             9.3138 |      1122.4417 |      0.0329 |      71.1397 |      0.9728 | \n",
      "   64 | 00m49s |   -0.16200 |              0.9478 |             0.9582 |    0.0542 |           9.9747 |      1.0000 |             8.1293 |      1134.7812 |      0.2446 |      75.0028 |      0.9872 | \n",
      "   65 | 00m46s |   -0.16092 |              0.9049 |             0.9670 |    0.0188 |           9.9842 |      1.0000 |             8.0389 |      1123.6415 |      0.0644 |      72.3642 |      0.9535 | \n",
      "   66 | 00m49s |   -0.15849 |              0.9712 |             0.9168 |    0.2734 |           0.1476 |      1.0000 |             8.0015 |      1126.9351 |      0.2475 |      70.1642 |      0.9853 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00012026]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   67 | 00m51s |   -0.16118 |              0.9205 |             0.9723 |    0.0306 |           8.5165 |      1.0000 |            10.4112 |      1126.0469 |      0.0295 |      80.3608 |      0.9977 | \n",
      "   68 | 00m46s |   -0.15849 |              0.9664 |             0.8086 |    0.0351 |           2.5883 |      1.0000 |            10.4588 |      1120.1123 |      0.0510 |      71.6857 |      0.9864 | \n",
      "   69 | 00m48s |   -0.16092 |              0.9173 |             0.9688 |    0.0168 |           4.7729 |      1.0000 |             8.5262 |      1124.9518 |      0.2801 |      84.9365 |      0.9940 | \n",
      "   70 | 00m49s |   -0.15768 |              0.9510 |             0.8733 |    0.9734 |           0.1200 |      1.0000 |            10.5988 |      1121.8870 |      0.0279 |      81.7521 |      0.9587 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0007637]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00052816]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   71 | 00m47s |   -0.15498 |              0.9243 |             0.8020 |    0.1089 |           0.0403 |      1.0000 |             8.0944 |      1121.6354 |      0.0532 |      74.9468 |      0.9304 | \n",
      "   72 | 00m51s |   -0.16523 |              0.9063 |             0.8959 |    0.1963 |           7.3078 |      1.0000 |             8.0580 |      1126.7471 |      0.2584 |      74.4108 |      0.9824 | \n",
      "   73 | 00m48s |   -0.15930 |              0.9080 |             0.8163 |    0.1249 |           9.9825 |      1.0000 |             8.0445 |      1122.0570 |      0.0395 |      80.3885 |      0.9882 | \n",
      "   74 | 00m52s |   -0.16172 |              0.9041 |             0.9517 |    0.0308 |           9.9202 |      1.0000 |             8.2316 |      1126.8322 |      0.0003 |      84.9865 |      0.9439 | \n",
      "   75 | 00m50s |   -0.15580 |              0.9538 |             0.9089 |    0.0005 |           9.3834 |      1.0000 |             8.8249 |      1131.2906 |      0.2934 |      79.3171 |      0.9929 | \n",
      "   76 | 00m52s |   -0.15633 |              0.9991 |             0.9969 |    0.0003 |           6.6076 |      1.0000 |            10.7666 |      1133.3068 |      0.0651 |      83.5678 |      0.9851 | \n",
      "   77 | 00m54s |   -0.15633 |              0.9091 |             0.9800 |    0.7349 |           4.1887 |      1.0000 |            10.8305 |      1134.8122 |      0.1711 |      70.0479 |      0.9344 | \n",
      "   78 | 00m58s |   -0.15418 |              0.9014 |             0.9407 |    0.0027 |           3.1692 |      1.0000 |            10.0413 |      1134.7714 |      0.2950 |      83.1075 |      0.9880 | \n",
      "   79 | 00m49s |   -0.15822 |              0.9235 |             0.9868 |    0.0266 |           0.1087 |      1.0000 |             8.7401 |      1133.0110 |      0.1884 |      77.6729 |      0.9867 | \n",
      "   80 | 00m53s |   -0.15903 |              0.9224 |             0.9996 |    0.0588 |           7.6702 |      1.0000 |             8.0058 |      1131.6903 |      0.2334 |      70.1135 |      0.9894 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00039913]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   81 | 00m53s |   -0.15553 |              0.9117 |             0.8215 |    0.5004 |           9.8420 |      1.0000 |            10.2659 |      1124.9167 |      0.2547 |      70.1198 |      0.9052 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0010388]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   82 | 00m54s |   -0.15822 |              0.9125 |             0.8612 |    0.3998 |           9.9785 |      1.0000 |             9.4055 |      1130.2669 |      0.2608 |      74.7813 |      0.9098 | \n",
      "   83 | 00m56s |   -0.15553 |              0.9133 |             0.8005 |    0.1169 |           0.0727 |      1.0000 |             8.2418 |      1125.2364 |      0.0714 |      73.7239 |      0.9041 | \n",
      "   84 | 00m52s |   -0.15984 |              0.9629 |             0.8062 |    0.1729 |           7.1097 |      1.0000 |            10.9786 |      1124.0610 |      0.2765 |      70.2010 |      0.9877 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00071824]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 63, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00134633]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   85 | 00m53s |   -0.16173 |              0.9159 |             0.8971 |    0.8911 |           6.5421 |      1.0000 |            10.9294 |      1120.6086 |      0.0292 |      77.8493 |      0.9930 | \n",
      "   86 | 00m57s |   -0.15553 |              0.9862 |             0.9973 |    0.1059 |           6.7733 |      1.0000 |            10.3636 |      1122.8189 |      0.2820 |      84.6935 |      0.9533 | \n",
      "   87 | 00m55s |   -0.15930 |              0.9408 |             0.9920 |    0.0328 |           5.5450 |      1.0000 |             8.5178 |      1134.7161 |      0.2965 |      84.9985 |      0.9811 | \n",
      "   88 | 00m53s |   -0.16065 |              0.9258 |             0.8704 |    0.8898 |           9.9536 |      1.0000 |             9.3809 |      1122.3315 |      0.1611 |      70.0683 |      0.9972 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00021217]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   89 | 00m54s |   -0.15956 |              0.9070 |             0.8595 |    0.0493 |           4.9872 |      1.0000 |             8.2714 |      1120.0052 |      0.0589 |      70.6117 |      0.9497 | \n",
      "   90 | 00m55s |   -0.16064 |              0.9330 |             0.8040 |    0.9964 |           7.1909 |      1.0000 |            10.8585 |      1134.9265 |      0.2742 |      70.1669 |      0.9323 | \n",
      "   91 | 00m56s |   -0.16361 |              0.9052 |             0.9976 |    0.0549 |           4.3341 |      1.0000 |             8.1131 |      1134.5150 |      0.2663 |      72.3514 |      0.9403 | \n",
      "   92 | 00m52s |   -0.15526 |              0.9559 |             0.9494 |    0.9167 |           0.1962 |      1.0000 |             8.6019 |      1120.0789 |      0.2956 |      84.9269 |      0.9789 | \n",
      "   93 | 00m56s |   -0.15957 |              0.9153 |             0.9438 |    0.9801 |           0.1187 |      1.0000 |             8.6949 |      1120.3579 |      0.1284 |      77.2512 |      0.9956 | \n",
      "   94 | 00m59s |   -0.16415 |              0.9041 |             0.8791 |    0.0147 |           0.0116 |      1.0000 |             8.1113 |      1120.3359 |      0.1682 |      70.5279 |      0.9891 | \n",
      "   95 | 01m03s |   -0.15768 |              0.9446 |             0.9860 |    0.8016 |           0.3915 |      1.0000 |            10.9502 |      1120.4014 |      0.0964 |      70.0100 |      0.9924 | \n",
      "   96 | 00m53s |   -0.16173 |              0.9880 |             0.9784 |    0.9749 |           6.8470 |      1.0000 |             8.2031 |      1120.0915 |      0.2926 |      73.0571 |      0.9087 | \n",
      "   97 | 01m05s |   -0.15822 |              0.9903 |             0.8858 |    0.0251 |           9.8419 |      1.0000 |            10.9750 |      1120.4971 |      0.0098 |      77.4673 |      0.9971 | \n",
      "   98 | 01m00s |   -0.15876 |              0.9017 |             0.9960 |    0.0726 |           0.0428 |      1.0000 |             8.2398 |      1121.9006 |      0.2606 |      80.2589 |      0.9114 | \n",
      "   99 | 01m00s |   -0.16092 |              0.9985 |             0.9965 |    0.0165 |           2.1623 |      1.0000 |             8.0835 |      1130.1209 |      0.1474 |      80.2982 |      0.9973 | \n",
      "  100 | 01m05s |   -0.15903 |              0.9458 |             0.8085 |    0.0477 |           8.7181 |      1.0000 |            10.7628 |      1121.0388 |      0.2675 |      74.6936 |      0.9035 | \n",
      "  101 | 01m06s |   -0.15660 |              0.9728 |             0.9828 |    0.0263 |           9.9524 |      1.0000 |            10.0703 |      1126.3341 |      0.0016 |      70.8569 |      0.9887 | \n",
      "  102 | 01m07s |   -0.15606 |              0.9364 |             0.9969 |    0.8406 |           0.0495 |      1.0000 |             8.0384 |      1127.9132 |      0.2610 |      71.9488 |      0.9243 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00065297]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  103 | 01m04s |   -0.15579 |              0.9243 |             0.8920 |    0.9842 |           9.9615 |      1.0000 |             8.1384 |      1130.5213 |      0.0441 |      77.5683 |      0.9717 | \n",
      "  104 | 01m03s |   -0.15714 |              0.9181 |             0.9755 |    0.0450 |           2.2848 |      1.0000 |             8.7042 |      1126.9107 |      0.0103 |      70.5496 |      0.9429 | \n",
      "  105 | 01m02s |   -0.15957 |              0.9069 |             0.9810 |    0.2098 |           0.0172 |      1.0000 |             9.5464 |      1122.7166 |      0.0921 |      74.9154 |      0.9545 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00202422]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  106 | 01m06s |   -0.15418 |              0.9464 |             0.8148 |    0.1670 |           1.7600 |      1.0000 |             8.2670 |      1123.7889 |      0.2995 |      72.0007 |      0.9451 | \n",
      "2018-06-16 01:22:55,217 - logHandler - train - INFO - Iteration: 2, XGBoost max auc: -0.153097\n",
      "2018-06-16 01:22:55,218 - logHandler - train - INFO - Param max_delta_step: 0.020852712439686227\n",
      "2018-06-16 01:22:55,219 - logHandler - train - INFO - Param reg_lambda: 72.3788624894255\n",
      "2018-06-16 01:22:55,220 - logHandler - train - INFO - Param reg_alpha: 0.04444945511893953\n",
      "2018-06-16 01:22:55,220 - logHandler - train - INFO - Param n_estimators: 1126.737455347604\n",
      "2018-06-16 01:22:55,221 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 01:22:55,221 - logHandler - train - INFO - Param subsample: 0.9921171988641246\n",
      "2018-06-16 01:22:55,222 - logHandler - train - INFO - Param min_child_weight: 8.008178148487723\n",
      "2018-06-16 01:22:55,223 - logHandler - train - INFO - Param gamma: 0.05764886774517597\n",
      "2018-06-16 01:22:55,223 - logHandler - train - INFO - Param colsample_bytree: 0.9070478510547068\n",
      "2018-06-16 01:22:55,224 - logHandler - train - INFO - Param colsample_bylevel: 0.9278993815101539\n",
      "2018-06-16 01:22:55,224 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 01:22:55,954 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 01:22:55,955 - logHandler - train - INFO - Iteration  3, Current random seed:  3\n",
      "2018-06-16 01:22:55,957 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 01:22:55,959 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m03s | \u001b[35m  -0.15768\u001b[0m | \u001b[32m             0.9593\u001b[0m | \u001b[32m            0.9818\u001b[0m | \u001b[32m   0.4361\u001b[0m | \u001b[32m          8.5483\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.3652\u001b[0m | \u001b[32m     1124.4273\u001b[0m | \u001b[32m     0.0207\u001b[0m | \u001b[32m     80.5172\u001b[0m | \u001b[32m     0.9400\u001b[0m | \n",
      "    2 | 00m02s | \u001b[35m  -0.15661\u001b[0m | \u001b[32m             0.9273\u001b[0m | \u001b[32m            0.8178\u001b[0m | \u001b[32m   0.8937\u001b[0m | \u001b[32m          4.9889\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.7889\u001b[0m | \u001b[32m     1132.9312\u001b[0m | \u001b[32m     0.2802\u001b[0m | \u001b[32m     72.3446\u001b[0m | \u001b[32m     0.9994\u001b[0m | \n",
      "    3 | 00m02s |   -0.15849 |              0.9354 |             0.9503 |    0.8288 |           1.8227 |      1.0000 |             8.5843 |      1120.8625 |      0.0274 |      77.4738 |      0.9763 | \n",
      "    4 | 00m02s | \u001b[35m  -0.15553\u001b[0m | \u001b[32m             0.9534\u001b[0m | \u001b[32m            0.9262\u001b[0m | \u001b[32m   0.1871\u001b[0m | \u001b[32m          9.2980\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.5707\u001b[0m | \u001b[32m     1133.1157\u001b[0m | \u001b[32m     0.2665\u001b[0m | \u001b[32m     72.1038\u001b[0m | \u001b[32m     0.9579\u001b[0m | \n",
      "    5 | 00m02s |   -0.16065 |              0.9439 |             0.8979 |    0.5095 |           4.3521 |      1.0000 |            10.6016 |      1126.7325 |      0.0256 |      72.1749 |      0.9992 | \n",
      "    6 | 00m02s |   -0.15579 |              0.9944 |             0.9766 |    0.9831 |           7.1587 |      1.0000 |            10.5948 |      1123.7887 |      0.1934 |      75.6885 |      0.9092 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.84521972e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 45, 'nit': 2, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m16s |   -0.15795 |              0.9112 |             0.8168 |    0.8944 |           9.9833 |      1.0000 |             8.0263 |      1123.0611 |      0.1882 |      72.3523 |      0.9897 | \n",
      "    8 | 00m16s |   -0.15849 |              1.0000 |             1.0000 |    0.9153 |           9.3116 |      1.0000 |             9.0583 |      1135.0000 |      0.3000 |      84.3922 |      1.0000 | \n",
      "    9 | 00m17s |   -0.15849 |              0.9986 |             0.8380 |    0.1454 |           0.0411 |      1.0000 |            10.9905 |      1120.1722 |      0.2729 |      84.4845 |      0.9844 | \n",
      "   10 | 00m17s |   -0.15822 |              0.9705 |             0.9505 |    0.9222 |           9.8972 |      1.0000 |            10.9680 |      1134.5247 |      0.0444 |      70.5586 |      0.9744 | \n",
      "   11 | 00m18s |   -0.15849 |              0.9709 |             0.9974 |    0.9023 |           0.1597 |      1.0000 |             8.0919 |      1134.2603 |      0.2522 |      82.1966 |      0.9414 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([4.49992099e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 00m18s |   -0.16146 |              0.9710 |             0.9871 |    0.0840 |           9.9200 |      1.0000 |             8.4366 |      1120.0763 |      0.2837 |      80.2685 |      0.9104 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([8.95531704e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 46, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 00m18s |   -0.15822 |              0.9810 |             0.9685 |    0.9660 |           9.2923 |      1.0000 |             8.0042 |      1129.4568 |      0.2604 |      78.5005 |      0.9173 | \n",
      "   14 | 00m19s |   -0.16119 |              0.9084 |             0.8045 |    0.2611 |           9.0523 |      1.0000 |            10.8368 |      1134.8861 |      0.2582 |      79.4329 |      0.9321 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-8.12329335e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 00m19s |   -0.16011 |              0.9608 |             0.9328 |    0.1237 |           0.4881 |      1.0000 |             8.0391 |      1134.8006 |      0.2050 |      70.6113 |      0.9422 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-9.77770515e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 00m19s |   -0.16038 |              0.9356 |             0.8956 |    0.9918 |           8.1628 |      1.0000 |             8.2136 |      1134.9005 |      0.1838 |      70.1727 |      0.9029 | \n",
      "   17 | 00m19s |   -0.15742 |              0.9950 |             0.8539 |    0.3775 |           2.1331 |      1.0000 |             8.0288 |      1123.5260 |      0.2938 |      84.9795 |      0.9281 | \n",
      "   18 | 00m20s |   -0.15957 |              0.9113 |             0.8647 |    0.8838 |           9.9561 |      1.0000 |            10.9414 |      1121.8486 |      0.2073 |      84.8381 |      0.9128 | \n",
      "   19 | 00m18s |   -0.16253 |              0.9083 |             0.8930 |    0.8533 |           0.4262 |      1.0000 |            10.9399 |      1129.1215 |      0.2935 |      84.9729 |      0.9930 | \n",
      "   20 | 00m19s |   -0.15768 |              0.9956 |             0.8646 |    0.4525 |           9.4177 |      1.0000 |            10.8638 |      1120.0100 |      0.2801 |      70.0244 |      0.9080 | \n",
      "   21 | 00m19s |   -0.16038 |              0.9605 |             0.8882 |    0.1082 |           9.8842 |      1.0000 |            10.9639 |      1123.7668 |      0.2845 |      74.4868 |      0.9968 | \n",
      "   22 | 00m19s |   -0.15876 |              0.9567 |             0.9777 |    0.8887 |           3.6746 |      1.0000 |             9.0446 |      1120.1773 |      0.0108 |      84.9573 |      0.9538 | \n",
      "   23 | 00m20s |   -0.15795 |              0.9680 |             0.8392 |    0.8092 |           1.8860 |      1.0000 |             8.0762 |      1120.0807 |      0.2518 |      70.0838 |      0.9531 | \n",
      "   24 | 00m19s |   -0.15660 |              0.9936 |             0.8924 |    0.0646 |           3.4571 |      1.0000 |             8.2669 |      1134.4963 |      0.2231 |      84.7721 |      0.9127 | \n",
      "   25 | 00m20s | \u001b[35m  -0.15498\u001b[0m | \u001b[32m             0.9950\u001b[0m | \u001b[32m            0.9963\u001b[0m | \u001b[32m   0.0221\u001b[0m | \u001b[32m          7.0040\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.0532\u001b[0m | \u001b[32m     1122.0845\u001b[0m | \u001b[32m     0.2747\u001b[0m | \u001b[32m     70.5050\u001b[0m | \u001b[32m     0.9722\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-4.6981484e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00036231]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 00m20s |   -0.16307 |              0.9955 |             0.9961 |    0.0327 |           2.6474 |      1.0000 |            10.0148 |      1134.9608 |      0.2988 |      76.7288 |      0.9864 | \n",
      "   27 | 00m19s |   -0.15553 |              0.9910 |             0.9833 |    0.6415 |           8.7859 |      1.0000 |             9.1810 |      1129.3592 |      0.2905 |      70.0728 |      0.9306 | \n",
      "   28 | 00m21s |   -0.15606 |              0.9847 |             0.8108 |    0.6650 |           4.6464 |      1.0000 |            10.8160 |      1120.0886 |      0.2774 |      80.6327 |      0.9907 | \n",
      "   29 | 00m20s | \u001b[35m  -0.15418\u001b[0m | \u001b[32m             0.9968\u001b[0m | \u001b[32m            0.9767\u001b[0m | \u001b[32m   0.7067\u001b[0m | \u001b[32m          4.9227\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.0092\u001b[0m | \u001b[32m     1129.3686\u001b[0m | \u001b[32m     0.1984\u001b[0m | \u001b[32m     72.9817\u001b[0m | \u001b[32m     0.9276\u001b[0m | \n",
      "   30 | 00m19s |   -0.16038 |              0.9728 |             0.8313 |    0.8892 |           5.6172 |      1.0000 |             8.0228 |      1120.2089 |      0.2816 |      73.2271 |      0.9181 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00014159]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 | 00m19s |   -0.15768 |              0.9872 |             0.9870 |    0.9047 |           0.0447 |      1.0000 |             8.2407 |      1126.4785 |      0.2524 |      70.1243 |      0.9242 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00017231]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 00m21s |   -0.15445 |              0.9111 |             0.9991 |    0.9212 |           3.8562 |      1.0000 |             8.1207 |      1126.3559 |      0.2730 |      78.8689 |      0.9194 | \n",
      "   33 | 00m20s |   -0.16119 |              0.9381 |             0.9954 |    0.1513 |           0.4873 |      1.0000 |             8.0354 |      1128.6194 |      0.1549 |      84.3590 |      0.9961 | \n",
      "   34 | 00m20s |   -0.16038 |              0.9762 |             0.9517 |    0.1417 |           0.0069 |      1.0000 |            10.6731 |      1120.1067 |      0.2189 |      70.5143 |      0.9246 | \n",
      "   35 | 00m21s |   -0.15714 |              0.9331 |             0.9943 |    0.9993 |           4.5817 |      1.0000 |            10.8535 |      1122.7608 |      0.2954 |      83.6998 |      0.9532 | \n",
      "   36 | 00m23s |   -0.15714 |              0.9958 |             0.8142 |    0.0098 |           9.7195 |      1.0000 |             8.0049 |      1120.1654 |      0.2618 |      70.3993 |      0.9580 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00048918]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 00m21s |   -0.16119 |              0.9380 |             0.8294 |    0.9795 |           0.1029 |      1.0000 |             8.0477 |      1121.1042 |      0.2857 |      83.8161 |      0.9826 | \n",
      "   38 | 00m23s |   -0.15957 |              0.9266 |             0.8007 |    0.9676 |           5.1841 |      1.0000 |             8.1828 |      1134.9773 |      0.0357 |      84.8168 |      0.9683 | \n",
      "   39 | 00m23s |   -0.15768 |              0.9151 |             0.9684 |    0.2483 |           0.2693 |      1.0000 |            10.8524 |      1134.8996 |      0.2780 |      84.6917 |      0.9313 | \n",
      "   40 | 00m24s |   -0.15957 |              0.9998 |             0.8010 |    0.0326 |           5.2846 |      1.0000 |             8.8271 |      1124.9558 |      0.2812 |      78.1432 |      0.9200 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00016131]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 00m22s |   -0.15526 |              0.9951 |             0.9875 |    0.5827 |           9.4275 |      1.0000 |            10.9702 |      1130.4699 |      0.1950 |      84.9474 |      0.9407 | \n",
      "   42 | 00m24s |   -0.15634 |              0.9494 |             0.9084 |    0.0362 |           9.6731 |      1.0000 |             8.5468 |      1127.9517 |      0.2617 |      84.7902 |      0.9287 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00024983]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 | 00m22s |   -0.15741 |              0.9012 |             0.9749 |    0.9174 |           8.5038 |      1.0000 |            10.8439 |      1131.7858 |      0.2512 |      73.8225 |      0.9346 | \n",
      "   44 | 00m22s |   -0.15634 |              0.9379 |             0.9628 |    0.1708 |           4.9838 |      1.0000 |            10.8673 |      1134.2965 |      0.0494 |      70.1125 |      0.9005 | \n",
      "   45 | 00m22s |   -0.15553 |              0.9114 |             0.9440 |    0.9269 |           0.3971 |      1.0000 |            10.4646 |      1134.7036 |      0.2661 |      70.3734 |      0.9815 | \n",
      "   46 | 00m23s |   -0.15822 |              0.9968 |             0.9950 |    0.9516 |           1.4627 |      1.0000 |            10.8111 |      1120.6024 |      0.0489 |      80.5748 |      0.9088 | \n",
      "   47 | 00m23s |   -0.15984 |              0.9079 |             0.8625 |    0.8358 |           0.5964 |      1.0000 |             8.2290 |      1134.7341 |      0.2804 |      84.9250 |      0.9622 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.32881575e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 00m24s |   -0.15714 |              0.9487 |             0.9803 |    0.0435 |           9.7257 |      1.0000 |            10.6371 |      1134.9452 |      0.0531 |      84.7593 |      0.9840 | \n",
      "   49 | 00m36s |   -0.15769 |              0.9652 |             0.9928 |    0.8559 |           5.7156 |      1.0000 |            10.6004 |      1133.9002 |      0.2997 |      84.4374 |      0.9727 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00052077]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 | 00m38s |   -0.16038 |              0.9849 |             0.9907 |    0.9084 |           8.5065 |      1.0000 |             8.0536 |      1123.4123 |      0.2569 |      70.1736 |      0.9698 | \n",
      "   51 | 00m41s |   -0.15849 |              0.9108 |             0.9376 |    0.0255 |           9.9148 |      1.0000 |             8.0718 |      1130.0724 |      0.0308 |      70.6916 |      0.9169 | \n",
      "   52 | 00m38s |   -0.15472 |              0.9333 |             0.9698 |    0.0922 |           1.9661 |      1.0000 |             9.0195 |      1130.7706 |      0.2906 |      70.0334 |      0.9222 | \n",
      "   53 | 00m41s |   -0.15768 |              0.9731 |             0.9880 |    0.9888 |           9.9582 |      1.0000 |            10.9041 |      1120.0652 |      0.1983 |      74.9976 |      0.9709 | \n",
      "   54 | 00m45s |   -0.15876 |              0.9019 |             0.9772 |    0.1719 |           6.0065 |      1.0000 |             9.3131 |      1120.0163 |      0.0322 |      70.3062 |      0.9858 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00023922]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   55 | 00m46s |   -0.15579 |              0.9362 |             0.9260 |    0.9608 |           0.0111 |      1.0000 |             8.0543 |      1128.8572 |      0.2421 |      75.4166 |      0.9586 | \n",
      "   56 | 00m43s | \u001b[35m  -0.15391\u001b[0m | \u001b[32m             0.9520\u001b[0m | \u001b[32m            0.8828\u001b[0m | \u001b[32m   0.0954\u001b[0m | \u001b[32m          0.3371\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.0316\u001b[0m | \u001b[32m     1120.0766\u001b[0m | \u001b[32m     0.2231\u001b[0m | \u001b[32m     70.4583\u001b[0m | \u001b[32m     0.9684\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00045909]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   57 | 00m43s |   -0.15714 |              0.9918 |             0.8750 |    0.9663 |           6.7631 |      1.0000 |             8.1606 |      1125.1522 |      0.0919 |      84.7701 |      0.9774 | \n",
      "   58 | 00m46s |   -0.15822 |              0.9645 |             0.9719 |    0.0156 |           2.0015 |      1.0000 |             8.2689 |      1122.2775 |      0.2978 |      70.1137 |      0.9562 | \n",
      "   59 | 00m42s |   -0.15849 |              0.9224 |             0.9981 |    0.0448 |           8.2455 |      1.0000 |            10.6236 |      1132.5464 |      0.2397 |      70.1055 |      0.9198 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([6.6454988e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 63, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   60 | 00m45s |   -0.15579 |              0.9556 |             0.9933 |    0.2190 |           9.9921 |      1.0000 |             8.0304 |      1134.8095 |      0.2404 |      73.7965 |      0.9092 | \n",
      "   61 | 00m40s |   -0.15957 |              0.9999 |             0.9707 |    0.4508 |           0.0228 |      1.0000 |            10.9864 |      1132.2131 |      0.0037 |      70.9700 |      0.9216 | \n",
      "   62 | 00m45s |   -0.15822 |              0.9917 |             0.9781 |    0.7776 |           9.8339 |      1.0000 |            10.4578 |      1134.9513 |      0.1420 |      75.1392 |      0.9038 | \n",
      "   63 | 00m44s |   -0.15957 |              0.9862 |             0.8478 |    0.9279 |           7.9734 |      1.0000 |             8.2239 |      1127.5658 |      0.2538 |      73.2891 |      0.9968 | \n",
      "   64 | 00m44s |   -0.16145 |              0.9872 |             0.9497 |    0.9641 |           3.7349 |      1.0000 |             9.8419 |      1132.6536 |      0.2769 |      70.1197 |      0.9033 | \n",
      "   65 | 00m45s |   -0.15741 |              0.9569 |             0.8190 |    0.0357 |           2.3282 |      1.0000 |            10.9207 |      1134.9785 |      0.2868 |      70.0367 |      0.9873 | \n",
      "   66 | 00m51s |   -0.15660 |              0.9216 |             0.9434 |    0.1719 |           6.2893 |      1.0000 |             8.0920 |      1130.4896 |      0.1090 |      84.9654 |      0.9020 | \n",
      "   67 | 00m51s |   -0.15903 |              0.9090 |             0.9415 |    0.6004 |           6.9583 |      1.0000 |             8.0011 |      1134.0268 |      0.0285 |      76.9155 |      0.9919 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00262584]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   68 | 00m49s |   -0.15795 |              0.9121 |             0.9028 |    0.0461 |           5.3167 |      1.0000 |             8.2127 |      1127.9310 |      0.1766 |      70.1509 |      0.9098 | \n",
      "   69 | 00m47s |   -0.15391 |              0.9063 |             0.9602 |    0.0910 |           3.9193 |      1.0000 |             8.0107 |      1120.1111 |      0.2710 |      82.8729 |      0.9614 | \n",
      "   70 | 00m50s |   -0.15499 |              0.9003 |             0.9537 |    0.0994 |           0.3014 |      1.0000 |             8.1161 |      1128.9168 |      0.2861 |      71.1491 |      0.9871 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00022257]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   71 | 00m50s |   -0.16173 |              0.9246 |             0.9976 |    0.9765 |           3.3983 |      1.0000 |             9.0707 |      1130.4058 |      0.2045 |      78.9044 |      0.9057 | \n",
      "   72 | 00m50s |   -0.15849 |              0.9136 |             0.9760 |    0.8641 |           7.6257 |      1.0000 |             8.4512 |      1122.4629 |      0.2502 |      79.5552 |      0.9071 | \n",
      "   73 | 00m53s |   -0.15795 |              0.9266 |             0.9409 |    0.0161 |           5.9897 |      1.0000 |            10.3103 |      1120.0535 |      0.2368 |      84.8770 |      0.9730 | \n",
      "   74 | 00m56s |   -0.15930 |              0.9113 |             0.9914 |    0.0346 |           4.9211 |      1.0000 |             8.7515 |      1134.8629 |      0.2686 |      73.2268 |      0.9026 | \n",
      "   75 | 00m52s |   -0.15984 |              0.9923 |             0.8948 |    0.4629 |           9.9182 |      1.0000 |             8.1063 |      1120.5738 |      0.2930 |      84.4469 |      0.9928 | \n",
      "   76 | 00m53s |   -0.15634 |              0.9214 |             0.9990 |    0.5498 |           9.9108 |      1.0000 |             8.2995 |      1131.5571 |      0.0724 |      82.6456 |      0.9944 | \n",
      "   77 | 00m55s |   -0.16119 |              0.9923 |             0.9919 |    0.9462 |           0.5693 |      1.0000 |             8.4054 |      1124.9922 |      0.2959 |      76.5301 |      0.9598 | \n",
      "   78 | 00m59s |   -0.15795 |              0.9475 |             0.9380 |    0.2063 |           7.1703 |      1.0000 |            10.9495 |      1127.0110 |      0.0251 |      84.8447 |      0.9949 | \n",
      "   79 | 00m54s |   -0.16173 |              0.9483 |             0.8622 |    0.9655 |           9.9817 |      1.0000 |            10.9820 |      1125.3165 |      0.2669 |      81.5461 |      0.9718 | \n",
      "   80 | 00m48s |   -0.15930 |              0.9797 |             0.9601 |    0.0306 |           5.0324 |      1.0000 |            10.5451 |      1120.1727 |      0.2993 |      75.6954 |      0.9546 | \n",
      "   81 | 00m52s |   -0.15849 |              0.9992 |             0.9320 |    0.1907 |           9.9465 |      1.0000 |            10.6984 |      1124.4697 |      0.0840 |      70.2259 |      0.9647 | \n",
      "   82 | 00m53s |   -0.15957 |              0.9495 |             0.9969 |    0.8802 |           0.0641 |      1.0000 |             8.1305 |      1120.0070 |      0.0675 |      70.2430 |      0.9689 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00039352]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   83 | 00m52s |   -0.15634 |              0.9753 |             0.9645 |    0.0331 |           0.0343 |      1.0000 |             8.0664 |      1120.2182 |      0.2862 |      78.3639 |      0.9654 | \n",
      "   84 | 00m53s |   -0.15903 |              0.9983 |             0.8338 |    0.9640 |           3.3154 |      1.0000 |             8.0105 |      1124.4309 |      0.0342 |      81.9744 |      0.9132 | \n",
      "   85 | 00m53s |   -0.15984 |              0.9702 |             0.9467 |    0.0612 |           0.1223 |      1.0000 |            10.0955 |      1134.9247 |      0.0961 |      70.1115 |      0.9989 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00186005]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   86 | 01m00s |   -0.15822 |              0.9811 |             0.9127 |    0.9818 |           0.2440 |      1.0000 |            10.9960 |      1134.6809 |      0.1957 |      74.7542 |      0.9654 | \n",
      "   87 | 00m56s |   -0.15795 |              0.9051 |             0.8087 |    0.9649 |           0.2933 |      1.0000 |             8.1590 |      1132.5352 |      0.2728 |      74.2741 |      0.9523 | \n",
      "   88 | 00m56s |   -0.15903 |              0.9526 |             0.9198 |    0.7717 |           6.9640 |      1.0000 |            10.9275 |      1134.8679 |      0.2344 |      72.8066 |      0.9997 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-6.77011899e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   89 | 00m54s |   -0.15633 |              0.9169 |             0.8801 |    0.0562 |           9.7881 |      1.0000 |             8.0107 |      1124.8358 |      0.0049 |      84.8109 |      0.9012 | \n",
      "   90 | 01m02s |   -0.15553 |              0.9734 |             0.9810 |    0.3873 |           3.2458 |      1.0000 |             8.0945 |      1120.0356 |      0.2817 |      79.3258 |      0.9533 | \n",
      "   91 | 00m56s |   -0.15930 |              0.9946 |             0.9876 |    0.1699 |           0.1727 |      1.0000 |             8.1252 |      1120.2091 |      0.0383 |      84.8139 |      0.9001 | \n",
      "   92 | 00m58s |   -0.15633 |              0.9344 |             0.9767 |    0.9963 |           0.4041 |      1.0000 |             8.1270 |      1130.9646 |      0.2581 |      70.0661 |      0.9905 | \n",
      "   93 | 00m54s |   -0.15849 |              0.9521 |             0.9172 |    0.9792 |           9.7442 |      1.0000 |             8.2064 |      1131.8520 |      0.0762 |      73.5303 |      0.9039 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00188761]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   94 | 01m03s |   -0.15606 |              0.9081 |             0.9919 |    0.6705 |           2.5834 |      1.0000 |            10.2164 |      1130.2907 |      0.2823 |      73.5870 |      0.9936 | \n",
      "   95 | 00m58s |   -0.16011 |              0.9030 |             0.9987 |    0.8675 |           0.0124 |      1.0000 |             8.1648 |      1120.0740 |      0.2876 |      74.2241 |      0.9980 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00129259]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   96 | 00m58s |   -0.15768 |              0.9148 |             0.9969 |    0.2045 |           7.3945 |      1.0000 |             8.2400 |      1134.9965 |      0.2538 |      82.5420 |      0.9258 | \n",
      "   97 | 00m57s |   -0.16065 |              0.9011 |             0.9941 |    0.7524 |           9.9808 |      1.0000 |             8.1102 |      1131.6618 |      0.0370 |      84.9185 |      0.9811 | \n",
      "   98 | 01m06s |   -0.15391 |              0.9948 |             0.9847 |    0.0061 |           6.1107 |      1.0000 |             8.0114 |      1123.5472 |      0.2877 |      83.9071 |      0.9677 | \n",
      "   99 | 00m59s |   -0.15822 |              0.9529 |             0.9613 |    0.0290 |           9.0716 |      1.0000 |             9.9384 |      1121.4208 |      0.2732 |      71.9310 |      0.9132 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00287681]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 | 01m05s |   -0.16038 |              0.9463 |             0.8857 |    0.8795 |           0.1320 |      1.0000 |            10.7768 |      1127.5862 |      0.2588 |      70.1103 |      0.9632 | \n",
      "  101 | 01m04s |   -0.15633 |              0.9593 |             0.9702 |    0.8410 |           9.9614 |      1.0000 |             8.0057 |      1134.9458 |      0.0292 |      78.0826 |      0.9818 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00021488]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  102 | 01m06s |   -0.15876 |              0.9083 |             0.9790 |    0.0324 |           3.6401 |      1.0000 |             8.0512 |      1130.5152 |      0.0575 |      74.4689 |      0.9601 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00021017]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  103 | 01m08s |   -0.15903 |              0.9457 |             0.9581 |    0.9443 |           9.1061 |      1.0000 |            10.9546 |      1120.0790 |      0.0279 |      79.9705 |      0.9030 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00010734]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  104 | 01m03s |   -0.15768 |              0.9212 |             0.9590 |    0.0852 |           9.9288 |      1.0000 |             8.3457 |      1134.6535 |      0.1161 |      70.5642 |      0.9928 | \n",
      "  105 | 01m08s |   -0.15633 |              0.9021 |             0.9574 |    0.0274 |           2.2309 |      1.0000 |            10.0461 |      1120.0147 |      0.2996 |      81.6842 |      0.9261 | \n",
      "  106 | 01m07s |   -0.15660 |              0.9894 |             0.9823 |    0.3963 |           9.9631 |      1.0000 |            10.9440 |      1128.7142 |      0.0492 |      71.1306 |      0.9700 | \n",
      "2018-06-16 02:29:53,045 - logHandler - train - INFO - Iteration: 3, XGBoost max auc: -0.153908\n",
      "2018-06-16 02:29:53,047 - logHandler - train - INFO - Param max_delta_step: 0.3370759174640936\n",
      "2018-06-16 02:29:53,049 - logHandler - train - INFO - Param reg_lambda: 70.45826887561066\n",
      "2018-06-16 02:29:53,050 - logHandler - train - INFO - Param reg_alpha: 0.2231359119462957\n",
      "2018-06-16 02:29:53,052 - logHandler - train - INFO - Param n_estimators: 1120.076647572242\n",
      "2018-06-16 02:29:53,053 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 02:29:53,055 - logHandler - train - INFO - Param subsample: 0.968371918266281\n",
      "2018-06-16 02:29:53,056 - logHandler - train - INFO - Param min_child_weight: 8.031645459038696\n",
      "2018-06-16 02:29:53,058 - logHandler - train - INFO - Param gamma: 0.09540001970585676\n",
      "2018-06-16 02:29:53,059 - logHandler - train - INFO - Param colsample_bytree: 0.882761482542285\n",
      "2018-06-16 02:29:53,061 - logHandler - train - INFO - Param colsample_bylevel: 0.9519747443685739\n",
      "2018-06-16 02:29:53,062 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 02:29:53,805 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 02:29:53,806 - logHandler - train - INFO - Iteration  4, Current random seed:  4\n",
      "2018-06-16 02:29:53,809 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 02:29:53,810 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.15768\u001b[0m | \u001b[32m             0.9680\u001b[0m | \u001b[32m            0.8775\u001b[0m | \u001b[32m   0.8225\u001b[0m | \u001b[32m          7.5622\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.0664\u001b[0m | \u001b[32m     1125.6375\u001b[0m | \u001b[32m     0.2855\u001b[0m | \u001b[32m     70.1915\u001b[0m | \u001b[32m     0.9425\u001b[0m | \n",
      "    2 | 00m01s |   -0.16226 |              0.9528 |             0.9395 |    0.5615 |           0.9376 |      1.0000 |             8.1428 |      1121.4964 |      0.0919 |      72.9090 |      0.9858 | \n",
      "    3 | 00m02s | \u001b[35m  -0.15552\u001b[0m | \u001b[32m             0.9507\u001b[0m | \u001b[32m            0.9307\u001b[0m | \u001b[32m   0.2956\u001b[0m | \u001b[32m          7.8060\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.9007\u001b[0m | \u001b[32m     1125.5246\u001b[0m | \u001b[32m     0.0032\u001b[0m | \u001b[32m     78.5168\u001b[0m | \u001b[32m     0.9244\u001b[0m | \n",
      "    4 | 00m02s |   -0.15930 |              0.9386 |             0.9852 |    0.2240 |           3.2064 |      1.0000 |             8.0129 |      1134.7412 |      0.0781 |      76.2066 |      0.9608 | \n",
      "    5 | 00m03s | \u001b[35m  -0.15391\u001b[0m | \u001b[32m             0.9927\u001b[0m | \u001b[32m            0.9292\u001b[0m | \u001b[32m   0.1199\u001b[0m | \u001b[32m          2.8161\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.8182\u001b[0m | \u001b[32m     1132.2521\u001b[0m | \u001b[32m     0.1217\u001b[0m | \u001b[32m     75.9552\u001b[0m | \u001b[32m     0.9787\u001b[0m | \n",
      "    6 | 00m02s |   -0.16200 |              0.9534 |             0.8891 |    0.4225 |           3.1276 |      1.0000 |             8.4890 |      1122.1927 |      0.2533 |      72.6349 |      0.9204 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.51423819e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m15s |   -0.16226 |              0.9956 |             0.8437 |    0.9904 |           2.4182 |      1.0000 |            10.9309 |      1133.3295 |      0.2759 |      84.9718 |      0.9878 | \n",
      "    8 | 00m17s |   -0.15769 |              0.9114 |             0.9937 |    0.1880 |           9.8796 |      1.0000 |            10.9363 |      1134.9633 |      0.0856 |      76.2950 |      0.9595 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.3123284e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9 | 00m17s |   -0.16091 |              0.9880 |             0.8322 |    0.1083 |           9.7843 |      1.0000 |            10.7296 |      1120.4973 |      0.0418 |      84.3699 |      0.9709 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.95030741e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10 | 00m17s |   -0.16173 |              0.9723 |             0.9889 |    0.8557 |           0.0792 |      1.0000 |            10.4610 |      1121.5204 |      0.0093 |      84.9389 |      0.9910 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.78139816e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 00m15s |   -0.16496 |              0.9002 |             0.8327 |    0.8649 |           0.0856 |      1.0000 |            10.9944 |      1130.9689 |      0.0256 |      70.2617 |      0.9000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.15691766e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 00m18s |   -0.15903 |              0.9321 |             0.9143 |    0.3184 |           9.5798 |      1.0000 |            10.9646 |      1120.8960 |      0.0053 |      70.9648 |      0.9979 | \n",
      "   13 | 00m18s |   -0.15471 |              0.9901 |             0.9009 |    0.0064 |           9.5372 |      1.0000 |             8.2391 |      1128.6534 |      0.0236 |      70.3576 |      0.9398 | \n",
      "   14 | 00m18s |   -0.15876 |              0.9652 |             0.9997 |    0.0252 |           0.2483 |      1.0000 |             8.9142 |      1128.0929 |      0.2367 |      82.5750 |      0.9979 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.62198117e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-9.01386668e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 00m18s |   -0.16146 |              0.9333 |             0.8778 |    0.0185 |           6.4070 |      1.0000 |            10.9944 |      1126.5105 |      0.0044 |      77.8238 |      0.9965 | \n",
      "   16 | 00m18s |   -0.15660 |              0.9255 |             0.9020 |    0.8825 |           9.9292 |      1.0000 |             8.3526 |      1120.3958 |      0.2406 |      74.8111 |      0.9534 | \n",
      "   17 | 00m18s |   -0.15876 |              0.9799 |             0.9576 |    0.1291 |           9.9768 |      1.0000 |             8.1306 |      1131.0056 |      0.2899 |      84.9336 |      0.9657 | \n",
      "   18 | 00m17s |   -0.15687 |              0.9458 |             0.9427 |    0.4772 |           5.5391 |      1.0000 |             8.0230 |      1120.3430 |      0.0208 |      84.4371 |      0.9031 | \n",
      "   19 | 00m18s |   -0.15822 |              0.9979 |             0.9098 |    0.9974 |           9.7570 |      1.0000 |             8.1195 |      1124.4123 |      0.0759 |      84.3351 |      0.9128 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([4.7720192e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-6.71585094e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 00m18s |   -0.15957 |              0.9992 |             0.8120 |    0.0643 |           0.2255 |      1.0000 |            10.8630 |      1134.7330 |      0.0981 |      81.9907 |      0.9671 | \n",
      "   21 | 00m17s |   -0.15796 |              0.9579 |             0.9033 |    0.6352 |           9.8770 |      1.0000 |             8.1182 |      1120.0994 |      0.2699 |      70.1325 |      0.9620 | \n",
      "   22 | 00m20s |   -0.16038 |              0.9995 |             0.9921 |    0.5762 |           9.8230 |      1.0000 |             8.2288 |      1130.7624 |      0.2617 |      76.8522 |      0.9388 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00028019]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 | 00m18s |   -0.15580 |              0.9866 |             0.9235 |    0.9441 |           9.7543 |      1.0000 |            10.8546 |      1134.8566 |      0.1268 |      70.1417 |      0.9241 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00011629]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00041014]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 00m20s |   -0.15526 |              0.9997 |             0.9793 |    0.0016 |           4.1840 |      1.0000 |            10.6185 |      1134.7776 |      0.1505 |      71.5138 |      0.9883 | \n",
      "   25 | 00m18s |   -0.15849 |              0.9138 |             0.9788 |    0.0212 |           9.7141 |      1.0000 |            10.7136 |      1134.2115 |      0.0103 |      84.9762 |      0.9774 | \n",
      "   26 | 00m20s |   -0.15607 |              0.9936 |             0.9725 |    0.1474 |           0.0790 |      1.0000 |             8.0940 |      1120.1159 |      0.2607 |      81.8970 |      0.9333 | \n",
      "   27 | 00m19s |   -0.15984 |              0.9855 |             0.9602 |    0.1017 |           9.9733 |      1.0000 |             8.1304 |      1120.7555 |      0.0871 |      82.0181 |      0.9426 | \n",
      "   28 | 00m19s |   -0.15930 |              0.9935 |             0.9540 |    0.8847 |           0.7088 |      1.0000 |            10.8587 |      1134.7629 |      0.0177 |      76.0681 |      0.9322 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00010607]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 00m19s |   -0.15876 |              0.9645 |             0.9549 |    0.0858 |           9.7655 |      1.0000 |            10.9321 |      1130.8276 |      0.0208 |      70.0656 |      0.9102 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00014422]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 00m20s |   -0.15714 |              0.9748 |             0.8001 |    0.0990 |           0.6074 |      1.0000 |             8.0412 |      1120.2506 |      0.1820 |      84.5573 |      0.9856 | \n",
      "   31 | 00m19s |   -0.15714 |              0.9967 |             0.8392 |    0.9729 |           1.6185 |      1.0000 |             8.2266 |      1124.5299 |      0.0559 |      80.2433 |      0.9206 | \n",
      "   32 | 00m22s |   -0.15741 |              0.9834 |             0.8426 |    0.0429 |           6.2928 |      1.0000 |             8.4583 |      1134.9097 |      0.0755 |      84.9529 |      0.9105 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00015787]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 00m20s |   -0.15741 |              0.9452 |             0.9978 |    0.9499 |           7.2706 |      1.0000 |             8.0992 |      1126.6492 |      0.0044 |      71.8311 |      0.9793 | \n",
      "   34 | 00m21s |   -0.15903 |              0.9944 |             0.8457 |    0.1409 |           4.5364 |      1.0000 |            10.7393 |      1134.0265 |      0.0043 |      80.5037 |      0.9096 | \n",
      "   35 | 00m22s |   -0.15499 |              0.9682 |             0.9599 |    0.0174 |           0.3808 |      1.0000 |             8.1754 |      1129.5626 |      0.2926 |      74.8715 |      0.9206 | \n",
      "   36 | 00m22s |   -0.15849 |              0.9618 |             0.8612 |    0.0890 |           9.9525 |      1.0000 |             8.4518 |      1134.8152 |      0.1486 |      71.4866 |      0.9412 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([5.65631017e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 00m22s |   -0.15714 |              0.9328 |             0.8010 |    0.2320 |           9.9387 |      1.0000 |             8.0604 |      1122.9996 |      0.1174 |      71.7588 |      0.9749 | \n",
      "   38 | 00m22s |   -0.15984 |              0.9941 |             0.8819 |    0.9959 |           6.8359 |      1.0000 |            10.7029 |      1120.0507 |      0.1821 |      80.1678 |      0.9431 | \n",
      "   39 | 00m22s |   -0.16119 |              0.9590 |             0.9828 |    0.0096 |           4.6278 |      1.0000 |             8.4206 |      1124.4948 |      0.2437 |      84.5281 |      0.9998 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00017062]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   40 | 00m22s |   -0.15606 |              0.9874 |             0.9481 |    0.5052 |           0.2298 |      1.0000 |             8.3372 |      1134.9248 |      0.0231 |      84.9793 |      0.9486 | \n",
      "   41 | 00m23s |   -0.15768 |              0.9067 |             0.8024 |    0.0024 |           3.0838 |      1.0000 |             9.7378 |      1131.4875 |      0.0046 |      74.4035 |      0.9022 | \n",
      "   42 | 00m23s |   -0.15930 |              0.9891 |             0.8847 |    0.9426 |           9.5051 |      1.0000 |             8.5473 |      1134.8803 |      0.1477 |      84.4524 |      0.9622 | \n",
      "   43 | 00m21s |   -0.16307 |              0.9963 |             0.9996 |    0.1032 |           3.5064 |      1.0000 |             8.0841 |      1128.1422 |      0.2977 |      76.6752 |      0.9916 | \n",
      "   44 | 00m24s |   -0.15904 |              0.9846 |             0.9792 |    0.9706 |           9.9911 |      1.0000 |            10.2923 |      1123.9751 |      0.0277 |      76.6665 |      0.9313 | \n",
      "   45 | 00m23s |   -0.15606 |              0.9781 |             0.8452 |    0.0241 |           0.2208 |      1.0000 |             8.0370 |      1134.5037 |      0.1238 |      70.2208 |      0.9801 | \n",
      "   46 | 00m23s |   -0.15903 |              0.9920 |             0.8316 |    0.9808 |           7.4944 |      1.0000 |             8.2590 |      1120.1270 |      0.0289 |      77.6400 |      0.9892 | \n",
      "   47 | 00m24s |   -0.15687 |              0.9217 |             0.8185 |    0.7790 |           0.0278 |      1.0000 |            10.7487 |      1120.2692 |      0.1053 |      70.6048 |      0.9007 | \n",
      "   48 | 00m24s |   -0.15552 |              0.9937 |             0.9235 |    0.2800 |           0.0504 |      1.0000 |            10.8484 |      1120.2871 |      0.2485 |      77.5289 |      0.9168 | \n",
      "   49 | 00m39s |   -0.16065 |              0.9841 |             0.9993 |    0.8947 |           6.5526 |      1.0000 |             8.2805 |      1134.3621 |      0.2942 |      70.0184 |      0.9798 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00032721]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 | 00m42s |   -0.16226 |              0.9949 |             0.9005 |    0.1069 |           0.1190 |      1.0000 |            10.6869 |      1124.1288 |      0.0023 |      70.5840 |      0.9247 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00011062]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 47, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   51 | 00m42s |   -0.15472 |              0.9294 |             0.9143 |    0.0660 |           0.1933 |      1.0000 |             9.4179 |      1133.5870 |      0.2955 |      74.5662 |      0.9128 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.89675988e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   52 | 00m43s |   -0.15849 |              0.9138 |             0.9387 |    0.0203 |           0.0181 |      1.0000 |            10.7349 |      1130.9574 |      0.1725 |      77.5715 |      0.9162 | \n",
      "   53 | 00m43s |   -0.15984 |              0.9975 |             0.8495 |    0.0586 |           6.2982 |      1.0000 |            10.9521 |      1134.7097 |      0.2752 |      73.4035 |      0.9449 | \n",
      "   54 | 00m49s |   -0.15849 |              0.9722 |             0.9977 |    0.9696 |           5.4635 |      1.0000 |            10.8692 |      1120.1262 |      0.1907 |      71.8618 |      0.9144 | \n",
      "   55 | 00m43s |   -0.15714 |              0.9828 |             0.9842 |    0.0753 |           0.0898 |      1.0000 |             8.1203 |      1130.8672 |      0.2418 |      70.1084 |      0.9983 | \n",
      "   56 | 00m46s |   -0.15714 |              0.9553 |             0.9918 |    0.9507 |           9.4587 |      1.0000 |             8.3664 |      1124.3281 |      0.0064 |      70.2849 |      0.9512 | \n",
      "   57 | 00m47s |   -0.16065 |              0.9959 |             0.9465 |    0.3045 |           9.8624 |      1.0000 |             8.1454 |      1126.0137 |      0.0199 |      79.5400 |      0.9990 | \n",
      "   58 | 00m46s |   -0.16011 |              0.9741 |             0.9384 |    0.3222 |           0.1780 |      1.0000 |             8.1961 |      1125.8029 |      0.2357 |      84.8545 |      0.9037 | \n",
      "   59 | 00m45s |   -0.15768 |              0.9047 |             0.9968 |    0.9903 |           8.8707 |      1.0000 |             9.2154 |      1120.0179 |      0.2934 |      84.8247 |      0.9261 | \n",
      "   60 | 00m46s |   -0.15714 |              0.9756 |             0.9786 |    0.0149 |           0.2762 |      1.0000 |             8.3574 |      1134.2680 |      0.0511 |      80.7072 |      0.9049 | \n",
      "   61 | 00m47s |   -0.15445 |              0.9943 |             0.9700 |    0.0112 |           1.0785 |      1.0000 |            10.0397 |      1120.0568 |      0.0861 |      70.1385 |      0.9307 | \n",
      "   62 | 00m46s |   -0.15742 |              0.9960 |             0.9664 |    0.0277 |           8.6212 |      1.0000 |             9.4503 |      1120.0037 |      0.2646 |      72.1211 |      0.9663 | \n",
      "   63 | 00m47s |   -0.15903 |              0.9607 |             0.9785 |    0.0645 |           0.2053 |      1.0000 |            10.6904 |      1134.7283 |      0.1062 |      70.2512 |      0.9857 | \n",
      "   64 | 00m46s |   -0.15552 |              0.9865 |             0.9745 |    0.0872 |           0.5736 |      1.0000 |             8.6379 |      1132.7884 |      0.0197 |      74.4126 |      0.9172 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([7.45571151e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   65 | 00m45s |   -0.15903 |              0.9073 |             0.8445 |    0.1099 |           3.4103 |      1.0000 |            10.9932 |      1120.0481 |      0.2684 |      84.6393 |      0.9033 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00031706]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   66 | 00m48s |   -0.15796 |              0.9098 |             0.9907 |    0.9192 |           9.9305 |      1.0000 |             8.0167 |      1128.8773 |      0.2684 |      70.7333 |      0.9980 | \n",
      "   67 | 00m48s |   -0.16281 |              0.9732 |             0.9414 |    0.0050 |           0.1603 |      1.0000 |             9.0675 |      1131.6896 |      0.2611 |      84.9846 |      0.9299 | \n",
      "   68 | 00m47s |   -0.16038 |              0.9153 |             0.9736 |    0.8412 |           8.9931 |      1.0000 |            10.4293 |      1129.5019 |      0.0428 |      84.8709 |      0.9054 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00031091]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   69 | 00m44s |   -0.15930 |              0.9482 |             0.8807 |    0.0265 |           0.2807 |      1.0000 |             9.5528 |      1123.9264 |      0.0126 |      80.4986 |      0.9057 | \n",
      "   70 | 00m55s |   -0.15957 |              0.9127 |             0.8076 |    0.1517 |           0.2526 |      1.0000 |             8.5937 |      1120.2278 |      0.2763 |      70.1371 |      0.9501 | \n",
      "   71 | 00m49s |   -0.15714 |              0.9649 |             0.9937 |    0.0352 |           9.6997 |      1.0000 |             9.8084 |      1134.9171 |      0.2628 |      70.1765 |      0.9919 | \n",
      "   72 | 00m49s |   -0.16064 |              0.9007 |             0.8878 |    0.0500 |           0.0210 |      1.0000 |            10.9434 |      1120.2804 |      0.0868 |      73.3005 |      0.9686 | \n",
      "   73 | 00m52s |   -0.16280 |              0.9535 |             0.8268 |    0.9110 |           0.1822 |      1.0000 |            10.0034 |      1120.0241 |      0.2360 |      79.9356 |      0.9058 | \n",
      "   74 | 00m49s |   -0.15661 |              0.9873 |             0.9982 |    0.2011 |           9.7270 |      1.0000 |            10.3671 |      1134.8888 |      0.2792 |      81.8381 |      0.9052 | \n",
      "   75 | 00m49s |   -0.15472 |              0.9837 |             0.9847 |    0.4096 |           0.0099 |      1.0000 |             8.2689 |      1123.5436 |      0.2885 |      77.1385 |      0.9112 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00054268]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   76 | 00m49s |   -0.15445 |              0.9847 |             0.9984 |    0.1750 |           2.3413 |      1.0000 |            10.6601 |      1132.8825 |      0.2933 |      72.0033 |      0.9160 | \n",
      "   77 | 00m53s |   -0.15660 |              0.9996 |             0.9947 |    0.3273 |           5.8564 |      1.0000 |             8.2216 |      1122.7057 |      0.2970 |      79.6417 |      0.9330 | \n",
      "   78 | 00m58s |   -0.15552 |              0.9983 |             0.9696 |    0.0174 |           8.9646 |      1.0000 |             8.2244 |      1125.0681 |      0.0567 |      75.5305 |      0.9134 | \n",
      "   79 | 00m53s |   -0.15741 |              0.9574 |             0.9858 |    0.1360 |           4.4942 |      1.0000 |            10.9349 |      1134.9708 |      0.2869 |      84.4652 |      0.9578 | \n",
      "   80 | 00m57s |   -0.15849 |              0.9893 |             0.9635 |    0.1249 |           3.0724 |      1.0000 |            10.8839 |      1134.8909 |      0.2369 |      70.0270 |      0.9515 | \n",
      "   81 | 00m52s |   -0.15471 |              0.9905 |             0.8795 |    0.0732 |           9.9433 |      1.0000 |             8.4589 |      1134.9933 |      0.0467 |      78.8339 |      0.9054 | \n",
      "   82 | 00m54s |   -0.15903 |              0.9922 |             0.9931 |    0.8133 |           0.0393 |      1.0000 |             9.4710 |      1127.9059 |      0.2697 |      75.5447 |      0.9502 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00207521]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   83 | 00m51s |   -0.15606 |              0.9965 |             0.9956 |    0.0134 |           0.0084 |      1.0000 |             8.4523 |      1120.0458 |      0.1107 |      76.5844 |      0.9439 | \n",
      "   84 | 00m53s |   -0.15984 |              0.9788 |             0.9720 |    0.0029 |           2.6503 |      1.0000 |            10.9895 |      1134.2015 |      0.2419 |      76.5314 |      0.9493 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.16270601e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   85 | 00m55s |   -0.15795 |              0.9483 |             0.8885 |    0.9772 |           7.3042 |      1.0000 |             8.0218 |      1131.5480 |      0.0466 |      82.5107 |      0.9389 | \n",
      "   86 | 01m01s |   -0.15876 |              0.9839 |             0.9182 |    0.9902 |           8.1030 |      1.0000 |             9.9203 |      1133.5375 |      0.0088 |      79.3835 |      0.9757 | \n",
      "   87 | 00m55s |   -0.16038 |              0.9922 |             0.9489 |    0.9348 |           0.5045 |      1.0000 |             8.4184 |      1134.5170 |      0.2956 |      72.5330 |      0.9985 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.38302343e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   88 | 00m54s |   -0.15930 |              0.9961 |             0.9716 |    0.9995 |           4.4985 |      1.0000 |            10.9642 |      1129.0257 |      0.0704 |      81.0526 |      0.9365 | \n",
      "   89 | 00m57s |   -0.16173 |              0.9703 |             0.9848 |    0.1520 |           0.0340 |      1.0000 |            10.9213 |      1130.5185 |      0.1332 |      73.8062 |      0.9987 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00053812]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00033193]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   90 | 01m01s |   -0.15903 |              0.9912 |             0.8571 |    0.7279 |           0.0589 |      1.0000 |             8.1032 |      1132.5132 |      0.2506 |      77.7408 |      0.9488 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00024406]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   91 | 00m59s |   -0.15445 |              0.9052 |             0.9780 |    0.1101 |           9.9400 |      1.0000 |             8.2630 |      1133.9097 |      0.0299 |      82.2176 |      0.9288 | \n",
      "   92 | 00m57s |   -0.15876 |              0.9986 |             0.9701 |    0.8603 |           5.7550 |      1.0000 |            10.7459 |      1130.7749 |      0.1589 |      71.3819 |      0.9465 | \n",
      "   93 | 00m58s |   -0.15526 |              0.9863 |             0.9679 |    0.1482 |           0.0793 |      1.0000 |             8.1127 |      1126.6742 |      0.2821 |      80.2855 |      0.9141 | \n",
      "   94 | 01m03s |   -0.15903 |              0.9210 |             0.9811 |    0.1331 |           9.7175 |      1.0000 |             8.2359 |      1120.5270 |      0.0448 |      84.8714 |      0.9779 | \n",
      "   95 | 00m58s |   -0.15633 |              0.9847 |             0.9946 |    0.3116 |           9.9492 |      1.0000 |            10.8470 |      1120.0830 |      0.1017 |      76.2358 |      0.9176 | \n",
      "   96 | 00m54s |   -0.15768 |              0.9985 |             0.9956 |    0.0432 |           6.1841 |      1.0000 |             8.3011 |      1123.0477 |      0.2140 |      70.0708 |      0.9011 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([6.32549636e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   97 | 01m02s |   -0.16172 |              0.9934 |             0.9481 |    0.1843 |           3.2905 |      1.0000 |            10.9958 |      1120.5439 |      0.2578 |      70.1087 |      0.9263 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00045023]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   98 | 01m02s |   -0.15607 |              0.9698 |             0.9794 |    0.0752 |           1.3417 |      1.0000 |             8.4012 |      1120.0772 |      0.0052 |      84.6418 |      0.9062 | \n",
      "   99 | 01m02s |   -0.15741 |              0.9886 |             0.9960 |    0.9850 |           6.2966 |      1.0000 |            10.7390 |      1122.8409 |      0.0020 |      75.2302 |      0.9004 | \n",
      "  100 | 01m10s |   -0.15795 |              0.9975 |             0.9123 |    0.9736 |           9.7261 |      1.0000 |            10.7384 |      1127.7942 |      0.0037 |      73.0909 |      0.9016 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00092997]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  101 | 01m03s |   -0.15499 |              0.9978 |             0.8279 |    0.9678 |           9.0266 |      1.0000 |             9.8422 |      1120.0159 |      0.0496 |      72.5369 |      0.9561 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00032836]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  102 | 01m03s |   -0.15499 |              0.9982 |             0.9988 |    0.0444 |           1.0015 |      1.0000 |             8.1078 |      1125.8611 |      0.2034 |      70.1848 |      0.9932 | \n",
      "  103 | 01m02s |   -0.15552 |              0.9728 |             0.9993 |    0.0299 |           0.0146 |      1.0000 |             8.0169 |      1134.8529 |      0.1126 |      74.2185 |      0.9381 | \n",
      "  104 | 01m05s |   -0.15903 |              0.9734 |             0.9689 |    0.8191 |           3.5393 |      1.0000 |            10.9533 |      1131.4104 |      0.1015 |      76.1838 |      0.9028 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00282865]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.0024531]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  105 | 01m04s |   -0.16604 |              0.9896 |             0.8166 |    0.0077 |           7.8849 |      1.0000 |             9.8944 |      1130.9117 |      0.0063 |      82.1035 |      0.9710 | \n",
      "  106 | 01m09s |   -0.16065 |              0.9805 |             0.8606 |    0.9992 |           3.8842 |      1.0000 |             8.3357 |      1134.9977 |      0.2097 |      82.8511 |      0.9842 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00035218]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-16 03:36:58,654 - logHandler - train - INFO - Iteration: 4, XGBoost max auc: -0.153909\n",
      "2018-06-16 03:36:58,657 - logHandler - train - INFO - Param max_delta_step: 2.8160816417711576\n",
      "2018-06-16 03:36:58,658 - logHandler - train - INFO - Param reg_lambda: 75.9551535284903\n",
      "2018-06-16 03:36:58,660 - logHandler - train - INFO - Param reg_alpha: 0.12165081281167889\n",
      "2018-06-16 03:36:58,661 - logHandler - train - INFO - Param n_estimators: 1132.2520581634885\n",
      "2018-06-16 03:36:58,663 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 03:36:58,664 - logHandler - train - INFO - Param subsample: 0.9786645168156343\n",
      "2018-06-16 03:36:58,666 - logHandler - train - INFO - Param min_child_weight: 10.818249398495455\n",
      "2018-06-16 03:36:58,668 - logHandler - train - INFO - Param gamma: 0.11989827827474364\n",
      "2018-06-16 03:36:58,670 - logHandler - train - INFO - Param colsample_bytree: 0.9291930735687759\n",
      "2018-06-16 03:36:58,671 - logHandler - train - INFO - Param colsample_bylevel: 0.992666899803768\n",
      "2018-06-16 03:36:58,673 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 03:36:59,719 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 03:36:59,721 - logHandler - train - INFO - Iteration  5, Current random seed:  5\n",
      "2018-06-16 03:36:59,723 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 03:36:59,725 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.15714\u001b[0m | \u001b[32m             0.9266\u001b[0m | \u001b[32m            0.8427\u001b[0m | \u001b[32m   0.1172\u001b[0m | \u001b[32m          5.4602\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.5568\u001b[0m | \u001b[32m     1132.6605\u001b[0m | \u001b[32m     0.1467\u001b[0m | \u001b[32m     72.4710\u001b[0m | \u001b[32m     0.9086\u001b[0m | \n",
      "    2 | 00m02s | \u001b[35m  -0.15660\u001b[0m | \u001b[32m             0.9426\u001b[0m | \u001b[32m            0.8906\u001b[0m | \u001b[32m   0.9507\u001b[0m | \u001b[32m          5.2458\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.8004\u001b[0m | \u001b[32m     1124.3761\u001b[0m | \u001b[32m     0.1383\u001b[0m | \u001b[32m     84.9251\u001b[0m | \u001b[32m     0.9094\u001b[0m | \n",
      "    3 | 00m02s |   -0.15957 |              0.9008 |             0.9049 |    0.0492 |           1.3315 |      1.0000 |             9.1955 |      1130.4436 |      0.0467 |      77.8237 |      0.9634 | \n",
      "    4 | 00m02s | \u001b[35m  -0.15580\u001b[0m | \u001b[32m             0.9085\u001b[0m | \u001b[32m            0.9653\u001b[0m | \u001b[32m   0.4195\u001b[0m | \u001b[32m          1.5090\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.0985\u001b[0m | \u001b[32m     1122.6873\u001b[0m | \u001b[32m     0.1795\u001b[0m | \u001b[32m     70.9079\u001b[0m | \u001b[32m     0.9228\u001b[0m | \n",
      "    5 | 00m03s |   -0.15714 |              0.9657 |             0.8125 |    0.0487 |           1.1685 |      1.0000 |             9.4016 |      1127.7835 |      0.2370 |      80.4656 |      0.9695 | \n",
      "    6 | 00m03s |   -0.15742 |              0.9430 |             0.8054 |    0.6525 |           7.6652 |      1.0000 |             8.8423 |      1124.1637 |      0.1017 |      78.5412 |      0.9438 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m16s |   -0.16118 |              0.9929 |             0.8328 |    0.9906 |           9.6726 |      1.0000 |            10.9941 |      1120.4072 |      0.0571 |      80.7314 |      0.9476 | \n",
      "    8 | 00m15s | \u001b[35m  -0.15525\u001b[0m | \u001b[32m             0.9561\u001b[0m | \u001b[32m            0.9171\u001b[0m | \u001b[32m   0.0307\u001b[0m | \u001b[32m          9.3364\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.1056\u001b[0m | \u001b[32m     1121.0064\u001b[0m | \u001b[32m     0.1861\u001b[0m | \u001b[32m     84.6990\u001b[0m | \u001b[32m     0.9621\u001b[0m | \n",
      "    9 | 00m16s |   -0.15795 |              0.9272 |             0.9140 |    0.0066 |           9.9018 |      1.0000 |             8.7770 |      1134.4653 |      0.2705 |      84.6548 |      0.9656 | \n",
      "   10 | 00m18s |   -0.15607 |              0.9017 |             0.8997 |    0.4943 |           9.7566 |      1.0000 |             8.0820 |      1120.1028 |      0.2160 |      70.0060 |      0.9604 | \n",
      "   11 | 00m16s |   -0.15903 |              0.9202 |             0.8311 |    0.3300 |           0.1036 |      1.0000 |             8.1956 |      1120.0032 |      0.1700 |      84.6993 |      0.9528 | \n",
      "   12 | 00m17s | \u001b[35m  -0.15391\u001b[0m | \u001b[32m             0.9893\u001b[0m | \u001b[32m            0.8318\u001b[0m | \u001b[32m   0.9722\u001b[0m | \u001b[32m          0.1328\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.5686\u001b[0m | \u001b[32m     1131.8231\u001b[0m | \u001b[32m     0.2921\u001b[0m | \u001b[32m     70.5153\u001b[0m | \u001b[32m     0.9040\u001b[0m | \n",
      "   13 | 00m17s |   -0.15633 |              0.9684 |             0.9994 |    0.0829 |           8.9986 |      1.0000 |             8.5677 |      1128.0834 |      0.2989 |      70.3458 |      0.9484 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([5.04376749e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 00m17s |   -0.15742 |              0.9799 |             0.8185 |    0.0123 |           3.3211 |      1.0000 |             8.0745 |      1127.3238 |      0.2808 |      70.0594 |      0.9434 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00012594]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 00m17s |   -0.16199 |              0.9896 |             0.9702 |    0.7146 |           0.0641 |      1.0000 |            10.7975 |      1134.1632 |      0.2597 |      70.1131 |      0.9719 | \n",
      "   16 | 00m18s |   -0.16065 |              0.9413 |             0.9856 |    0.8204 |           9.8346 |      1.0000 |             8.1905 |      1134.9406 |      0.0047 |      70.4345 |      0.9597 | \n",
      "   17 | 00m18s |   -0.16199 |              0.9087 |             0.8201 |    0.9772 |           0.7447 |      1.0000 |             8.1339 |      1134.7408 |      0.2623 |      83.9931 |      0.9027 | \n",
      "   18 | 00m19s |   -0.15849 |              0.9000 |             1.0000 |    0.9291 |           5.2890 |      1.0000 |             8.0000 |      1133.1058 |      0.3000 |      78.4594 |      0.9000 | \n",
      "   19 | 00m18s |   -0.15957 |              0.9201 |             0.8048 |    0.8140 |           9.8511 |      1.0000 |            10.9030 |      1130.2614 |      0.2657 |      70.4216 |      0.9205 | \n",
      "   20 | 00m18s |   -0.15876 |              0.9215 |             0.8935 |    0.7348 |           0.1678 |      1.0000 |            10.7877 |      1120.0642 |      0.0985 |      70.3706 |      0.9522 | \n",
      "   21 | 00m20s |   -0.15445 |              0.9631 |             0.9486 |    0.0812 |           9.9702 |      1.0000 |            10.6870 |      1129.3385 |      0.2910 |      84.8479 |      0.9372 | \n",
      "   22 | 00m19s |   -0.15715 |              0.9956 |             0.9592 |    0.9399 |           0.2531 |      1.0000 |             8.4280 |      1120.0165 |      0.2287 |      74.1668 |      0.9201 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.01076853e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00026941]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 | 00m18s | \u001b[35m  -0.15391\u001b[0m | \u001b[32m             0.9184\u001b[0m | \u001b[32m            0.8126\u001b[0m | \u001b[32m   0.4683\u001b[0m | \u001b[32m          0.0200\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.8575\u001b[0m | \u001b[32m     1124.5323\u001b[0m | \u001b[32m     0.2902\u001b[0m | \u001b[32m     84.9956\u001b[0m | \u001b[32m     0.9739\u001b[0m | \n",
      "   24 | 00m19s | \u001b[35m  -0.15283\u001b[0m | \u001b[32m             0.9244\u001b[0m | \u001b[32m            0.8997\u001b[0m | \u001b[32m   0.0209\u001b[0m | \u001b[32m          6.8319\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.6968\u001b[0m | \u001b[32m     1123.8822\u001b[0m | \u001b[32m     0.2887\u001b[0m | \u001b[32m     84.6287\u001b[0m | \u001b[32m     0.9172\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00042739]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 00m19s |   -0.15849 |              0.9609 |             0.8574 |    0.0345 |           9.8936 |      1.0000 |            10.9014 |      1120.7046 |      0.2992 |      73.1545 |      0.9315 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00052011]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 00m17s |   -0.15903 |              0.9060 |             0.9475 |    0.9979 |           0.0999 |      1.0000 |            10.4572 |      1128.0106 |      0.2775 |      74.6258 |      0.9059 | \n",
      "   27 | 00m19s |   -0.15445 |              0.9229 |             0.8021 |    0.0519 |           0.2552 |      1.0000 |             8.0252 |      1127.2717 |      0.1789 |      84.5990 |      0.9275 | \n",
      "   28 | 00m19s |   -0.15876 |              0.9646 |             0.8581 |    0.0162 |           9.8357 |      1.0000 |             8.1853 |      1129.4229 |      0.2242 |      76.7077 |      0.9053 | \n",
      "   29 | 00m17s |   -0.16388 |              0.9131 |             0.9799 |    0.1036 |           3.6255 |      1.0000 |            10.9679 |      1130.0582 |      0.0051 |      84.9740 |      0.9157 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00023548]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 00m19s |   -0.15984 |              0.9032 |             0.8761 |    0.6671 |           0.6184 |      1.0000 |             8.2233 |      1134.7780 |      0.2742 |      71.9028 |      0.9959 | \n",
      "   31 | 00m20s |   -0.15876 |              0.9925 |             0.8611 |    0.2813 |           9.8811 |      1.0000 |             8.0550 |      1126.6151 |      0.2461 |      84.9279 |      0.9270 | \n",
      "   32 | 00m19s |   -0.15499 |              0.9974 |             0.9532 |    0.8234 |           0.0096 |      1.0000 |             8.0927 |      1121.3653 |      0.2637 |      70.1550 |      0.9508 | \n",
      "   33 | 00m20s |   -0.16037 |              0.9989 |             0.9409 |    0.9991 |           4.5159 |      1.0000 |             8.9497 |      1120.8592 |      0.2563 |      70.8086 |      0.9071 | \n",
      "   34 | 00m21s |   -0.15768 |              0.9387 |             0.9843 |    0.6269 |           0.1953 |      1.0000 |             8.0053 |      1124.3069 |      0.1259 |      81.7454 |      0.9288 | \n",
      "   35 | 00m19s |   -0.16038 |              0.9142 |             0.8024 |    0.9083 |           9.9982 |      1.0000 |            10.7816 |      1134.9444 |      0.1406 |      84.5856 |      0.9348 | \n",
      "   36 | 00m20s |   -0.15768 |              0.9173 |             0.9718 |    0.2035 |           9.2552 |      1.0000 |            10.9413 |      1120.3429 |      0.2503 |      84.9919 |      0.9555 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00021549]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 00m23s |   -0.16361 |              0.9039 |             0.8622 |    0.1275 |           8.2131 |      1.0000 |             8.0755 |      1120.1070 |      0.2961 |      79.6784 |      0.9277 | \n",
      "   38 | 00m22s |   -0.15822 |              0.9218 |             0.9867 |    0.0105 |           9.9637 |      1.0000 |            10.5852 |      1134.6272 |      0.0631 |      78.7260 |      0.9994 | \n",
      "   39 | 00m22s |   -0.15768 |              0.9894 |             0.8238 |    0.0810 |           9.9667 |      1.0000 |             8.7172 |      1124.4212 |      0.1166 |      70.6406 |      0.9067 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.14582363e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   40 | 00m23s |   -0.15472 |              0.9861 |             0.9892 |    0.1099 |           0.0403 |      1.0000 |             8.5764 |      1128.9154 |      0.1612 |      70.2369 |      0.9846 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.18543567e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 00m22s |   -0.15768 |              0.9584 |             0.9832 |    0.0164 |           9.9518 |      1.0000 |            10.9228 |      1125.4434 |      0.1586 |      78.8342 |      0.9140 | \n",
      "   42 | 00m22s |   -0.16146 |              0.9982 |             0.8238 |    0.9380 |           6.5771 |      1.0000 |             8.4809 |      1131.5654 |      0.0037 |      70.5177 |      0.9984 | \n",
      "   43 | 00m24s |   -0.15876 |              0.9184 |             0.8112 |    0.7880 |           9.6985 |      1.0000 |            10.5529 |      1123.1555 |      0.2868 |      84.8863 |      0.9785 | \n",
      "   44 | 00m24s |   -0.15687 |              0.9694 |             0.8089 |    0.0168 |           0.3694 |      1.0000 |            10.8725 |      1121.3105 |      0.2630 |      75.7018 |      0.9076 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00019061]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 | 00m26s |   -0.16011 |              0.9639 |             0.9911 |    0.3525 |           9.8503 |      1.0000 |            10.9578 |      1120.1986 |      0.2420 |      70.0478 |      0.9756 | \n",
      "   46 | 00m27s |   -0.15607 |              0.9998 |             0.8464 |    0.0649 |           3.0767 |      1.0000 |            10.5456 |      1120.3282 |      0.0369 |      84.9771 |      0.9190 | \n",
      "   47 | 00m26s |   -0.15553 |              0.9722 |             0.8671 |    0.0916 |           9.4962 |      1.0000 |            10.9180 |      1134.9922 |      0.1908 |      70.4629 |      0.9389 | \n",
      "   48 | 00m24s |   -0.15822 |              0.9609 |             0.8056 |    0.8416 |           0.0272 |      1.0000 |             8.7451 |      1124.7790 |      0.2508 |      73.2583 |      0.9051 | \n",
      "   49 | 00m36s |   -0.16011 |              0.9982 |             0.9711 |    0.0373 |           1.8329 |      1.0000 |             9.4519 |      1125.2014 |      0.2782 |      84.8424 |      0.9159 | \n",
      "   50 | 00m43s |   -0.15768 |              0.9061 |             0.8007 |    0.0720 |           6.0249 |      1.0000 |            10.9891 |      1123.7220 |      0.0101 |      80.7810 |      0.9155 | \n",
      "   51 | 00m42s |   -0.15795 |              0.9234 |             0.8817 |    0.8478 |           0.2629 |      1.0000 |            10.7737 |      1120.0185 |      0.1247 |      83.2082 |      0.9133 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00019659]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   52 | 00m38s |   -0.15957 |              0.9737 |             0.8183 |    0.0406 |           0.3621 |      1.0000 |             8.1130 |      1120.0533 |      0.0069 |      72.2762 |      0.9259 | \n",
      "   53 | 00m41s |   -0.15715 |              0.9743 |             0.8026 |    0.0230 |           6.0627 |      1.0000 |             8.1862 |      1134.6683 |      0.2649 |      70.0722 |      0.9379 | \n",
      "   54 | 00m46s |   -0.15983 |              0.9580 |             0.8026 |    0.9666 |           0.0600 |      1.0000 |             8.0549 |      1130.6381 |      0.1992 |      84.6820 |      0.9992 | \n",
      "   55 | 00m47s |   -0.15606 |              0.9205 |             0.8287 |    0.0208 |           8.1297 |      1.0000 |            10.8578 |      1133.5092 |      0.2708 |      82.5992 |      0.9278 | \n",
      "   56 | 00m45s |   -0.15660 |              0.9161 |             0.9483 |    0.8984 |           9.8252 |      1.0000 |             8.0723 |      1123.2158 |      0.2965 |      72.7591 |      0.9714 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.17247214e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   57 | 00m43s |   -0.15795 |              0.9178 |             0.8639 |    0.1696 |           0.0775 |      1.0000 |            10.8012 |      1134.8046 |      0.2361 |      84.6622 |      0.9297 | \n",
      "   58 | 00m47s |   -0.15984 |              0.9005 |             0.8863 |    0.0416 |           0.0158 |      1.0000 |             8.8763 |      1132.0183 |      0.2455 |      70.0759 |      0.9244 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.72262971e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   59 | 00m45s |   -0.15849 |              0.9862 |             0.9516 |    0.1547 |           0.0707 |      1.0000 |             8.3023 |      1134.9893 |      0.2656 |      79.6192 |      0.9321 | \n",
      "   60 | 00m44s |   -0.15660 |              0.9893 |             0.9599 |    0.9669 |           0.0801 |      1.0000 |            10.7377 |      1125.1892 |      0.2911 |      70.1334 |      0.9847 | \n",
      "   61 | 00m44s |   -0.15768 |              0.9473 |             0.9354 |    0.6825 |           6.4900 |      1.0000 |            10.9793 |      1134.8776 |      0.2971 |      73.3848 |      0.9829 | \n",
      "   62 | 00m49s |   -0.15876 |              0.9464 |             0.9782 |    0.9752 |           1.1078 |      1.0000 |             8.4487 |      1129.4981 |      0.2995 |      70.2428 |      0.9135 | \n",
      "   63 | 00m47s |   -0.15525 |              0.9594 |             0.8148 |    0.8378 |           0.0670 |      1.0000 |            10.9656 |      1134.5906 |      0.2722 |      76.3218 |      0.9513 | \n",
      "   64 | 00m45s |   -0.15445 |              0.9768 |             0.8255 |    0.0737 |           8.6686 |      1.0000 |             8.0567 |      1134.0682 |      0.2027 |      73.8812 |      0.9794 | \n",
      "   65 | 00m46s |   -0.15849 |              0.9932 |             0.8100 |    0.0578 |           6.1468 |      1.0000 |            10.6940 |      1130.2713 |      0.2872 |      76.8015 |      0.9504 | \n",
      "   66 | 00m50s |   -0.15741 |              0.9190 |             0.8752 |    0.5837 |           6.3712 |      1.0000 |             8.0637 |      1120.0466 |      0.1660 |      84.9949 |      0.9215 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00043313]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   67 | 00m53s |   -0.15553 |              0.9236 |             0.9237 |    0.0186 |           6.9897 |      1.0000 |             8.6389 |      1123.6913 |      0.0123 |      84.8904 |      0.9519 | \n",
      "   68 | 00m52s |   -0.15849 |              0.9808 |             0.8037 |    0.9818 |           0.1351 |      1.0000 |            10.8825 |      1134.8008 |      0.0451 |      80.4473 |      0.9298 | \n",
      "   69 | 00m46s |   -0.15930 |              0.9955 |             0.8720 |    0.9018 |           0.0036 |      1.0000 |             8.0314 |      1129.5113 |      0.1716 |      78.7517 |      0.9161 | \n",
      "   70 | 00m52s |   -0.15903 |              0.9728 |             0.8036 |    0.0460 |           6.5191 |      1.0000 |             8.0619 |      1134.9979 |      0.2653 |      78.9337 |      0.9708 | \n",
      "   71 | 00m51s |   -0.15876 |              0.9981 |             0.8066 |    0.8978 |           9.9875 |      1.0000 |             8.6009 |      1131.2886 |      0.2323 |      81.2702 |      0.9896 | \n",
      "   72 | 00m55s |   -0.15579 |              0.9854 |             0.9279 |    0.0602 |           9.9738 |      1.0000 |             8.9817 |      1132.6704 |      0.2946 |      70.3526 |      0.9430 | \n",
      "   73 | 00m49s |   -0.15579 |              0.9785 |             0.8787 |    0.7322 |           9.9785 |      1.0000 |            10.9009 |      1134.9185 |      0.2934 |      73.6596 |      0.9055 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00046695]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 | 00m52s |   -0.15822 |              0.9806 |             0.8172 |    0.1970 |           6.8762 |      1.0000 |             8.1233 |      1128.3581 |      0.2925 |      82.0136 |      0.9463 | \n",
      "   75 | 00m51s |   -0.15634 |              0.9088 |             0.8092 |    0.0998 |           0.0525 |      1.0000 |            10.8874 |      1131.0581 |      0.2869 |      81.1032 |      0.9374 | \n",
      "   76 | 00m48s |   -0.15983 |              0.9850 |             0.8423 |    0.0068 |           0.0318 |      1.0000 |             8.4618 |      1124.3254 |      0.2622 |      70.1526 |      0.9020 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00038856]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00057206]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   77 | 00m55s |   -0.15579 |              0.9799 |             0.9476 |    0.0515 |           6.3045 |      1.0000 |            10.8816 |      1126.0669 |      0.2893 |      72.9562 |      0.9928 | \n",
      "   78 | 00m59s |   -0.16037 |              0.9782 |             0.9854 |    0.9557 |           1.0937 |      1.0000 |            10.9950 |      1122.1081 |      0.0086 |      74.1546 |      0.9575 | \n",
      "   79 | 00m54s |   -0.15795 |              0.9505 |             0.9824 |    0.1961 |           0.1090 |      1.0000 |             9.6912 |      1131.1771 |      0.2801 |      73.3651 |      0.9984 | \n",
      "   80 | 00m55s |   -0.15607 |              0.9619 |             0.9956 |    0.0389 |           4.3833 |      1.0000 |             8.4057 |      1124.0585 |      0.2835 |      74.4130 |      0.9979 | \n",
      "   81 | 00m53s |   -0.15579 |              0.9230 |             0.8585 |    0.0312 |           0.1019 |      1.0000 |            10.9577 |      1123.9276 |      0.2410 |      80.1966 |      0.9918 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00094398]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   82 | 00m53s |   -0.15849 |              0.9096 |             0.9032 |    0.8797 |           5.0819 |      1.0000 |            10.8854 |      1121.3678 |      0.2599 |      84.7334 |      0.9994 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00164143]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   83 | 00m54s |   -0.15957 |              0.9773 |             0.8646 |    0.0611 |           9.5626 |      1.0000 |            10.9053 |      1133.0213 |      0.0327 |      73.2567 |      0.9519 | \n",
      "   84 | 00m52s |   -0.16200 |              0.9956 |             0.8815 |    0.0222 |           0.0018 |      1.0000 |            10.4627 |      1120.8271 |      0.0741 |      84.9739 |      0.9859 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00176365]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 63, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   85 | 00m51s |   -0.16173 |              0.9521 |             0.8426 |    0.6241 |           0.2176 |      1.0000 |             9.2889 |      1120.1119 |      0.0105 |      79.0522 |      0.9641 | \n",
      "   86 | 00m58s | \u001b[35m  -0.15175\u001b[0m | \u001b[32m             0.9075\u001b[0m | \u001b[32m            0.8091\u001b[0m | \u001b[32m   0.0022\u001b[0m | \u001b[32m          9.8950\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.5972\u001b[0m | \u001b[32m     1123.7132\u001b[0m | \u001b[32m     0.2943\u001b[0m | \u001b[32m     82.8138\u001b[0m | \u001b[32m     0.9479\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00047023]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   87 | 01m00s |   -0.15741 |              0.9798 |             0.8093 |    0.8542 |           3.2307 |      1.0000 |             8.0396 |      1134.2163 |      0.2685 |      74.3994 |      0.9442 | \n",
      "   88 | 00m52s |   -0.15634 |              0.9303 |             0.8002 |    0.9883 |           0.2936 |      1.0000 |            10.7422 |      1126.7342 |      0.1328 |      82.6520 |      0.9031 | \n",
      "   89 | 00m57s |   -0.15769 |              0.9128 |             0.8207 |    0.9906 |           0.3663 |      1.0000 |             8.3632 |      1124.6098 |      0.1234 |      84.9011 |      0.9153 | \n",
      "   90 | 01m03s |   -0.16226 |              0.9327 |             0.8075 |    0.1415 |           9.6985 |      1.0000 |             8.0703 |      1123.9399 |      0.1464 |      82.2840 |      0.9000 | \n",
      "   91 | 00m53s |   -0.15957 |              0.9153 |             0.8175 |    0.0103 |           9.7917 |      1.0000 |             9.1756 |      1124.7040 |      0.2706 |      74.2837 |      0.9977 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00027598]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   92 | 00m54s |   -0.15768 |              1.0000 |             0.8951 |    0.0241 |           3.2354 |      1.0000 |            10.8579 |      1124.2284 |      0.2272 |      70.0761 |      0.9868 | \n",
      "   93 | 00m59s |   -0.15930 |              0.9192 |             0.8113 |    0.8354 |           5.4771 |      1.0000 |             8.0633 |      1127.4125 |      0.2572 |      76.2806 |      0.9992 | \n",
      "   94 | 01m03s |   -0.15687 |              0.9113 |             0.8122 |    0.0528 |           4.2631 |      1.0000 |             8.7267 |      1121.5221 |      0.2944 |      83.1718 |      0.9144 | \n",
      "   95 | 01m04s |   -0.15930 |              0.9043 |             0.9417 |    0.4847 |           7.1393 |      1.0000 |             8.1198 |      1124.3548 |      0.1779 |      70.1222 |      0.9978 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00167548]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   96 | 00m59s |   -0.15903 |              0.9967 |             0.8164 |    0.0295 |           6.9159 |      1.0000 |            10.5369 |      1127.6579 |      0.2992 |      84.9246 |      0.9646 | \n",
      "   97 | 01m02s |   -0.15903 |              0.9094 |             0.8184 |    0.0436 |           9.9819 |      1.0000 |             9.5831 |      1132.1921 |      0.2584 |      82.3895 |      0.9082 | \n",
      "   98 | 01m07s |   -0.15606 |              0.9883 |             0.8685 |    0.1324 |           5.3612 |      1.0000 |            10.0174 |      1134.7872 |      0.2966 |      84.5986 |      0.9105 | \n",
      "   99 | 01m06s |   -0.16200 |              0.9945 |             0.8682 |    0.0167 |           0.0068 |      1.0000 |            10.9864 |      1129.0317 |      0.2213 |      71.5112 |      0.9090 | \n",
      "  100 | 01m04s |   -0.15795 |              0.9399 |             0.9380 |    0.7318 |           8.5978 |      1.0000 |             8.0278 |      1131.8512 |      0.2488 |      84.8974 |      0.9372 | \n",
      "  101 | 01m05s |   -0.15849 |              0.9812 |             0.9765 |    0.0395 |           8.4897 |      1.0000 |            10.9900 |      1121.8470 |      0.2785 |      78.3994 |      0.9524 | \n",
      "  102 | 00m59s |   -0.16253 |              0.9750 |             0.9716 |    0.8844 |           8.8218 |      1.0000 |            10.9453 |      1125.1811 |      0.2748 |      81.6007 |      0.9455 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00014904]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00103933]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  103 | 01m03s |   -0.15633 |              0.9669 |             0.9717 |    0.8257 |           9.9370 |      1.0000 |             8.0074 |      1133.3177 |      0.2689 |      77.7783 |      0.9049 | \n",
      "  104 | 01m11s |   -0.15580 |              0.9551 |             0.8081 |    0.0519 |           9.2489 |      1.0000 |            10.8970 |      1122.8423 |      0.0077 |      84.9461 |      0.9513 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00290952]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  105 | 01m08s |   -0.15903 |              0.9032 |             0.9859 |    0.9484 |           9.9201 |      1.0000 |             8.3982 |      1120.1401 |      0.1242 |      73.7462 |      0.9774 | \n",
      "  106 | 01m06s |   -0.15903 |              0.9581 |             0.8396 |    0.0700 |           4.5019 |      1.0000 |            10.9243 |      1134.9235 |      0.1805 |      78.2901 |      0.9830 | \n",
      "2018-06-16 04:44:27,670 - logHandler - train - INFO - Iteration: 5, XGBoost max auc: -0.151750\n",
      "2018-06-16 04:44:27,671 - logHandler - train - INFO - Param max_delta_step: 9.895022882647535\n",
      "2018-06-16 04:44:27,671 - logHandler - train - INFO - Param reg_lambda: 82.8137821058157\n",
      "2018-06-16 04:44:27,672 - logHandler - train - INFO - Param reg_alpha: 0.2943250379887892\n",
      "2018-06-16 04:44:27,673 - logHandler - train - INFO - Param n_estimators: 1123.713161942442\n",
      "2018-06-16 04:44:27,673 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 04:44:27,674 - logHandler - train - INFO - Param subsample: 0.9479068139511281\n",
      "2018-06-16 04:44:27,675 - logHandler - train - INFO - Param min_child_weight: 10.597198885531588\n",
      "2018-06-16 04:44:27,675 - logHandler - train - INFO - Param gamma: 0.0021729922505190347\n",
      "2018-06-16 04:44:27,676 - logHandler - train - INFO - Param colsample_bytree: 0.8091194603441866\n",
      "2018-06-16 04:44:27,677 - logHandler - train - INFO - Param colsample_bylevel: 0.9075078661465273\n",
      "2018-06-16 04:44:27,677 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 04:44:28,567 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 04:44:28,568 - logHandler - train - INFO - Iteration  6, Current random seed:  6\n",
      "2018-06-16 04:44:28,571 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 04:44:28,572 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.16091\u001b[0m | \u001b[32m             0.9858\u001b[0m | \u001b[32m            0.8282\u001b[0m | \u001b[32m   0.0926\u001b[0m | \u001b[32m          8.4855\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.8854\u001b[0m | \u001b[32m     1128.9871\u001b[0m | \u001b[32m     0.1666\u001b[0m | \u001b[32m     83.6761\u001b[0m | \u001b[32m     0.9964\u001b[0m | \n",
      "    2 | 00m02s | \u001b[35m  -0.15471\u001b[0m | \u001b[32m             0.9674\u001b[0m | \u001b[32m            0.9596\u001b[0m | \u001b[32m   0.6336\u001b[0m | \u001b[32m          0.2162\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.1679\u001b[0m | \u001b[32m     1131.5977\u001b[0m | \u001b[32m     0.0405\u001b[0m | \u001b[32m     82.2991\u001b[0m | \u001b[32m     0.9271\u001b[0m | \n",
      "    3 | 00m02s |   -0.16307 |              0.9031 |             0.9909 |    0.0356 |           9.0393 |      1.0000 |             8.1202 |      1127.7416 |      0.2045 |      76.3936 |      0.9841 | \n",
      "    4 | 00m04s | \u001b[35m  -0.15417\u001b[0m | \u001b[32m             0.9330\u001b[0m | \u001b[32m            0.9393\u001b[0m | \u001b[32m   0.1787\u001b[0m | \u001b[32m          4.5050\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.9844\u001b[0m | \u001b[32m     1129.0011\u001b[0m | \u001b[32m     0.2188\u001b[0m | \u001b[32m     72.9420\u001b[0m | \u001b[32m     0.9304\u001b[0m | \n",
      "    5 | 00m02s |   -0.15903 |              0.9292 |             0.9599 |    0.5693 |           3.8319 |      1.0000 |             8.1923 |      1128.5007 |      0.1332 |      75.3226 |      0.9165 | \n",
      "    6 | 00m02s |   -0.15580 |              0.9802 |             0.9299 |    0.3317 |           5.9915 |      1.0000 |            10.8460 |      1131.2543 |      0.1876 |      74.3899 |      0.9989 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m14s |   -0.15876 |              0.9648 |             0.9099 |    0.9174 |           0.2183 |      1.0000 |            10.9547 |      1120.1904 |      0.0726 |      82.5963 |      0.9242 | \n",
      "    8 | 00m15s |   -0.15822 |              0.9335 |             0.9318 |    0.0015 |           0.2369 |      1.0000 |            10.5235 |      1134.9008 |      0.0353 |      70.4318 |      0.9636 | \n",
      "    9 | 00m16s |   -0.15876 |              0.9567 |             0.8046 |    0.9251 |           6.4655 |      1.0000 |            10.9156 |      1120.1074 |      0.2225 |      70.1904 |      0.9343 | \n",
      "   10 | 00m15s |   -0.15579 |              0.9562 |             0.8889 |    0.0004 |           0.7006 |      1.0000 |            10.9759 |      1133.5068 |      0.2829 |      81.5443 |      0.9066 | \n",
      "   11 | 00m17s |   -0.15741 |              0.9047 |             0.9779 |    0.7679 |           0.0477 |      1.0000 |            10.9840 |      1127.6827 |      0.0079 |      71.3269 |      0.9329 | \n",
      "   12 | 00m16s |   -0.15795 |              0.9400 |             0.8241 |    0.5676 |           9.9920 |      1.0000 |            10.7065 |      1134.8070 |      0.2889 |      70.5350 |      0.9232 | \n",
      "   13 | 00m16s |   -0.16145 |              0.9758 |             0.8312 |    0.9940 |           1.1904 |      1.0000 |            10.6769 |      1128.0942 |      0.2469 |      84.4621 |      0.9900 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-8.73875433e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 00m18s |   -0.15849 |              0.9389 |             0.8450 |    0.0264 |           0.7602 |      1.0000 |            10.1118 |      1120.3831 |      0.0444 |      70.0994 |      0.9920 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.76338821e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.64455722e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 00m19s |   -0.15661 |              0.9062 |             0.9905 |    0.0489 |           3.5154 |      1.0000 |             8.1376 |      1134.7958 |      0.2562 |      84.3624 |      0.9617 | \n",
      "   16 | 00m18s |   -0.15795 |              0.9559 |             0.9044 |    0.0466 |           0.6596 |      1.0000 |             8.2235 |      1120.4008 |      0.0432 |      84.5480 |      0.9924 | \n",
      "   17 | 00m18s |   -0.15580 |              0.9353 |             0.8548 |    0.0074 |           8.3244 |      1.0000 |            10.9543 |      1124.5360 |      0.0220 |      70.0225 |      0.9351 | \n",
      "   18 | 00m18s |   -0.15768 |              0.9339 |             0.9190 |    0.0902 |           9.7373 |      1.0000 |            10.7431 |      1120.1045 |      0.1654 |      83.7717 |      0.9034 | \n",
      "   19 | 00m17s |   -0.15741 |              0.9831 |             0.9884 |    0.0059 |           4.0695 |      1.0000 |            10.9725 |      1121.1171 |      0.0442 |      76.2644 |      0.9073 | \n",
      "   20 | 00m17s | \u001b[35m  -0.15364\u001b[0m | \u001b[32m             0.9940\u001b[0m | \u001b[32m            0.8370\u001b[0m | \u001b[32m   0.0962\u001b[0m | \u001b[32m          0.4661\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.0014\u001b[0m | \u001b[32m     1133.2736\u001b[0m | \u001b[32m     0.2804\u001b[0m | \u001b[32m     78.0118\u001b[0m | \u001b[32m     0.9875\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00029652]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 00m18s |   -0.15472 |              0.9126 |             0.8517 |    0.2253 |           0.1291 |      1.0000 |             8.0692 |      1134.5129 |      0.0275 |      81.8176 |      0.9370 | \n",
      "   22 | 00m18s |   -0.15795 |              0.9504 |             0.9757 |    0.2971 |           9.7047 |      1.0000 |            10.7982 |      1134.9061 |      0.2863 |      84.6243 |      0.9249 | \n",
      "   23 | 00m18s |   -0.15930 |              0.9263 |             0.9912 |    0.0426 |           0.0935 |      1.0000 |             8.7610 |      1132.0405 |      0.2920 |      79.9873 |      0.9036 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00012721]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 00m21s |   -0.16172 |              0.9446 |             0.9363 |    0.8490 |           9.9286 |      1.0000 |             8.1639 |      1120.1763 |      0.0326 |      83.7134 |      0.9151 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-4.50683682e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 00m18s |   -0.15633 |              0.9838 |             0.9827 |    0.0803 |           6.9815 |      1.0000 |             8.2079 |      1134.9955 |      0.0018 |      70.1321 |      0.9748 | \n",
      "   26 | 00m19s |   -0.15903 |              0.9990 |             0.8176 |    0.7016 |           9.9450 |      1.0000 |             8.0911 |      1134.9738 |      0.0854 |      84.4688 |      0.9546 | \n",
      "   27 | 00m20s |   -0.15661 |              0.9877 |             0.9448 |    0.8651 |           0.0331 |      1.0000 |            10.9735 |      1134.2197 |      0.2007 |      84.9824 |      0.9415 | \n",
      "   28 | 00m19s |   -0.15849 |              0.9959 |             0.8206 |    0.9814 |           3.5017 |      1.0000 |             8.7908 |      1134.9168 |      0.0052 |      80.8402 |      0.9154 | \n",
      "   29 | 00m19s |   -0.15795 |              0.9958 |             0.8447 |    0.8810 |           0.2005 |      1.0000 |             8.2811 |      1120.0381 |      0.1480 |      76.3401 |      0.9786 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-5.62636706e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 00m19s |   -0.16199 |              0.9918 |             0.8034 |    0.0056 |           9.0107 |      1.0000 |             8.0302 |      1120.1583 |      0.0041 |      74.8364 |      0.9898 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00039219]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 | 00m19s |   -0.15795 |              0.9916 |             0.8150 |    0.5112 |           0.3626 |      1.0000 |             8.0670 |      1130.5483 |      0.0815 |      70.1791 |      0.9029 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([4.91181272e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 00m18s |   -0.15768 |              0.9614 |             0.8069 |    0.3045 |           6.5993 |      1.0000 |            10.9763 |      1129.1697 |      0.0186 |      70.1218 |      0.9932 | \n",
      "   33 | 00m19s |   -0.15606 |              0.9958 |             0.8985 |    0.0121 |           9.9533 |      1.0000 |             8.4446 |      1134.7899 |      0.0049 |      78.4751 |      0.9095 | \n",
      "   34 | 00m20s |   -0.15634 |              0.9543 |             0.8390 |    0.0100 |           0.5719 |      1.0000 |            10.7261 |      1129.8537 |      0.0386 |      73.8288 |      0.9798 | \n",
      "   35 | 00m20s |   -0.15633 |              0.9915 |             0.9540 |    0.8343 |           0.5891 |      1.0000 |             8.0384 |      1134.7162 |      0.2006 |      74.5073 |      0.9466 | \n",
      "   36 | 00m20s |   -0.15876 |              0.9956 |             0.8080 |    0.2509 |           9.8569 |      1.0000 |            10.9968 |      1121.5026 |      0.1508 |      76.8527 |      0.9959 | \n",
      "   37 | 00m21s |   -0.15580 |              0.9486 |             0.8135 |    0.1286 |           0.0022 |      1.0000 |             8.0096 |      1131.0111 |      0.1002 |      84.6136 |      0.9095 | \n",
      "   38 | 00m21s |   -0.16253 |              0.9887 |             0.9743 |    0.0156 |           3.8444 |      1.0000 |            10.9931 |      1124.5634 |      0.2651 |      71.3558 |      0.9880 | \n",
      "   39 | 00m22s |   -0.15768 |              0.9646 |             0.9208 |    0.0279 |           4.4452 |      1.0000 |            10.9550 |      1134.2306 |      0.0035 |      84.7982 |      0.9042 | \n",
      "   40 | 00m27s |   -0.15607 |              0.9221 |             0.8012 |    0.9437 |           3.7609 |      1.0000 |             8.0646 |      1120.1836 |      0.1422 |      84.7924 |      0.9102 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00026443]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 00m23s |   -0.15741 |              0.9048 |             0.9632 |    0.0673 |           9.3493 |      1.0000 |            10.0512 |      1120.3592 |      0.0896 |      70.0278 |      0.9427 | \n",
      "   42 | 00m24s |   -0.16038 |              0.9747 |             0.9479 |    0.0197 |           9.9147 |      1.0000 |             8.2947 |      1134.5850 |      0.0148 |      70.3736 |      0.9451 | \n",
      "   43 | 00m24s |   -0.16227 |              0.9982 |             0.8473 |    0.8762 |           0.1519 |      1.0000 |             8.0836 |      1120.0734 |      0.1361 |      70.2087 |      0.9693 | \n",
      "   44 | 00m24s |   -0.15660 |              0.9046 |             0.8051 |    0.0704 |           4.5547 |      1.0000 |            10.9274 |      1134.4208 |      0.2188 |      71.4877 |      0.9521 | \n",
      "   45 | 00m25s |   -0.15687 |              0.9850 |             0.8750 |    0.0403 |           6.1778 |      1.0000 |             8.3857 |      1120.0686 |      0.0159 |      81.9559 |      0.9829 | \n",
      "   46 | 00m24s |   -0.16064 |              0.9285 |             0.9334 |    0.0030 |           9.9596 |      1.0000 |            10.9147 |      1120.2708 |      0.0454 |      72.4187 |      0.9262 | \n",
      "   47 | 00m23s |   -0.15849 |              0.9857 |             0.8073 |    0.3492 |           4.6799 |      1.0000 |            10.8906 |      1126.9011 |      0.0357 |      77.9255 |      0.9492 | \n",
      "   48 | 00m23s |   -0.15795 |              0.9184 |             0.9307 |    0.9291 |           0.3384 |      1.0000 |            10.9286 |      1120.0094 |      0.0069 |      70.5940 |      0.9115 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00082912]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([7.8943385e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 00m34s |   -0.15768 |              0.9585 |             0.9370 |    0.0416 |           9.9323 |      1.0000 |            10.8505 |      1131.6692 |      0.1020 |      79.7974 |      0.9807 | \n",
      "   50 | 00m40s |   -0.16011 |              0.9050 |             0.9663 |    0.9913 |           6.5294 |      1.0000 |            10.7808 |      1120.2531 |      0.0156 |      83.9025 |      0.9882 | \n",
      "   51 | 00m41s |   -0.15822 |              0.9402 |             0.8574 |    0.0222 |           3.6890 |      1.0000 |             8.0032 |      1134.2424 |      0.2795 |      73.1198 |      0.9373 | \n",
      "   52 | 00m47s |   -0.15957 |              0.9538 |             0.8191 |    0.7665 |           0.0063 |      1.0000 |            10.9471 |      1133.4966 |      0.0064 |      76.7251 |      0.9374 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.4367323e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53 | 00m41s |   -0.15391 |              0.9583 |             0.9726 |    0.0319 |           9.7124 |      1.0000 |            10.9218 |      1134.9598 |      0.2211 |      75.1080 |      0.9660 | \n",
      "   54 | 00m51s |   -0.15822 |              0.9800 |             0.9154 |    0.0851 |           9.7837 |      1.0000 |            10.8800 |      1124.7972 |      0.0624 |      84.9109 |      0.9704 | \n",
      "   55 | 00m48s |   -0.15525 |              0.9877 |             0.8242 |    0.0597 |           9.8211 |      1.0000 |             9.2892 |      1120.1069 |      0.0092 |      84.8711 |      0.9910 | \n",
      "   56 | 00m45s |   -0.15526 |              0.9529 |             0.8336 |    0.9901 |           0.4932 |      1.0000 |             8.0944 |      1132.6600 |      0.1367 |      82.6780 |      0.9921 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00154679]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   57 | 00m48s |   -0.16038 |              0.9879 |             0.9507 |    0.0245 |           9.6138 |      1.0000 |            10.9084 |      1128.4101 |      0.0228 |      72.8083 |      0.9092 | \n",
      "   58 | 00m44s |   -0.15714 |              0.9689 |             0.9332 |    0.0538 |           9.1694 |      1.0000 |            10.9534 |      1134.6666 |      0.0456 |      70.0938 |      0.9084 | \n",
      "   59 | 00m47s | \u001b[35m  -0.15202\u001b[0m | \u001b[32m             0.9652\u001b[0m | \u001b[32m            0.8144\u001b[0m | \u001b[32m   0.6865\u001b[0m | \u001b[32m          1.8296\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.9937\u001b[0m | \u001b[32m     1130.8694\u001b[0m | \u001b[32m     0.0333\u001b[0m | \u001b[32m     70.1891\u001b[0m | \u001b[32m     0.9459\u001b[0m | \n",
      "   60 | 00m47s |   -0.16415 |              0.9472 |             0.8171 |    0.9930 |           0.1115 |      1.0000 |             8.2513 |      1120.3339 |      0.0009 |      81.0506 |      0.9358 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00105555]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   61 | 00m46s |   -0.15903 |              0.9672 |             0.8738 |    0.9880 |           9.9131 |      1.0000 |             8.0947 |      1123.7274 |      0.1106 |      70.1356 |      0.9711 | \n",
      "   62 | 00m48s |   -0.16065 |              0.9875 |             0.8632 |    0.0074 |           1.0923 |      1.0000 |            10.5372 |      1131.6535 |      0.0790 |      84.1722 |      0.9957 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.38773061e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   63 | 00m46s |   -0.15957 |              0.9959 |             0.9710 |    0.1827 |           4.9763 |      1.0000 |             8.0430 |      1124.3734 |      0.0103 |      84.2648 |      0.9915 | \n",
      "   64 | 00m44s |   -0.16038 |              0.9716 |             0.8405 |    0.0240 |           0.2476 |      1.0000 |            10.6084 |      1120.1479 |      0.0108 |      76.0429 |      0.9545 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([7.14114019e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00128014]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   65 | 00m48s |   -0.15553 |              0.9994 |             0.9214 |    0.0049 |           0.2102 |      1.0000 |            10.6950 |      1129.9549 |      0.2469 |      70.3022 |      0.9517 | \n",
      "   66 | 00m56s |   -0.16200 |              0.9994 |             0.9508 |    0.2537 |           2.3632 |      1.0000 |            10.9580 |      1120.0525 |      0.0586 |      84.8263 |      0.9474 | \n",
      "   67 | 00m51s |   -0.16092 |              0.9589 |             0.9521 |    0.0620 |           7.6611 |      1.0000 |             8.3413 |      1120.0663 |      0.2298 |      84.9991 |      0.9013 | \n",
      "   68 | 00m55s |   -0.15688 |              0.9986 |             0.9002 |    0.9793 |           0.0025 |      1.0000 |             9.1173 |      1125.7229 |      0.0729 |      84.9898 |      0.9187 | \n",
      "   69 | 00m49s |   -0.15795 |              0.9944 |             0.8051 |    0.1101 |           9.4669 |      1.0000 |            10.8606 |      1134.6944 |      0.0429 |      80.7623 |      0.9406 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00023533]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   70 | 00m50s |   -0.15741 |              0.9983 |             0.8011 |    0.8706 |           3.9046 |      1.0000 |             9.4978 |      1120.0602 |      0.1856 |      76.4001 |      0.9802 | \n",
      "   71 | 00m54s |   -0.16685 |              0.9598 |             0.9744 |    0.3182 |           0.0172 |      1.0000 |             8.3184 |      1134.9698 |      0.0025 |      84.9007 |      0.9978 | \n",
      "   72 | 00m54s |   -0.16146 |              0.9839 |             0.9150 |    0.0395 |           4.1014 |      1.0000 |             8.0881 |      1120.1134 |      0.0424 |      72.2114 |      0.9926 | \n",
      "   73 | 00m53s |   -0.15930 |              0.9188 |             0.9114 |    0.0056 |           8.2957 |      1.0000 |             8.0251 |      1133.7211 |      0.0960 |      84.9538 |      0.9495 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00064188]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 | 00m57s |   -0.15876 |              0.9735 |             0.8501 |    0.9371 |           9.6548 |      1.0000 |            10.8416 |      1126.1356 |      0.0124 |      80.5049 |      0.9013 | \n",
      "   75 | 00m51s |   -0.15714 |              0.9671 |             0.9434 |    0.0679 |           0.2258 |      1.0000 |             8.0123 |      1134.6210 |      0.0755 |      70.1336 |      0.9593 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00043961]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00116783]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   76 | 00m53s |   -0.16038 |              0.9532 |             0.9513 |    0.9582 |           0.1981 |      1.0000 |            10.9369 |      1134.8718 |      0.2917 |      81.9788 |      0.9971 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([8.04945412e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   77 | 00m56s |   -0.16253 |              0.9326 |             0.8269 |    0.8564 |           9.9763 |      1.0000 |            10.9945 |      1124.2399 |      0.1142 |      70.1143 |      0.9862 | \n",
      "   78 | 00m59s |   -0.15553 |              0.9608 |             0.9547 |    0.0612 |           9.9632 |      1.0000 |             8.0906 |      1124.0974 |      0.0429 |      84.8482 |      0.9265 | \n",
      "   79 | 00m55s |   -0.15444 |              0.9849 |             0.9126 |    0.8123 |           0.1173 |      1.0000 |            10.0706 |      1120.1611 |      0.0937 |      84.9649 |      0.9072 | \n",
      "   80 | 00m56s |   -0.15768 |              0.9876 |             0.8161 |    0.0451 |           9.8205 |      1.0000 |             8.0624 |      1121.0078 |      0.0148 |      70.1131 |      0.9795 | \n",
      "   81 | 00m54s |   -0.15741 |              0.9150 |             0.8139 |    0.0088 |           0.1736 |      1.0000 |             8.0621 |      1134.8616 |      0.2569 |      76.8670 |      0.9239 | \n",
      "   82 | 00m57s |   -0.15311 |              0.9991 |             0.8562 |    0.0536 |           7.5543 |      1.0000 |             8.1089 |      1125.3961 |      0.0133 |      70.0535 |      0.9733 | \n",
      "   83 | 00m57s |   -0.15498 |              0.9921 |             0.8032 |    0.0208 |           2.8260 |      1.0000 |             8.0415 |      1133.7397 |      0.0325 |      82.2277 |      0.9554 | \n",
      "   84 | 00m53s |   -0.15634 |              0.9835 |             0.9946 |    0.8582 |           4.0266 |      1.0000 |            10.9968 |      1133.6391 |      0.2677 |      70.1841 |      0.9762 | \n",
      "   85 | 00m52s |   -0.15499 |              0.9703 |             0.8056 |    0.8799 |           0.3893 |      1.0000 |             8.0054 |      1131.8546 |      0.0224 |      75.8359 |      0.9065 | \n",
      "   86 | 00m57s |   -0.15579 |              0.9869 |             0.8934 |    0.9659 |           6.0255 |      1.0000 |             8.8808 |      1124.3037 |      0.0004 |      75.3375 |      0.9199 | \n",
      "   87 | 01m00s |   -0.16118 |              0.9849 |             0.9632 |    0.8357 |           2.2480 |      1.0000 |            10.9963 |      1130.0933 |      0.0630 |      73.0359 |      0.9037 | \n",
      "   88 | 00m56s |   -0.15822 |              0.9970 |             0.8086 |    0.9540 |           0.5219 |      1.0000 |             9.2613 |      1134.7733 |      0.0042 |      70.0695 |      0.9710 | \n",
      "   89 | 00m54s |   -0.15606 |              0.9690 |             0.8206 |    0.9238 |           0.1182 |      1.0000 |             8.2317 |      1123.8926 |      0.0631 |      74.4359 |      0.9924 | \n",
      "   90 | 01m00s |   -0.15714 |              0.9925 |             0.8029 |    0.0691 |           5.3772 |      1.0000 |             8.0602 |      1122.9088 |      0.0484 |      77.1425 |      0.9359 | \n",
      "   91 | 00m57s |   -0.15714 |              0.9135 |             0.8117 |    0.2850 |           7.0856 |      1.0000 |            10.7774 |      1126.4797 |      0.0004 |      74.0761 |      0.9908 | \n",
      "   92 | 00m58s |   -0.15903 |              0.9871 |             0.8168 |    0.2713 |           6.9079 |      1.0000 |            10.9354 |      1120.3496 |      0.0426 |      78.7788 |      0.9291 | \n",
      "   93 | 00m54s |   -0.15579 |              0.9872 |             0.8150 |    0.8052 |           0.0316 |      1.0000 |            10.9647 |      1127.5596 |      0.0369 |      82.5290 |      0.9223 | \n",
      "   94 | 01m06s |   -0.15606 |              0.9314 |             0.8083 |    0.0117 |           2.9159 |      1.0000 |             8.7296 |      1131.0004 |      0.0189 |      70.0015 |      0.9534 | \n",
      "   95 | 01m00s |   -0.15822 |              0.9812 |             0.9378 |    0.9793 |           9.5859 |      1.0000 |             8.0340 |      1134.8675 |      0.0286 |      74.2921 |      0.9522 | \n",
      "   96 | 00m59s |   -0.15499 |              0.9039 |             0.9943 |    0.2617 |           6.6493 |      1.0000 |             8.0013 |      1134.9354 |      0.2799 |      78.7803 |      0.9582 | \n",
      "   97 | 00m58s |   -0.15795 |              0.9600 |             0.8534 |    0.9891 |           0.0106 |      1.0000 |            10.8629 |      1123.8549 |      0.0389 |      76.8822 |      0.9888 | \n",
      "   98 | 01m04s |   -0.16172 |              0.9805 |             0.9974 |    0.9012 |           9.6106 |      1.0000 |             8.0197 |      1127.9444 |      0.1213 |      84.7960 |      0.9938 | \n",
      "   99 | 01m05s |   -0.15984 |              0.9867 |             0.9772 |    0.4746 |           7.8255 |      1.0000 |             8.0806 |      1134.6527 |      0.2903 |      82.3283 |      0.9567 | \n",
      "  100 | 01m02s |   -0.15984 |              0.9914 |             0.8539 |    0.0295 |           9.9805 |      1.0000 |             9.2560 |      1123.0823 |      0.0474 |      81.7690 |      0.9965 | \n",
      "  101 | 01m01s |   -0.15903 |              0.9125 |             0.8728 |    0.9852 |           0.1880 |      1.0000 |            10.8185 |      1132.1812 |      0.0204 |      83.3176 |      0.9008 | \n",
      "  102 | 01m06s |   -0.15499 |              0.9534 |             0.8163 |    0.0312 |           0.3056 |      1.0000 |            10.9186 |      1125.6554 |      0.0330 |      70.0259 |      0.9412 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.30296282e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00040287]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  103 | 01m05s |   -0.15849 |              0.9740 |             0.8163 |    0.8052 |           0.5880 |      1.0000 |             8.1758 |      1128.8177 |      0.0457 |      81.8084 |      0.9838 | \n",
      "  104 | 01m07s |   -0.16010 |              0.9865 |             0.9699 |    0.2997 |           3.0331 |      1.0000 |             8.0785 |      1134.9307 |      0.0627 |      77.0799 |      0.9142 | \n",
      "  105 | 01m04s |   -0.15526 |              0.9817 |             0.8222 |    0.0928 |           8.3624 |      1.0000 |             8.0297 |      1133.5994 |      0.2708 |      76.4686 |      0.9243 | \n",
      "  106 | 01m09s |   -0.15606 |              0.9585 |             0.9035 |    0.8875 |           6.5617 |      1.0000 |             8.0545 |      1122.0900 |      0.0138 |      70.3674 |      0.9360 | \n",
      "2018-06-16 05:52:30,852 - logHandler - train - INFO - Iteration: 6, XGBoost max auc: -0.152021\n",
      "2018-06-16 05:52:30,854 - logHandler - train - INFO - Param max_delta_step: 1.8296132402798893\n",
      "2018-06-16 05:52:30,855 - logHandler - train - INFO - Param reg_lambda: 70.18914987242893\n",
      "2018-06-16 05:52:30,856 - logHandler - train - INFO - Param reg_alpha: 0.033271279755363016\n",
      "2018-06-16 05:52:30,858 - logHandler - train - INFO - Param n_estimators: 1130.869426749267\n",
      "2018-06-16 05:52:30,859 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 05:52:30,860 - logHandler - train - INFO - Param subsample: 0.9459456312758112\n",
      "2018-06-16 05:52:30,862 - logHandler - train - INFO - Param min_child_weight: 10.993709916137018\n",
      "2018-06-16 05:52:30,863 - logHandler - train - INFO - Param gamma: 0.686478168527857\n",
      "2018-06-16 05:52:30,864 - logHandler - train - INFO - Param colsample_bytree: 0.8144324847877015\n",
      "2018-06-16 05:52:30,866 - logHandler - train - INFO - Param colsample_bylevel: 0.9651785575702245\n",
      "2018-06-16 05:52:30,867 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 05:52:31,796 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 05:52:31,798 - logHandler - train - INFO - Iteration  7, Current random seed:  7\n",
      "2018-06-16 05:52:31,800 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 05:52:31,802 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.15903\u001b[0m | \u001b[32m             0.9114\u001b[0m | \u001b[32m            0.9125\u001b[0m | \u001b[32m   0.8713\u001b[0m | \u001b[32m          5.1632\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.6555\u001b[0m | \u001b[32m     1127.8569\u001b[0m | \u001b[32m     0.0037\u001b[0m | \u001b[32m     82.1640\u001b[0m | \u001b[32m     0.9685\u001b[0m | \n",
      "    2 | 00m01s | \u001b[35m  -0.15876\u001b[0m | \u001b[32m             0.9361\u001b[0m | \u001b[32m            0.8672\u001b[0m | \u001b[32m   0.4835\u001b[0m | \u001b[32m          0.4057\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.8206\u001b[0m | \u001b[32m     1127.7797\u001b[0m | \u001b[32m     0.0448\u001b[0m | \u001b[32m     72.8354\u001b[0m | \u001b[32m     0.9967\u001b[0m | \n",
      "    3 | 00m01s |   -0.16307 |              0.9419 |             0.8093 |    0.3642 |           2.1253 |      1.0000 |             8.2735 |      1121.0007 |      0.1963 |      76.5476 |      0.9092 | \n",
      "    4 | 00m02s | \u001b[35m  -0.15741\u001b[0m | \u001b[32m             0.9539\u001b[0m | \u001b[32m            0.8741\u001b[0m | \u001b[32m   0.5196\u001b[0m | \u001b[32m          5.0421\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.3334\u001b[0m | \u001b[32m     1127.0047\u001b[0m | \u001b[32m     0.0941\u001b[0m | \u001b[32m     81.3760\u001b[0m | \u001b[32m     0.9312\u001b[0m | \n",
      "    5 | 00m02s | \u001b[35m  -0.15553\u001b[0m | \u001b[32m             0.9299\u001b[0m | \u001b[32m            0.8058\u001b[0m | \u001b[32m   0.3115\u001b[0m | \u001b[32m          6.5455\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.7939\u001b[0m | \u001b[32m     1127.8449\u001b[0m | \u001b[32m     0.1578\u001b[0m | \u001b[32m     73.6569\u001b[0m | \u001b[32m     0.9026\u001b[0m | \n",
      "    6 | 00m02s |   -0.15687 |              0.9416 |             0.9187 |    0.1880 |           1.7694 |      1.0000 |             9.0349 |      1133.2360 |      0.2317 |      70.4838 |      0.9334 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.13350429e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m16s |   -0.15903 |              0.9333 |             0.9876 |    0.7318 |           9.6984 |      1.0000 |            10.9286 |      1134.5746 |      0.2547 |      70.4317 |      0.9863 | \n",
      "    8 | 00m16s |   -0.15768 |              0.9558 |             0.8603 |    0.0655 |           9.6795 |      1.0000 |            10.5595 |      1134.6635 |      0.1180 |      84.8198 |      0.9881 | \n",
      "    9 | 00m17s |   -0.15984 |              0.9711 |             0.8183 |    0.0163 |           9.9807 |      1.0000 |            10.9134 |      1121.1453 |      0.0522 |      84.8277 |      0.9433 | \n",
      "   10 | 00m18s |   -0.15687 |              0.9938 |             0.8340 |    0.0520 |           0.2472 |      1.0000 |            10.3286 |      1134.6709 |      0.0360 |      83.9165 |      0.9281 | \n",
      "   11 | 00m18s |   -0.15957 |              0.9986 |             0.9652 |    0.0201 |           9.3927 |      1.0000 |             8.4875 |      1130.7954 |      0.0097 |      75.6763 |      0.9205 | \n",
      "   12 | 00m16s |   -0.15903 |              0.9339 |             0.9551 |    0.5613 |           9.7770 |      1.0000 |            10.9477 |      1121.7445 |      0.2581 |      70.1888 |      0.9494 | \n",
      "   13 | 00m17s |   -0.16146 |              0.9866 |             0.8294 |    0.9919 |           3.4106 |      1.0000 |            10.5616 |      1133.9596 |      0.2960 |      77.7565 |      0.9433 | \n",
      "   14 | 00m18s | \u001b[35m  -0.15445\u001b[0m | \u001b[32m             0.9137\u001b[0m | \u001b[32m            0.8609\u001b[0m | \u001b[32m   0.0011\u001b[0m | \u001b[32m          1.0468\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.9368\u001b[0m | \u001b[32m     1126.7998\u001b[0m | \u001b[32m     0.2920\u001b[0m | \u001b[32m     84.9791\u001b[0m | \u001b[32m     0.9312\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00023185]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 00m17s |   -0.15822 |              0.9014 |             0.8413 |    0.0985 |           5.7372 |      1.0000 |            10.6795 |      1127.5760 |      0.0334 |      70.0026 |      0.9099 | \n",
      "   16 | 00m18s |   -0.16253 |              0.9700 |             0.8629 |    0.8351 |           9.9263 |      1.0000 |             8.0036 |      1127.9245 |      0.0325 |      70.0382 |      0.9970 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.60153575e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 00m18s |   -0.15661 |              0.9797 |             0.8110 |    0.3896 |           9.8778 |      1.0000 |             8.0282 |      1126.1368 |      0.2808 |      83.9100 |      0.9721 | \n",
      "   18 | 00m17s |   -0.15741 |              0.9925 |             0.8526 |    0.3784 |           0.0335 |      1.0000 |             8.0043 |      1134.4995 |      0.2369 |      84.5445 |      0.9940 | \n",
      "   19 | 00m18s |   -0.16199 |              0.9104 |             0.9702 |    0.0121 |           9.9719 |      1.0000 |            10.9585 |      1128.4197 |      0.2403 |      82.6011 |      0.9598 | \n",
      "   20 | 00m18s |   -0.16254 |              0.9482 |             0.8911 |    0.0189 |           9.8556 |      1.0000 |             8.0978 |      1120.7286 |      0.2421 |      78.7960 |      0.9793 | \n",
      "   21 | 00m18s |   -0.15768 |              0.9368 |             0.8231 |    0.7822 |           0.5507 |      1.0000 |            10.7278 |      1122.0911 |      0.2891 |      84.8000 |      0.9170 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.53197952e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([5.47010904e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 00m18s |   -0.15526 |              0.9352 |             0.8262 |    0.1410 |           7.5972 |      1.0000 |             8.1455 |      1134.9561 |      0.2937 |      70.5121 |      0.9323 | \n",
      "   23 | 00m20s |   -0.15526 |              0.9532 |             0.9112 |    0.0058 |           5.9131 |      1.0000 |             8.0359 |      1134.9898 |      0.0799 |      84.9030 |      0.9389 | \n",
      "   24 | 00m17s |   -0.15660 |              0.9779 |             0.8076 |    0.0563 |           0.8030 |      1.0000 |            10.2553 |      1134.6147 |      0.1485 |      70.3831 |      0.9185 | \n",
      "   25 | 00m18s |   -0.16307 |              0.9841 |             0.8377 |    0.5203 |           9.8555 |      1.0000 |             8.1353 |      1134.8367 |      0.1976 |      84.8453 |      0.9257 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([9.39142374e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 00m20s |   -0.16091 |              0.9786 |             0.8534 |    0.4085 |           4.8626 |      1.0000 |             8.2841 |      1120.2601 |      0.2506 |      84.9325 |      0.9771 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-8.46327093e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   27 | 00m18s |   -0.16280 |              0.9990 |             0.8028 |    0.6965 |           0.7208 |      1.0000 |            10.7539 |      1120.6106 |      0.1885 |      70.0101 |      0.9010 | \n",
      "   28 | 00m19s |   -0.15607 |              0.9680 |             0.8538 |    0.0098 |           4.2367 |      1.0000 |            10.0521 |      1131.5623 |      0.2688 |      84.8397 |      0.9971 | \n",
      "   29 | 00m20s |   -0.15580 |              0.9307 |             0.8045 |    0.0151 |           1.1182 |      1.0000 |             8.0630 |      1134.6912 |      0.1627 |      76.2885 |      0.9486 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-4.18569689e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 00m20s |   -0.15742 |              0.9742 |             0.8022 |    0.0168 |           6.1202 |      1.0000 |            10.0142 |      1134.4423 |      0.1815 |      73.4547 |      0.9983 | \n",
      "   31 | 00m17s |   -0.16199 |              0.9159 |             0.8246 |    0.1696 |           0.1007 |      1.0000 |             8.2035 |      1129.3088 |      0.2677 |      70.3657 |      0.9074 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-6.89308381e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 00m20s |   -0.16011 |              0.9721 |             0.8634 |    0.9888 |           2.4643 |      1.0000 |             8.0486 |      1134.5669 |      0.1072 |      70.1436 |      0.9543 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00039463]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 47, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 00m19s |   -0.15580 |              0.9391 |             0.9910 |    0.8016 |           4.9785 |      1.0000 |            10.8377 |      1123.7322 |      0.2973 |      74.3468 |      0.9716 | \n",
      "   34 | 00m19s |   -0.16146 |              0.9784 |             0.9906 |    0.0528 |           5.2984 |      1.0000 |             8.1456 |      1126.2573 |      0.2983 |      76.5841 |      0.9371 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00017372]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 00m19s |   -0.15633 |              0.9551 |             0.8344 |    0.9828 |           9.7796 |      1.0000 |            10.9890 |      1123.2232 |      0.2941 |      74.6268 |      0.9286 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([8.83762841e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 | 00m22s |   -0.15741 |              0.9211 |             0.8647 |    0.9475 |           1.5030 |      1.0000 |            10.9553 |      1120.3488 |      0.2230 |      77.2999 |      0.9003 | \n",
      "   37 | 00m20s |   -0.16173 |              0.9738 |             0.8203 |    0.9497 |           5.5987 |      1.0000 |            10.7368 |      1120.7144 |      0.0045 |      72.2897 |      0.9180 | \n",
      "   38 | 00m22s |   -0.16253 |              0.9135 |             0.8351 |    0.7977 |           9.4865 |      1.0000 |             8.6386 |      1121.8835 |      0.2256 |      84.9547 |      0.9098 | \n",
      "   39 | 00m23s |   -0.16038 |              0.9025 |             0.8207 |    0.1052 |           5.5439 |      1.0000 |             9.6651 |      1124.0806 |      0.0778 |      84.9444 |      0.9018 | \n",
      "   40 | 00m22s |   -0.15796 |              0.9203 |             0.8108 |    0.1116 |           0.5549 |      1.0000 |             8.6517 |      1120.1197 |      0.1981 |      84.8615 |      0.9640 | \n",
      "   41 | 00m21s |   -0.15903 |              0.9886 |             0.8003 |    0.0010 |           9.9356 |      1.0000 |            10.5636 |      1131.2653 |      0.2010 |      70.8926 |      0.9814 | \n",
      "   42 | 00m22s |   -0.15687 |              0.9181 |             0.8135 |    0.1335 |           0.0176 |      1.0000 |            10.8271 |      1127.5547 |      0.1284 |      79.5686 |      0.9236 | \n",
      "   43 | 00m23s |   -0.15606 |              0.9199 |             0.8113 |    0.0057 |           5.9598 |      1.0000 |             8.1325 |      1134.9161 |      0.2936 |      81.0487 |      0.9460 | \n",
      "   44 | 00m23s |   -0.15957 |              0.9377 |             0.8160 |    0.9571 |           2.1777 |      1.0000 |            10.9710 |      1128.9050 |      0.2721 |      70.6983 |      0.9753 | \n",
      "   45 | 00m23s |   -0.15472 |              0.9920 |             0.8120 |    0.9469 |           0.4004 |      1.0000 |             8.0960 |      1123.3180 |      0.2805 |      82.4057 |      0.9408 | \n",
      "   46 | 00m25s |   -0.15822 |              0.9588 |             0.8085 |    0.0350 |           0.6020 |      1.0000 |             9.9929 |      1121.8023 |      0.2745 |      80.9974 |      0.9976 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00013573]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   47 | 00m24s |   -0.15741 |              0.9728 |             0.8901 |    0.0094 |           0.1628 |      1.0000 |             8.0665 |      1129.1674 |      0.0390 |      84.8339 |      0.9205 | \n",
      "   48 | 00m24s |   -0.15984 |              0.9991 |             0.9338 |    0.0231 |           4.5381 |      1.0000 |            10.8354 |      1134.9839 |      0.2449 |      84.7845 |      0.9901 | \n",
      "   49 | 00m36s |   -0.15633 |              0.9560 |             0.8000 |    0.0906 |           7.8373 |      1.0000 |             8.1482 |      1130.0732 |      0.2414 |      84.6110 |      0.9198 | \n",
      "   50 | 00m40s |   -0.15606 |              0.9090 |             0.8004 |    0.0873 |           0.8342 |      1.0000 |             9.0656 |      1134.1054 |      0.0395 |      81.1113 |      0.9875 | \n",
      "   51 | 00m38s |   -0.15714 |              0.9151 |             0.8154 |    0.9577 |           0.1108 |      1.0000 |             9.7302 |      1124.0061 |      0.2874 |      76.7536 |      0.9903 | \n",
      "   52 | 00m42s |   -0.15984 |              0.9063 |             0.8138 |    0.9613 |           5.2518 |      1.0000 |            10.9472 |      1127.0781 |      0.0119 |      74.8424 |      0.9886 | \n",
      "   53 | 00m41s |   -0.15984 |              0.9799 |             0.8100 |    0.0042 |           9.2094 |      1.0000 |            10.7002 |      1124.3385 |      0.2714 |      72.6754 |      0.9050 | \n",
      "   54 | 00m45s |   -0.15795 |              0.9806 |             0.8960 |    0.8809 |           9.9096 |      1.0000 |            10.8984 |      1120.4114 |      0.2930 |      79.3886 |      0.9863 | \n",
      "   55 | 00m46s | \u001b[35m  -0.15364\u001b[0m | \u001b[32m             0.9839\u001b[0m | \u001b[32m            0.9754\u001b[0m | \u001b[32m   0.9975\u001b[0m | \u001b[32m          6.9802\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.4614\u001b[0m | \u001b[32m     1126.3924\u001b[0m | \u001b[32m     0.2704\u001b[0m | \u001b[32m     71.1725\u001b[0m | \u001b[32m     0.9005\u001b[0m | \n",
      "   56 | 00m49s |   -0.15498 |              0.9723 |             0.9370 |    0.0467 |           0.0349 |      1.0000 |            10.9142 |      1134.7110 |      0.2404 |      76.1202 |      0.9982 | \n",
      "   57 | 00m43s |   -0.15795 |              0.9389 |             0.9860 |    0.8237 |           6.7841 |      1.0000 |             9.2005 |      1131.7440 |      0.2996 |      70.8246 |      0.9048 | \n",
      "   58 | 00m48s | \u001b[35m  -0.15283\u001b[0m | \u001b[32m             0.9611\u001b[0m | \u001b[32m            0.8253\u001b[0m | \u001b[32m   0.0522\u001b[0m | \u001b[32m          9.9580\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.6695\u001b[0m | \u001b[32m     1134.7443\u001b[0m | \u001b[32m     0.2521\u001b[0m | \u001b[32m     71.6911\u001b[0m | \u001b[32m     0.9386\u001b[0m | \n",
      "   59 | 00m48s |   -0.16280 |              0.9704 |             0.9141 |    0.9856 |           9.8299 |      1.0000 |             8.6009 |      1120.1692 |      0.2902 |      70.9150 |      0.9196 | \n",
      "   60 | 00m45s |   -0.15741 |              0.9065 |             0.9451 |    0.9955 |           3.9054 |      1.0000 |             9.4690 |      1125.2182 |      0.2807 |      71.0119 |      0.9556 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([8.63740936e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   61 | 00m45s |   -0.15795 |              0.9324 |             0.8698 |    0.0789 |           0.0586 |      1.0000 |             9.2283 |      1134.9188 |      0.0342 |      72.9657 |      0.9268 | \n",
      "   62 | 00m47s |   -0.15715 |              0.9838 |             0.9538 |    0.0128 |           0.2879 |      1.0000 |            10.1091 |      1131.6941 |      0.2723 |      77.3985 |      0.9216 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00025435]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   63 | 00m48s |   -0.15795 |              0.9642 |             0.8220 |    0.1168 |           9.9059 |      1.0000 |             9.2251 |      1134.9423 |      0.2718 |      78.1029 |      0.9748 | \n",
      "   64 | 00m48s |   -0.15606 |              0.9934 |             0.8204 |    0.1440 |           0.6154 |      1.0000 |            10.9846 |      1122.5751 |      0.2965 |      73.7004 |      0.9248 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0014465]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   65 | 00m50s |   -0.15579 |              0.9931 |             0.8101 |    0.0111 |           9.2910 |      1.0000 |             9.7325 |      1134.7688 |      0.0175 |      70.1583 |      0.9804 | \n",
      "   66 | 00m54s |   -0.15525 |              0.9954 |             0.8453 |    0.0092 |           3.9901 |      1.0000 |             8.2962 |      1127.5558 |      0.2396 |      83.5861 |      0.9988 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0003281]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   67 | 00m48s |   -0.15633 |              0.9878 |             0.9124 |    0.0429 |           0.2399 |      1.0000 |            10.9704 |      1126.4717 |      0.2523 |      84.7546 |      0.9789 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00051656]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   68 | 00m50s |   -0.15633 |              0.9912 |             0.8876 |    0.1668 |           0.0100 |      1.0000 |            10.5889 |      1134.9296 |      0.2909 |      78.9987 |      0.9191 | \n",
      "   69 | 00m44s |   -0.16361 |              0.9165 |             0.8226 |    0.7335 |           0.1143 |      1.0000 |             8.2968 |      1124.2286 |      0.0189 |      84.9616 |      0.9398 | \n",
      "   70 | 00m50s |   -0.15580 |              0.9977 |             0.9943 |    0.7688 |           0.8356 |      1.0000 |             8.4913 |      1120.0601 |      0.2631 |      82.2260 |      0.9126 | \n",
      "   71 | 00m51s |   -0.15633 |              0.9742 |             0.8271 |    0.0782 |           2.7726 |      1.0000 |             8.0799 |      1132.4765 |      0.2692 |      83.0707 |      0.9158 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.000785]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   72 | 00m50s |   -0.15957 |              0.9118 |             0.8049 |    0.0338 |           0.4620 |      1.0000 |             9.3520 |      1130.4483 |      0.2989 |      83.5262 |      0.9473 | \n",
      "   73 | 00m52s |   -0.15795 |              0.9428 |             0.8460 |    0.6744 |           9.2595 |      1.0000 |             8.0495 |      1134.9873 |      0.0368 |      72.8091 |      0.9222 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00048087]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 | 00m54s |   -0.15418 |              0.9960 |             0.9405 |    0.1912 |           5.3749 |      1.0000 |             8.0270 |      1129.6272 |      0.2775 |      71.7887 |      0.9317 | \n",
      "   75 | 00m54s |   -0.15768 |              0.9220 |             0.9965 |    0.7609 |           9.9106 |      1.0000 |            10.8908 |      1120.1008 |      0.2607 |      73.7731 |      0.9135 | \n",
      "   76 | 00m52s |   -0.16307 |              0.9266 |             0.8442 |    0.0579 |           1.9339 |      1.0000 |             8.0932 |      1134.8884 |      0.1575 |      84.8906 |      0.9328 | \n",
      "   77 | 00m54s |   -0.16388 |              0.9861 |             0.9652 |    0.9488 |           0.6443 |      1.0000 |             8.0576 |      1134.8891 |      0.2025 |      80.3149 |      0.9247 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00166899]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   78 | 00m55s |   -0.16037 |              0.9198 |             0.9168 |    0.0978 |           1.7559 |      1.0000 |            10.8633 |      1120.0907 |      0.2975 |      84.8577 |      0.9350 | \n",
      "   79 | 00m57s |   -0.15580 |              0.9375 |             0.8153 |    0.8724 |           9.9946 |      1.0000 |            10.7071 |      1125.1563 |      0.2585 |      84.8309 |      0.9217 | \n",
      "   80 | 00m53s |   -0.16011 |              0.9934 |             0.9602 |    0.8141 |           2.7010 |      1.0000 |            10.9933 |      1125.2967 |      0.2908 |      81.9941 |      0.9245 | \n",
      "   81 | 00m57s |   -0.16334 |              0.9582 |             0.8279 |    0.8955 |           9.7847 |      1.0000 |             8.4378 |      1125.7129 |      0.2880 |      79.7724 |      0.9933 | \n",
      "   82 | 00m59s |   -0.15471 |              0.9834 |             0.8112 |    0.0111 |           7.2284 |      1.0000 |             9.6503 |      1133.3282 |      0.1132 |      83.0173 |      0.9170 | \n",
      "   83 | 00m53s |   -0.16010 |              0.9243 |             0.8027 |    0.9918 |           0.4849 |      1.0000 |            10.8548 |      1120.0011 |      0.2356 |      73.6047 |      0.9752 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00049197]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   84 | 00m51s |   -0.16011 |              0.9568 |             0.9616 |    0.9104 |           0.0265 |      1.0000 |            10.9795 |      1124.8976 |      0.2765 |      70.4295 |      0.9769 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00071021]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   85 | 00m53s |   -0.16011 |              0.9297 |             0.8155 |    0.0157 |           0.1630 |      1.0000 |             8.0637 |      1127.1468 |      0.2922 |      80.4868 |      0.9124 | \n",
      "   86 | 01m03s |   -0.16119 |              0.9448 |             0.8237 |    0.9866 |           6.2021 |      1.0000 |             8.1189 |      1120.7899 |      0.2655 |      79.0592 |      0.9527 | \n",
      "   87 | 00m56s |   -0.15741 |              0.9997 |             0.8010 |    0.0881 |           5.2927 |      1.0000 |             8.1527 |      1132.6805 |      0.1508 |      79.3491 |      0.9395 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00133648]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   88 | 00m55s |   -0.15876 |              0.9552 |             0.8000 |    0.7897 |           9.8910 |      1.0000 |             8.0167 |      1134.5274 |      0.2907 |      70.0297 |      0.9776 | \n",
      "   89 | 00m57s |   -0.16038 |              0.9941 |             0.9084 |    0.1589 |           7.9751 |      1.0000 |            10.2950 |      1127.4630 |      0.2803 |      84.9390 |      0.9307 | \n",
      "   90 | 01m01s |   -0.16065 |              0.9463 |             0.8283 |    0.0543 |           9.9519 |      1.0000 |            10.9123 |      1134.5444 |      0.2092 |      73.7193 |      0.9218 | \n",
      "   91 | 01m01s |   -0.15445 |              0.9846 |             0.9595 |    0.0557 |           2.4290 |      1.0000 |             8.1344 |      1134.7471 |      0.2904 |      70.0909 |      0.9991 | \n",
      "   92 | 00m57s |   -0.15688 |              0.9882 |             0.9948 |    0.0178 |           3.7399 |      1.0000 |            10.9496 |      1134.8905 |      0.0978 |      70.7116 |      0.9244 | \n",
      "   93 | 00m59s |   -0.15795 |              0.9910 |             0.8488 |    0.4939 |           0.1085 |      1.0000 |            10.8782 |      1127.1655 |      0.2624 |      75.0712 |      0.9079 | \n",
      "   94 | 01m03s |   -0.15687 |              0.9563 |             0.9636 |    0.0212 |           7.0558 |      1.0000 |             8.2028 |      1133.7222 |      0.0998 |      84.7936 |      0.9966 | \n",
      "   95 | 01m01s |   -0.15876 |              0.9974 |             0.8573 |    0.0081 |           3.8345 |      1.0000 |             8.2545 |      1134.6858 |      0.1106 |      72.8837 |      0.9393 | \n",
      "   96 | 00m59s |   -0.15768 |              0.9537 |             0.8179 |    0.0523 |           9.9541 |      1.0000 |             9.2723 |      1122.9786 |      0.2782 |      82.6433 |      0.9175 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00072865]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   97 | 01m05s |   -0.15984 |              0.9791 |             0.9846 |    0.3011 |           6.7890 |      1.0000 |             8.0877 |      1126.2421 |      0.2964 |      71.0443 |      1.0000 | \n",
      "   98 | 01m05s |   -0.16038 |              0.9005 |             0.9371 |    0.9836 |           9.2142 |      1.0000 |            10.8307 |      1126.0603 |      0.2627 |      70.7877 |      0.9103 | \n",
      "   99 | 01m03s |   -0.15526 |              0.9749 |             0.8057 |    0.0204 |           3.6363 |      1.0000 |            10.9667 |      1134.8522 |      0.0894 |      78.5474 |      0.9845 | \n",
      "  100 | 01m05s |   -0.16065 |              0.9824 |             0.9698 |    0.0051 |           9.9705 |      1.0000 |             8.0163 |      1133.0177 |      0.2605 |      71.8912 |      0.9774 | \n",
      "  101 | 01m07s |   -0.16146 |              0.9878 |             0.9074 |    0.9586 |           5.3719 |      1.0000 |             9.5348 |      1129.1311 |      0.2913 |      70.0490 |      0.9850 | \n",
      "  102 | 01m08s |   -0.16037 |              0.9302 |             0.9549 |    0.0376 |           3.7043 |      1.0000 |            10.7576 |      1129.8831 |      0.2849 |      73.2649 |      0.9012 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00013049]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  103 | 01m08s |   -0.15606 |              0.9826 |             0.9311 |    0.9364 |           2.4482 |      1.0000 |            10.9176 |      1122.4409 |      0.0080 |      74.3003 |      0.9118 | \n",
      "  104 | 01m05s |   -0.15768 |              0.9690 |             0.8327 |    0.8788 |           3.1665 |      1.0000 |             8.0481 |      1123.1159 |      0.2438 |      81.0083 |      0.9032 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00037043]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  105 | 01m06s |   -0.16065 |              0.9929 |             0.9044 |    0.9091 |           0.1191 |      1.0000 |            10.7803 |      1120.4368 |      0.2609 |      79.6579 |      0.9162 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00076862]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00039091]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  106 | 01m03s |   -0.15687 |              0.9902 |             0.8081 |    0.0803 |           4.2014 |      1.0000 |            10.6231 |      1125.3963 |      0.1599 |      72.2293 |      0.9031 | \n",
      "2018-06-16 07:00:15,603 - logHandler - train - INFO - Iteration: 7, XGBoost max auc: -0.152833\n",
      "2018-06-16 07:00:15,605 - logHandler - train - INFO - Param max_delta_step: 9.958041318136274\n",
      "2018-06-16 07:00:15,606 - logHandler - train - INFO - Param reg_lambda: 71.69111402723836\n",
      "2018-06-16 07:00:15,608 - logHandler - train - INFO - Param reg_alpha: 0.252088985485875\n",
      "2018-06-16 07:00:15,609 - logHandler - train - INFO - Param n_estimators: 1134.744299872792\n",
      "2018-06-16 07:00:15,611 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 07:00:15,612 - logHandler - train - INFO - Param subsample: 0.9386457955022636\n",
      "2018-06-16 07:00:15,614 - logHandler - train - INFO - Param min_child_weight: 8.669526960449879\n",
      "2018-06-16 07:00:15,615 - logHandler - train - INFO - Param gamma: 0.05224328610744211\n",
      "2018-06-16 07:00:15,617 - logHandler - train - INFO - Param colsample_bytree: 0.8252812146025409\n",
      "2018-06-16 07:00:15,618 - logHandler - train - INFO - Param colsample_bylevel: 0.9610558441573448\n",
      "2018-06-16 07:00:15,620 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 07:00:16,504 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 07:00:16,505 - logHandler - train - INFO - Iteration  8, Current random seed:  8\n",
      "2018-06-16 07:00:16,508 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 07:00:16,509 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m01s | \u001b[35m  -0.15984\u001b[0m | \u001b[32m             0.9590\u001b[0m | \u001b[32m            0.9279\u001b[0m | \u001b[32m   0.2828\u001b[0m | \u001b[32m          7.6371\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.3413\u001b[0m | \u001b[32m     1121.7273\u001b[0m | \u001b[32m     0.1637\u001b[0m | \u001b[32m     82.4738\u001b[0m | \u001b[32m     0.9502\u001b[0m | \n",
      "    2 | 00m02s | \u001b[35m  -0.15607\u001b[0m | \u001b[32m             0.9021\u001b[0m | \u001b[32m            0.9136\u001b[0m | \u001b[32m   0.8264\u001b[0m | \u001b[32m          3.4478\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.9794\u001b[0m | \u001b[32m     1132.5574\u001b[0m | \u001b[32m     0.2295\u001b[0m | \u001b[32m     72.9375\u001b[0m | \u001b[32m     0.9905\u001b[0m | \n",
      "    3 | 00m02s |   -0.15634 |              0.9520 |             0.9495 |    0.7411 |           5.0753 |      1.0000 |             9.2541 |      1122.5234 |      0.0039 |      76.7554 |      0.9361 | \n",
      "    4 | 00m02s |   -0.15660 |              0.9316 |             0.9059 |    0.4121 |           7.6857 |      1.0000 |            10.4213 |      1120.0811 |      0.1770 |      70.1401 |      0.9627 | \n",
      "    5 | 00m02s |   -0.15957 |              0.9867 |             0.9152 |    0.0527 |           9.9112 |      1.0000 |            10.3917 |      1127.5043 |      0.1236 |      76.9140 |      0.9597 | \n",
      "    6 | 00m01s |   -0.15876 |              0.9612 |             0.9969 |    0.1445 |           2.2319 |      1.0000 |             9.5795 |      1134.0108 |      0.0151 |      80.9821 |      0.9177 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m16s |   -0.15742 |              0.9083 |             0.9300 |    0.9675 |           6.0914 |      1.0000 |             8.1057 |      1134.4765 |      0.2876 |      70.3409 |      0.9601 | \n",
      "    8 | 00m15s |   -0.15984 |              0.9566 |             0.9436 |    0.9531 |           0.2189 |      1.0000 |            10.1550 |      1120.7934 |      0.0309 |      70.1791 |      0.9931 | \n",
      "    9 | 00m16s |   -0.15849 |              0.9456 |             0.8408 |    0.9974 |           9.4785 |      1.0000 |            10.8161 |      1133.2994 |      0.0790 |      84.5444 |      0.9375 | \n",
      "   10 | 00m17s |   -0.15687 |              0.9963 |             0.9178 |    0.9646 |           0.6284 |      1.0000 |            10.7971 |      1120.3723 |      0.2031 |      84.9164 |      0.9022 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.04116526e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 00m16s |   -0.15930 |              0.9347 |             0.9365 |    0.9231 |           9.9982 |      1.0000 |            10.7588 |      1120.3402 |      0.0400 |      75.4129 |      0.9813 | \n",
      "   12 | 00m17s |   -0.15768 |              0.9247 |             0.8202 |    0.9682 |           1.2723 |      1.0000 |             8.5507 |      1129.3289 |      0.2945 |      84.4084 |      0.9139 | \n",
      "   13 | 00m17s |   -0.15633 |              0.9057 |             0.9827 |    0.9156 |           9.8889 |      1.0000 |            10.9601 |      1134.5674 |      0.1530 |      70.4830 |      0.9698 | \n",
      "   14 | 00m18s |   -0.15768 |              0.9352 |             0.9766 |    0.7839 |           6.6727 |      1.0000 |            10.9682 |      1127.9233 |      0.0026 |      70.0395 |      0.9336 | \n",
      "   15 | 00m16s |   -0.16496 |              0.9867 |             0.9955 |    0.9395 |           9.9389 |      1.0000 |             8.0035 |      1120.0542 |      0.1513 |      70.1385 |      0.9837 | \n",
      "   16 | 00m18s | \u001b[35m  -0.15499\u001b[0m | \u001b[32m             0.9737\u001b[0m | \u001b[32m            0.8013\u001b[0m | \u001b[32m   0.9130\u001b[0m | \u001b[32m          2.7153\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.8093\u001b[0m | \u001b[32m     1120.5151\u001b[0m | \u001b[32m     0.2862\u001b[0m | \u001b[32m     77.3360\u001b[0m | \u001b[32m     0.9197\u001b[0m | \n",
      "   17 | 00m16s |   -0.16065 |              0.9282 |             0.8375 |    0.0264 |           0.6900 |      1.0000 |             8.0458 |      1121.1183 |      0.0063 |      84.0793 |      0.9670 | \n",
      "   18 | 00m18s |   -0.15984 |              0.9674 |             0.9900 |    0.9657 |           5.6860 |      1.0000 |             8.0537 |      1134.9436 |      0.2175 |      79.9803 |      0.9611 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0003481]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 00m16s |   -0.16388 |              0.9052 |             0.8039 |    0.2529 |           4.0193 |      1.0000 |            10.9960 |      1127.4202 |      0.0445 |      83.0830 |      0.9728 | \n",
      "   20 | 00m18s |   -0.15552 |              0.9561 |             0.8354 |    0.0558 |           0.3065 |      1.0000 |            10.6229 |      1134.9778 |      0.0813 |      70.2107 |      0.9908 | \n",
      "   21 | 00m18s |   -0.15795 |              0.9215 |             0.8417 |    0.9835 |           0.0809 |      1.0000 |            10.7261 |      1134.9848 |      0.0114 |      84.7933 |      0.9366 | \n",
      "   22 | 00m19s |   -0.16172 |              0.9906 |             0.9803 |    0.1739 |           0.4932 |      1.0000 |             8.0518 |      1126.7872 |      0.2795 |      70.8007 |      0.9600 | \n",
      "   23 | 00m19s |   -0.15553 |              0.9798 |             0.9036 |    0.0369 |           5.1638 |      1.0000 |            10.3539 |      1134.2927 |      0.2773 |      70.4678 |      0.9105 | \n",
      "   24 | 00m19s |   -0.16145 |              0.9165 |             0.9798 |    0.9725 |           0.0906 |      1.0000 |             8.0039 |      1134.6220 |      0.0847 |      73.4352 |      0.9429 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.97705986e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 63, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 00m19s |   -0.16118 |              0.9443 |             0.9895 |    0.1337 |           9.8409 |      1.0000 |             8.0185 |      1134.4720 |      0.2782 |      83.9759 |      0.9709 | \n",
      "   26 | 00m20s |   -0.15525 |              0.9187 |             0.9970 |    0.2700 |           3.5307 |      1.0000 |            10.6579 |      1120.4441 |      0.2980 |      75.8386 |      0.9003 | \n",
      "   27 | 00m18s |   -0.16065 |              0.9940 |             0.8874 |    0.9786 |           4.9785 |      1.0000 |            10.7120 |      1120.4693 |      0.2873 |      70.9540 |      0.9472 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.53740111e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 00m19s |   -0.15822 |              0.9142 |             0.9089 |    0.1948 |           9.5220 |      1.0000 |             8.0255 |      1132.4374 |      0.0135 |      70.0943 |      0.9055 | \n",
      "   29 | 00m19s |   -0.15741 |              0.9576 |             0.9921 |    0.6031 |           0.0497 |      1.0000 |            10.8081 |      1125.0118 |      0.0409 |      78.7373 |      0.9115 | \n",
      "   30 | 00m20s |   -0.16092 |              0.9062 |             0.8662 |    0.8752 |           0.5013 |      1.0000 |             8.2982 |      1120.1712 |      0.2531 |      79.5572 |      0.9653 | \n",
      "   31 | 00m19s | \u001b[35m  -0.15391\u001b[0m | \u001b[32m             0.9549\u001b[0m | \u001b[32m            0.8094\u001b[0m | \u001b[32m   0.2107\u001b[0m | \u001b[32m          0.1110\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.8426\u001b[0m | \u001b[32m     1120.2237\u001b[0m | \u001b[32m     0.0001\u001b[0m | \u001b[32m     75.5729\u001b[0m | \u001b[32m     0.9927\u001b[0m | \n",
      "   32 | 00m20s |   -0.15930 |              0.9883 |             0.8097 |    0.5845 |           9.8272 |      1.0000 |            10.5736 |      1120.1347 |      0.0021 |      84.6993 |      0.9730 | \n",
      "   33 | 00m20s |   -0.15822 |              0.9389 |             0.8356 |    0.9586 |           1.2954 |      1.0000 |            10.7224 |      1132.9859 |      0.0888 |      70.0067 |      0.9453 | \n",
      "   34 | 00m20s |   -0.16011 |              0.9469 |             0.9701 |    0.9381 |           0.0596 |      1.0000 |             8.1002 |      1134.9751 |      0.2552 |      84.7121 |      0.9441 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00053024]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.21964033e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 47, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 00m20s |   -0.15957 |              0.9288 |             0.8267 |    0.3156 |           9.9154 |      1.0000 |            10.6595 |      1134.9315 |      0.1418 |      76.3940 |      0.9390 | \n",
      "   36 | 00m23s |   -0.15795 |              0.9269 |             0.8215 |    0.0081 |           0.0203 |      1.0000 |            10.9437 |      1121.8893 |      0.0845 |      70.2216 |      0.9368 | \n",
      "   37 | 00m21s |   -0.15687 |              0.9084 |             0.8784 |    0.0083 |           9.8668 |      1.0000 |            10.7213 |      1124.2466 |      0.1179 |      70.5774 |      0.9981 | \n",
      "   38 | 00m23s |   -0.15822 |              0.9865 |             0.9842 |    0.9929 |           9.5359 |      1.0000 |             8.2016 |      1127.9137 |      0.0523 |      84.5424 |      0.9714 | \n",
      "   39 | 00m23s |   -0.15525 |              0.9780 |             0.9148 |    0.2131 |           4.0910 |      1.0000 |            10.9878 |      1120.1805 |      0.0147 |      79.6159 |      0.9622 | \n",
      "   40 | 00m22s |   -0.16011 |              0.9435 |             0.9493 |    0.9446 |           7.1614 |      1.0000 |             8.5557 |      1120.0989 |      0.0111 |      84.9954 |      0.9405 | \n",
      "   41 | 00m22s |   -0.15418 |              0.9887 |             0.8096 |    0.9909 |           0.0473 |      1.0000 |            10.1782 |      1134.5491 |      0.1727 |      78.9670 |      0.9840 | \n",
      "   42 | 00m22s |   -0.15876 |              0.9346 |             0.8028 |    0.9371 |           2.4120 |      1.0000 |            10.9118 |      1134.8679 |      0.1184 |      75.8501 |      0.9093 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00029114]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 | 00m23s |   -0.15822 |              0.9068 |             0.8024 |    0.5342 |           0.2418 |      1.0000 |             9.6738 |      1130.8536 |      0.0470 |      78.5591 |      0.9904 | \n",
      "   44 | 00m23s |   -0.15687 |              0.9630 |             0.9473 |    0.9516 |           0.3162 |      1.0000 |            10.7181 |      1132.5029 |      0.2989 |      81.9051 |      0.9697 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00017733]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 | 00m23s |   -0.16361 |              0.9662 |             0.9780 |    0.9110 |           0.0358 |      1.0000 |             8.2362 |      1126.7888 |      0.0590 |      84.9654 |      0.9769 | \n",
      "   46 | 00m24s |   -0.16011 |              0.9946 |             0.8085 |    0.7054 |           7.5647 |      1.0000 |             9.5576 |      1130.3489 |      0.2989 |      72.4398 |      0.9990 | \n",
      "   47 | 00m22s |   -0.15930 |              0.9075 |             0.9811 |    0.0222 |           9.5886 |      1.0000 |            10.1978 |      1134.9659 |      0.0797 |      70.2415 |      0.9775 | \n",
      "   48 | 00m22s |   -0.15796 |              0.9675 |             0.9407 |    0.1299 |           0.1049 |      1.0000 |            10.9643 |      1134.9709 |      0.2926 |      77.4555 |      0.9137 | \n",
      "   49 | 00m35s |   -0.15660 |              0.9573 |             0.8403 |    0.0525 |           1.2891 |      1.0000 |             8.3828 |      1120.1707 |      0.0219 |      70.3439 |      0.9258 | \n",
      "   50 | 00m41s |   -0.15714 |              0.9159 |             0.8190 |    0.9752 |           9.9484 |      1.0000 |             9.2512 |      1131.1384 |      0.1919 |      82.0801 |      0.9557 | \n",
      "   51 | 00m39s |   -0.16415 |              0.9255 |             0.8556 |    0.1532 |           9.9241 |      1.0000 |            10.9129 |      1120.0374 |      0.0884 |      70.8849 |      0.9471 | \n",
      "   52 | 00m43s |   -0.15849 |              0.9444 |             0.9067 |    0.0597 |           7.0302 |      1.0000 |             8.1038 |      1123.0528 |      0.1026 |      70.0729 |      0.9855 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00036624]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53 | 00m40s |   -0.15930 |              0.9308 |             0.9445 |    0.9780 |           9.9774 |      1.0000 |            10.7055 |      1124.0987 |      0.0100 |      80.0978 |      0.9148 | \n",
      "   54 | 00m45s |   -0.15822 |              0.9349 |             0.8192 |    0.1157 |           0.1939 |      1.0000 |            10.9516 |      1120.1002 |      0.0786 |      79.1866 |      0.9210 | \n",
      "   55 | 00m44s |   -0.15984 |              0.9055 |             0.8454 |    0.9667 |           4.9358 |      1.0000 |            10.8855 |      1121.2107 |      0.2950 |      84.6941 |      0.9919 | \n",
      "   56 | 00m46s |   -0.16200 |              0.9180 |             0.8148 |    0.9326 |           6.1858 |      1.0000 |             8.8189 |      1133.3202 |      0.1943 |      84.8840 |      0.9942 | \n",
      "   57 | 00m46s |   -0.15768 |              0.9354 |             0.8924 |    0.2868 |           7.8617 |      1.0000 |             8.0054 |      1120.1326 |      0.0545 |      78.4092 |      0.9885 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-8.32795922e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   58 | 00m49s |   -0.15741 |              0.9423 |             0.8995 |    0.1349 |           2.9611 |      1.0000 |             8.6191 |      1133.4891 |      0.0094 |      70.0874 |      0.9943 | \n",
      "   59 | 00m49s |   -0.15445 |              0.9639 |             0.9784 |    0.0728 |           9.9748 |      1.0000 |            10.6717 |      1131.1465 |      0.2318 |      70.1006 |      0.9923 | \n",
      "   60 | 00m48s |   -0.16199 |              0.9817 |             0.8016 |    0.0262 |           0.1090 |      1.0000 |            10.4103 |      1123.9353 |      0.2269 |      74.7804 |      0.9973 | \n",
      "   61 | 00m44s |   -0.16011 |              0.9613 |             0.9649 |    0.9835 |           3.3143 |      1.0000 |             8.1428 |      1126.3408 |      0.2557 |      80.2763 |      0.9562 | \n",
      "   62 | 00m48s |   -0.16037 |              0.9492 |             0.8157 |    0.7901 |           0.5198 |      1.0000 |             8.1012 |      1134.9681 |      0.2765 |      80.6623 |      0.9760 | \n",
      "   63 | 00m48s |   -0.15822 |              0.9513 |             0.9959 |    0.8226 |           9.9932 |      1.0000 |             9.2670 |      1133.2458 |      0.0708 |      76.0047 |      0.9004 | \n",
      "   64 | 00m44s |   -0.15741 |              0.9515 |             0.9534 |    0.9985 |           9.5979 |      1.0000 |            10.1960 |      1134.9844 |      0.2977 |      81.5809 |      0.9425 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00029192]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 66, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   65 | 00m48s |   -0.15795 |              0.9137 |             0.8524 |    0.9167 |           6.5879 |      1.0000 |            10.9650 |      1120.0925 |      0.1217 |      79.0094 |      0.9067 | \n",
      "   66 | 00m51s |   -0.16172 |              0.9999 |             0.9933 |    0.0892 |           2.3808 |      1.0000 |             9.1022 |      1120.0904 |      0.0004 |      77.1228 |      0.9463 | \n",
      "   67 | 00m51s |   -0.15661 |              0.9330 |             0.9782 |    0.0389 |           9.9445 |      1.0000 |             8.3782 |      1123.5161 |      0.1727 |      84.6703 |      0.9884 | \n",
      "   68 | 00m48s |   -0.16173 |              0.9224 |             0.8660 |    0.9706 |           9.8842 |      1.0000 |             8.0118 |      1124.6755 |      0.1785 |      76.1476 |      0.9930 | \n",
      "   69 | 00m50s |   -0.15579 |              0.9216 |             0.9424 |    0.0187 |           7.5259 |      1.0000 |            10.8505 |      1123.3518 |      0.0169 |      75.4862 |      0.9822 | \n",
      "   70 | 00m47s | \u001b[35m  -0.15337\u001b[0m | \u001b[32m             0.9238\u001b[0m | \u001b[32m            0.9728\u001b[0m | \u001b[32m   0.9277\u001b[0m | \u001b[32m          6.9255\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.9015\u001b[0m | \u001b[32m     1132.7447\u001b[0m | \u001b[32m     0.0532\u001b[0m | \u001b[32m     78.4632\u001b[0m | \u001b[32m     0.9927\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00030068]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   71 | 00m50s |   -0.16038 |              0.9362 |             0.9632 |    0.4406 |           6.3356 |      1.0000 |            10.8710 |      1133.1020 |      0.0500 |      70.3473 |      0.9910 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00118082]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   72 | 00m53s |   -0.15741 |              0.9293 |             0.9436 |    0.0767 |           0.0372 |      1.0000 |             8.0885 |      1133.1509 |      0.2941 |      70.5898 |      0.9606 | \n",
      "   73 | 00m52s |   -0.16119 |              0.9282 |             0.9883 |    0.9792 |           3.8335 |      1.0000 |            10.9699 |      1127.7474 |      0.2865 |      77.6204 |      0.9640 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00045368]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 | 00m53s |   -0.15741 |              0.9160 |             0.9345 |    0.1605 |           9.9325 |      1.0000 |            10.7706 |      1129.4903 |      0.2787 |      84.6728 |      0.9532 | \n",
      "   75 | 00m56s |   -0.16146 |              0.9111 |             0.8073 |    0.9502 |           1.9521 |      1.0000 |            10.1494 |      1122.2077 |      0.0748 |      81.7777 |      0.9874 | \n",
      "   76 | 00m55s |   -0.15984 |              0.9134 |             0.9983 |    0.1367 |           9.7545 |      1.0000 |             8.4070 |      1127.1816 |      0.2876 |      70.1546 |      0.9940 | \n",
      "   77 | 00m53s |   -0.15822 |              0.9408 |             0.9917 |    0.0460 |           3.6391 |      1.0000 |            10.5399 |      1120.0921 |      0.1344 |      84.9177 |      0.9159 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.000371]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   78 | 00m56s |   -0.15822 |              0.9748 |             0.8733 |    0.9572 |           9.8561 |      1.0000 |             8.4566 |      1134.8817 |      0.2033 |      70.1258 |      0.9700 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00037945]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   79 | 00m52s |   -0.15795 |              0.9555 |             0.9746 |    0.0519 |           9.8310 |      1.0000 |            10.9640 |      1132.9589 |      0.1903 |      79.5942 |      0.9287 | \n",
      "   80 | 00m53s |   -0.15822 |              0.9958 |             0.8620 |    0.0294 |           0.1696 |      1.0000 |            10.9664 |      1132.0993 |      0.1544 |      72.0152 |      0.9095 | \n",
      "   81 | 00m57s |   -0.15714 |              0.9941 |             0.9549 |    0.9717 |           9.9599 |      1.0000 |            10.9710 |      1125.3027 |      0.2306 |      70.0529 |      0.9336 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.0002252]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-7.91094499e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   82 | 00m54s |   -0.16172 |              0.9306 |             0.8310 |    0.9399 |           0.0799 |      1.0000 |             8.3272 |      1120.6574 |      0.1386 |      84.9979 |      0.9937 | \n",
      "   83 | 00m53s |   -0.15687 |              0.9575 |             0.9186 |    0.1910 |           0.0651 |      1.0000 |             8.0336 |      1120.4031 |      0.2610 |      70.1299 |      0.9289 | \n",
      "   84 | 00m55s |   -0.15956 |              0.9070 |             0.9780 |    0.0541 |           5.9990 |      1.0000 |             8.0682 |      1129.8975 |      0.2692 |      81.9624 |      0.9229 | \n",
      "   85 | 00m52s |   -0.15606 |              0.9140 |             0.8906 |    0.9098 |           0.1362 |      1.0000 |            10.9786 |      1120.0793 |      0.0803 |      75.5836 |      0.9162 | \n",
      "   86 | 00m59s |   -0.15984 |              0.9093 |             0.9115 |    0.0372 |           0.0058 |      1.0000 |             9.3309 |      1131.7160 |      0.2693 |      84.9566 |      0.9195 | \n",
      "   87 | 00m54s |   -0.16011 |              0.9687 |             0.8433 |    0.9660 |           9.9851 |      1.0000 |             8.3093 |      1120.1362 |      0.2950 |      83.7265 |      0.9016 | \n",
      "   88 | 00m53s |   -0.15633 |              0.9257 |             0.8619 |    0.0917 |           0.3553 |      1.0000 |            10.8528 |      1120.2112 |      0.0488 |      70.2732 |      0.9557 | \n",
      "   89 | 00m55s |   -0.15822 |              0.9959 |             0.8113 |    0.0808 |           7.0729 |      1.0000 |             9.9757 |      1120.3766 |      0.0121 |      74.5935 |      0.9887 | \n",
      "   90 | 00m56s |   -0.15741 |              0.9465 |             0.9808 |    0.7122 |           9.8336 |      1.0000 |            10.8882 |      1131.2283 |      0.2883 |      73.9258 |      0.9727 | \n",
      "   91 | 00m55s |   -0.15499 |              0.9575 |             0.9966 |    0.0272 |           6.1038 |      1.0000 |            10.9008 |      1123.7134 |      0.1707 |      70.0543 |      0.9382 | \n",
      "   92 | 00m56s |   -0.15849 |              1.0000 |             0.8123 |    0.8353 |           5.4117 |      1.0000 |            10.7251 |      1133.4851 |      0.2817 |      78.7959 |      0.9177 | \n",
      "   93 | 00m55s |   -0.15634 |              0.9661 |             0.9319 |    0.9911 |           0.2635 |      1.0000 |             8.0322 |      1130.6958 |      0.0193 |      83.9250 |      0.9017 | \n",
      "   94 | 00m58s |   -0.15364 |              0.9279 |             0.9023 |    0.4664 |           4.1523 |      1.0000 |            10.9931 |      1121.0422 |      0.1007 |      76.4102 |      0.9910 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00085963]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00236308]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   95 | 00m59s |   -0.15687 |              0.9069 |             0.9791 |    0.5477 |           0.4675 |      1.0000 |            10.7664 |      1134.9152 |      0.2883 |      72.4156 |      0.9075 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0002905]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   96 | 01m01s |   -0.15498 |              0.9012 |             0.8490 |    0.0543 |           0.2780 |      1.0000 |            10.9136 |      1120.1407 |      0.0504 |      84.9837 |      0.9599 | \n",
      "   97 | 00m58s |   -0.16037 |              0.9181 |             0.8798 |    0.0413 |           4.4286 |      1.0000 |            10.8921 |      1121.5686 |      0.2981 |      78.5313 |      0.9857 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00136036]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   98 | 01m06s |   -0.15984 |              0.9563 |             0.9945 |    0.9951 |           9.4791 |      1.0000 |            10.5609 |      1123.4899 |      0.0034 |      84.8336 |      0.9004 | \n",
      "   99 | 01m04s |   -0.15768 |              0.9312 |             0.9998 |    0.8508 |           6.2587 |      1.0000 |            10.8310 |      1134.9201 |      0.0389 |      74.5285 |      0.9907 | \n",
      "  100 | 01m04s |   -0.15930 |              0.9803 |             0.9898 |    0.0290 |           9.8920 |      1.0000 |             8.0269 |      1120.9956 |      0.0008 |      80.4693 |      0.9720 | \n",
      "  101 | 01m05s |   -0.15687 |              0.9856 |             0.9853 |    0.9750 |           8.1359 |      1.0000 |            10.9297 |      1126.5186 |      0.0058 |      74.8340 |      0.9518 | \n",
      "  102 | 01m00s |   -0.15472 |              0.9128 |             0.9695 |    0.1539 |           3.3282 |      1.0000 |            10.9423 |      1134.8888 |      0.2487 |      70.1384 |      0.9848 | \n",
      "  103 | 01m04s |   -0.15876 |              0.9245 |             0.9962 |    0.9859 |           8.4256 |      1.0000 |            10.9793 |      1129.8281 |      0.2538 |      79.2685 |      0.9116 | \n",
      "  104 | 01m08s |   -0.16145 |              0.9132 |             0.9934 |    0.9448 |           3.8242 |      1.0000 |             8.4793 |      1131.8296 |      0.0272 |      77.2400 |      0.9455 | \n",
      "  105 | 01m04s |   -0.15849 |              0.9598 |             0.8136 |    0.7370 |           4.7802 |      1.0000 |             8.0914 |      1120.0719 |      0.0983 |      82.0204 |      0.9792 | \n",
      "  106 | 01m06s |   -0.15364 |              0.9249 |             0.9171 |    0.0090 |           5.7258 |      1.0000 |             8.1346 |      1120.0065 |      0.0692 |      70.0452 |      0.9873 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00187059]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-16 08:07:05,974 - logHandler - train - INFO - Iteration: 8, XGBoost max auc: -0.153366\n",
      "2018-06-16 08:07:05,977 - logHandler - train - INFO - Param max_delta_step: 6.92551373797488\n",
      "2018-06-16 08:07:05,978 - logHandler - train - INFO - Param reg_lambda: 78.4631674855181\n",
      "2018-06-16 08:07:05,979 - logHandler - train - INFO - Param reg_alpha: 0.053183402902424945\n",
      "2018-06-16 08:07:05,981 - logHandler - train - INFO - Param n_estimators: 1132.7446831118145\n",
      "2018-06-16 08:07:05,982 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 08:07:05,984 - logHandler - train - INFO - Param subsample: 0.9927217894374856\n",
      "2018-06-16 08:07:05,985 - logHandler - train - INFO - Param min_child_weight: 10.901465227742616\n",
      "2018-06-16 08:07:05,987 - logHandler - train - INFO - Param gamma: 0.9277000992791363\n",
      "2018-06-16 08:07:05,988 - logHandler - train - INFO - Param colsample_bytree: 0.9728261269100937\n",
      "2018-06-16 08:07:05,989 - logHandler - train - INFO - Param colsample_bylevel: 0.9238338499371307\n",
      "2018-06-16 08:07:05,991 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 08:07:07,004 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 08:07:07,006 - logHandler - train - INFO - Iteration  9, Current random seed:  9\n",
      "2018-06-16 08:07:07,008 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 08:07:07,010 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.15984\u001b[0m | \u001b[32m             0.9649\u001b[0m | \u001b[32m            0.9382\u001b[0m | \u001b[32m   0.3320\u001b[0m | \u001b[32m          5.2964\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.3944\u001b[0m | \u001b[32m     1127.7202\u001b[0m | \u001b[32m     0.0007\u001b[0m | \u001b[32m     74.2106\u001b[0m | \u001b[32m     0.9183\u001b[0m | \n",
      "    2 | 00m01s | \u001b[35m  -0.15714\u001b[0m | \u001b[32m             0.9673\u001b[0m | \u001b[32m            0.9460\u001b[0m | \u001b[32m   0.4677\u001b[0m | \u001b[32m          0.9475\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.9543\u001b[0m | \u001b[32m     1120.6357\u001b[0m | \u001b[32m     0.2781\u001b[0m | \u001b[32m     78.0048\u001b[0m | \u001b[32m     0.9188\u001b[0m | \n",
      "    3 | 00m02s |   -0.15768 |              0.9401 |             0.9404 |    0.0127 |           3.0165 |      1.0000 |            10.8984 |      1120.9631 |      0.0094 |      77.1190 |      0.9975 | \n",
      "    4 | 00m02s |   -0.15768 |              0.9401 |             0.8300 |    0.0821 |           1.5552 |      1.0000 |             8.9650 |      1129.9435 |      0.0035 |      77.8914 |      0.9065 | \n",
      "    5 | 00m01s | \u001b[35m  -0.15553\u001b[0m | \u001b[32m             0.9827\u001b[0m | \u001b[32m            0.9250\u001b[0m | \u001b[32m   0.3039\u001b[0m | \u001b[32m          8.0500\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.2607\u001b[0m | \u001b[32m     1121.3074\u001b[0m | \u001b[32m     0.0496\u001b[0m | \u001b[32m     72.1954\u001b[0m | \u001b[32m     0.9561\u001b[0m | \n",
      "    6 | 00m02s |   -0.15714 |              0.9893 |             0.8636 |    0.6525 |           8.2480 |      1.0000 |             8.1533 |      1133.0340 |      0.2019 |      74.4132 |      0.9623 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m14s |   -0.16065 |              0.9450 |             0.9720 |    0.8908 |           0.5739 |      1.0000 |            10.8186 |      1134.1271 |      0.1927 |      70.3572 |      0.9820 | \n",
      "    8 | 00m16s |   -0.16065 |              0.9192 |             0.8043 |    0.9432 |           9.8964 |      1.0000 |            10.8332 |      1120.2086 |      0.1612 |      84.7539 |      0.9673 | \n",
      "    9 | 00m17s |   -0.15957 |              0.9370 |             0.8271 |    0.8169 |           9.9868 |      1.0000 |            10.6792 |      1134.8387 |      0.0311 |      84.9610 |      0.9594 | \n",
      "   10 | 00m17s |   -0.15660 |              0.9555 |             0.9470 |    0.4279 |           0.0732 |      1.0000 |             8.0845 |      1134.6888 |      0.1275 |      84.7559 |      0.9676 | \n",
      "   11 | 00m17s |   -0.15741 |              0.9254 |             0.9581 |    0.0300 |           9.6546 |      1.0000 |            10.8332 |      1134.7439 |      0.2685 |      71.8034 |      0.9219 | \n",
      "   12 | 00m17s |   -0.16065 |              0.9388 |             0.8330 |    0.0651 |           2.2569 |      1.0000 |             8.8141 |      1120.3155 |      0.2748 |      70.1183 |      0.9314 | \n",
      "   13 | 00m17s |   -0.15903 |              0.9105 |             0.8321 |    0.9878 |           0.3421 |      1.0000 |            10.8459 |      1134.8694 |      0.2415 |      83.9324 |      0.9991 | \n",
      "   14 | 00m19s |   -0.15741 |              0.9793 |             0.9194 |    0.3752 |           9.7601 |      1.0000 |             8.0429 |      1120.0368 |      0.2779 |      76.8821 |      0.9286 | \n",
      "   15 | 00m17s |   -0.15768 |              0.9049 |             0.9049 |    0.7681 |           9.8580 |      1.0000 |            10.4980 |      1120.3857 |      0.0039 |      70.6819 |      0.9975 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.22550668e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 00m18s |   -0.15768 |              0.9959 |             0.9979 |    0.1373 |           9.9662 |      1.0000 |            10.6888 |      1126.4916 |      0.2739 |      76.9587 |      0.9537 | \n",
      "   17 | 00m19s |   -0.15742 |              0.9926 |             0.8069 |    0.0489 |           3.9710 |      1.0000 |             9.7855 |      1134.9753 |      0.2828 |      79.2048 |      0.9281 | \n",
      "   18 | 00m18s |   -0.16038 |              0.9965 |             0.8043 |    0.0643 |           0.2483 |      1.0000 |            10.7575 |      1124.4099 |      0.2258 |      84.9435 |      0.9620 | \n",
      "   19 | 00m17s |   -0.15849 |              0.9869 |             0.8004 |    0.0844 |           0.1418 |      1.0000 |             8.2430 |      1134.9892 |      0.0136 |      72.0497 |      0.9111 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00051329]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 00m18s |   -0.15687 |              0.9598 |             0.8112 |    0.8146 |           7.3202 |      1.0000 |            10.9816 |      1121.4749 |      0.2379 |      75.3013 |      0.9120 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([9.25793906e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 00m18s |   -0.15822 |              0.9852 |             0.8606 |    0.5253 |           0.1176 |      1.0000 |             8.0051 |      1120.4662 |      0.0114 |      83.5438 |      0.9265 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00053073]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 00m18s |   -0.16038 |              0.9840 |             0.8487 |    0.0804 |           9.6994 |      1.0000 |             8.0184 |      1134.9008 |      0.2060 |      82.3982 |      0.9346 | \n",
      "   23 | 00m17s |   -0.15957 |              0.9967 |             0.9600 |    0.9882 |           0.1245 |      1.0000 |             9.1349 |      1134.2090 |      0.0955 |      77.8830 |      0.9057 | \n",
      "   24 | 00m18s |   -0.16119 |              0.9775 |             0.8456 |    0.0349 |           9.9595 |      1.0000 |            10.8778 |      1124.9988 |      0.1996 |      70.1584 |      0.9370 | \n",
      "   25 | 00m19s |   -0.16091 |              0.9283 |             0.9911 |    0.9662 |           4.5181 |      1.0000 |             8.1500 |      1129.9386 |      0.2242 |      84.9307 |      0.9782 | \n",
      "   26 | 00m19s |   -0.15849 |              0.9232 |             0.8006 |    0.0044 |           8.8545 |      1.0000 |            10.7696 |      1120.0927 |      0.2963 |      74.0082 |      0.9925 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-8.07931538e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   27 | 00m19s |   -0.15849 |              0.9992 |             0.9641 |    0.9194 |           0.2011 |      1.0000 |            10.7462 |      1120.6067 |      0.0311 |      73.8314 |      0.9431 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0001758]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 00m20s |   -0.16200 |              0.9601 |             0.9961 |    0.9386 |           9.1720 |      1.0000 |             8.1015 |      1134.8667 |      0.1317 |      70.2838 |      0.9355 | \n",
      "   29 | 00m18s |   -0.15741 |              0.9929 |             0.8579 |    0.7669 |           9.5730 |      1.0000 |            10.7507 |      1134.8936 |      0.0169 |      77.2035 |      0.9629 | \n",
      "   30 | 00m20s |   -0.16092 |              0.9990 |             0.8904 |    0.8822 |           5.9044 |      1.0000 |             8.2993 |      1120.0492 |      0.0071 |      73.4652 |      0.9381 | \n",
      "   31 | 00m19s |   -0.15903 |              0.9640 |             0.9944 |    0.1681 |           0.2144 |      1.0000 |            10.8839 |      1126.3959 |      0.2842 |      73.1032 |      0.9729 | \n",
      "   32 | 00m21s | \u001b[35m  -0.15471\u001b[0m | \u001b[32m             0.9625\u001b[0m | \u001b[32m            0.9446\u001b[0m | \u001b[32m   0.8006\u001b[0m | \u001b[32m          9.8602\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.0676\u001b[0m | \u001b[32m     1120.6615\u001b[0m | \u001b[32m     0.0106\u001b[0m | \u001b[32m     84.5577\u001b[0m | \u001b[32m     0.9160\u001b[0m | \n",
      "   33 | 00m19s |   -0.15688 |              0.9536 |             0.9935 |    0.0128 |           5.7111 |      1.0000 |            10.9740 |      1134.3881 |      0.0551 |      74.8198 |      0.9105 | \n",
      "   34 | 00m20s |   -0.15552 |              0.9414 |             0.9984 |    0.5780 |           3.9048 |      1.0000 |            10.9664 |      1120.2023 |      0.2838 |      70.3095 |      0.9195 | \n",
      "   35 | 00m19s |   -0.15930 |              0.9032 |             0.9203 |    0.9832 |           9.9866 |      1.0000 |             8.3369 |      1124.0395 |      0.0369 |      80.1441 |      0.9339 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00019732]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 | 00m22s |   -0.15984 |              0.9332 |             0.9745 |    0.0635 |           4.7672 |      1.0000 |             8.1649 |      1120.7307 |      0.1498 |      84.8014 |      0.9021 | \n",
      "   37 | 00m21s |   -0.16038 |              0.9503 |             0.9936 |    0.0163 |           0.0068 |      1.0000 |             8.3019 |      1126.2249 |      0.0745 |      82.0454 |      0.9026 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00027604]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   38 | 00m21s |   -0.16011 |              0.9887 |             0.9943 |    0.9898 |           0.0834 |      1.0000 |            10.4618 |      1120.1628 |      0.2472 |      84.3947 |      0.9036 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00013606]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00059557]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 00m21s |   -0.15580 |              0.9986 |             0.8140 |    0.1038 |           0.7814 |      1.0000 |            10.0385 |      1132.4029 |      0.0453 |      84.7443 |      0.9127 | \n",
      "   40 | 00m21s |   -0.15741 |              0.9914 |             0.8736 |    0.6106 |           9.9992 |      1.0000 |             8.3162 |      1127.7246 |      0.2145 |      84.8108 |      0.9228 | \n",
      "   41 | 00m22s |   -0.15957 |              0.9989 |             0.9460 |    0.0331 |           5.3446 |      1.0000 |            10.7365 |      1120.4553 |      0.2351 |      70.0556 |      0.9051 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([5.36104344e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00093715]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 00m23s |   -0.16119 |              0.9053 |             0.9797 |    0.9380 |           9.3444 |      1.0000 |            10.6296 |      1130.4545 |      0.2679 |      72.7882 |      0.9694 | \n",
      "   43 | 00m24s |   -0.16119 |              0.9672 |             0.8517 |    0.0614 |           9.8359 |      1.0000 |             8.2435 |      1134.8844 |      0.0999 |      74.3495 |      0.9885 | \n",
      "   44 | 00m24s |   -0.15472 |              0.9486 |             0.9234 |    0.9421 |           0.0386 |      1.0000 |             8.5380 |      1126.9624 |      0.2518 |      70.0997 |      0.9602 | \n",
      "   45 | 00m23s |   -0.15849 |              0.9312 |             0.9358 |    0.9480 |           4.3890 |      1.0000 |             8.2707 |      1134.9653 |      0.2725 |      73.6471 |      0.9810 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([4.20301221e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 47, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46 | 00m24s |   -0.15957 |              0.9771 |             0.9820 |    0.0296 |           8.9915 |      1.0000 |            10.7518 |      1131.3662 |      0.2215 |      83.2606 |      0.9001 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00085316]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   47 | 00m26s |   -0.16092 |              0.9883 |             0.9973 |    0.9027 |           9.9228 |      1.0000 |             8.1762 |      1123.7274 |      0.2728 |      71.4107 |      0.9999 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00028965]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 00m23s |   -0.15822 |              0.9846 |             0.8303 |    0.8587 |           0.5015 |      1.0000 |            10.8486 |      1120.9175 |      0.1410 |      70.0567 |      0.9714 | \n",
      "   49 | 00m34s |   -0.16145 |              0.9865 |             0.9971 |    0.9871 |           9.6727 |      1.0000 |            10.3863 |      1121.1247 |      0.0399 |      74.1796 |      0.9007 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0003474]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 | 00m43s |   -0.15849 |              0.9444 |             0.9276 |    0.0030 |           9.5929 |      1.0000 |             8.0699 |      1120.0507 |      0.2074 |      84.3423 |      0.9508 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00028562]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   51 | 00m40s |   -0.15849 |              0.9125 |             0.8011 |    0.2505 |           1.4860 |      1.0000 |             8.0129 |      1131.0099 |      0.2519 |      70.0642 |      0.9900 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00031611]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   52 | 00m43s |   -0.15984 |              0.9055 |             0.8609 |    0.9861 |           4.4010 |      1.0000 |            10.6957 |      1123.4149 |      0.2441 |      71.6546 |      0.9900 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([7.0382242e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53 | 00m39s |   -0.16092 |              0.9818 |             0.9914 |    0.0985 |           0.1023 |      1.0000 |             8.0773 |      1131.2205 |      0.2077 |      73.2851 |      0.9869 | \n",
      "   54 | 00m48s |   -0.15849 |              0.9336 |             0.9264 |    0.9037 |           0.3174 |      1.0000 |             8.1060 |      1134.6652 |      0.1540 |      70.2113 |      0.9044 | \n",
      "   55 | 00m46s |   -0.16361 |              0.9056 |             0.8225 |    0.0032 |           8.4446 |      1.0000 |             8.7130 |      1130.2821 |      0.0830 |      78.0411 |      0.9663 | \n",
      "   56 | 00m47s |   -0.16092 |              0.9379 |             0.8089 |    0.9539 |           5.1428 |      1.0000 |            10.9988 |      1124.1134 |      0.0786 |      82.1061 |      0.9295 | \n",
      "   57 | 00m45s |   -0.15983 |              0.9644 |             0.8077 |    0.9867 |           5.0199 |      1.0000 |             8.1156 |      1134.9905 |      0.0356 |      84.9119 |      0.9037 | \n",
      "   58 | 00m48s |   -0.15795 |              0.9044 |             0.8190 |    0.8730 |           0.0600 |      1.0000 |             8.3047 |      1129.8219 |      0.1968 |      84.8702 |      0.9130 | \n",
      "   59 | 00m47s |   -0.15661 |              0.9237 |             0.9720 |    0.0278 |           0.4036 |      1.0000 |            10.9526 |      1131.7400 |      0.2984 |      80.1343 |      0.9660 | \n",
      "   60 | 00m47s |   -0.15929 |              0.9758 |             0.9846 |    0.2400 |           9.5122 |      1.0000 |            10.8049 |      1125.5784 |      0.2579 |      84.9552 |      0.9110 | \n",
      "   61 | 00m45s |   -0.16038 |              0.9846 |             0.9515 |    0.8034 |           6.0527 |      1.0000 |             8.0316 |      1120.1238 |      0.1679 |      80.7351 |      0.9913 | \n",
      "   62 | 00m48s |   -0.15849 |              0.9856 |             0.9911 |    0.9025 |           0.1903 |      1.0000 |             8.0088 |      1120.4186 |      0.2635 |      70.1011 |      0.9413 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([5.58168314e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   63 | 00m49s |   -0.16065 |              0.9947 |             0.9997 |    0.9742 |           9.5067 |      1.0000 |             8.2170 |      1123.2656 |      0.2707 |      84.8330 |      0.9013 | \n",
      "   64 | 00m46s |   -0.15903 |              0.9321 |             0.9758 |    0.0193 |           8.9192 |      1.0000 |             8.0538 |      1120.7907 |      0.2279 |      70.2852 |      0.9014 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00043729]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   65 | 00m47s |   -0.15984 |              0.9439 |             0.8009 |    0.7057 |           6.8932 |      1.0000 |            10.7198 |      1134.9414 |      0.2153 |      71.5018 |      0.9207 | \n",
      "   66 | 00m49s |   -0.16199 |              0.9227 |             0.9511 |    0.1987 |           0.0918 |      1.0000 |            10.9492 |      1120.2604 |      0.1970 |      80.3455 |      0.9012 | \n",
      "   67 | 00m48s |   -0.15768 |              0.9216 |             0.9026 |    0.9413 |           0.3516 |      1.0000 |             8.2835 |      1124.3682 |      0.2833 |      76.3632 |      0.9299 | \n",
      "   68 | 00m49s |   -0.15876 |              0.9139 |             0.8888 |    0.0877 |           0.0208 |      1.0000 |            10.9479 |      1134.9035 |      0.2822 |      75.0266 |      0.9319 | \n",
      "   69 | 00m47s |   -0.15903 |              0.9297 |             0.9942 |    0.9953 |           9.8778 |      1.0000 |             8.4182 |      1132.7275 |      0.0414 |      84.7662 |      0.9645 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00213556]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   70 | 00m53s |   -0.16118 |              0.9072 |             0.8762 |    0.0033 |           0.3361 |      1.0000 |             8.0251 |      1133.6204 |      0.2084 |      80.9395 |      0.9002 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00033307]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   71 | 00m51s |   -0.15903 |              0.9881 |             0.8560 |    0.9531 |           0.3512 |      1.0000 |            10.8581 |      1126.9708 |      0.2416 |      78.6147 |      0.9044 | \n",
      "   72 | 00m52s |   -0.15876 |              0.9345 |             0.9637 |    0.0024 |           5.1777 |      1.0000 |            10.9937 |      1124.0617 |      0.2416 |      76.8949 |      0.9090 | \n",
      "   73 | 00m47s |   -0.16361 |              0.9275 |             0.8070 |    0.0201 |           9.9534 |      1.0000 |             8.1304 |      1123.7609 |      0.0558 |      74.3298 |      0.9483 | \n",
      "   74 | 00m56s | \u001b[35m  -0.15445\u001b[0m | \u001b[32m             0.9938\u001b[0m | \u001b[32m            0.9104\u001b[0m | \u001b[32m   0.0050\u001b[0m | \u001b[32m          5.7732\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.4665\u001b[0m | \u001b[32m     1133.4036\u001b[0m | \u001b[32m     0.2886\u001b[0m | \u001b[32m     70.2594\u001b[0m | \u001b[32m     0.9017\u001b[0m | \n",
      "   75 | 00m52s | \u001b[35m  -0.15364\u001b[0m | \u001b[32m             0.9976\u001b[0m | \u001b[32m            0.8647\u001b[0m | \u001b[32m   0.0960\u001b[0m | \u001b[32m          9.9976\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.0838\u001b[0m | \u001b[32m     1121.2046\u001b[0m | \u001b[32m     0.0085\u001b[0m | \u001b[32m     80.1459\u001b[0m | \u001b[32m     0.9039\u001b[0m | \n",
      "   76 | 00m50s |   -0.15714 |              0.9937 |             0.8051 |    0.9521 |           1.2571 |      1.0000 |             8.2148 |      1123.7113 |      0.0282 |      84.7979 |      0.9314 | \n",
      "   77 | 00m52s |   -0.16145 |              0.9886 |             0.9589 |    0.9341 |           9.7177 |      1.0000 |             8.1343 |      1120.0159 |      0.0535 |      82.0954 |      0.9887 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00174665]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   78 | 00m58s |   -0.15660 |              0.9939 |             0.9707 |    0.9951 |           5.6873 |      1.0000 |             8.0623 |      1129.2859 |      0.1434 |      70.0440 |      0.9573 | \n",
      "   79 | 00m55s |   -0.15687 |              0.9181 |             0.9361 |    0.0639 |           7.2840 |      1.0000 |             9.9384 |      1120.0875 |      0.1346 |      77.4313 |      0.9042 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00033541]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   80 | 00m53s |   -0.15525 |              0.9139 |             0.8436 |    0.0957 |           9.8845 |      1.0000 |            10.6375 |      1124.6328 |      0.0212 |      80.9392 |      0.9737 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00172504]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   81 | 00m54s |   -0.16281 |              0.9912 |             0.8120 |    0.0685 |           9.9299 |      1.0000 |             8.0242 |      1126.5202 |      0.0028 |      84.9343 |      0.9564 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00024493]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   82 | 00m56s |   -0.15795 |              0.9511 |             0.8171 |    0.7870 |           9.9657 |      1.0000 |            10.7731 |      1127.1589 |      0.0724 |      82.5926 |      0.9105 | \n",
      "   83 | 00m53s |   -0.15930 |              0.9482 |             0.9531 |    0.0463 |           0.0519 |      1.0000 |            10.9667 |      1134.6437 |      0.2300 |      84.8804 |      0.9575 | \n",
      "   84 | 00m54s |   -0.16065 |              0.9965 |             0.8269 |    0.0699 |           5.2416 |      1.0000 |            10.7069 |      1131.2356 |      0.2971 |      75.0862 |      0.9015 | \n",
      "   85 | 00m52s |   -0.15876 |              0.9995 |             0.9939 |    0.9380 |           0.5734 |      1.0000 |            10.8253 |      1128.8207 |      0.1170 |      84.8296 |      0.9630 | \n",
      "   86 | 00m59s | \u001b[35m  -0.15337\u001b[0m | \u001b[32m             0.9076\u001b[0m | \u001b[32m            0.9114\u001b[0m | \u001b[32m   0.0105\u001b[0m | \u001b[32m          9.9512\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.4515\u001b[0m | \u001b[32m     1130.9720\u001b[0m | \u001b[32m     0.2982\u001b[0m | \u001b[32m     70.2316\u001b[0m | \u001b[32m     0.9995\u001b[0m | \n",
      "   87 | 00m57s |   -0.15849 |              0.9101 |             0.8274 |    0.9930 |           1.9262 |      1.0000 |             9.2473 |      1120.0536 |      0.0531 |      84.7962 |      0.9014 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00200929]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   88 | 00m58s |   -0.15660 |              0.9341 |             0.9571 |    0.0271 |           9.9292 |      1.0000 |            10.9060 |      1123.0143 |      0.2550 |      78.7500 |      0.9737 | \n",
      "   89 | 00m58s |   -0.15606 |              0.9854 |             0.8014 |    0.0686 |           9.9911 |      1.0000 |            10.7834 |      1132.3767 |      0.0147 |      70.1267 |      0.9640 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00025191]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   90 | 01m03s |   -0.15687 |              0.9957 |             0.8919 |    0.1342 |           9.9208 |      1.0000 |             8.2046 |      1131.0158 |      0.0071 |      71.0005 |      0.9036 | \n",
      "   91 | 00m56s |   -0.15472 |              0.9880 |             0.9979 |    0.9278 |           0.1958 |      1.0000 |             8.6864 |      1132.9813 |      0.1905 |      84.8408 |      0.9186 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00074]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   92 | 00m54s |   -0.15930 |              0.9922 |             0.8192 |    0.9157 |           7.3665 |      1.0000 |             9.5540 |      1120.9456 |      0.2852 |      70.5215 |      0.9304 | \n",
      "   93 | 01m00s |   -0.15768 |              0.9904 |             0.9947 |    0.0024 |           1.2917 |      1.0000 |             8.0383 |      1125.6393 |      0.2851 |      71.4106 |      0.9459 | \n",
      "   94 | 01m02s |   -0.16226 |              0.9943 |             0.9855 |    0.9294 |           2.3617 |      1.0000 |             8.8578 |      1122.0635 |      0.0281 |      80.5982 |      0.9073 | \n",
      "   95 | 01m00s |   -0.16281 |              0.9282 |             0.9206 |    0.0374 |           0.2690 |      1.0000 |             8.2916 |      1120.0276 |      0.1390 |      75.8078 |      0.9460 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00227271]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   96 | 01m01s |   -0.15579 |              0.9616 |             0.9830 |    0.0047 |           2.3149 |      1.0000 |            10.7683 |      1134.9169 |      0.2026 |      70.0807 |      0.9853 | \n",
      "   97 | 01m03s |   -0.15714 |              0.9608 |             0.9715 |    0.0195 |           0.0373 |      1.0000 |             8.4621 |      1134.1136 |      0.2931 |      70.3420 |      0.9989 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00066301]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   98 | 01m05s |   -0.15714 |              0.9919 |             0.9904 |    0.6676 |           5.0402 |      1.0000 |            10.9513 |      1120.1486 |      0.2571 |      73.6142 |      0.9064 | \n",
      "   99 | 01m03s |   -0.16388 |              0.9907 |             0.9544 |    0.9685 |           8.8283 |      1.0000 |             9.8007 |      1134.9886 |      0.2253 |      80.8743 |      0.9148 | \n",
      "  100 | 01m02s |   -0.15849 |              0.9972 |             0.8042 |    0.3469 |           9.7612 |      1.0000 |            10.5916 |      1131.6231 |      0.2744 |      84.9729 |      0.9192 | \n",
      "  101 | 01m04s | \u001b[35m  -0.15202\u001b[0m | \u001b[32m             0.9824\u001b[0m | \u001b[32m            0.9242\u001b[0m | \u001b[32m   0.1839\u001b[0m | \u001b[32m          0.5706\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.7276\u001b[0m | \u001b[32m     1134.9276\u001b[0m | \u001b[32m     0.0211\u001b[0m | \u001b[32m     80.2829\u001b[0m | \u001b[32m     0.9327\u001b[0m | \n",
      "  102 | 01m02s |   -0.15849 |              0.9997 |             0.9649 |    0.1326 |           2.4301 |      1.0000 |            10.7575 |      1134.4633 |      0.0312 |      83.3008 |      0.9554 | \n",
      "  103 | 01m10s |   -0.15526 |              0.9942 |             0.8869 |    0.3176 |           9.8984 |      1.0000 |             8.3407 |      1134.9460 |      0.0424 |      84.9306 |      0.9248 | \n",
      "  104 | 01m08s |   -0.15849 |              0.9772 |             0.9962 |    0.2617 |           9.9844 |      1.0000 |            10.9325 |      1133.0104 |      0.2217 |      76.8261 |      0.9038 | \n",
      "  105 | 01m06s |   -0.15956 |              0.9912 |             0.9663 |    0.9652 |           0.0976 |      1.0000 |             8.4249 |      1120.1805 |      0.0485 |      84.9004 |      0.9236 | \n",
      "  106 | 01m07s |   -0.15741 |              0.9838 |             0.8272 |    0.9594 |           0.0654 |      1.0000 |             9.4670 |      1131.2131 |      0.0347 |      81.2895 |      0.9998 | \n",
      "2018-06-16 09:14:37,723 - logHandler - train - INFO - Iteration: 9, XGBoost max auc: -0.152022\n",
      "2018-06-16 09:14:37,725 - logHandler - train - INFO - Param max_delta_step: 0.5705717903943563\n",
      "2018-06-16 09:14:37,727 - logHandler - train - INFO - Param reg_lambda: 80.28290557109493\n",
      "2018-06-16 09:14:37,729 - logHandler - train - INFO - Param reg_alpha: 0.021090709817583386\n",
      "2018-06-16 09:14:37,730 - logHandler - train - INFO - Param n_estimators: 1134.9276052859964\n",
      "2018-06-16 09:14:37,732 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 09:14:37,733 - logHandler - train - INFO - Param subsample: 0.932683198306179\n",
      "2018-06-16 09:14:37,735 - logHandler - train - INFO - Param min_child_weight: 10.727563655339614\n",
      "2018-06-16 09:14:37,736 - logHandler - train - INFO - Param gamma: 0.18393696018162453\n",
      "2018-06-16 09:14:37,738 - logHandler - train - INFO - Param colsample_bytree: 0.9241993163531039\n",
      "2018-06-16 09:14:37,739 - logHandler - train - INFO - Param colsample_bylevel: 0.9823787513482977\n",
      "2018-06-16 09:14:37,741 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 09:14:38,450 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 09:14:38,451 - logHandler - train - INFO - Iteration 10, Current random seed: 10\n",
      "2018-06-16 09:14:38,452 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 09:14:38,454 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.16038\u001b[0m | \u001b[32m             0.9991\u001b[0m | \u001b[32m            0.9200\u001b[0m | \u001b[32m   0.1353\u001b[0m | \u001b[32m          9.2247\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.2386\u001b[0m | \u001b[32m     1127.8162\u001b[0m | \u001b[32m     0.2134\u001b[0m | \u001b[32m     84.6362\u001b[0m | \u001b[32m     0.9712\u001b[0m | \n",
      "    2 | 00m02s | \u001b[35m  -0.15525\u001b[0m | \u001b[32m             0.9349\u001b[0m | \u001b[32m            0.8571\u001b[0m | \u001b[32m   0.8862\u001b[0m | \u001b[32m          1.7646\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.7267\u001b[0m | \u001b[32m     1124.7309\u001b[0m | \u001b[32m     0.2371\u001b[0m | \u001b[32m     74.7882\u001b[0m | \u001b[32m     0.9197\u001b[0m | \n",
      "    3 | 00m02s |   -0.16011 |              0.9330 |             0.9316 |    0.3811 |           7.3864 |      1.0000 |             9.6920 |      1125.8318 |      0.1401 |      74.2833 |      0.9634 | \n",
      "    4 | 00m01s |   -0.15633 |              0.9895 |             0.8693 |    0.8826 |           0.3726 |      1.0000 |            10.9464 |      1128.4112 |      0.0506 |      77.4376 |      0.9081 | \n",
      "    5 | 00m02s |   -0.15930 |              0.9910 |             0.9084 |    0.0632 |           5.2568 |      1.0000 |            10.8941 |      1126.6097 |      0.0975 |      84.0435 |      0.9527 | \n",
      "    6 | 00m02s |   -0.15607 |              0.9708 |             0.8079 |    0.5578 |           2.6843 |      1.0000 |             9.5962 |      1123.7288 |      0.1191 |      82.3439 |      0.9853 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m15s |   -0.16334 |              0.9889 |             0.9178 |    0.9537 |           8.7589 |      1.0000 |            10.7330 |      1120.0048 |      0.0753 |      84.2770 |      0.9201 | \n",
      "    8 | 00m15s |   -0.15768 |              0.9634 |             0.9317 |    0.0935 |           0.1376 |      1.0000 |             8.8960 |      1120.5313 |      0.2232 |      70.1220 |      0.9586 | \n",
      "    9 | 00m16s | \u001b[35m  -0.15390\u001b[0m | \u001b[32m             0.9643\u001b[0m | \u001b[32m            0.8267\u001b[0m | \u001b[32m   0.9033\u001b[0m | \u001b[32m          0.5627\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.1041\u001b[0m | \u001b[32m     1134.0195\u001b[0m | \u001b[32m     0.2744\u001b[0m | \u001b[32m     84.2506\u001b[0m | \u001b[32m     0.9658\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.06585903e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-6.26331511e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10 | 00m17s |   -0.15984 |              0.9044 |             0.8017 |    0.8077 |           2.3638 |      1.0000 |             8.1357 |      1134.9503 |      0.2751 |      70.3382 |      0.9292 | \n",
      "   11 | 00m17s |   -0.15930 |              0.9163 |             0.9986 |    0.8840 |           0.1340 |      1.0000 |             8.2007 |      1126.4888 |      0.2992 |      83.8556 |      0.9118 | \n",
      "   12 | 00m17s |   -0.16037 |              0.9020 |             0.8288 |    0.9932 |           9.4699 |      1.0000 |            10.4239 |      1134.8149 |      0.0668 |      83.9433 |      0.9845 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.74662733e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 00m17s |   -0.16280 |              0.9100 |             0.8449 |    0.0899 |           0.5090 |      1.0000 |             8.5682 |      1134.6559 |      0.2681 |      78.3909 |      0.9334 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([6.3961746e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 00m18s |   -0.15606 |              0.9099 |             0.8433 |    0.9714 |           1.4317 |      1.0000 |             8.1648 |      1126.2751 |      0.0084 |      70.6247 |      0.9832 | \n",
      "   15 | 00m18s |   -0.15849 |              0.9047 |             0.8609 |    0.9843 |           5.8498 |      1.0000 |            10.8774 |      1120.0903 |      0.0760 |      70.0452 |      0.9829 | \n",
      "   16 | 00m19s |   -0.15930 |              0.9648 |             0.8102 |    0.9763 |           5.3500 |      1.0000 |             8.1796 |      1132.6692 |      0.0048 |      84.4120 |      0.9628 | \n",
      "   17 | 00m17s |   -0.15606 |              0.9544 |             0.8382 |    0.0317 |           0.1913 |      1.0000 |            10.9795 |      1120.6001 |      0.0194 |      84.6967 |      0.9844 | \n",
      "   18 | 00m18s |   -0.15445 |              0.9838 |             0.8047 |    0.0365 |           0.2123 |      1.0000 |            10.7164 |      1133.6755 |      0.1185 |      84.9759 |      0.9714 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-9.99334366e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 00m18s |   -0.15957 |              0.9378 |             0.8071 |    0.7223 |           0.0988 |      1.0000 |            10.7046 |      1127.2918 |      0.2838 |      70.1978 |      0.9829 | \n",
      "   20 | 00m19s |   -0.15903 |              0.9148 |             0.8828 |    0.9388 |           9.8629 |      1.0000 |             8.0245 |      1133.4520 |      0.0792 |      70.0543 |      0.9426 | \n",
      "   21 | 00m18s |   -0.15741 |              0.9624 |             0.8711 |    0.9124 |           9.1920 |      1.0000 |             8.0052 |      1120.9469 |      0.2767 |      70.3197 |      0.9587 | \n",
      "   22 | 00m18s |   -0.15822 |              0.9980 |             0.8577 |    0.9952 |           0.4330 |      1.0000 |            10.2843 |      1120.1848 |      0.2970 |      75.1648 |      0.9828 | \n",
      "   23 | 00m18s |   -0.16118 |              0.9089 |             0.8051 |    0.8639 |           0.0115 |      1.0000 |            10.8223 |      1125.4301 |      0.2604 |      83.5007 |      0.9922 | \n",
      "   24 | 00m19s |   -0.16091 |              0.9835 |             0.8120 |    0.0251 |           4.8762 |      1.0000 |             8.1032 |      1120.8599 |      0.0503 |      76.0474 |      0.9068 | \n",
      "   25 | 00m18s |   -0.15634 |              0.9723 |             0.8343 |    0.9414 |           0.8812 |      1.0000 |             8.1671 |      1120.2276 |      0.1668 |      84.8589 |      0.9277 | \n",
      "   26 | 00m19s |   -0.15661 |              0.9577 |             0.9595 |    0.0421 |           0.0321 |      1.0000 |             8.1422 |      1134.8714 |      0.1612 |      84.8016 |      0.9048 | \n",
      "   27 | 00m18s |   -0.15660 |              0.9495 |             0.9476 |    0.9861 |           0.0741 |      1.0000 |            10.7081 |      1134.8154 |      0.1265 |      84.0118 |      0.9578 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([8.68225652e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 00m20s |   -0.15930 |              0.9044 |             0.8058 |    0.8743 |           8.0472 |      1.0000 |            10.9706 |      1134.7503 |      0.2661 |      70.1622 |      0.9690 | \n",
      "   29 | 00m20s |   -0.15984 |              0.9933 |             0.8431 |    0.1581 |           9.8011 |      1.0000 |            10.8510 |      1124.9941 |      0.2672 |      70.3783 |      0.9732 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0001029]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 00m21s |   -0.16038 |              0.9760 |             0.8151 |    0.9812 |           3.7826 |      1.0000 |             8.1342 |      1128.8451 |      0.2988 |      70.9203 |      0.9992 | \n",
      "   31 | 00m19s |   -0.15580 |              0.9715 |             0.8049 |    0.9630 |           9.5777 |      1.0000 |            10.9913 |      1125.1541 |      0.2186 |      79.1133 |      0.9209 | \n",
      "   32 | 00m19s |   -0.15903 |              0.9366 |             0.8153 |    0.9547 |           9.5404 |      1.0000 |            10.9298 |      1134.6648 |      0.0234 |      75.5568 |      0.9051 | \n",
      "   33 | 00m19s |   -0.15983 |              0.9253 |             0.8053 |    0.2297 |           0.0736 |      1.0000 |             8.1132 |      1122.7625 |      0.0052 |      79.0900 |      0.9903 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.6055468e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 00m19s |   -0.15714 |              0.9964 |             0.8038 |    0.9992 |           0.3031 |      1.0000 |            10.1260 |      1122.4434 |      0.0237 |      70.4248 |      0.9925 | \n",
      "   35 | 00m21s |   -0.15822 |              0.9304 |             0.8514 |    0.1861 |           9.9852 |      1.0000 |            10.9980 |      1120.1256 |      0.0031 |      76.3936 |      0.9872 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([8.06252247e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 | 00m21s |   -0.16011 |              0.9354 |             0.9356 |    0.0620 |           4.2225 |      1.0000 |             8.7660 |      1120.5080 |      0.2992 |      84.9329 |      0.9619 | \n",
      "   37 | 00m23s |   -0.15714 |              0.9998 |             0.9304 |    0.9219 |           0.0695 |      1.0000 |             8.0600 |      1127.1026 |      0.2454 |      74.5646 |      0.9731 | \n",
      "   38 | 00m22s |   -0.16145 |              0.9995 |             0.8359 |    0.7596 |           0.2402 |      1.0000 |             8.3832 |      1132.5762 |      0.0790 |      84.9908 |      0.9420 | \n",
      "   39 | 00m22s |   -0.15849 |              0.9415 |             0.8474 |    0.1836 |           5.0818 |      1.0000 |            10.7118 |      1134.9614 |      0.2835 |      84.0323 |      0.9785 | \n",
      "   40 | 00m22s |   -0.16146 |              0.9967 |             0.8630 |    0.9099 |           9.9520 |      1.0000 |             8.0481 |      1134.6892 |      0.1075 |      80.2079 |      0.9883 | \n",
      "   41 | 00m23s |   -0.15768 |              0.9011 |             0.8301 |    0.8973 |           4.9099 |      1.0000 |             8.0398 |      1128.7321 |      0.2835 |      79.6530 |      0.9494 | \n",
      "   42 | 00m22s |   -0.16092 |              0.9284 |             0.8677 |    0.8918 |           0.2009 |      1.0000 |            10.9675 |      1134.8807 |      0.2608 |      70.3429 |      0.9552 | \n",
      "   43 | 00m22s |   -0.15984 |              0.9559 |             0.8651 |    0.9710 |           9.1056 |      1.0000 |             8.2997 |      1134.9759 |      0.1753 |      84.8838 |      0.9129 | \n",
      "   44 | 00m23s |   -0.15499 |              0.9283 |             0.9415 |    0.0231 |           0.1581 |      1.0000 |            10.9166 |      1120.1395 |      0.2804 |      81.6250 |      0.9198 | \n",
      "   45 | 00m23s |   -0.15930 |              0.9912 |             0.9975 |    0.9827 |           9.9077 |      1.0000 |            10.9381 |      1126.9377 |      0.0193 |      72.9127 |      0.9932 | \n",
      "   46 | 00m22s |   -0.15768 |              0.9790 |             0.8316 |    0.8529 |           3.1567 |      1.0000 |             8.1600 |      1120.0450 |      0.2409 |      70.3354 |      0.9143 | \n",
      "   47 | 00m24s |   -0.15903 |              0.9845 |             0.8318 |    0.9846 |           9.8579 |      1.0000 |             8.1055 |      1123.5584 |      0.0962 |      82.6049 |      0.9681 | \n",
      "   48 | 00m23s |   -0.15741 |              0.9994 |             0.9093 |    0.8985 |           4.7546 |      1.0000 |            10.9909 |      1124.3585 |      0.2013 |      77.3333 |      0.9989 | \n",
      "   49 | 00m35s |   -0.15849 |              0.9255 |             0.8199 |    0.9555 |           9.6492 |      1.0000 |            10.9093 |      1121.9287 |      0.1707 |      73.6293 |      0.9008 | \n",
      "   50 | 00m41s |   -0.15741 |              0.9897 |             0.8019 |    0.0434 |           0.0244 |      1.0000 |            10.9895 |      1124.3380 |      0.2553 |      74.5568 |      0.9227 | \n",
      "   51 | 00m40s |   -0.15472 |              0.9694 |             0.8182 |    0.9660 |           0.0248 |      1.0000 |             8.0357 |      1120.1330 |      0.1327 |      70.0776 |      0.9296 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00016916]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00109889]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   52 | 00m43s |   -0.15418 |              0.9097 |             0.8016 |    0.6347 |           0.3567 |      1.0000 |            10.1341 |      1134.9299 |      0.2836 |      84.5145 |      0.9186 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.09623247e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53 | 00m41s |   -0.16037 |              0.9119 |             0.9703 |    0.1307 |           0.7369 |      1.0000 |            10.5581 |      1132.3315 |      0.2902 |      82.0865 |      0.9432 | \n",
      "   54 | 00m45s |   -0.16227 |              0.9106 |             0.8713 |    0.0586 |           9.9285 |      1.0000 |             9.1284 |      1120.1778 |      0.0518 |      70.2163 |      0.9065 | \n",
      "   55 | 00m44s | \u001b[35m  -0.15337\u001b[0m | \u001b[32m             0.9410\u001b[0m | \u001b[32m            0.9371\u001b[0m | \u001b[32m   0.0864\u001b[0m | \u001b[32m          9.7147\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.9986\u001b[0m | \u001b[32m     1124.0241\u001b[0m | \u001b[32m     0.2787\u001b[0m | \u001b[32m     84.1534\u001b[0m | \u001b[32m     0.9787\u001b[0m | \n",
      "   56 | 00m45s |   -0.16065 |              0.9074 |             0.8527 |    0.9577 |           9.9717 |      1.0000 |            10.7766 |      1126.3870 |      0.2997 |      84.5690 |      0.9739 | \n",
      "   57 | 00m42s |   -0.15849 |              0.9023 |             0.9147 |    0.0235 |           9.8592 |      1.0000 |            10.9273 |      1120.7593 |      0.1351 |      81.8691 |      0.9683 | \n",
      "   58 | 00m47s |   -0.16307 |              0.9193 |             0.8488 |    0.9299 |           9.8614 |      1.0000 |             8.0208 |      1124.3528 |      0.1377 |      75.6999 |      0.9551 | \n",
      "   59 | 00m48s |   -0.15822 |              0.9030 |             0.8032 |    0.8885 |           0.0487 |      1.0000 |             8.1651 |      1134.7795 |      0.1490 |      81.5958 |      0.9932 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00161786]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   60 | 00m48s |   -0.15714 |              0.9251 |             0.9215 |    0.0950 |           9.9220 |      1.0000 |            10.9486 |      1134.2469 |      0.1899 |      70.1962 |      0.9620 | \n",
      "   61 | 00m42s |   -0.15876 |              0.9956 |             0.8638 |    0.0017 |           9.9257 |      1.0000 |            10.8688 |      1130.0026 |      0.0004 |      81.0256 |      0.9485 | \n",
      "   62 | 00m44s |   -0.15687 |              0.9979 |             0.9512 |    0.9867 |           5.4491 |      1.0000 |             8.0318 |      1124.4680 |      0.2641 |      83.3206 |      0.9452 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0004319]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   63 | 00m49s |   -0.15714 |              0.9992 |             0.8040 |    0.2584 |           0.1324 |      1.0000 |             8.1842 |      1122.3074 |      0.2805 |      84.5906 |      0.9154 | \n",
      "   64 | 00m49s |   -0.16011 |              0.9003 |             0.9782 |    0.9474 |           5.7485 |      1.0000 |             8.1179 |      1124.6158 |      0.0172 |      70.0515 |      0.9369 | \n",
      "   65 | 00m48s |   -0.15795 |              0.9308 |             0.8661 |    0.0153 |           2.2488 |      1.0000 |            10.9605 |      1131.5837 |      0.0736 |      75.0250 |      0.9999 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00171858]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   66 | 00m47s |   -0.16388 |              0.9798 |             0.8045 |    0.2818 |           2.8800 |      1.0000 |             8.0646 |      1134.8667 |      0.2830 |      84.9999 |      0.9528 | \n",
      "   67 | 00m48s |   -0.15715 |              0.9544 |             0.8828 |    0.9146 |           0.0124 |      1.0000 |             8.0447 |      1134.7305 |      0.2151 |      73.3778 |      0.9931 | \n",
      "   68 | 00m50s |   -0.15606 |              0.9271 |             0.8486 |    0.0905 |           0.0188 |      1.0000 |             8.1198 |      1134.9880 |      0.0714 |      70.5791 |      0.9656 | \n",
      "   69 | 00m48s |   -0.15499 |              0.9772 |             0.9996 |    0.7603 |           6.3503 |      1.0000 |            10.9931 |      1132.3125 |      0.2997 |      80.3929 |      0.9929 | \n",
      "   70 | 00m53s |   -0.16118 |              0.9556 |             0.8420 |    0.7535 |           4.7868 |      1.0000 |            10.9945 |      1120.1963 |      0.2879 |      81.0573 |      0.9006 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.0002036]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   71 | 00m51s |   -0.15903 |              0.9161 |             0.9997 |    0.9967 |           0.2546 |      1.0000 |             8.2974 |      1133.3905 |      0.1886 |      70.0845 |      0.9847 | \n",
      "   72 | 00m56s |   -0.15876 |              0.9273 |             0.9893 |    0.0236 |           9.9256 |      1.0000 |            10.9696 |      1132.0774 |      0.2614 |      74.8005 |      0.9844 | \n",
      "   73 | 00m50s |   -0.15688 |              0.9987 |             0.8716 |    0.0414 |           0.0722 |      1.0000 |            10.8477 |      1134.5760 |      0.2798 |      84.8962 |      0.9911 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00163755]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 | 00m53s |   -0.15741 |              0.9243 |             0.9143 |    0.4233 |           9.7136 |      1.0000 |             8.0254 |      1121.0400 |      0.2855 |      84.9918 |      0.9133 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00011418]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   75 | 00m52s |   -0.15552 |              0.9921 |             0.8386 |    0.0487 |           6.5714 |      1.0000 |            10.8920 |      1132.0385 |      0.0199 |      70.1730 |      0.9271 | \n",
      "   76 | 00m55s |   -0.15849 |              0.9736 |             0.8281 |    0.9429 |           5.1229 |      1.0000 |             8.2150 |      1134.9917 |      0.2839 |      76.6549 |      0.9162 | \n",
      "   77 | 00m53s |   -0.15714 |              0.9889 |             0.8153 |    0.9879 |           9.9577 |      1.0000 |            10.9604 |      1131.7513 |      0.1514 |      70.4242 |      0.9427 | \n",
      "   78 | 00m53s |   -0.15876 |              0.9023 |             0.8137 |    0.8449 |           0.2670 |      1.0000 |            10.9973 |      1120.0683 |      0.2185 |      70.0220 |      0.9770 | \n",
      "   79 | 00m51s |   -0.16038 |              0.9244 |             0.8348 |    0.9543 |           5.3553 |      1.0000 |            10.9065 |      1132.2540 |      0.2273 |      84.8350 |      0.9218 | \n",
      "   80 | 00m52s |   -0.15660 |              0.9332 |             0.8838 |    0.0166 |           5.4112 |      1.0000 |            10.9734 |      1134.7553 |      0.0391 |      79.8433 |      0.9075 | \n",
      "   81 | 00m57s |   -0.15930 |              0.9435 |             0.9939 |    0.9665 |           8.5178 |      1.0000 |             8.0203 |      1120.2380 |      0.2046 |      78.1597 |      0.9193 | \n",
      "   82 | 00m54s |   -0.15795 |              0.9357 |             0.9990 |    0.9331 |           2.2508 |      1.0000 |             8.0215 |      1121.1565 |      0.0379 |      82.3640 |      0.9031 | \n",
      "   83 | 00m55s |   -0.16038 |              0.9048 |             0.9464 |    0.9715 |           5.7061 |      1.0000 |             8.1814 |      1134.2574 |      0.2778 |      81.6115 |      0.9363 | \n",
      "   84 | 00m53s |   -0.16038 |              0.9607 |             0.8188 |    0.9595 |           6.1005 |      1.0000 |            10.8243 |      1130.0443 |      0.0072 |      76.4913 |      0.9004 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00020948]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   85 | 00m56s |   -0.15607 |              0.9963 |             0.9883 |    0.2850 |           5.4729 |      1.0000 |            10.9371 |      1120.8165 |      0.2113 |      73.5266 |      0.9082 | \n",
      "   86 | 00m54s |   -0.15714 |              0.9400 |             0.9027 |    0.0087 |           3.5404 |      1.0000 |            10.8596 |      1126.9793 |      0.2845 |      79.2374 |      0.9046 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00247712]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   87 | 01m01s |   -0.16361 |              0.9568 |             0.8264 |    0.0521 |           4.3987 |      1.0000 |            10.8735 |      1134.7020 |      0.0975 |      72.8475 |      0.9397 | \n",
      "   88 | 00m59s |   -0.16145 |              0.9379 |             0.9452 |    0.0445 |           3.2767 |      1.0000 |            10.9624 |      1126.5860 |      0.0853 |      70.5091 |      0.9577 | \n",
      "   89 | 00m56s |   -0.15606 |              0.9035 |             0.9865 |    0.9977 |           0.4571 |      1.0000 |             8.0026 |      1123.9023 |      0.2632 |      70.0832 |      0.9083 | \n",
      "   90 | 01m02s |   -0.16011 |              0.9249 |             0.8273 |    0.0194 |           0.1430 |      1.0000 |            10.9071 |      1132.6644 |      0.0774 |      70.0976 |      0.9353 | \n",
      "   91 | 01m02s |   -0.15607 |              0.9018 |             0.9883 |    0.1426 |           7.2845 |      1.0000 |            10.9259 |      1124.6866 |      0.0480 |      81.4066 |      0.9943 | \n",
      "   92 | 01m00s |   -0.16118 |              0.9111 |             0.8181 |    0.0251 |           7.3788 |      1.0000 |            10.8979 |      1133.2460 |      0.2378 |      81.3971 |      0.9043 | \n",
      "   93 | 00m55s |   -0.15903 |              0.9638 |             0.8020 |    0.8847 |           2.9404 |      1.0000 |            10.7097 |      1133.7403 |      0.0319 |      81.2865 |      0.9939 | \n",
      "   94 | 00m57s |   -0.15498 |              0.9619 |             0.9929 |    0.9466 |           5.3551 |      1.0000 |             8.1833 |      1120.1189 |      0.1760 |      73.0730 |      0.9916 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00244587]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   95 | 01m05s |   -0.15984 |              0.9316 |             0.9882 |    0.9745 |           9.9076 |      1.0000 |             8.1718 |      1128.8483 |      0.2444 |      80.6166 |      0.9907 | \n",
      "   96 | 01m01s |   -0.15714 |              0.9724 |             0.9584 |    0.0984 |           9.9848 |      1.0000 |             8.8095 |      1129.3886 |      0.2910 |      70.1181 |      0.9548 | \n",
      "   97 | 01m04s |   -0.15741 |              0.9759 |             0.9836 |    0.0635 |           9.9207 |      1.0000 |            10.9169 |      1125.1734 |      0.2824 |      77.6993 |      0.9601 | \n",
      "   98 | 01m00s |   -0.15902 |              0.9013 |             0.8250 |    0.3641 |           0.0786 |      1.0000 |             8.3405 |      1120.1116 |      0.0701 |      83.0048 |      0.9714 | \n",
      "   99 | 01m01s |   -0.15795 |              0.9767 |             0.8245 |    0.9700 |           7.6369 |      1.0000 |             9.3870 |      1120.2014 |      0.2986 |      75.0027 |      0.9676 | \n",
      "  100 | 01m05s |   -0.16334 |              0.9326 |             0.9072 |    0.9069 |           0.3536 |      1.0000 |             8.7469 |      1134.9605 |      0.1261 |      84.9841 |      0.9739 | \n",
      "  101 | 01m09s |   -0.15660 |              0.9757 |             0.9803 |    0.0194 |           0.4059 |      1.0000 |             8.0876 |      1127.5850 |      0.0130 |      70.9257 |      0.9020 | \n",
      "  102 | 01m06s |   -0.16037 |              0.9960 |             0.8640 |    0.3604 |           1.4667 |      1.0000 |             8.0135 |      1126.8889 |      0.2924 |      80.9322 |      0.9335 | \n",
      "  103 | 01m14s |   -0.15391 |              0.9625 |             0.9615 |    0.0070 |           9.3033 |      1.0000 |             8.0482 |      1134.3728 |      0.2727 |      73.3849 |      0.9019 | \n",
      "  104 | 01m00s |   -0.16011 |              0.9189 |             0.9933 |    0.9620 |           0.0258 |      1.0000 |            10.9722 |      1121.3116 |      0.0286 |      82.2252 |      0.9272 | \n",
      "  105 | 01m08s |   -0.15607 |              0.9667 |             0.9736 |    0.9798 |           9.7384 |      1.0000 |            10.5151 |      1120.0390 |      0.0305 |      70.1893 |      0.9532 | \n",
      "  106 | 01m06s |   -0.15876 |              0.9860 |             0.8072 |    0.9734 |           0.0477 |      1.0000 |            10.9460 |      1130.4990 |      0.0215 |      74.5001 |      0.9173 | \n",
      "2018-06-16 10:22:06,378 - logHandler - train - INFO - Iteration: 10, XGBoost max auc: -0.153368\n",
      "2018-06-16 10:22:06,380 - logHandler - train - INFO - Param max_delta_step: 9.714685729295336\n",
      "2018-06-16 10:22:06,382 - logHandler - train - INFO - Param reg_lambda: 84.15339729536973\n",
      "2018-06-16 10:22:06,383 - logHandler - train - INFO - Param reg_alpha: 0.2786652950064102\n",
      "2018-06-16 10:22:06,385 - logHandler - train - INFO - Param n_estimators: 1124.0241191097145\n",
      "2018-06-16 10:22:06,387 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 10:22:06,388 - logHandler - train - INFO - Param subsample: 0.978654607383983\n",
      "2018-06-16 10:22:06,390 - logHandler - train - INFO - Param min_child_weight: 10.998568043199977\n",
      "2018-06-16 10:22:06,391 - logHandler - train - INFO - Param gamma: 0.08635228480740675\n",
      "2018-06-16 10:22:06,393 - logHandler - train - INFO - Param colsample_bytree: 0.9370550414658004\n",
      "2018-06-16 10:22:06,395 - logHandler - train - INFO - Param colsample_bylevel: 0.9409506926707077\n",
      "2018-06-16 10:22:06,396 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 10:22:07,320 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 10:22:07,322 - logHandler - train - INFO - Iteration 11, Current random seed: 11\n",
      "2018-06-16 10:22:07,324 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 10:22:07,325 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.15849\u001b[0m | \u001b[32m             0.9400\u001b[0m | \u001b[32m            0.9931\u001b[0m | \u001b[32m   0.7448\u001b[0m | \u001b[32m          0.1177\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.2686\u001b[0m | \u001b[32m     1121.8100\u001b[0m | \u001b[32m     0.2546\u001b[0m | \u001b[32m     72.2878\u001b[0m | \u001b[32m     0.9124\u001b[0m | \n",
      "    2 | 00m02s | \u001b[35m  -0.15769\u001b[0m | \u001b[32m             0.9447\u001b[0m | \u001b[32m            0.9587\u001b[0m | \u001b[32m   0.8552\u001b[0m | \u001b[32m          3.7974\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.5596\u001b[0m | \u001b[32m     1133.6619\u001b[0m | \u001b[32m     0.0416\u001b[0m | \u001b[32m     82.5255\u001b[0m | \u001b[32m     0.9477\u001b[0m | \n",
      "    3 | 00m02s |   -0.15930 |              0.9606 |             0.8845 |    0.6352 |           4.6765 |      1.0000 |            10.8861 |      1123.0472 |      0.0545 |      81.9821 |      0.9704 | \n",
      "    4 | 00m02s | \u001b[35m  -0.15580\u001b[0m | \u001b[32m             0.9718\u001b[0m | \u001b[32m            0.9492\u001b[0m | \u001b[32m   0.0850\u001b[0m | \u001b[32m          2.6685\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.6002\u001b[0m | \u001b[32m     1127.8547\u001b[0m | \u001b[32m     0.0143\u001b[0m | \u001b[32m     76.6881\u001b[0m | \u001b[32m     0.9452\u001b[0m | \n",
      "    5 | 00m01s |   -0.15984 |              0.9169 |             0.8649 |    0.8329 |           6.6935 |      1.0000 |            10.7243 |      1125.7228 |      0.0348 |      82.6915 |      0.9370 | \n",
      "    6 | 00m01s |   -0.15741 |              0.9950 |             0.8340 |    0.0686 |           0.9387 |      1.0000 |             8.4851 |      1133.1651 |      0.1636 |      80.4963 |      0.9312 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m15s |   -0.15633 |              0.9070 |             0.9288 |    0.1328 |           0.2127 |      1.0000 |            10.7682 |      1133.9941 |      0.2889 |      70.1690 |      0.9407 | \n",
      "    8 | 00m18s |   -0.15687 |              0.9484 |             0.9559 |    0.0009 |           9.8908 |      1.0000 |             9.0290 |      1133.8079 |      0.0005 |      70.6664 |      0.9840 | \n",
      "    9 | 00m16s |   -0.15984 |              0.9419 |             0.8161 |    0.1464 |           0.2205 |      1.0000 |            10.7060 |      1120.1496 |      0.0133 |      70.0719 |      0.9806 | \n",
      "   10 | 00m18s |   -0.16064 |              0.9889 |             0.9545 |    0.8921 |           1.0147 |      1.0000 |             8.1918 |      1133.1941 |      0.0009 |      71.7169 |      0.9569 | \n",
      "   11 | 00m17s |   -0.16092 |              0.9068 |             0.9650 |    0.0267 |           9.6499 |      1.0000 |            10.9167 |      1121.6484 |      0.2899 |      70.4362 |      0.9416 | \n",
      "   12 | 00m17s |   -0.16011 |              0.9928 |             0.9346 |    0.0104 |           9.1853 |      1.0000 |            10.7346 |      1134.2589 |      0.2896 |      79.9676 |      0.9572 | \n",
      "   13 | 00m18s |   -0.15876 |              0.9280 |             0.9061 |    0.7617 |           0.0891 |      1.0000 |            10.7514 |      1127.5175 |      0.2955 |      84.4970 |      0.9052 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([5.21490847e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 00m19s |   -0.15849 |              0.9195 |             0.9851 |    0.1073 |           3.4060 |      1.0000 |             8.0328 |      1120.4236 |      0.2101 |      84.8574 |      0.9284 | \n",
      "   15 | 00m18s |   -0.16065 |              0.9092 |             0.8103 |    0.8375 |           6.4387 |      1.0000 |            10.8863 |      1134.7271 |      0.2806 |      70.7782 |      0.9846 | \n",
      "   16 | 00m18s |   -0.15849 |              0.9040 |             0.9137 |    0.2761 |           0.0979 |      1.0000 |            10.8889 |      1134.9917 |      0.0385 |      84.5697 |      0.9196 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([4.58822356e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 00m18s |   -0.15741 |              0.9390 |             0.9520 |    0.0231 |           6.9097 |      1.0000 |             8.0179 |      1127.5787 |      0.2607 |      70.4994 |      0.9230 | \n",
      "   18 | 00m18s |   -0.15795 |              0.9016 |             0.9741 |    0.9656 |           9.8593 |      1.0000 |             8.0091 |      1122.9421 |      0.0507 |      80.1357 |      0.9332 | \n",
      "   19 | 00m19s |   -0.16064 |              0.9711 |             0.9828 |    0.0187 |           6.5256 |      1.0000 |             8.0075 |      1132.1469 |      0.2826 |      84.7667 |      0.9824 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00014314]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 00m18s |   -0.16092 |              0.9002 |             0.9886 |    0.0439 |           0.3065 |      1.0000 |            10.6180 |      1133.2068 |      0.0009 |      75.7881 |      0.9780 | \n",
      "   21 | 00m19s |   -0.15957 |              0.9944 |             0.8071 |    0.0951 |           0.0018 |      1.0000 |             8.0959 |      1124.4334 |      0.0254 |      81.7427 |      0.9294 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-6.60810169e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 00m20s | \u001b[35m  -0.15256\u001b[0m | \u001b[32m             0.9795\u001b[0m | \u001b[32m            0.8649\u001b[0m | \u001b[32m   0.0729\u001b[0m | \u001b[32m          6.2388\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.0223\u001b[0m | \u001b[32m     1120.5124\u001b[0m | \u001b[32m     0.2103\u001b[0m | \u001b[32m     77.1490\u001b[0m | \u001b[32m     0.9114\u001b[0m | \n",
      "   23 | 00m20s |   -0.15687 |              0.9967 |             0.9366 |    0.2071 |           9.9169 |      1.0000 |             8.4289 |      1120.4877 |      0.2306 |      84.6521 |      0.9560 | \n",
      "   24 | 00m20s |   -0.15606 |              0.9300 |             0.8327 |    0.0357 |           9.9986 |      1.0000 |             8.0305 |      1120.2007 |      0.2275 |      71.4819 |      0.9604 | \n",
      "   25 | 00m18s |   -0.15957 |              0.9120 |             0.9917 |    0.1052 |           4.7162 |      1.0000 |             8.4193 |      1134.9438 |      0.2069 |      70.0149 |      0.9615 | \n",
      "   26 | 00m19s |   -0.15957 |              0.9663 |             0.8210 |    0.0463 |           9.7436 |      1.0000 |             8.4588 |      1120.1487 |      0.2732 |      76.0198 |      0.9159 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00023762]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 37, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   27 | 00m19s |   -0.15552 |              0.9519 |             0.9918 |    0.8728 |           4.3044 |      1.0000 |             8.0559 |      1120.5114 |      0.0780 |      70.1035 |      0.9842 | \n",
      "   28 | 00m20s |   -0.16011 |              0.9879 |             0.8371 |    0.9677 |           5.2389 |      1.0000 |             8.0999 |      1124.9598 |      0.2938 |      81.4087 |      0.9777 | \n",
      "   29 | 00m20s |   -0.16038 |              0.9446 |             0.8915 |    0.9654 |           9.8189 |      1.0000 |             8.3943 |      1134.2546 |      0.0314 |      84.6150 |      0.9176 | \n",
      "   30 | 00m22s |   -0.15364 |              0.9694 |             0.9914 |    0.0779 |           3.6539 |      1.0000 |             8.0247 |      1120.1715 |      0.0346 |      74.6724 |      0.9655 | \n",
      "   31 | 00m21s |   -0.15633 |              0.9499 |             0.9367 |    0.9463 |           9.6803 |      1.0000 |             8.1673 |      1134.9553 |      0.1509 |      70.1265 |      0.9217 | \n",
      "   32 | 00m21s |   -0.15903 |              0.9652 |             0.8609 |    0.0369 |           0.1894 |      1.0000 |            10.9107 |      1127.4433 |      0.0450 |      70.0070 |      0.9295 | \n",
      "   33 | 00m20s |   -0.16038 |              0.9151 |             0.9751 |    0.0064 |           0.5297 |      1.0000 |             8.0004 |      1120.1932 |      0.2911 |      70.4966 |      0.9008 | \n",
      "   34 | 00m21s |   -0.15984 |              0.9974 |             0.9277 |    0.9786 |           0.8043 |      1.0000 |            10.4250 |      1120.0541 |      0.2857 |      76.8606 |      0.9046 | \n",
      "   35 | 00m21s |   -0.15768 |              0.9501 |             0.9314 |    0.2597 |           8.8338 |      1.0000 |             8.0124 |      1134.9479 |      0.0557 |      76.6397 |      0.9109 | \n",
      "   36 | 00m22s |   -0.15768 |              0.9834 |             0.8643 |    0.9668 |           9.7408 |      1.0000 |             8.1981 |      1124.3675 |      0.0299 |      70.0408 |      0.9574 | \n",
      "   37 | 00m34s |   -0.16064 |              0.9134 |             0.8441 |    0.0009 |           6.6362 |      1.0000 |             8.0786 |      1122.9839 |      0.0514 |      73.4151 |      0.9104 | \n",
      "   38 | 00m24s |   -0.16146 |              0.9619 |             0.9553 |    0.8814 |           9.9560 |      1.0000 |             8.0425 |      1120.1486 |      0.0845 |      70.0229 |      0.9490 | \n",
      "   39 | 00m23s |   -0.15418 |              0.9974 |             0.8805 |    0.1058 |           9.9726 |      1.0000 |             8.1214 |      1127.5179 |      0.0072 |      82.5036 |      0.9558 | \n",
      "   40 | 00m22s |   -0.15850 |              0.9572 |             0.8733 |    0.9023 |           0.1987 |      1.0000 |             8.0713 |      1134.5116 |      0.1288 |      84.3802 |      0.9806 | \n",
      "   41 | 00m23s |   -0.15714 |              0.9083 |             0.8867 |    0.0091 |           5.8636 |      1.0000 |             8.0449 |      1120.1448 |      0.1548 |      79.9750 |      0.9756 | \n",
      "   42 | 00m23s |   -0.15741 |              0.9798 |             0.9966 |    0.0763 |           0.3386 |      1.0000 |            10.9827 |      1120.1677 |      0.2111 |      84.2499 |      0.9807 | \n",
      "   43 | 00m24s |   -0.15363 |              0.9864 |             0.9525 |    0.5500 |           9.9700 |      1.0000 |             8.0896 |      1128.8220 |      0.2797 |      77.2608 |      0.9606 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00021032]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   44 | 00m23s |   -0.15903 |              0.9913 |             0.9010 |    0.1797 |           9.6720 |      1.0000 |            10.9675 |      1127.2679 |      0.1908 |      84.8722 |      0.9964 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00032109]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 66, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 | 00m23s |   -0.16092 |              0.9751 |             0.9257 |    0.9681 |           0.3456 |      1.0000 |            10.9376 |      1129.2832 |      0.2872 |      79.4311 |      0.9008 | \n",
      "   46 | 00m25s |   -0.15741 |              0.9969 |             0.8683 |    0.1493 |           9.6297 |      1.0000 |            10.9713 |      1127.8640 |      0.2427 |      70.0728 |      0.9843 | \n",
      "   47 | 00m24s |   -0.15795 |              0.9944 |             0.9469 |    0.1991 |           4.4542 |      1.0000 |            10.8819 |      1120.8916 |      0.2900 |      70.3611 |      0.9896 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00014033]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00034591]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-7.09054439e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 00m24s |   -0.16038 |              0.9992 |             0.9581 |    0.2511 |           5.5148 |      1.0000 |            10.8241 |      1120.3654 |      0.0247 |      84.9706 |      0.9719 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00057677]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00019272]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 00m34s |   -0.15930 |              0.9922 |             0.8667 |    0.8929 |           0.3223 |      1.0000 |             8.3948 |      1120.2481 |      0.1262 |      84.9673 |      0.9040 | \n",
      "   50 | 00m39s |   -0.15688 |              0.9778 |             0.8603 |    0.4137 |           9.9261 |      1.0000 |             8.0734 |      1130.0617 |      0.2724 |      70.0172 |      0.9586 | \n",
      "   51 | 00m43s |   -0.15984 |              0.9941 |             0.9954 |    0.0316 |           9.0870 |      1.0000 |             8.1794 |      1121.5506 |      0.2497 |      70.0804 |      0.9121 | \n",
      "   52 | 00m40s |   -0.15714 |              0.9694 |             0.9975 |    0.0163 |           0.2257 |      1.0000 |             9.8047 |      1130.0798 |      0.0223 |      84.8383 |      0.9928 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00027973]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53 | 00m45s |   -0.15768 |              0.9723 |             0.9936 |    0.7977 |           9.9911 |      1.0000 |             8.0418 |      1131.6917 |      0.0099 |      81.4048 |      0.9987 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([4.28051571e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   54 | 00m48s |   -0.15687 |              0.9226 |             0.8839 |    0.8651 |           9.9708 |      1.0000 |             8.2367 |      1125.1610 |      0.0845 |      84.9248 |      0.9364 | \n",
      "   55 | 00m51s |   -0.15876 |              0.9428 |             0.8093 |    0.6147 |           3.3649 |      1.0000 |             8.1715 |      1120.1048 |      0.2445 |      75.4821 |      0.9818 | \n",
      "   56 | 00m50s |   -0.15768 |              0.9869 |             0.9936 |    0.7843 |           8.8843 |      1.0000 |            10.9633 |      1128.8737 |      0.0150 |      74.5340 |      0.9555 | \n",
      "   57 | 00m47s |   -0.15741 |              0.9647 |             0.9782 |    0.9037 |           0.4104 |      1.0000 |            10.9325 |      1134.5534 |      0.0986 |      70.2889 |      0.9996 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([5.23781346e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   58 | 00m48s |   -0.15553 |              0.9053 |             0.9301 |    0.2957 |           9.9750 |      1.0000 |            10.9965 |      1134.8968 |      0.1126 |      70.2335 |      0.9317 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00056428]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   59 | 00m43s |   -0.15499 |              0.9739 |             0.9944 |    0.0456 |           5.1861 |      1.0000 |             8.1098 |      1131.9446 |      0.0111 |      77.0353 |      0.9146 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00022037]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   60 | 00m46s |   -0.15984 |              0.9898 |             0.9970 |    0.3936 |           3.0664 |      1.0000 |            10.9970 |      1125.0561 |      0.0553 |      84.6923 |      0.9020 | \n",
      "   61 | 00m45s |   -0.16118 |              0.9049 |             0.9816 |    0.0179 |           5.5611 |      1.0000 |            10.9258 |      1120.0281 |      0.1444 |      76.1419 |      0.9897 | \n",
      "   62 | 00m45s |   -0.15903 |              0.9974 |             0.9164 |    0.9313 |           4.2505 |      1.0000 |            10.6539 |      1128.5484 |      0.0155 |      70.0427 |      0.9108 | \n",
      "   63 | 00m47s |   -0.15822 |              0.9583 |             0.9656 |    0.0335 |           9.9373 |      1.0000 |             8.0061 |      1126.3136 |      0.0047 |      72.6350 |      0.9822 | \n",
      "   64 | 00m47s |   -0.16038 |              0.9969 |             0.8697 |    0.9993 |           9.6870 |      1.0000 |            10.8193 |      1134.9065 |      0.2794 |      75.0643 |      0.9331 | \n",
      "   65 | 00m47s |   -0.15768 |              0.9802 |             0.8106 |    0.1469 |           0.2032 |      1.0000 |             9.3322 |      1134.9757 |      0.0066 |      70.0346 |      0.9700 | \n",
      "   66 | 00m49s |   -0.16172 |              0.9740 |             0.9523 |    0.1731 |           0.3169 |      1.0000 |            10.9866 |      1122.7912 |      0.0365 |      77.5671 |      0.9283 | \n",
      "   67 | 00m52s |   -0.16010 |              0.9865 |             0.9949 |    0.9396 |           0.7240 |      1.0000 |             8.0751 |      1126.0172 |      0.0783 |      70.1665 |      0.9149 | \n",
      "   68 | 00m56s |   -0.15957 |              0.9762 |             0.9730 |    0.0100 |           2.4965 |      1.0000 |             8.1614 |      1134.9079 |      0.2258 |      84.0101 |      0.9377 | \n",
      "   69 | 00m48s |   -0.15526 |              0.9985 |             0.9935 |    0.0648 |           9.9056 |      1.0000 |            10.9857 |      1126.0619 |      0.1812 |      79.5301 |      0.9061 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00035112]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   70 | 00m52s |   -0.15714 |              0.9991 |             0.9544 |    0.0839 |           6.6337 |      1.0000 |             8.2276 |      1128.0351 |      0.0702 |      78.3434 |      0.9501 | \n",
      "   71 | 00m52s |   -0.16334 |              0.9956 |             0.8914 |    0.9991 |           9.9011 |      1.0000 |            10.9103 |      1133.3633 |      0.2841 |      84.8690 |      0.9205 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.24680586e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   72 | 00m50s |   -0.15633 |              0.9954 |             0.9935 |    0.0044 |           9.9906 |      1.0000 |             8.3367 |      1122.6834 |      0.2902 |      82.9231 |      0.9016 | \n",
      "   73 | 00m52s |   -0.15742 |              0.9939 |             0.9951 |    0.0825 |           0.3914 |      1.0000 |             8.0284 |      1129.7986 |      0.0439 |      77.9176 |      0.9595 | \n",
      "   74 | 00m55s |   -0.15876 |              0.9616 |             0.8097 |    0.4414 |           9.9135 |      1.0000 |             9.7580 |      1130.5248 |      0.0825 |      78.1010 |      0.9107 | \n",
      "   75 | 00m56s |   -0.15822 |              0.9957 |             0.9394 |    0.9932 |           7.0741 |      1.0000 |             8.1535 |      1120.0064 |      0.0669 |      75.1752 |      0.9803 | \n",
      "   76 | 00m54s |   -0.16011 |              0.9460 |             0.9925 |    0.9490 |           3.4515 |      1.0000 |             9.0813 |      1134.9023 |      0.2944 |      77.3990 |      0.9282 | \n",
      "   77 | 00m48s |   -0.15741 |              0.9969 |             0.9907 |    0.0890 |           2.7310 |      1.0000 |            10.9948 |      1134.8416 |      0.0921 |      71.1795 |      0.9231 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00077998]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   78 | 00m56s |   -0.15633 |              0.9725 |             0.8574 |    0.0504 |           3.4657 |      1.0000 |             8.0574 |      1130.0625 |      0.2971 |      73.5459 |      0.9882 | \n",
      "   79 | 00m51s |   -0.15310 |              0.9418 |             0.9606 |    0.0352 |           0.0801 |      1.0000 |             8.2627 |      1125.1743 |      0.2022 |      84.9700 |      0.9071 | \n",
      "   80 | 00m52s |   -0.15633 |              0.9787 |             0.9738 |    0.7859 |           0.0113 |      1.0000 |             8.0985 |      1128.6780 |      0.0996 |      84.7635 |      0.9157 | \n",
      "   81 | 00m55s |   -0.15606 |              0.9964 |             0.9547 |    0.2952 |           3.9537 |      1.0000 |            10.9582 |      1130.9383 |      0.2849 |      77.2635 |      0.9177 | \n",
      "   82 | 00m55s |   -0.15769 |              0.9291 |             0.9818 |    0.9887 |           1.0411 |      1.0000 |            10.4642 |      1122.6900 |      0.2932 |      70.0216 |      0.9179 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00057465]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   83 | 00m53s |   -0.16308 |              0.9935 |             0.9981 |    0.9879 |           0.9408 |      1.0000 |            10.7895 |      1120.0545 |      0.1038 |      72.7896 |      0.9237 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00024355]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 47, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   84 | 00m53s |   -0.15741 |              0.9465 |             0.9710 |    0.0368 |           0.1158 |      1.0000 |             8.4237 |      1120.0992 |      0.0948 |      78.1243 |      0.9982 | \n",
      "   85 | 00m53s |   -0.15768 |              0.9123 |             0.9878 |    0.9869 |           9.8224 |      1.0000 |             8.0539 |      1132.1979 |      0.0438 |      73.3492 |      0.9294 | \n",
      "   86 | 00m57s |   -0.16092 |              0.9888 |             0.9396 |    0.9901 |           9.6415 |      1.0000 |            10.9603 |      1121.1715 |      0.2633 |      84.9950 |      0.9995 | \n",
      "   87 | 00m58s |   -0.15822 |              0.9897 |             0.9604 |    0.8771 |           9.9453 |      1.0000 |             8.5453 |      1128.1297 |      0.2983 |      83.1161 |      0.9317 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0027915]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   88 | 00m55s |   -0.15822 |              0.9933 |             0.9524 |    0.1034 |           2.6553 |      1.0000 |             8.6569 |      1122.8418 |      0.0773 |      70.1545 |      0.9870 | \n",
      "   89 | 00m56s |   -0.15714 |              0.9807 |             0.9699 |    0.0855 |           3.7688 |      1.0000 |             8.0832 |      1122.4555 |      0.0170 |      77.1913 |      0.9762 | \n",
      "   90 | 00m57s |   -0.15552 |              0.9415 |             0.8510 |    0.0287 |           5.1244 |      1.0000 |             8.3260 |      1120.0464 |      0.0028 |      71.7510 |      0.9247 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00044346]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   91 | 00m51s |   -0.16011 |              0.9880 |             0.9235 |    0.0795 |           9.9985 |      1.0000 |             8.1040 |      1125.9847 |      0.1599 |      79.2846 |      0.9376 | \n",
      "   92 | 00m56s |   -0.15876 |              0.9995 |             0.9374 |    0.8166 |           3.0697 |      1.0000 |             8.0085 |      1128.5355 |      0.0109 |      75.7738 |      0.9390 | \n",
      "   93 | 00m55s |   -0.15984 |              0.9901 |             0.8037 |    0.9048 |           4.7816 |      1.0000 |            10.9902 |      1134.9124 |      0.1615 |      84.5746 |      0.9857 | \n",
      "   94 | 01m06s |   -0.15687 |              0.9474 |             0.9880 |    0.0235 |           4.0351 |      1.0000 |            10.7489 |      1129.3317 |      0.1098 |      81.2809 |      0.9915 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00078049]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   95 | 01m00s |   -0.15687 |              0.9263 |             0.9759 |    0.9446 |           0.0600 |      1.0000 |             9.1026 |      1123.7493 |      0.0281 |      84.6626 |      0.9834 | \n",
      "   96 | 00m58s |   -0.15687 |              0.9853 |             0.9900 |    0.0772 |           9.9918 |      1.0000 |             8.0606 |      1130.8145 |      0.1895 |      76.0787 |      0.9109 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00070788]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   97 | 01m01s |   -0.15687 |              0.9430 |             0.9027 |    0.0516 |           9.8547 |      1.0000 |            10.8704 |      1120.0762 |      0.0728 |      82.6749 |      0.9620 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00095559]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   98 | 01m00s |   -0.15553 |              0.9294 |             0.8838 |    0.1065 |           9.9354 |      1.0000 |            10.9181 |      1134.8555 |      0.0011 |      84.4539 |      0.9287 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00261407]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   99 | 01m02s |   -0.16172 |              0.9727 |             0.8005 |    0.1463 |           6.5569 |      1.0000 |             8.1466 |      1134.5191 |      0.0105 |      80.6182 |      0.9712 | \n",
      "  100 | 01m03s |   -0.15822 |              0.9999 |             0.9813 |    0.0692 |           6.3749 |      1.0000 |             8.2604 |      1124.1586 |      0.0030 |      84.8365 |      0.9841 | \n",
      "  101 | 01m06s |   -0.15472 |              0.9730 |             0.8916 |    0.0635 |           9.9855 |      1.0000 |             8.1549 |      1131.2594 |      0.0075 |      84.7762 |      0.9887 | \n",
      "  102 | 01m00s |   -0.15418 |              0.9007 |             0.9944 |    0.1259 |           0.0641 |      1.0000 |             8.1744 |      1134.7049 |      0.2870 |      74.0152 |      0.9722 | \n",
      "  103 | 01m02s |   -0.15741 |              0.9864 |             0.9764 |    0.0053 |           4.6180 |      1.0000 |            10.9958 |      1128.1709 |      0.2854 |      76.4238 |      0.9613 | \n",
      "  104 | 01m03s |   -0.15391 |              0.9603 |             0.9928 |    0.0168 |           0.1056 |      1.0000 |             8.5046 |      1126.9448 |      0.2925 |      74.4290 |      0.9754 | \n",
      "  105 | 01m05s |   -0.15876 |              0.9326 |             0.9676 |    0.0304 |           5.9604 |      1.0000 |             8.0739 |      1120.2741 |      0.2508 |      75.9462 |      0.9303 | \n",
      "  106 | 01m06s |   -0.15606 |              0.9912 |             0.9232 |    0.9568 |           8.7179 |      1.0000 |            10.9720 |      1122.9140 |      0.0978 |      79.1200 |      0.9641 | \n",
      "2018-06-16 11:29:51,739 - logHandler - train - INFO - Iteration: 11, XGBoost max auc: -0.152559\n",
      "2018-06-16 11:29:51,741 - logHandler - train - INFO - Param max_delta_step: 6.2388472317112615\n",
      "2018-06-16 11:29:51,743 - logHandler - train - INFO - Param reg_lambda: 77.1489604737812\n",
      "2018-06-16 11:29:51,744 - logHandler - train - INFO - Param reg_alpha: 0.2102627471971234\n",
      "2018-06-16 11:29:51,746 - logHandler - train - INFO - Param n_estimators: 1120.512387706952\n",
      "2018-06-16 11:29:51,747 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 11:29:51,748 - logHandler - train - INFO - Param subsample: 0.9114462919010179\n",
      "2018-06-16 11:29:51,750 - logHandler - train - INFO - Param min_child_weight: 8.02233294214159\n",
      "2018-06-16 11:29:51,751 - logHandler - train - INFO - Param gamma: 0.07285547098152556\n",
      "2018-06-16 11:29:51,753 - logHandler - train - INFO - Param colsample_bytree: 0.8649289791209649\n",
      "2018-06-16 11:29:51,754 - logHandler - train - INFO - Param colsample_bylevel: 0.979513227700241\n",
      "2018-06-16 11:29:51,756 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 11:29:52,670 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 11:29:52,671 - logHandler - train - INFO - Iteration 12, Current random seed: 12\n",
      "2018-06-16 11:29:52,680 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 11:29:52,680 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.15984\u001b[0m | \u001b[32m             0.9854\u001b[0m | \u001b[32m            0.8356\u001b[0m | \u001b[32m   0.0943\u001b[0m | \u001b[32m          1.5323\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.6630\u001b[0m | \u001b[32m     1133.1868\u001b[0m | \u001b[32m     0.1578\u001b[0m | \u001b[32m     74.1008\u001b[0m | \u001b[32m     0.9861\u001b[0m | \n",
      "    2 | 00m02s | \u001b[35m  -0.15795\u001b[0m | \u001b[32m             0.9807\u001b[0m | \u001b[32m            0.9367\u001b[0m | \u001b[32m   0.2957\u001b[0m | \u001b[32m          8.9483\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.6629\u001b[0m | \u001b[32m     1125.1428\u001b[0m | \u001b[32m     0.2302\u001b[0m | \u001b[32m     82.5421\u001b[0m | \u001b[32m     0.9510\u001b[0m | \n",
      "    3 | 00m01s |   -0.16011 |              0.9362 |             0.8746 |    0.3694 |           0.9936 |      1.0000 |            10.3564 |      1122.9232 |      0.0070 |      70.4750 |      0.9672 | \n",
      "    4 | 00m01s |   -0.15903 |              0.9496 |             0.8212 |    0.8477 |           1.3080 |      1.0000 |             9.6326 |      1120.8573 |      0.1030 |      82.6172 |      0.9057 | \n",
      "    5 | 00m02s |   -0.15984 |              0.9717 |             0.8292 |    0.1829 |           6.8817 |      1.0000 |             8.7481 |      1122.2733 |      0.0957 |      73.1352 |      0.9138 | \n",
      "    6 | 00m02s | \u001b[35m  -0.15742\u001b[0m | \u001b[32m             0.9272\u001b[0m | \u001b[32m            0.8877\u001b[0m | \u001b[32m   0.5457\u001b[0m | \u001b[32m          2.6870\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.4262\u001b[0m | \u001b[32m     1124.4478\u001b[0m | \u001b[32m     0.0196\u001b[0m | \u001b[32m     81.0963\u001b[0m | \u001b[32m     0.9504\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m16s |   -0.16119 |              0.9732 |             0.9426 |    0.9414 |           9.3629 |      1.0000 |             8.9367 |      1134.9916 |      0.0414 |      84.8397 |      0.9521 | \n",
      "    8 | 00m17s |   -0.16065 |              0.9244 |             0.9823 |    0.0075 |           0.1496 |      1.0000 |             8.2495 |      1121.9592 |      0.2908 |      84.7453 |      0.9861 | \n",
      "    9 | 00m17s |   -0.16091 |              0.9650 |             0.8884 |    0.9853 |           9.5857 |      1.0000 |             8.0021 |      1120.2345 |      0.2534 |      84.9674 |      0.9451 | \n",
      "   10 | 00m16s |   -0.15795 |              0.9243 |             0.9135 |    0.6965 |           0.0237 |      1.0000 |            10.9062 |      1132.8089 |      0.0345 |      84.7408 |      0.9075 | \n",
      "   11 | 00m17s |   -0.16415 |              0.9039 |             0.9420 |    0.9120 |           9.9914 |      1.0000 |            10.7605 |      1131.2218 |      0.0287 |      70.8029 |      0.9638 | \n",
      "   12 | 00m17s |   -0.16092 |              0.9530 |             0.8128 |    0.0446 |           7.3003 |      1.0000 |            10.9489 |      1121.4442 |      0.0022 |      84.6309 |      0.9288 | \n",
      "   13 | 00m17s |   -0.16388 |              0.9068 |             0.8028 |    0.9900 |           4.9755 |      1.0000 |            10.9433 |      1128.7171 |      0.2972 |      80.3505 |      0.9966 | \n",
      "   14 | 00m19s | \u001b[35m  -0.15741\u001b[0m | \u001b[32m             0.9098\u001b[0m | \u001b[32m            0.9895\u001b[0m | \u001b[32m   0.6278\u001b[0m | \u001b[32m          9.9479\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.9095\u001b[0m | \u001b[32m     1120.3022\u001b[0m | \u001b[32m     0.1277\u001b[0m | \u001b[32m     77.3870\u001b[0m | \u001b[32m     0.9084\u001b[0m | \n",
      "   15 | 00m17s |   -0.16065 |              0.9723 |             0.9683 |    0.0147 |           0.1695 |      1.0000 |             8.8710 |      1120.5835 |      0.0469 |      76.7965 |      0.9812 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.27552412e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 00m18s |   -0.16226 |              0.9757 |             0.8785 |    0.8635 |           0.1516 |      1.0000 |             8.0783 |      1134.2793 |      0.0012 |      70.3525 |      0.9027 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.23325025e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 00m17s |   -0.16037 |              0.9076 |             0.8056 |    0.3167 |           0.0608 |      1.0000 |             8.0912 |      1134.8845 |      0.0108 |      84.9671 |      0.9780 | \n",
      "   18 | 00m18s | \u001b[35m  -0.15633\u001b[0m | \u001b[32m             0.9198\u001b[0m | \u001b[32m            0.9680\u001b[0m | \u001b[32m   0.2096\u001b[0m | \u001b[32m          9.9325\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.0431\u001b[0m | \u001b[32m     1129.2420\u001b[0m | \u001b[32m     0.0722\u001b[0m | \u001b[32m     77.8256\u001b[0m | \u001b[32m     0.9515\u001b[0m | \n",
      "   19 | 00m17s |   -0.15714 |              0.9881 |             0.9938 |    0.1855 |           0.5750 |      1.0000 |            10.8811 |      1134.3709 |      0.0691 |      73.2763 |      0.9221 | \n",
      "   20 | 00m18s |   -0.15849 |              0.9910 |             0.9978 |    0.2120 |           0.1150 |      1.0000 |            10.2674 |      1127.8389 |      0.0273 |      77.9425 |      0.9041 | \n",
      "   21 | 00m18s |   -0.15768 |              0.9077 |             0.8278 |    0.0794 |           9.6884 |      1.0000 |            10.9923 |      1120.0387 |      0.1099 |      70.3207 |      0.9048 | \n",
      "   22 | 00m18s | \u001b[35m  -0.15338\u001b[0m | \u001b[32m             0.9847\u001b[0m | \u001b[32m            0.9856\u001b[0m | \u001b[32m   0.1088\u001b[0m | \u001b[32m          9.0773\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.2833\u001b[0m | \u001b[32m     1134.5236\u001b[0m | \u001b[32m     0.1194\u001b[0m | \u001b[32m     70.1950\u001b[0m | \u001b[32m     0.9192\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.66779398e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 | 00m19s |   -0.15741 |              0.9735 |             0.9838 |    0.6299 |           9.8352 |      1.0000 |             8.1213 |      1120.0290 |      0.1372 |      70.2289 |      0.9611 | \n",
      "   24 | 00m19s |   -0.15876 |              0.9985 |             0.9812 |    0.0652 |           8.6049 |      1.0000 |             8.0707 |      1134.8109 |      0.1036 |      75.9370 |      0.9375 | \n",
      "   25 | 00m19s |   -0.15903 |              0.9557 |             0.9941 |    0.0027 |           1.3743 |      1.0000 |            10.9528 |      1133.0345 |      0.0590 |      70.0816 |      0.9292 | \n",
      "   26 | 00m19s |   -0.15661 |              0.9630 |             0.8209 |    0.0908 |           9.7293 |      1.0000 |             8.9614 |      1134.8915 |      0.0270 |      70.0587 |      0.9186 | \n",
      "   27 | 00m19s |   -0.15472 |              0.9405 |             0.9999 |    0.0280 |           9.7484 |      1.0000 |             8.3521 |      1125.1531 |      0.0826 |      70.0029 |      0.9940 | \n",
      "   28 | 00m20s |   -0.15472 |              0.9502 |             0.9823 |    0.6267 |           9.9472 |      1.0000 |             8.1325 |      1126.5947 |      0.0017 |      84.0423 |      0.9920 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00013304]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 00m18s |   -0.15768 |              0.9463 |             0.9882 |    0.0128 |           9.7616 |      1.0000 |             8.0153 |      1122.2409 |      0.0091 |      80.5808 |      0.9427 | \n",
      "   30 | 00m19s |   -0.15687 |              0.9164 |             0.9978 |    0.7760 |           5.3404 |      1.0000 |             8.0348 |      1127.9854 |      0.0027 |      84.9415 |      0.9738 | \n",
      "   31 | 00m20s | \u001b[35m  -0.15202\u001b[0m | \u001b[32m             0.9886\u001b[0m | \u001b[32m            0.9725\u001b[0m | \u001b[32m   0.3408\u001b[0m | \u001b[32m          9.9382\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.1269\u001b[0m | \u001b[32m     1134.8958\u001b[0m | \u001b[32m     0.2226\u001b[0m | \u001b[32m     70.0666\u001b[0m | \u001b[32m     0.9306\u001b[0m | \n",
      "   32 | 00m19s |   -0.15607 |              0.9128 |             0.9736 |    0.2163 |           9.8050 |      1.0000 |             8.2495 |      1130.8024 |      0.2724 |      70.1842 |      0.9026 | \n",
      "   33 | 00m18s |   -0.15714 |              0.9679 |             0.9868 |    0.8271 |           0.4385 |      1.0000 |            10.6977 |      1125.3431 |      0.1828 |      84.8291 |      0.9909 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00013281]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 00m19s |   -0.15876 |              0.9957 |             0.9760 |    0.0887 |           5.1287 |      1.0000 |            10.9661 |      1120.1004 |      0.1055 |      70.1552 |      0.9574 | \n",
      "   35 | 00m19s |   -0.15984 |              0.9944 |             0.9967 |    0.0809 |           9.7839 |      1.0000 |             8.1507 |      1134.1748 |      0.0537 |      70.0692 |      0.9334 | \n",
      "   36 | 00m23s |   -0.15607 |              0.9316 |             0.9216 |    0.9984 |           3.8388 |      1.0000 |            10.9625 |      1134.4457 |      0.2687 |      70.2748 |      0.9620 | \n",
      "   37 | 00m23s |   -0.15983 |              0.9130 |             0.9131 |    0.4381 |           0.0614 |      1.0000 |             8.1054 |      1121.0377 |      0.2932 |      70.1778 |      0.9863 | \n",
      "   38 | 00m23s |   -0.15742 |              0.9520 |             0.9542 |    0.1268 |           0.0969 |      1.0000 |             9.0955 |      1134.8982 |      0.2807 |      79.7492 |      0.9785 | \n",
      "   39 | 00m22s |   -0.15822 |              0.9549 |             0.9816 |    0.9708 |           9.8167 |      1.0000 |            10.8837 |      1124.4346 |      0.2769 |      70.1939 |      0.9089 | \n",
      "   40 | 00m22s |   -0.15849 |              0.9538 |             0.8792 |    0.3537 |           9.7452 |      1.0000 |            10.7538 |      1134.9586 |      0.2871 |      73.2400 |      0.9171 | \n",
      "   41 | 00m21s |   -0.16038 |              0.9029 |             0.8457 |    0.0354 |           0.1908 |      1.0000 |            10.9487 |      1120.9008 |      0.2900 |      81.6609 |      0.9137 | \n",
      "   42 | 00m25s |   -0.15741 |              0.9025 |             0.9881 |    0.6605 |           6.1960 |      1.0000 |             8.7307 |      1134.9232 |      0.2844 |      70.1559 |      0.9362 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00076935]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 | 00m23s |   -0.15391 |              0.9364 |             0.8954 |    0.8987 |           0.0705 |      1.0000 |             8.0452 |      1129.3964 |      0.2654 |      83.6046 |      0.9544 | \n",
      "   44 | 00m23s |   -0.15849 |              0.9957 |             0.9500 |    0.0384 |           9.8366 |      1.0000 |             8.6619 |      1131.1036 |      0.2852 |      84.9770 |      0.9065 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00028228]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 | 00m23s |   -0.15903 |              0.9802 |             0.8208 |    0.0011 |           0.4531 |      1.0000 |            10.7119 |      1120.2129 |      0.2331 |      70.2334 |      0.9716 | \n",
      "   46 | 00m22s |   -0.16308 |              0.9904 |             0.8295 |    0.8369 |           0.0319 |      1.0000 |             8.2016 |      1128.3404 |      0.2791 |      70.2040 |      0.9027 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00015093]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   47 | 00m25s |   -0.15607 |              0.9661 |             0.8963 |    0.0744 |           6.3567 |      1.0000 |            10.9609 |      1129.6201 |      0.2591 |      71.0029 |      0.9046 | \n",
      "   48 | 00m24s |   -0.15741 |              0.9624 |             0.9417 |    0.9306 |           5.5581 |      1.0000 |             8.0341 |      1134.1925 |      0.2958 |      84.3343 |      0.9474 | \n",
      "   49 | 00m34s |   -0.16038 |              0.9739 |             0.8189 |    0.8218 |           9.1654 |      1.0000 |             8.1155 |      1128.2604 |      0.2480 |      73.3027 |      0.9809 | \n",
      "   50 | 00m42s |   -0.16010 |              0.9521 |             0.8703 |    0.2362 |           0.6440 |      1.0000 |            10.8051 |      1134.7553 |      0.2934 |      70.2010 |      0.9572 | \n",
      "   51 | 00m41s |   -0.15580 |              0.9661 |             0.9848 |    0.9645 |           0.0840 |      1.0000 |             8.2965 |      1134.3182 |      0.1293 |      78.3103 |      0.9432 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00145133]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   52 | 00m45s |   -0.16011 |              0.9813 |             0.9406 |    0.9140 |           9.9869 |      1.0000 |             8.0914 |      1134.9402 |      0.2468 |      80.3945 |      0.9631 | \n",
      "   53 | 00m40s |   -0.15660 |              0.9865 |             0.8106 |    0.9369 |           9.6574 |      1.0000 |            10.9698 |      1128.8485 |      0.0688 |      84.9139 |      0.9139 | \n",
      "   54 | 00m46s |   -0.15580 |              0.9657 |             0.8163 |    0.3661 |           0.2068 |      1.0000 |            10.9726 |      1120.0801 |      0.0034 |      84.5363 |      0.9334 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00010389]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   55 | 00m45s |   -0.15714 |              0.9496 |             0.9849 |    0.8675 |           9.9615 |      1.0000 |            10.8212 |      1120.9478 |      0.1054 |      84.6345 |      0.9950 | \n",
      "   56 | 00m49s |   -0.15445 |              0.9928 |             0.9714 |    0.9666 |           9.1448 |      1.0000 |            10.4584 |      1134.7830 |      0.2106 |      70.0468 |      0.9442 | \n",
      "   57 | 00m45s |   -0.15930 |              0.9195 |             0.8359 |    0.0010 |           0.2044 |      1.0000 |             8.0497 |      1127.1267 |      0.1120 |      82.8432 |      0.9042 | \n",
      "   58 | 00m47s |   -0.15715 |              0.9094 |             0.8705 |    0.9546 |           0.2768 |      1.0000 |            10.8940 |      1120.2081 |      0.1092 |      72.7683 |      0.9361 | \n",
      "   59 | 00m49s |   -0.15687 |              0.9764 |             0.9783 |    0.8983 |           0.1412 |      1.0000 |            10.9149 |      1131.7003 |      0.2639 |      72.1875 |      0.9028 | \n",
      "   60 | 01m21s |   -0.15661 |              0.9250 |             0.8218 |    0.0439 |           9.7849 |      1.0000 |             8.0167 |      1123.4652 |      0.2650 |      72.8746 |      0.9126 | \n",
      "   61 | 00m58s |   -0.16280 |              0.9884 |             0.9763 |    0.9628 |           5.7318 |      1.0000 |            10.9474 |      1120.2255 |      0.2542 |      80.3068 |      0.9086 | \n",
      "   62 | 01m29s |   -0.16092 |              0.9588 |             0.9754 |    0.9281 |           9.4621 |      1.0000 |             8.1149 |      1127.4217 |      0.2946 |      80.8846 |      0.9276 | \n",
      "   63 | 00m58s |   -0.15715 |              0.9154 |             0.9343 |    0.0704 |           7.0087 |      1.0000 |            10.9833 |      1134.8279 |      0.2438 |      84.0556 |      0.9743 | \n",
      "   64 | 01m00s |   -0.15418 |              0.9148 |             0.9984 |    0.0668 |           9.8547 |      1.0000 |             8.5285 |      1124.2875 |      0.2766 |      84.9342 |      0.9340 | \n",
      "   65 | 00m59s |   -0.15876 |              0.9492 |             0.9749 |    0.8153 |           4.4225 |      1.0000 |            10.9808 |      1134.7884 |      0.1913 |      79.6007 |      0.9091 | \n",
      "   66 | 01m06s |   -0.16200 |              0.9849 |             0.8626 |    0.8806 |           0.0058 |      1.0000 |            10.9889 |      1122.4988 |      0.0058 |      79.6805 |      0.9774 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.000325]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   67 | 00m58s |   -0.16361 |              0.9424 |             0.9973 |    0.1183 |           2.7429 |      1.0000 |             8.0482 |      1134.1711 |      0.0341 |      82.2867 |      0.9253 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00010039]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   68 | 01m11s |   -0.16011 |              0.9336 |             0.8259 |    0.8518 |           8.6428 |      1.0000 |             8.0950 |      1134.7006 |      0.2740 |      70.7746 |      0.9030 | \n",
      "   69 | 01m02s |   -0.15660 |              0.9207 |             0.9320 |    0.1051 |           9.7838 |      1.0000 |            10.9307 |      1126.0901 |      0.2455 |      74.6833 |      0.9485 | \n",
      "   70 | 01m07s | \u001b[35m  -0.15041\u001b[0m | \u001b[32m             0.9454\u001b[0m | \u001b[32m            0.8860\u001b[0m | \u001b[32m   0.1904\u001b[0m | \u001b[32m          7.9378\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.9978\u001b[0m | \u001b[32m     1134.9394\u001b[0m | \u001b[32m     0.2999\u001b[0m | \u001b[32m     70.9079\u001b[0m | \u001b[32m     0.9324\u001b[0m | \n",
      "   71 | 03m15s |   -0.15418 |              0.9276 |             0.9951 |    0.0850 |           7.3131 |      1.0000 |             8.0842 |      1120.0226 |      0.2345 |      75.8004 |      0.9085 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00090763]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   72 | 00m51s |   -0.15526 |              0.9058 |             0.9973 |    0.0813 |           4.9234 |      1.0000 |             8.0856 |      1125.8883 |      0.1899 |      72.4881 |      0.9137 | \n",
      "   73 | 00m54s |   -0.16199 |              0.9586 |             0.9448 |    0.9759 |           1.0365 |      1.0000 |            10.8402 |      1134.9216 |      0.0032 |      84.8413 |      0.9918 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00034781]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 65, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 | 00m55s |   -0.15822 |              0.9120 |             0.9643 |    0.0379 |           9.3142 |      1.0000 |            10.9179 |      1132.3234 |      0.2115 |      80.5461 |      0.9168 | \n",
      "   75 | 00m51s |   -0.15526 |              0.9489 |             0.9760 |    0.2921 |           9.8379 |      1.0000 |            10.5985 |      1127.9056 |      0.2755 |      70.1923 |      0.9101 | \n",
      "   76 | 00m55s |   -0.15660 |              0.9216 |             0.9584 |    0.0234 |           0.3549 |      1.0000 |             8.0733 |      1134.9940 |      0.2851 |      76.0818 |      0.9922 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00055338]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.89974171e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 47, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00240238]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   77 | 00m58s |   -0.16011 |              0.9022 |             0.9771 |    0.8394 |           0.0467 |      1.0000 |            10.7758 |      1132.8256 |      0.2296 |      78.4060 |      0.9876 | \n",
      "   78 | 00m56s |   -0.16307 |              0.9551 |             0.9763 |    0.0417 |           6.8914 |      1.0000 |             9.6167 |      1129.1392 |      0.2430 |      75.4570 |      0.9202 | \n",
      "   79 | 00m58s |   -0.15795 |              0.9012 |             0.8883 |    0.0047 |           7.1539 |      1.0000 |             8.0333 |      1123.7176 |      0.2801 |      70.0657 |      0.9125 | \n",
      "   80 | 00m56s |   -0.15337 |              0.9002 |             0.9978 |    0.0983 |           0.2040 |      1.0000 |             8.0972 |      1126.3485 |      0.1080 |      74.9844 |      0.9360 | \n",
      "   81 | 00m54s |   -0.15930 |              0.9528 |             0.9971 |    0.0104 |           2.8594 |      1.0000 |             9.4099 |      1120.3182 |      0.0039 |      72.5726 |      0.9022 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00044865]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00171494]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   82 | 00m57s |   -0.15741 |              0.9407 |             0.9924 |    0.9473 |           6.9750 |      1.0000 |            10.9794 |      1125.9377 |      0.1640 |      84.6654 |      0.9092 | \n",
      "   83 | 00m56s |   -0.15660 |              0.9134 |             0.9885 |    0.1312 |           9.9780 |      1.0000 |            10.4684 |      1134.9011 |      0.2597 |      70.0268 |      0.9216 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00173987]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   84 | 00m58s |   -0.15903 |              0.9881 |             0.9575 |    0.9777 |           3.4229 |      1.0000 |            10.9049 |      1131.5989 |      0.2750 |      84.9772 |      0.9922 | \n",
      "   85 | 01m00s |   -0.15633 |              0.9655 |             0.9665 |    0.1806 |           3.5479 |      1.0000 |             8.0362 |      1120.1587 |      0.1514 |      84.6796 |      0.9724 | \n",
      "   86 | 01m11s |   -0.15822 |              0.9588 |             0.9568 |    0.0450 |           9.7085 |      1.0000 |             8.0743 |      1120.0307 |      0.0037 |      84.7341 |      0.9260 | \n",
      "   87 | 01m37s |   -0.16011 |              0.9448 |             0.9314 |    0.9934 |           9.2361 |      1.0000 |            10.7046 |      1120.0509 |      0.2847 |      71.1478 |      0.9956 | \n",
      "   88 | 02m36s |   -0.15741 |              0.9358 |             0.9714 |    0.0115 |           3.7919 |      1.0000 |             8.0239 |      1123.2138 |      0.2337 |      76.2595 |      0.9875 | \n",
      "   89 | 01m19s |   -0.15715 |              0.9840 |             0.9580 |    0.9846 |           0.1547 |      1.0000 |             8.0665 |      1126.2316 |      0.0796 |      79.2452 |      0.9086 | \n",
      "   90 | 01m08s |   -0.15606 |              0.9858 |             0.8646 |    0.7096 |           9.3141 |      1.0000 |            10.8291 |      1134.8031 |      0.2970 |      80.6174 |      0.9013 | \n",
      "   91 | 01m01s |   -0.15418 |              0.9582 |             0.8961 |    0.1603 |           0.0075 |      1.0000 |             8.2323 |      1130.8148 |      0.2934 |      76.8205 |      0.9003 | \n",
      "   92 | 01m14s |   -0.15579 |              0.9653 |             0.9316 |    0.0668 |           6.9617 |      1.0000 |             8.1291 |      1128.4207 |      0.2847 |      70.2019 |      0.9658 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-4.59461444e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 2, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   93 | 00m58s |   -0.15552 |              0.9974 |             0.8090 |    0.1254 |           8.3988 |      1.0000 |             8.5337 |      1134.9226 |      0.2776 |      82.1235 |      0.9125 | \n",
      "   94 | 01m01s |   -0.15957 |              0.9822 |             0.9484 |    0.8965 |           0.2629 |      1.0000 |            10.4227 |      1120.0480 |      0.0513 |      70.3803 |      0.9411 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([5.97559965e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   95 | 01m04s |   -0.15633 |              0.9989 |             0.9754 |    0.8819 |           0.2879 |      1.0000 |             8.0388 |      1132.8239 |      0.2932 |      84.7621 |      0.9105 | \n",
      "   96 | 00m58s |   -0.16199 |              0.9486 |             0.9112 |    0.6551 |           0.0712 |      1.0000 |             8.0230 |      1120.0120 |      0.0551 |      82.5146 |      0.9359 | \n",
      "   97 | 01m01s |   -0.15607 |              0.9768 |             0.9678 |    0.0083 |           5.3501 |      1.0000 |            10.9000 |      1134.9329 |      0.2065 |      70.0700 |      0.9770 | \n",
      "   98 | 01m00s |   -0.15903 |              0.9895 |             0.9431 |    0.9432 |           4.0871 |      1.0000 |            10.8918 |      1127.0961 |      0.2673 |      70.1943 |      0.9120 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00300683]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   99 | 01m02s |   -0.15822 |              0.9378 |             0.8345 |    0.8273 |           0.0231 |      1.0000 |             8.8505 |      1127.7006 |      0.0266 |      84.9571 |      0.9062 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0004242]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 | 01m07s |   -0.15849 |              0.9038 |             0.9674 |    0.0043 |           8.1042 |      1.0000 |             8.9552 |      1134.8724 |      0.2874 |      70.8196 |      0.9077 | \n",
      "  101 | 01m06s |   -0.16280 |              0.9892 |             0.8687 |    0.3430 |           7.6756 |      1.0000 |            10.9230 |      1134.8972 |      0.1376 |      77.7518 |      0.9126 | \n",
      "  102 | 01m38s |   -0.15983 |              0.9899 |             0.8115 |    0.2062 |           0.1582 |      1.0000 |            10.9898 |      1126.5621 |      0.2850 |      73.3643 |      0.9200 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00395008]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  103 | 02m38s |   -0.15930 |              0.9820 |             0.9781 |    0.1997 |           9.9725 |      1.0000 |            10.9852 |      1130.0907 |      0.2739 |      74.1762 |      0.9116 | \n",
      "  104 | 01m22s |   -0.15418 |              0.9942 |             0.8518 |    0.0280 |           3.2851 |      1.0000 |             8.0457 |      1130.0944 |      0.0472 |      77.7452 |      0.9020 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00288221]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  105 | 01m35s |   -0.15903 |              0.9287 |             0.9935 |    0.0272 |           7.4300 |      1.0000 |            10.9633 |      1120.0343 |      0.1331 |      74.7755 |      0.9126 | \n",
      "  106 | 01m50s |   -0.15390 |              0.9729 |             0.8177 |    0.2893 |           6.3788 |      1.0000 |             8.0445 |      1134.9378 |      0.2702 |      70.0363 |      0.9572 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00066842]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-16 12:50:52,061 - logHandler - train - INFO - Iteration: 12, XGBoost max auc: -0.150406\n",
      "2018-06-16 12:50:52,074 - logHandler - train - INFO - Param max_delta_step: 7.937836403156933\n",
      "2018-06-16 12:50:52,075 - logHandler - train - INFO - Param reg_lambda: 70.90793319295437\n",
      "2018-06-16 12:50:52,076 - logHandler - train - INFO - Param reg_alpha: 0.2999237786726997\n",
      "2018-06-16 12:50:52,078 - logHandler - train - INFO - Param n_estimators: 1134.939444082298\n",
      "2018-06-16 12:50:52,079 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 12:50:52,080 - logHandler - train - INFO - Param subsample: 0.932372321717568\n",
      "2018-06-16 12:50:52,081 - logHandler - train - INFO - Param min_child_weight: 10.997812891620937\n",
      "2018-06-16 12:50:52,082 - logHandler - train - INFO - Param gamma: 0.19044156089954611\n",
      "2018-06-16 12:50:52,083 - logHandler - train - INFO - Param colsample_bytree: 0.8859979365996691\n",
      "2018-06-16 12:50:52,084 - logHandler - train - INFO - Param colsample_bylevel: 0.9453766982973477\n",
      "2018-06-16 12:50:52,085 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 12:50:53,302 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 12:50:53,305 - logHandler - train - INFO - Iteration 13, Current random seed: 13\n",
      "2018-06-16 12:50:53,353 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 12:50:53,354 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.15822\u001b[0m | \u001b[32m             0.9055\u001b[0m | \u001b[32m            0.9466\u001b[0m | \u001b[32m   0.9297\u001b[0m | \u001b[32m          9.6034\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.7276\u001b[0m | \u001b[32m     1126.3375\u001b[0m | \u001b[32m     0.0063\u001b[0m | \u001b[32m     80.7799\u001b[0m | \u001b[32m     0.9571\u001b[0m | \n",
      "    2 | 00m02s |   -0.15903 |              0.9803 |             0.8732 |    0.1813 |           6.6810 |      1.0000 |             8.7443 |      1131.8955 |      0.2861 |      73.8483 |      0.9508 | \n",
      "    3 | 00m03s | \u001b[35m  -0.15607\u001b[0m | \u001b[32m             0.9013\u001b[0m | \u001b[32m            0.9895\u001b[0m | \u001b[32m   0.7851\u001b[0m | \u001b[32m          5.5972\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.1372\u001b[0m | \u001b[32m     1121.8745\u001b[0m | \u001b[32m     0.1998\u001b[0m | \u001b[32m     72.3567\u001b[0m | \u001b[32m     0.9743\u001b[0m | \n",
      "    4 | 00m02s |   -0.15741 |              0.9984 |             0.9946 |    0.1255 |           3.0435 |      1.0000 |             9.5772 |      1122.5858 |      0.1396 |      71.5199 |      0.9990 | \n",
      "    5 | 00m03s |   -0.15903 |              0.9916 |             0.8231 |    0.7085 |           2.1256 |      1.0000 |             8.1522 |      1132.7870 |      0.1344 |      81.0474 |      0.9406 | \n",
      "    6 | 00m03s | \u001b[35m  -0.15552\u001b[0m | \u001b[32m             0.9129\u001b[0m | \u001b[32m            0.9183\u001b[0m | \u001b[32m   0.7000\u001b[0m | \u001b[32m          7.5832\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.1976\u001b[0m | \u001b[32m     1125.9169\u001b[0m | \u001b[32m     0.2094\u001b[0m | \u001b[32m     81.9460\u001b[0m | \u001b[32m     0.9382\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-7.37275815e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m17s |   -0.15661 |              0.9101 |             0.8049 |    0.6178 |           9.9697 |      1.0000 |             8.0612 |      1120.0666 |      0.1045 |      80.3543 |      0.9819 | \n",
      "    8 | 00m20s |   -0.16226 |              0.9272 |             0.9881 |    0.8312 |           0.9459 |      1.0000 |             8.8780 |      1120.1870 |      0.2714 |      84.7059 |      0.9909 | \n",
      "    9 | 00m20s |   -0.16065 |              0.9876 |             0.9783 |    0.9387 |           9.8186 |      1.0000 |             8.0201 |      1134.5000 |      0.1621 |      84.5902 |      0.9160 | \n",
      "   10 | 00m19s |   -0.15715 |              0.9244 |             0.8074 |    0.9985 |           1.0728 |      1.0000 |             8.0621 |      1124.6058 |      0.0117 |      70.1121 |      0.9228 | \n",
      "   11 | 00m19s |   -0.15849 |              0.9793 |             0.9856 |    0.0326 |           9.9542 |      1.0000 |             8.0488 |      1122.6348 |      0.0049 |      71.8479 |      0.9907 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([8.78329572e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 00m20s |   -0.16146 |              0.9268 |             0.8135 |    0.9284 |           0.9940 |      1.0000 |             8.0710 |      1123.8352 |      0.2862 |      76.0470 |      0.9975 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-5.82941173e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 00m19s |   -0.16199 |              0.9074 |             0.9714 |    0.4846 |           0.2607 |      1.0000 |            10.6377 |      1133.8558 |      0.2604 |      70.0621 |      0.9936 | \n",
      "   14 | 00m20s |   -0.15607 |              0.9922 |             0.8021 |    0.0272 |           9.3578 |      1.0000 |            10.9232 |      1120.2151 |      0.2253 |      84.8044 |      0.9026 | \n",
      "   15 | 00m19s |   -0.15957 |              0.9540 |             0.8038 |    0.9807 |           7.6295 |      1.0000 |            10.7922 |      1122.8155 |      0.0429 |      70.1714 |      0.9117 | \n",
      "   16 | 00m30s |   -0.15876 |              0.9545 |             0.9693 |    0.9606 |           8.6237 |      1.0000 |             8.0391 |      1121.1522 |      0.1326 |      84.9667 |      0.9146 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.22989706e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 00m18s |   -0.15633 |              0.9219 |             0.8171 |    0.1155 |           4.3148 |      1.0000 |            10.9687 |      1134.3390 |      0.2374 |      84.1384 |      0.9321 | \n",
      "   18 | 00m18s |   -0.15580 |              0.9088 |             0.9345 |    0.1180 |           2.5059 |      1.0000 |             8.1974 |      1120.0936 |      0.2731 |      70.7990 |      0.9294 | \n",
      "   19 | 00m18s |   -0.15822 |              0.9240 |             0.9509 |    0.0737 |           5.1361 |      1.0000 |            10.8246 |      1120.1659 |      0.0082 |      81.5531 |      0.9523 | \n",
      "   20 | 00m20s |   -0.15822 |              0.9346 |             0.9354 |    0.0078 |           1.0094 |      1.0000 |             8.0050 |      1133.8399 |      0.2532 |      84.5519 |      0.9542 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.0583421e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 00m16s |   -0.16280 |              0.9392 |             0.8075 |    0.0277 |           6.9936 |      1.0000 |            10.8987 |      1129.9198 |      0.2639 |      84.7808 |      0.9978 | \n",
      "   22 | 00m18s |   -0.15795 |              0.9379 |             0.8741 |    0.9652 |           0.4177 |      1.0000 |            10.9064 |      1133.6645 |      0.1553 |      84.9763 |      0.9243 | \n",
      "   23 | 00m19s |   -0.16091 |              0.9385 |             0.9775 |    0.5380 |           0.3165 |      1.0000 |            10.5165 |      1120.7154 |      0.2627 |      70.4640 |      0.9143 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00036959]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 00m19s |   -0.15741 |              0.9723 |             0.9823 |    0.9303 |           9.9621 |      1.0000 |            10.9917 |      1120.1148 |      0.2608 |      80.4517 |      0.9054 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00012194]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 00m19s |   -0.16038 |              0.9841 |             0.9700 |    0.0423 |           8.0706 |      1.0000 |             8.1830 |      1123.3849 |      0.2625 |      75.6538 |      0.9012 | \n",
      "   26 | 00m19s |   -0.16011 |              0.9973 |             0.9976 |    0.4844 |           9.6869 |      1.0000 |             8.1939 |      1134.7799 |      0.0328 |      70.1242 |      0.9945 | \n",
      "   27 | 00m19s |   -0.16065 |              0.9006 |             0.9784 |    0.9497 |           5.2570 |      1.0000 |             8.0271 |      1134.7804 |      0.0452 |      74.2459 |      0.9744 | \n",
      "   28 | 00m20s |   -0.15553 |              0.9121 |             0.9982 |    0.2297 |           9.9270 |      1.0000 |            10.5612 |      1134.9999 |      0.1284 |      77.6609 |      0.9843 | \n",
      "   29 | 00m20s |   -0.15822 |              0.9603 |             0.9387 |    0.1010 |           0.6795 |      1.0000 |            10.9395 |      1134.9388 |      0.1052 |      80.1421 |      0.9662 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.88710905e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 00m20s |   -0.15822 |              0.9042 |             0.8585 |    0.0724 |           7.0427 |      1.0000 |             8.4848 |      1124.7977 |      0.2725 |      70.0224 |      0.9799 | \n",
      "   31 | 00m19s |   -0.15660 |              0.9226 |             0.9747 |    0.9090 |           9.3814 |      1.0000 |            10.9829 |      1134.9611 |      0.0703 |      70.6002 |      0.9221 | \n",
      "   32 | 00m21s |   -0.15876 |              0.9590 |             0.9409 |    0.8355 |           9.9541 |      1.0000 |             8.0125 |      1120.5528 |      0.2157 |      70.1450 |      0.9939 | \n",
      "   33 | 00m19s |   -0.15768 |              0.9050 |             0.9775 |    0.8627 |           5.3974 |      1.0000 |             8.1236 |      1134.9303 |      0.0166 |      84.5242 |      0.9961 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00011863]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 00m19s |   -0.15984 |              0.9020 |             0.8197 |    0.0187 |           8.9674 |      1.0000 |             8.1079 |      1134.8446 |      0.0422 |      79.1448 |      0.9170 | \n",
      "   35 | 00m19s |   -0.16200 |              0.9321 |             0.9088 |    0.7702 |           5.0227 |      1.0000 |             8.0634 |      1120.6859 |      0.0140 |      70.1432 |      0.9823 | \n",
      "   36 | 00m22s | \u001b[35m  -0.15472\u001b[0m | \u001b[32m             0.9116\u001b[0m | \u001b[32m            0.9131\u001b[0m | \u001b[32m   0.0260\u001b[0m | \u001b[32m          9.9612\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.7807\u001b[0m | \u001b[32m     1120.0102\u001b[0m | \u001b[32m     0.1653\u001b[0m | \u001b[32m     71.6828\u001b[0m | \u001b[32m     0.9174\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00022155]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 00m22s |   -0.16037 |              0.9241 |             0.9516 |    0.8935 |           9.4673 |      1.0000 |            10.9990 |      1129.2579 |      0.2811 |      70.4208 |      0.9945 | \n",
      "   38 | 00m23s |   -0.16497 |              0.9299 |             0.8458 |    0.9342 |           7.7968 |      1.0000 |            10.9877 |      1134.9721 |      0.2959 |      78.0287 |      0.9972 | \n",
      "   39 | 00m22s |   -0.15660 |              0.9218 |             0.9926 |    0.1394 |           0.8272 |      1.0000 |             8.0299 |      1129.7237 |      0.0249 |      74.1640 |      0.9389 | \n",
      "   40 | 00m23s |   -0.15499 |              0.9143 |             0.9733 |    0.1025 |           0.4490 |      1.0000 |             8.3088 |      1127.8870 |      0.0102 |      84.5338 |      0.9008 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0001347]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 63, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 00m22s |   -0.16065 |              0.9089 |             0.9848 |    0.1295 |           2.2344 |      1.0000 |            10.8514 |      1128.7215 |      0.1908 |      82.2555 |      0.9020 | \n",
      "   42 | 00m23s |   -0.16038 |              0.9053 |             0.9951 |    0.8264 |           9.9370 |      1.0000 |            10.8859 |      1134.8721 |      0.0211 |      83.8388 |      0.9204 | \n",
      "   43 | 00m24s |   -0.15795 |              0.9627 |             0.9086 |    0.0026 |           9.9965 |      1.0000 |             8.4467 |      1125.9452 |      0.2504 |      84.6644 |      0.9235 | \n",
      "   44 | 00m24s |   -0.15957 |              0.9046 |             0.9201 |    0.0967 |           0.2183 |      1.0000 |             8.3898 |      1120.1141 |      0.0018 |      73.5711 |      0.9055 | \n",
      "   45 | 00m23s |   -0.15849 |              0.9056 |             0.9807 |    0.9174 |           9.9918 |      1.0000 |             8.4994 |      1131.0413 |      0.1129 |      73.3445 |      0.9063 | \n",
      "   46 | 00m23s |   -0.16119 |              0.9071 |             0.8746 |    0.0489 |           9.9808 |      1.0000 |            10.8363 |      1134.7141 |      0.2831 |      73.3562 |      0.9939 | \n",
      "   47 | 00m24s |   -0.15984 |              0.9297 |             0.9900 |    0.9051 |           2.8935 |      1.0000 |             8.0570 |      1131.4352 |      0.1542 |      70.0702 |      0.9303 | \n",
      "   48 | 00m24s |   -0.15526 |              0.9167 |             0.9983 |    0.0496 |           5.2708 |      1.0000 |             8.1018 |      1120.1222 |      0.0715 |      84.4996 |      0.9935 | \n",
      "   49 | 00m35s |   -0.16065 |              0.9160 |             0.9889 |    0.0131 |           9.2403 |      1.0000 |             8.5858 |      1131.0390 |      0.0501 |      80.9871 |      0.9634 | \n",
      "   50 | 00m38s |   -0.16011 |              0.9150 |             0.8620 |    0.1331 |           3.9143 |      1.0000 |             9.2627 |      1124.2506 |      0.0057 |      84.7849 |      0.9500 | \n",
      "   51 | 00m42s |   -0.15930 |              0.9014 |             0.8880 |    0.0738 |           4.0025 |      1.0000 |            10.9614 |      1128.6575 |      0.0241 |      70.7996 |      0.9022 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([6.42116647e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   52 | 00m44s |   -0.15633 |              0.9146 |             0.9700 |    0.0478 |           0.2664 |      1.0000 |             8.1541 |      1126.3065 |      0.2957 |      71.1292 |      0.9686 | \n",
      "   53 | 00m40s |   -0.16092 |              0.9809 |             0.9844 |    0.9063 |           0.0072 |      1.0000 |             8.0384 |      1120.0360 |      0.2986 |      70.0083 |      0.9847 | \n",
      "   54 | 00m48s |   -0.16037 |              0.9143 |             0.9777 |    0.0003 |           8.7084 |      1.0000 |             9.3943 |      1120.6597 |      0.2421 |      81.9077 |      0.9071 | \n",
      "   55 | 00m49s |   -0.15876 |              0.9092 |             0.9290 |    0.7896 |           9.8722 |      1.0000 |            10.6540 |      1120.0800 |      0.2383 |      74.6669 |      0.9964 | \n",
      "   56 | 00m50s |   -0.15552 |              0.9159 |             0.8647 |    0.5427 |           3.4360 |      1.0000 |             8.0472 |      1130.0138 |      0.0264 |      84.9381 |      0.9121 | \n",
      "   57 | 00m45s |   -0.15768 |              0.9870 |             0.9626 |    0.8919 |           4.6309 |      1.0000 |             8.1580 |      1127.8426 |      0.0644 |      76.0369 |      0.9063 | \n",
      "   58 | 00m44s |   -0.15795 |              0.9561 |             0.8265 |    0.0905 |           0.1966 |      1.0000 |            10.8076 |      1134.7518 |      0.0088 |      84.4931 |      0.9921 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00067145]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00020733]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   59 | 00m49s |   -0.15579 |              0.9654 |             0.9015 |    0.8507 |           4.4518 |      1.0000 |             8.0189 |      1120.0594 |      0.1688 |      78.4648 |      0.9009 | \n",
      "   60 | 00m47s |   -0.16307 |              0.9332 |             0.9462 |    0.0645 |           0.4329 |      1.0000 |             8.0903 |      1134.8311 |      0.0690 |      72.2802 |      0.9290 | \n",
      "   61 | 00m50s |   -0.16011 |              0.9148 |             0.8638 |    0.9473 |           4.7290 |      1.0000 |            10.9796 |      1120.0287 |      0.2770 |      84.5952 |      0.9695 | \n",
      "   62 | 00m44s |   -0.15633 |              0.9462 |             0.9702 |    0.0099 |           3.9587 |      1.0000 |            10.9359 |      1134.6429 |      0.0850 |      70.4070 |      0.9313 | \n",
      "   63 | 00m50s |   -0.15849 |              0.9177 |             0.9833 |    0.0865 |           9.8535 |      1.0000 |            10.9709 |      1121.4850 |      0.0575 |      70.1805 |      0.9551 | \n",
      "   64 | 00m49s |   -0.15903 |              0.9031 |             0.9825 |    0.0869 |           2.8053 |      1.0000 |            10.7529 |      1133.6591 |      0.0007 |      84.9644 |      0.9714 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00111824]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   65 | 00m49s |   -0.16200 |              0.9071 |             0.8003 |    0.4344 |           2.7188 |      1.0000 |             8.1104 |      1120.0428 |      0.2374 |      82.8836 |      0.9380 | \n",
      "   66 | 00m48s |   -0.16119 |              0.9908 |             0.8858 |    0.1967 |           4.4566 |      1.0000 |            10.9552 |      1120.0634 |      0.2492 |      74.3600 |      0.9827 | \n",
      "   67 | 00m50s |   -0.16308 |              0.9036 |             0.9778 |    0.9931 |           9.2296 |      1.0000 |             8.1389 |      1120.2263 |      0.0333 |      74.3531 |      0.9130 | \n",
      "   68 | 00m51s |   -0.15957 |              0.9984 |             0.8987 |    0.9583 |           0.4411 |      1.0000 |            10.8995 |      1134.8591 |      0.1595 |      73.5296 |      0.9027 | \n",
      "   69 | 00m51s |   -0.15526 |              0.9873 |             0.8947 |    0.0343 |           0.0734 |      1.0000 |            10.9144 |      1122.0820 |      0.0067 |      84.9057 |      0.9294 | \n",
      "   70 | 00m47s | \u001b[35m  -0.15364\u001b[0m | \u001b[32m             0.9419\u001b[0m | \u001b[32m            0.9078\u001b[0m | \u001b[32m   0.8742\u001b[0m | \u001b[32m          0.0338\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.9610\u001b[0m | \u001b[32m     1127.4486\u001b[0m | \u001b[32m     0.2689\u001b[0m | \u001b[32m     84.9673\u001b[0m | \u001b[32m     0.9109\u001b[0m | \n",
      "   71 | 00m49s |   -0.16172 |              0.9438 |             0.9923 |    0.9847 |           0.3058 |      1.0000 |            10.9877 |      1128.4137 |      0.2309 |      74.8868 |      0.9221 | \n",
      "   72 | 00m53s |   -0.16038 |              0.9992 |             0.9654 |    0.9625 |           5.0589 |      1.0000 |             8.0618 |      1127.2040 |      0.2835 |      72.1159 |      0.9265 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00010999]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   73 | 00m54s |   -0.15768 |              0.9052 |             0.9321 |    0.0123 |           7.7537 |      1.0000 |             8.8645 |      1134.7287 |      0.0123 |      84.9340 |      0.9019 | \n",
      "   74 | 00m53s |   -0.15849 |              0.9360 |             0.8096 |    0.1038 |           9.9824 |      1.0000 |             8.1286 |      1120.3417 |      0.0801 |      84.9977 |      0.9370 | \n",
      "   75 | 00m53s |   -0.15903 |              0.9749 |             0.8299 |    0.9646 |           8.6726 |      1.0000 |             8.1455 |      1127.3198 |      0.0325 |      84.8689 |      0.9346 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00015031]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00012181]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   76 | 00m51s |   -0.15606 |              0.9127 |             0.8289 |    0.7461 |           9.6187 |      1.0000 |            10.9489 |      1120.1653 |      0.0095 |      84.9761 |      0.9813 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0006031]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   77 | 00m49s |   -0.15606 |              0.9308 |             0.8163 |    0.9054 |           9.8287 |      1.0000 |             8.0605 |      1127.5858 |      0.2883 |      78.7641 |      0.9543 | \n",
      "   78 | 00m58s |   -0.15795 |              0.9881 |             0.9848 |    0.9934 |           0.9026 |      1.0000 |             8.2382 |      1128.6897 |      0.2348 |      84.7601 |      0.9971 | \n",
      "   79 | 00m57s |   -0.15553 |              0.9466 |             0.9899 |    0.1228 |           9.9836 |      1.0000 |            10.7959 |      1126.2201 |      0.2967 |      74.4572 |      0.9216 | \n",
      "   80 | 00m54s |   -0.15742 |              0.9053 |             0.8611 |    0.9922 |           6.0574 |      1.0000 |             9.4155 |      1134.3864 |      0.1834 |      70.1288 |      0.9266 | \n",
      "   81 | 00m51s |   -0.15687 |              0.9025 |             0.9658 |    0.1288 |           2.3050 |      1.0000 |             8.2997 |      1132.0455 |      0.2993 |      74.9188 |      0.9041 | \n",
      "   82 | 00m53s |   -0.15499 |              0.9676 |             0.9745 |    0.0391 |           0.5034 |      1.0000 |             8.2094 |      1122.8570 |      0.2805 |      70.2016 |      0.9020 | \n",
      "   83 | 00m53s |   -0.16415 |              0.9749 |             0.8587 |    0.2113 |           0.0145 |      1.0000 |            10.9195 |      1127.7943 |      0.0737 |      84.8357 |      0.9069 | \n",
      "   84 | 00m58s |   -0.16200 |              0.9006 |             0.9553 |    0.7512 |           0.1188 |      1.0000 |             8.1322 |      1124.6827 |      0.1481 |      82.0175 |      0.9092 | \n",
      "   85 | 00m54s |   -0.15714 |              0.9054 |             0.8980 |    0.9115 |           0.4618 |      1.0000 |             8.0480 |      1134.8132 |      0.2186 |      79.7000 |      0.9023 | \n",
      "   86 | 01m04s |   -0.15957 |              0.9109 |             0.9536 |    0.1440 |           3.7733 |      1.0000 |             8.0669 |      1129.9791 |      0.2599 |      80.7552 |      0.9542 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00022074]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   87 | 01m00s |   -0.16119 |              0.9066 |             0.9883 |    0.7917 |           0.1355 |      1.0000 |             8.0752 |      1125.0044 |      0.0769 |      84.9411 |      0.9788 | \n",
      "   88 | 00m57s |   -0.15903 |              0.9158 |             0.9993 |    0.6776 |           0.6506 |      1.0000 |            10.9708 |      1120.7657 |      0.1405 |      79.7599 |      0.9284 | \n",
      "   89 | 01m00s |   -0.15903 |              0.9223 |             0.9856 |    0.8676 |           0.0749 |      1.0000 |            10.9539 |      1120.0639 |      0.2780 |      84.8267 |      0.9899 | \n",
      "   90 | 01m02s |   -0.15660 |              0.9258 |             0.9687 |    0.9851 |           4.3479 |      1.0000 |            10.3620 |      1123.3640 |      0.2856 |      78.7881 |      0.9086 | \n",
      "   91 | 01m00s |   -0.15687 |              0.9690 |             0.9995 |    0.3474 |           0.8642 |      1.0000 |            10.4350 |      1134.9672 |      0.2662 |      84.8282 |      0.9047 | \n",
      "   92 | 00m53s |   -0.16038 |              0.9270 |             0.9796 |    0.7784 |           0.2569 |      1.0000 |            10.9268 |      1124.3893 |      0.2882 |      84.9757 |      0.9044 | \n",
      "   93 | 00m57s |   -0.16037 |              0.9588 |             0.9107 |    0.0640 |           0.0037 |      1.0000 |             8.2474 |      1120.0613 |      0.0455 |      84.2877 |      0.9574 | \n",
      "   94 | 01m06s |   -0.16145 |              0.9118 |             0.9967 |    0.9910 |           9.9605 |      1.0000 |            10.4307 |      1126.8942 |      0.2928 |      84.7772 |      0.9040 | \n",
      "   95 | 01m06s |   -0.15822 |              0.9217 |             0.8871 |    0.9571 |           1.6077 |      1.0000 |            10.5964 |      1134.8585 |      0.0195 |      83.0202 |      0.9367 | \n",
      "   96 | 01m00s |   -0.16227 |              0.9049 |             0.8805 |    0.9233 |           0.3347 |      1.0000 |             9.1444 |      1129.8954 |      0.2473 |      79.7175 |      0.9082 | \n",
      "   97 | 01m09s |   -0.15445 |              0.9038 |             0.9733 |    0.0040 |           9.8693 |      1.0000 |             8.0706 |      1127.4355 |      0.1416 |      70.1034 |      0.9299 | \n",
      "   98 | 01m09s |   -0.15848 |              0.9937 |             0.8024 |    0.0176 |           9.9747 |      1.0000 |            10.8124 |      1130.8330 |      0.0691 |      76.4755 |      0.9142 | \n",
      "   99 | 01m06s |   -0.16146 |              0.9133 |             0.9621 |    0.0423 |           1.5604 |      1.0000 |            10.3274 |      1120.3883 |      0.0253 |      84.8492 |      0.9207 | \n",
      "  100 | 01m12s |   -0.16361 |              0.9845 |             0.8633 |    0.8845 |           0.0478 |      1.0000 |            10.8033 |      1127.7713 |      0.1513 |      70.1123 |      0.9044 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00098895]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  101 | 01m16s |   -0.15768 |              0.9018 |             0.8699 |    0.0499 |           2.5940 |      1.0000 |             8.5002 |      1134.8376 |      0.0261 |      78.4625 |      0.9043 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([5.41056361e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  102 | 03m05s |   -0.15499 |              0.9042 |             0.9424 |    0.0424 |           9.9346 |      1.0000 |             8.1551 |      1127.9746 |      0.0582 |      75.6006 |      0.9009 | \n",
      "  103 | 02m04s |   -0.16011 |              0.9116 |             0.8137 |    0.1704 |           3.5445 |      1.0000 |             8.1134 |      1122.7064 |      0.0073 |      74.9897 |      0.9123 | \n",
      "  104 | 01m56s |   -0.16469 |              0.9054 |             0.8563 |    0.9747 |           6.6935 |      1.0000 |            10.8760 |      1127.6491 |      0.2994 |      75.9431 |      0.9936 | \n",
      "  105 | 01m53s |   -0.15930 |              0.9016 |             0.8233 |    0.9968 |           3.9362 |      1.0000 |            10.5205 |      1128.3173 |      0.0257 |      83.2926 |      0.9022 | \n",
      "  106 | 01m15s |   -0.16119 |              0.9038 |             0.9125 |    0.0302 |           9.7296 |      1.0000 |             9.0937 |      1131.9528 |      0.0267 |      70.0989 |      0.9118 | \n",
      "2018-06-16 14:06:03,477 - logHandler - train - INFO - Iteration: 13, XGBoost max auc: -0.153642\n",
      "2018-06-16 14:06:03,674 - logHandler - train - INFO - Param max_delta_step: 0.033790921169783994\n",
      "2018-06-16 14:06:03,683 - logHandler - train - INFO - Param reg_lambda: 84.96727963544518\n",
      "2018-06-16 14:06:03,684 - logHandler - train - INFO - Param reg_alpha: 0.26894232341868785\n",
      "2018-06-16 14:06:03,685 - logHandler - train - INFO - Param n_estimators: 1127.4486326184735\n",
      "2018-06-16 14:06:03,687 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 14:06:03,688 - logHandler - train - INFO - Param subsample: 0.9109149807105168\n",
      "2018-06-16 14:06:03,688 - logHandler - train - INFO - Param min_child_weight: 10.961046942636953\n",
      "2018-06-16 14:06:03,688 - logHandler - train - INFO - Param gamma: 0.8742197259009479\n",
      "2018-06-16 14:06:03,689 - logHandler - train - INFO - Param colsample_bytree: 0.9078384318208456\n",
      "2018-06-16 14:06:03,689 - logHandler - train - INFO - Param colsample_bylevel: 0.9418870474694689\n",
      "2018-06-16 14:06:03,691 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 14:06:04,919 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 14:06:04,937 - logHandler - train - INFO - Iteration 14, Current random seed: 14\n",
      "2018-06-16 14:06:05,079 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 14:06:05,083 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m04s | \u001b[35m  -0.16037\u001b[0m | \u001b[32m             0.9745\u001b[0m | \u001b[32m            0.8497\u001b[0m | \u001b[32m   0.7942\u001b[0m | \u001b[32m          7.4490\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.1174\u001b[0m | \u001b[32m     1127.2362\u001b[0m | \u001b[32m     0.2860\u001b[0m | \u001b[32m     78.1601\u001b[0m | \u001b[32m     0.9288\u001b[0m | \n",
      "    2 | 00m04s | \u001b[35m  -0.15876\u001b[0m | \u001b[32m             0.9142\u001b[0m | \u001b[32m            0.8537\u001b[0m | \u001b[32m   0.2443\u001b[0m | \u001b[32m          5.4469\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.4736\u001b[0m | \u001b[32m     1125.9870\u001b[0m | \u001b[32m     0.1950\u001b[0m | \u001b[32m     84.1471\u001b[0m | \u001b[32m     0.9384\u001b[0m | \n",
      "    3 | 00m16s | \u001b[35m  -0.15606\u001b[0m | \u001b[32m             0.9585\u001b[0m | \u001b[32m            0.8625\u001b[0m | \u001b[32m   0.5168\u001b[0m | \u001b[32m          2.9655\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.2323\u001b[0m | \u001b[32m     1132.8153\u001b[0m | \u001b[32m     0.0008\u001b[0m | \u001b[32m     73.2924\u001b[0m | \u001b[32m     0.9327\u001b[0m | \n",
      "    4 | 00m04s |   -0.15660 |              0.9859 |             0.9586 |    0.5300 |           9.9590 |      1.0000 |            10.6072 |      1129.8485 |      0.1048 |      81.8236 |      0.9857 | \n",
      "    5 | 00m04s |   -0.15983 |              0.9184 |             0.8658 |    0.1856 |           8.1178 |      1.0000 |             8.3676 |      1132.3939 |      0.2724 |      82.4398 |      0.9419 | \n",
      "    6 | 00m03s |   -0.15768 |              0.9173 |             0.8230 |    0.4935 |           3.2035 |      1.0000 |            10.2702 |      1127.8210 |      0.2613 |      72.3021 |      0.9958 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m19s |   -0.16173 |              0.9016 |             0.9687 |    0.4878 |           0.0556 |      1.0000 |            10.9650 |      1134.8640 |      0.2243 |      82.8617 |      0.9475 | \n",
      "    8 | 00m17s |   -0.15715 |              0.9353 |             0.9802 |    0.0011 |           9.1339 |      1.0000 |            10.9594 |      1134.3283 |      0.1176 |      70.1965 |      0.9942 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.62182935e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9 | 00m17s |   -0.15768 |              0.9619 |             0.9824 |    0.7487 |           0.1096 |      1.0000 |             8.2962 |      1120.2882 |      0.0429 |      71.1240 |      0.9395 | \n",
      "   10 | 00m18s | \u001b[35m  -0.15525\u001b[0m | \u001b[32m             0.9333\u001b[0m | \u001b[32m            0.9889\u001b[0m | \u001b[32m   0.8224\u001b[0m | \u001b[32m          0.2661\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.9421\u001b[0m | \u001b[32m     1134.2046\u001b[0m | \u001b[32m     0.0178\u001b[0m | \u001b[32m     70.0503\u001b[0m | \u001b[32m     0.9240\u001b[0m | \n",
      "   11 | 00m37s | \u001b[35m  -0.15283\u001b[0m | \u001b[32m             0.9059\u001b[0m | \u001b[32m            0.9475\u001b[0m | \u001b[32m   0.0040\u001b[0m | \u001b[32m          9.9796\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.5130\u001b[0m | \u001b[32m     1120.2300\u001b[0m | \u001b[32m     0.0475\u001b[0m | \u001b[32m     76.7739\u001b[0m | \u001b[32m     0.9685\u001b[0m | \n",
      "   12 | 00m24s |   -0.15876 |              0.9262 |             0.9242 |    0.1234 |           8.7496 |      1.0000 |             8.3232 |      1120.3771 |      0.0058 |      70.2821 |      0.9989 | \n",
      "   13 | 00m50s |   -0.16092 |              0.9908 |             0.9102 |    0.0789 |           0.3479 |      1.0000 |            10.9468 |      1125.9160 |      0.0156 |      70.5153 |      0.9009 | \n",
      "   14 | 00m22s |   -0.15741 |              0.9331 |             0.9530 |    0.5873 |           9.6278 |      1.0000 |            10.9044 |      1120.0245 |      0.2776 |      84.9306 |      0.9969 | \n",
      "   15 | 00m22s |   -0.15849 |              0.9372 |             0.8922 |    0.1010 |           0.3102 |      1.0000 |             8.2506 |      1134.9619 |      0.2774 |      70.2251 |      0.9245 | \n",
      "   16 | 00m24s |   -0.15741 |              0.9000 |             1.0000 |    0.0000 |           0.3003 |      1.0000 |             8.0000 |      1120.0000 |      0.0000 |      83.2467 |      0.9000 | \n",
      "   17 | 00m20s |   -0.16038 |              0.9513 |             0.8376 |    0.1056 |           9.0412 |      1.0000 |            10.8714 |      1134.9380 |      0.0227 |      84.3896 |      0.9625 | \n",
      "   18 | 00m23s |   -0.15741 |              0.9051 |             0.9794 |    0.0152 |           8.7521 |      1.0000 |             8.1411 |      1120.3203 |      0.0631 |      82.6610 |      0.9172 | \n",
      "   19 | 00m42s |   -0.16146 |              0.9683 |             0.9087 |    0.9392 |           0.1779 |      1.0000 |             8.0064 |      1128.3811 |      0.0905 |      84.7806 |      0.9774 | \n",
      "   20 | 00m30s |   -0.15445 |              0.9069 |             0.9710 |    0.4878 |           1.0111 |      1.0000 |            10.5067 |      1120.0435 |      0.0238 |      78.5042 |      0.9787 | \n",
      "   21 | 00m46s |   -0.15849 |              0.9050 |             0.9859 |    0.8201 |           7.2923 |      1.0000 |            10.9839 |      1120.0597 |      0.0530 |      70.3806 |      0.9916 | \n",
      "   22 | 00m26s |   -0.15876 |              0.9054 |             0.9771 |    0.9004 |           0.0870 |      1.0000 |             8.0125 |      1129.0043 |      0.0140 |      71.2331 |      0.9935 | \n",
      "   23 | 00m27s |   -0.15391 |              0.9718 |             0.9884 |    0.0522 |           1.2097 |      1.0000 |            10.7394 |      1134.7338 |      0.2771 |      73.7294 |      0.9969 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00039775]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 00m19s |   -0.16092 |              0.9606 |             0.8131 |    0.4864 |           0.9444 |      1.0000 |            10.9701 |      1134.6509 |      0.0465 |      74.4718 |      0.9956 | \n",
      "   25 | 00m21s |   -0.15661 |              0.9728 |             0.9875 |    0.0261 |           3.9969 |      1.0000 |             9.1369 |      1120.0552 |      0.2075 |      75.8803 |      0.9312 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.65303679e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 00m21s |   -0.15580 |              0.9419 |             0.9441 |    0.1592 |           0.2728 |      1.0000 |            10.9157 |      1120.1140 |      0.2816 |      84.3731 |      0.9942 | \n",
      "   27 | 01m23s |   -0.15903 |              0.9081 |             0.9928 |    0.0142 |           9.2086 |      1.0000 |             8.1335 |      1129.4627 |      0.0975 |      73.4769 |      0.9592 | \n",
      "   28 | 00m51s |   -0.16118 |              0.9061 |             0.9707 |    0.9831 |           5.6139 |      1.0000 |             8.8473 |      1134.6209 |      0.2421 |      70.3411 |      0.9972 | \n",
      "   29 | 00m29s |   -0.16092 |              0.9060 |             0.9927 |    0.0122 |           5.4817 |      1.0000 |            10.7800 |      1132.8625 |      0.0927 |      79.2596 |      0.9583 | \n",
      "   30 | 00m24s |   -0.15822 |              0.9768 |             0.9231 |    0.0704 |           9.9300 |      1.0000 |             8.2388 |      1125.6408 |      0.2920 |      84.9317 |      0.9074 | \n",
      "   31 | 00m26s |   -0.15984 |              0.9925 |             0.9559 |    0.9205 |           9.6475 |      1.0000 |             8.1690 |      1120.0475 |      0.2943 |      74.3873 |      0.9319 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00079782]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 00m22s |   -0.15687 |              0.9891 |             0.9477 |    0.0021 |           1.7210 |      1.0000 |             8.0617 |      1134.8363 |      0.2160 |      84.3359 |      0.9996 | \n",
      "   33 | 00m23s |   -0.15903 |              0.9862 |             0.9774 |    0.0269 |           3.5361 |      1.0000 |             9.9064 |      1132.0749 |      0.2927 |      70.0439 |      0.9709 | \n",
      "   34 | 00m23s | \u001b[35m  -0.15148\u001b[0m | \u001b[32m             0.9499\u001b[0m | \u001b[32m            0.9892\u001b[0m | \u001b[32m   0.0150\u001b[0m | \u001b[32m          0.0064\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.7038\u001b[0m | \u001b[32m     1128.8367\u001b[0m | \u001b[32m     0.2753\u001b[0m | \u001b[32m     79.7314\u001b[0m | \u001b[32m     0.9022\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00059539]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 00m21s |   -0.15634 |              0.9008 |             0.9681 |    0.7175 |           9.9376 |      1.0000 |            10.5549 |      1134.6969 |      0.2413 |      75.1686 |      0.9815 | \n",
      "   36 | 00m22s |   -0.15634 |              0.9510 |             0.9877 |    0.0251 |           9.8629 |      1.0000 |            10.9761 |      1122.4219 |      0.2801 |      70.5818 |      0.9183 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-8.71446155e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 00m24s |   -0.15795 |              0.9198 |             0.9961 |    0.9605 |           0.3135 |      1.0000 |             8.2306 |      1134.4769 |      0.2994 |      77.3575 |      0.9110 | \n",
      "   38 | 00m22s |   -0.15957 |              0.9044 |             0.9916 |    0.0051 |           0.5937 |      1.0000 |            10.7354 |      1126.5313 |      0.2150 |      77.3550 |      0.9220 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([7.23050272e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00022849]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 47, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 00m25s |   -0.15741 |              0.9916 |             0.9309 |    0.0086 |           9.9099 |      1.0000 |            10.8599 |      1121.9736 |      0.1216 |      81.5799 |      0.9884 | \n",
      "   40 | 00m23s |   -0.16146 |              0.9158 |             0.9688 |    0.0939 |           0.0600 |      1.0000 |            10.5112 |      1120.0018 |      0.2509 |      72.9553 |      0.9455 | \n",
      "   41 | 00m37s |   -0.15687 |              0.9092 |             0.9606 |    0.9903 |           9.8513 |      1.0000 |            10.8576 |      1127.6928 |      0.0567 |      71.3691 |      0.9634 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00010794]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 00m25s |   -0.15661 |              0.9377 |             0.9937 |    0.1625 |           2.5722 |      1.0000 |             8.0802 |      1125.9846 |      0.0184 |      75.0427 |      0.9328 | \n",
      "   43 | 00m24s |   -0.16280 |              0.9164 |             0.9854 |    0.0085 |           0.2123 |      1.0000 |             8.6570 |      1131.8260 |      0.0857 |      84.7737 |      0.9793 | \n",
      "   44 | 00m24s |   -0.15984 |              0.9477 |             0.9598 |    0.8965 |           3.9584 |      1.0000 |             9.9265 |      1120.1545 |      0.2655 |      83.1886 |      0.9059 | \n",
      "   45 | 00m24s |   -0.15903 |              0.9989 |             0.8601 |    0.9363 |           0.1249 |      1.0000 |             8.7074 |      1121.4657 |      0.2977 |      78.6445 |      0.9976 | \n",
      "   46 | 00m23s |   -0.16118 |              0.9878 |             0.9447 |    0.9429 |           9.8431 |      1.0000 |             9.0785 |      1134.8211 |      0.1612 |      84.9713 |      0.9173 | \n",
      "   47 | 00m25s |   -0.15741 |              0.9838 |             0.9969 |    0.8795 |           2.1446 |      1.0000 |             8.1000 |      1130.1665 |      0.2908 |      78.3978 |      0.9973 | \n",
      "   48 | 00m24s |   -0.15553 |              0.9904 |             0.9924 |    0.0400 |           0.1675 |      1.0000 |             8.7532 |      1124.8083 |      0.0878 |      82.1066 |      0.9792 | \n",
      "   49 | 00m38s |   -0.16011 |              0.9658 |             0.9503 |    0.2049 |           5.6502 |      1.0000 |            10.9622 |      1134.8787 |      0.2400 |      72.0439 |      0.9310 | \n",
      "   50 | 00m42s |   -0.15984 |              0.9681 |             0.9969 |    0.4689 |           9.9634 |      1.0000 |             8.3635 |      1134.8566 |      0.2765 |      70.6112 |      0.9654 | \n",
      "   51 | 00m43s |   -0.15876 |              0.9169 |             0.9640 |    0.0216 |           9.8858 |      1.0000 |             8.0906 |      1134.8470 |      0.0945 |      78.8697 |      0.9141 | \n",
      "   52 | 00m38s |   -0.15660 |              0.9971 |             0.9800 |    0.0637 |           0.0129 |      1.0000 |             8.3547 |      1131.4870 |      0.0302 |      76.2344 |      0.9889 | \n",
      "   53 | 00m42s |   -0.16011 |              0.9962 |             0.9973 |    0.0707 |           9.8934 |      1.0000 |            10.2955 |      1125.3835 |      0.0157 |      74.3178 |      0.9275 | \n",
      "   54 | 00m47s |   -0.15607 |              0.9326 |             0.8538 |    0.7717 |           9.9464 |      1.0000 |            10.1116 |      1120.0543 |      0.0053 |      71.3988 |      0.9025 | \n",
      "   55 | 00m47s |   -0.15930 |              0.9068 |             0.9918 |    0.5447 |           9.9311 |      1.0000 |            10.9189 |      1127.7405 |      0.2721 |      84.0701 |      0.9869 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00041231]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   56 | 00m47s |   -0.15768 |              0.9346 |             0.9127 |    0.8891 |           3.3752 |      1.0000 |             8.4939 |      1124.1789 |      0.1559 |      70.1168 |      0.9031 | \n",
      "   57 | 00m49s |   -0.16011 |              0.9246 |             0.9911 |    0.0597 |           4.5997 |      1.0000 |             8.2207 |      1127.6495 |      0.2852 |      81.8868 |      0.9328 | \n",
      "   58 | 00m44s |   -0.15472 |              0.9166 |             0.9941 |    0.0498 |           9.6428 |      1.0000 |            10.9135 |      1131.4833 |      0.2898 |      76.0422 |      0.9199 | \n",
      "   59 | 00m47s |   -0.15660 |              0.9445 |             0.8021 |    0.0767 |           0.4702 |      1.0000 |            10.9714 |      1120.3536 |      0.0229 |      80.7674 |      0.9242 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00023367]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 63, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   60 | 00m43s |   -0.15876 |              0.9874 |             0.9860 |    0.8948 |           0.0901 |      1.0000 |            10.8716 |      1125.9910 |      0.1581 |      84.9960 |      0.9032 | \n",
      "   61 | 00m45s |   -0.16038 |              0.9335 |             0.9703 |    0.9763 |           9.4398 |      1.0000 |            10.5997 |      1120.0332 |      0.0117 |      79.8645 |      0.9483 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00047712]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   62 | 00m46s |   -0.15957 |              0.9437 |             0.9835 |    0.1416 |           9.9775 |      1.0000 |            10.2497 |      1131.2825 |      0.2996 |      70.0772 |      0.9064 | \n",
      "   63 | 00m48s |   -0.15553 |              0.9171 |             0.8004 |    0.0484 |           0.0140 |      1.0000 |             8.0193 |      1134.8702 |      0.2948 |      82.2810 |      0.9594 | \n",
      "   64 | 00m49s |   -0.15822 |              0.9758 |             0.9336 |    0.0158 |           6.9061 |      1.0000 |             9.9209 |      1120.5321 |      0.0060 |      84.9017 |      0.9074 | \n",
      "   65 | 00m45s |   -0.15634 |              0.9138 |             0.8255 |    0.1316 |           9.9578 |      1.0000 |             9.0484 |      1120.2581 |      0.0196 |      84.5690 |      0.9117 | \n",
      "   66 | 00m52s | \u001b[35m  -0.15095\u001b[0m | \u001b[32m             0.9028\u001b[0m | \u001b[32m            0.9798\u001b[0m | \u001b[32m   0.0073\u001b[0m | \u001b[32m          2.2875\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.2561\u001b[0m | \u001b[32m     1131.9346\u001b[0m | \u001b[32m     0.2851\u001b[0m | \u001b[32m     73.8554\u001b[0m | \u001b[32m     0.9092\u001b[0m | \n",
      "   67 | 00m53s |   -0.15526 |              0.9436 |             0.9843 |    0.0217 |           2.0779 |      1.0000 |             8.3247 |      1134.7167 |      0.2640 |      73.9984 |      0.9132 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00073819]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 63, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   68 | 00m51s |   -0.15957 |              0.9149 |             0.9990 |    0.0010 |           0.5094 |      1.0000 |            10.3459 |      1133.4346 |      0.2591 |      72.0536 |      0.9940 | \n",
      "   69 | 00m48s |   -0.15687 |              0.9630 |             0.9562 |    0.0090 |           9.8427 |      1.0000 |            10.5931 |      1134.5701 |      0.2785 |      80.9620 |      0.9020 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.58164185e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   70 | 00m50s |   -0.16092 |              0.9721 |             0.9786 |    0.8644 |           4.9213 |      1.0000 |             8.0359 |      1129.6112 |      0.2087 |      73.5908 |      0.9344 | \n",
      "   71 | 00m54s |   -0.15633 |              0.9026 |             0.9991 |    0.0146 |           9.9660 |      1.0000 |             8.3547 |      1127.6516 |      0.0380 |      79.6663 |      0.9528 | \n",
      "   72 | 00m52s |   -0.15687 |              0.9623 |             0.9664 |    0.1388 |           0.4619 |      1.0000 |             8.2638 |      1123.9391 |      0.1868 |      70.0202 |      0.9874 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([7.6588369e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   73 | 00m51s |   -0.15714 |              0.9332 |             0.9457 |    0.9364 |           1.4880 |      1.0000 |            10.7205 |      1134.8290 |      0.2785 |      70.0202 |      0.9339 | \n",
      "   74 | 00m53s |   -0.15552 |              0.9143 |             0.8077 |    0.2216 |           0.0609 |      1.0000 |             8.8681 |      1124.4376 |      0.2706 |      84.8209 |      0.9124 | \n",
      "   75 | 00m54s |   -0.15876 |              0.9942 |             0.9614 |    0.1809 |           5.1802 |      1.0000 |            10.8913 |      1126.7024 |      0.0502 |      70.0132 |      0.9696 | \n",
      "   76 | 00m54s |   -0.15984 |              0.9084 |             0.9754 |    0.0115 |           4.1673 |      1.0000 |            10.9905 |      1121.9138 |      0.2456 |      79.6807 |      0.9915 | \n",
      "   77 | 00m52s |   -0.15471 |              0.9392 |             0.9999 |    0.0364 |           3.2750 |      1.0000 |             9.1027 |      1130.7355 |      0.2794 |      75.1965 |      0.9108 | \n",
      "   78 | 00m54s |   -0.15687 |              0.9068 |             0.9378 |    0.0811 |           0.0829 |      1.0000 |             8.0237 |      1121.9868 |      0.0068 |      73.5742 |      0.9067 | \n",
      "   79 | 00m52s |   -0.15687 |              0.9876 |             0.9582 |    0.0148 |           2.5580 |      1.0000 |             8.3956 |      1134.6020 |      0.2892 |      81.2546 |      0.9319 | \n",
      "   80 | 00m56s |   -0.16038 |              0.9133 |             0.9715 |    0.8914 |           2.9675 |      1.0000 |            10.9398 |      1122.5130 |      0.0849 |      73.2181 |      0.9156 | \n",
      "   81 | 00m53s |   -0.15741 |              0.9322 |             0.8616 |    0.0948 |           9.8025 |      1.0000 |             8.5241 |      1120.0001 |      0.2635 |      78.2163 |      0.9235 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00255566]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00218357]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   82 | 00m57s |   -0.15499 |              0.9601 |             0.8101 |    0.0010 |           3.3132 |      1.0000 |             8.0735 |      1120.0508 |      0.1196 |      70.7254 |      0.9025 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00067762]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00084974]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   83 | 00m55s |   -0.15741 |              0.9004 |             0.8080 |    0.1681 |           9.6777 |      1.0000 |            10.7738 |      1120.0175 |      0.2263 |      72.7981 |      0.9481 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00218797]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   84 | 00m50s |   -0.16092 |              0.9092 |             0.9698 |    0.0512 |           2.0219 |      1.0000 |            10.6000 |      1134.8993 |      0.0147 |      70.0413 |      0.9141 | \n",
      "   85 | 00m54s |   -0.15417 |              0.9679 |             0.9670 |    0.0127 |           9.3505 |      1.0000 |             8.2982 |      1132.5914 |      0.2643 |      84.9929 |      0.9690 | \n",
      "   86 | 01m00s |   -0.15903 |              0.9829 |             0.8653 |    0.0249 |           3.8094 |      1.0000 |             8.1005 |      1120.0818 |      0.2567 |      84.9544 |      0.9945 | \n",
      "   87 | 01m01s |   -0.15768 |              0.9952 |             0.9544 |    0.0246 |           1.2276 |      1.0000 |             8.7544 |      1120.0169 |      0.2830 |      77.8131 |      0.9418 | \n",
      "   88 | 00m52s |   -0.15957 |              0.9472 |             0.9842 |    0.0165 |           0.2444 |      1.0000 |             8.1446 |      1131.1414 |      0.2969 |      80.1814 |      0.9936 | \n",
      "   89 | 00m53s |   -0.15795 |              0.9117 |             0.9498 |    0.8246 |           0.0245 |      1.0000 |             8.2667 |      1126.5953 |      0.1848 |      77.8293 |      0.9034 | \n",
      "   90 | 03m50s |   -0.15741 |              0.9558 |             0.8973 |    0.0049 |           9.8183 |      1.0000 |             8.0711 |      1134.9796 |      0.0518 |      84.7380 |      0.9152 | \n",
      "   91 | 00m59s |   -0.16415 |              0.9995 |             0.9103 |    0.9522 |           9.9516 |      1.0000 |            10.9159 |      1132.8419 |      0.0131 |      70.2368 |      0.9552 | \n",
      "   92 | 00m58s |   -0.15903 |              0.9519 |             0.9677 |    0.9620 |           0.2070 |      1.0000 |             8.4003 |      1120.5845 |      0.2202 |      84.9975 |      0.9202 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00030428]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   93 | 01m17s |   -0.15849 |              0.9674 |             0.9818 |    0.0069 |           0.3342 |      1.0000 |            10.2980 |      1127.6232 |      0.2590 |      81.9583 |      0.9895 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00029101]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   94 | 03m53s |   -0.16253 |              0.9122 |             0.9916 |    0.9090 |           9.5046 |      1.0000 |             8.4070 |      1125.7314 |      0.0067 |      70.1024 |      0.9928 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00086473]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   95 | 01m07s |   -0.15660 |              0.9578 |             0.8857 |    0.6853 |           0.0447 |      1.0000 |             8.1991 |      1134.9894 |      0.0932 |      84.6548 |      0.9243 | \n",
      "   96 | 01m07s |   -0.15687 |              0.9710 |             0.9796 |    0.0080 |           7.3887 |      1.0000 |            10.0779 |      1134.3206 |      0.2933 |      84.9403 |      0.9396 | \n",
      "   97 | 02m33s |   -0.15310 |              0.9712 |             0.9891 |    0.0021 |           9.7697 |      1.0000 |             8.5204 |      1134.5943 |      0.1839 |      73.7514 |      0.9600 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00019739]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00037735]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 63, 'nit': 8, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   98 | 02m40s |   -0.15310 |              0.9892 |             0.9983 |    0.2244 |           9.7999 |      1.0000 |            10.8477 |      1120.2065 |      0.0634 |      70.1431 |      0.9224 | \n",
      "   99 | 02m00s |   -0.15714 |              0.9850 |             0.9837 |    0.1687 |           2.6146 |      1.0000 |             8.0164 |      1127.3357 |      0.1272 |      70.0287 |      0.9514 | \n",
      "  100 | 01m51s |   -0.15957 |              0.9024 |             0.9846 |    0.0173 |           9.9852 |      1.0000 |            10.7714 |      1129.8531 |      0.2813 |      79.8754 |      0.9919 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00228978]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  101 | 01m45s |   -0.15795 |              0.9255 |             0.9936 |    0.7480 |           9.9688 |      1.0000 |             8.2881 |      1123.4580 |      0.0207 |      80.9743 |      0.9088 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00066862]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  102 | 02m22s |   -0.15553 |              0.9955 |             0.9750 |    0.7433 |           9.8927 |      1.0000 |             8.9479 |      1129.4726 |      0.0159 |      84.9713 |      0.9216 | \n",
      "  103 | 01m19s |   -0.16334 |              0.9585 |             0.9895 |    0.1008 |           9.9974 |      1.0000 |            10.6543 |      1134.8492 |      0.0319 |      76.0602 |      0.9887 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00300739]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  104 | 02m07s |   -0.15768 |              0.9021 |             0.9715 |    0.9634 |           9.9528 |      1.0000 |             8.4576 |      1131.7257 |      0.2960 |      75.6357 |      0.9607 | \n",
      "  105 | 01m43s |   -0.15418 |              0.9603 |             0.9792 |    0.0820 |           2.1233 |      1.0000 |            10.9674 |      1120.6540 |      0.0070 |      84.9595 |      0.9103 | \n",
      "  106 | 01m22s |   -0.15984 |              0.9496 |             0.9608 |    0.1389 |           9.7919 |      1.0000 |            10.7010 |      1132.0455 |      0.2998 |      84.6605 |      0.9288 | \n",
      "2018-06-16 15:34:55,888 - logHandler - train - INFO - Iteration: 14, XGBoost max auc: -0.150946\n",
      "2018-06-16 15:34:56,160 - logHandler - train - INFO - Param max_delta_step: 2.287536207221538\n",
      "2018-06-16 15:34:56,161 - logHandler - train - INFO - Param reg_lambda: 73.85540397929837\n",
      "2018-06-16 15:34:56,162 - logHandler - train - INFO - Param reg_alpha: 0.2851213341451585\n",
      "2018-06-16 15:34:56,162 - logHandler - train - INFO - Param n_estimators: 1131.9346450393186\n",
      "2018-06-16 15:34:56,163 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-16 15:34:56,164 - logHandler - train - INFO - Param subsample: 0.9092196773958371\n",
      "2018-06-16 15:34:56,165 - logHandler - train - INFO - Param min_child_weight: 8.256141994143556\n",
      "2018-06-16 15:34:56,165 - logHandler - train - INFO - Param gamma: 0.0073493589556297145\n",
      "2018-06-16 15:34:56,166 - logHandler - train - INFO - Param colsample_bytree: 0.9797955160096147\n",
      "2018-06-16 15:34:56,167 - logHandler - train - INFO - Param colsample_bylevel: 0.9028238091570775\n",
      "2018-06-16 15:34:56,167 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-16 15:34:57,116 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-16 15:34:57,117 - logHandler - train - INFO - Iteration 15, Current random seed: 15\n",
      "2018-06-16 15:34:57,188 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-16 15:34:57,188 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m  -0.16577\u001b[0m | \u001b[32m             0.9302\u001b[0m | \u001b[32m            0.9710\u001b[0m | \u001b[32m   0.5649\u001b[0m | \u001b[32m          6.4537\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.7291\u001b[0m | \u001b[32m     1131.5821\u001b[0m | \u001b[32m     0.1983\u001b[0m | \u001b[32m     81.9064\u001b[0m | \u001b[32m     0.9359\u001b[0m | \n",
      "    2 | 00m03s | \u001b[35m  -0.15552\u001b[0m | \u001b[32m             0.9796\u001b[0m | \u001b[32m            0.8275\u001b[0m | \u001b[32m   0.3804\u001b[0m | \u001b[32m          9.2619\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.2046\u001b[0m | \u001b[32m     1134.7755\u001b[0m | \u001b[32m     0.1470\u001b[0m | \u001b[32m     81.6130\u001b[0m | \u001b[32m     0.9992\u001b[0m | \n",
      "    3 | 00m02s |   -0.16254 |              0.9782 |             0.9594 |    0.8978 |           6.3076 |      1.0000 |            10.5535 |      1120.8727 |      0.2914 |      71.3888 |      0.9212 | \n",
      "    4 | 00m01s |   -0.16038 |              0.9132 |             0.9149 |    0.6921 |           9.5475 |      1.0000 |             9.0690 |      1127.4789 |      0.0620 |      75.1803 |      0.9318 | \n",
      "    5 | 00m03s | \u001b[35m  -0.15552\u001b[0m | \u001b[32m             0.9430\u001b[0m | \u001b[32m            0.8531\u001b[0m | \u001b[32m   0.1328\u001b[0m | \u001b[32m          8.7823\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.6325\u001b[0m | \u001b[32m     1134.9726\u001b[0m | \u001b[32m     0.1896\u001b[0m | \u001b[32m     78.5204\u001b[0m | \u001b[32m     0.9122\u001b[0m | \n",
      "    6 | 00m03s |   -0.15822 |              0.9392 |             0.8551 |    0.4569 |           9.6544 |      1.0000 |            10.3106 |      1133.0552 |      0.0774 |      77.2135 |      0.9407 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 00m11s |   -0.16173 |              0.9196 |             0.8787 |    0.0983 |           9.9794 |      1.0000 |             8.1167 |      1120.2483 |      0.1617 |      84.4418 |      0.9829 | \n",
      "    8 | 01m58s |   -0.15714 |              0.9127 |             0.8617 |    0.9010 |           8.9699 |      1.0000 |             8.1323 |      1134.9750 |      0.0342 |      70.4222 |      0.9094 | \n",
      "    9 | 06m52s |   -0.15876 |              0.9582 |             0.8735 |    0.0136 |           9.8554 |      1.0000 |             8.0587 |      1122.0973 |      0.2771 |      70.3906 |      0.9075 | \n",
      "   10 | 04m13s |   -0.16119 |              0.9663 |             0.9624 |    0.2909 |           0.0420 |      1.0000 |             8.6056 |      1120.1687 |      0.0251 |      70.3137 |      0.9885 | \n",
      "   11 | 10m36s | \u001b[35m  -0.15391\u001b[0m | \u001b[32m             0.9135\u001b[0m | \u001b[32m            0.9883\u001b[0m | \u001b[32m   0.6766\u001b[0m | \u001b[32m          9.8366\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.1313\u001b[0m | \u001b[32m     1134.2970\u001b[0m | \u001b[32m     0.2988\u001b[0m | \u001b[32m     84.5990\u001b[0m | \u001b[32m     0.9151\u001b[0m | \n",
      "   12 | 06m47s |   -0.15768 |              0.9681 |             0.8750 |    0.3436 |           9.8515 |      1.0000 |             8.0425 |      1134.6774 |      0.0399 |      84.0108 |      0.9076 | \n",
      "   13 | 05m51s |   -0.16011 |              0.9011 |             0.8285 |    0.9350 |           0.0205 |      1.0000 |             8.3601 |      1132.5340 |      0.2754 |      70.0005 |      0.9452 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.53296312e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00019816]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 05m08s |   -0.16145 |              0.9387 |             0.8026 |    0.9918 |           9.6813 |      1.0000 |             8.6899 |      1134.9391 |      0.2894 |      77.1721 |      0.9050 | \n",
      "   15 | 05m38s |   -0.15768 |              0.9213 |             0.9651 |    0.0281 |           0.0318 |      1.0000 |            10.5965 |      1120.0884 |      0.1173 |      84.8748 |      0.9348 | \n",
      "   16 | 06m17s |   -0.16091 |              1.0000 |             1.0000 |    0.0000 |          10.0000 |      1.0000 |            11.0000 |      1128.7643 |      0.3000 |      83.5508 |      1.0000 | \n",
      "   17 | 06m44s |   -0.15768 |              0.9515 |             0.9656 |    0.4740 |           0.7292 |      1.0000 |            10.9501 |      1134.8607 |      0.1939 |      84.7587 |      0.9173 | \n",
      "   18 | 05m59s |   -0.15930 |              0.9753 |             0.9688 |    0.1140 |           4.1979 |      1.0000 |            10.7618 |      1134.8025 |      0.1501 |      70.1082 |      0.9977 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00015817]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 05m10s |   -0.16308 |              0.9670 |             0.8198 |    0.0376 |           0.1339 |      1.0000 |             8.0016 |      1120.0326 |      0.2114 |      78.2090 |      0.9375 | \n",
      "   20 | 05m11s |   -0.15957 |              1.0000 |             0.9394 |    0.0000 |          10.0000 |      1.0000 |            11.0000 |      1135.0000 |      0.0000 |      85.0000 |      1.0000 | \n",
      "   21 | 06m38s |   -0.15903 |              0.9000 |             1.0000 |    0.0000 |           9.7705 |      1.0000 |            10.7464 |      1129.5061 |      0.3000 |      70.5954 |      1.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00030384]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00019056]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 08m47s |   -0.15472 |              0.9763 |             0.9027 |    0.1186 |           9.9153 |      1.0000 |            10.5523 |      1120.0353 |      0.2113 |      78.0145 |      0.9210 | \n",
      "   23 | 06m26s |   -0.15660 |              0.9100 |             0.9135 |    0.1679 |           0.1025 |      1.0000 |            10.9825 |      1134.9251 |      0.1507 |      77.0949 |      0.9692 | \n",
      "   24 | 03m38s |   -0.16092 |              0.9013 |             0.9517 |    0.0187 |           0.2213 |      1.0000 |             8.6295 |      1134.8279 |      0.2060 |      83.6430 |      0.9861 | \n",
      "   25 | 05m59s |   -0.15929 |              0.9931 |             0.8769 |    0.8452 |           0.1411 |      1.0000 |            10.9410 |      1120.2876 |      0.2000 |      76.9809 |      0.9719 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.72573109e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 06m40s |   -0.15984 |              0.9325 |             0.9049 |    0.1667 |           0.3884 |      1.0000 |             8.0454 |      1134.8329 |      0.0354 |      70.1588 |      0.9870 | \n",
      "   27 | 04m53s |   -0.15984 |              0.9219 |             0.9997 |    0.9583 |           9.8818 |      1.0000 |             8.3002 |      1120.0369 |      0.0888 |      75.2097 |      0.9854 | \n",
      "   28 | 06m31s |   -0.15768 |              0.9264 |             0.9861 |    0.0268 |           0.0806 |      1.0000 |            10.5437 |      1126.9423 |      0.2629 |      71.8282 |      0.9919 | \n",
      "   29 | 05m52s |   -0.15930 |              0.9382 |             0.9170 |    0.0697 |           6.1971 |      1.0000 |             8.0331 |      1133.6314 |      0.2807 |      70.3978 |      0.9762 | \n",
      "   30 | 06m55s |   -0.15715 |              0.9558 |             0.9887 |    0.0649 |           5.0998 |      1.0000 |            10.4849 |      1120.1418 |      0.2853 |      80.4073 |      0.9145 | \n",
      "   31 | 06m17s |   -0.15984 |              0.9142 |             0.9055 |    0.8833 |           9.9957 |      1.0000 |            10.9458 |      1120.0561 |      0.1355 |      84.6926 |      0.9616 | \n",
      "   32 | 05m44s |   -0.15687 |              0.9020 |             0.8328 |    0.1060 |           9.9026 |      1.0000 |            10.6872 |      1134.8547 |      0.2877 |      71.0469 |      0.9663 | \n",
      "   33 | 04m53s |   -0.16118 |              0.9148 |             0.9880 |    0.0033 |           9.5476 |      1.0000 |            10.5172 |      1134.7136 |      0.1964 |      80.3266 |      0.9237 | \n",
      "   34 | 07m00s |   -0.15499 |              0.9426 |             0.8022 |    0.1904 |           5.3500 |      1.0000 |             9.0140 |      1134.8009 |      0.2808 |      84.3587 |      0.9811 | \n",
      "   35 | 04m46s |   -0.15606 |              1.0000 |             1.0000 |    1.0000 |           0.0000 |      1.0000 |             8.2202 |      1120.0625 |      0.0000 |      85.0000 |      1.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00053531]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 | 07m19s |   -0.15714 |              0.9101 |             0.9751 |    0.0679 |           9.9444 |      1.0000 |            10.7282 |      1120.1654 |      0.1121 |      70.2998 |      0.9902 | \n",
      "   37 | 05m06s |   -0.16227 |              0.9752 |             0.8538 |    0.8500 |           0.2838 |      1.0000 |            10.7547 |      1123.9974 |      0.1879 |      84.4654 |      0.9811 | \n",
      "   38 | 07m00s |   -0.15903 |              0.9451 |             0.8065 |    0.0259 |           0.0008 |      1.0000 |            10.9455 |      1131.9293 |      0.2598 |      70.0602 |      0.9227 | \n",
      "   39 | 06m25s |   -0.16037 |              0.9783 |             0.8048 |    0.1469 |           5.3830 |      1.0000 |            10.8806 |      1120.4121 |      0.0213 |      74.2856 |      0.9841 | \n",
      "   40 | 07m41s |   -0.16118 |              0.9934 |             0.8399 |    0.9472 |           4.8153 |      1.0000 |            10.1775 |      1120.3915 |      0.2332 |      84.9580 |      0.9933 | \n",
      "   41 | 08m14s |   -0.15687 |              0.9751 |             0.8614 |    0.0816 |           9.8116 |      1.0000 |             8.0756 |      1133.3397 |      0.2993 |      74.9309 |      0.9961 | \n",
      "   42 | 05m04s |   -0.16145 |              0.9797 |             0.8131 |    0.7747 |           0.1624 |      1.0000 |            10.6721 |      1125.1051 |      0.1661 |      70.0681 |      0.9657 | \n",
      "   43 | 07m45s |   -0.15957 |              0.9261 |             0.8182 |    0.3312 |           5.7445 |      1.0000 |            10.7790 |      1131.0545 |      0.2683 |      75.4873 |      0.9976 | \n",
      "   44 | 07m18s |   -0.15795 |              0.9048 |             0.9560 |    0.9702 |           5.3772 |      1.0000 |             9.4018 |      1134.8341 |      0.1707 |      84.8824 |      0.9860 | \n",
      "   45 | 05m56s |   -0.16173 |              0.9597 |             0.8226 |    0.5606 |           9.8589 |      1.0000 |            10.4568 |      1122.8359 |      0.2901 |      79.3719 |      0.9888 | \n",
      "   46 | 08m09s |   -0.16038 |              0.9897 |             0.9485 |    0.7838 |           9.8845 |      1.0000 |             8.0630 |      1132.3899 |      0.2687 |      84.9512 |      0.9978 | \n",
      "   47 | 06m37s |   -0.15849 |              0.9770 |             0.8435 |    0.9532 |           0.1106 |      1.0000 |            10.9060 |      1134.9564 |      0.2207 |      71.7775 |      0.9835 | \n",
      "   48 | 05m34s |   -0.16199 |              0.9892 |             0.8075 |    0.7058 |           0.0936 |      1.0000 |            10.6174 |      1129.4891 |      0.2956 |      78.7536 |      0.9715 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-9.58197768e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 08m06s |   -0.15579 |              0.9993 |             0.8216 |    0.1827 |           0.0856 |      1.0000 |             8.1573 |      1134.9694 |      0.2294 |      74.9233 |      0.9253 | \n",
      "   50 | 08m26s |   -0.15903 |              0.9321 |             0.9446 |    0.1011 |           8.2028 |      1.0000 |             8.3038 |      1134.8877 |      0.2934 |      84.5786 |      0.9884 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00018433]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   51 | 09m30s |   -0.16281 |              0.9118 |             0.8135 |    0.8301 |           2.4399 |      1.0000 |             9.0540 |      1134.8783 |      0.2955 |      78.9660 |      0.9120 | \n",
      "   52 | 08m24s |   -0.15822 |              0.9902 |             0.8094 |    0.9378 |           9.9927 |      1.0000 |            10.8809 |      1134.3349 |      0.2912 |      84.5839 |      0.9041 | \n",
      "   53 | 12m50s |   -0.15552 |              0.9181 |             0.8138 |    0.0277 |           9.9657 |      1.0000 |             8.4909 |      1130.0046 |      0.2713 |      78.2146 |      0.9631 | \n",
      "   54 | 06m44s |   -0.15930 |              0.9248 |             0.9245 |    0.0656 |           0.2495 |      1.0000 |            10.2832 |      1130.7546 |      0.2845 |      84.9786 |      0.9085 | \n",
      "   55 | 06m46s |   -0.15552 |              0.9099 |             0.8124 |    0.0870 |           0.5318 |      1.0000 |             9.3621 |      1132.1973 |      0.0432 |      73.9114 |      0.9939 | \n",
      "   56 | 08m04s |   -0.15660 |              0.9833 |             0.9907 |    0.1835 |           7.2926 |      1.0000 |             8.2399 |      1120.0001 |      0.2879 |      70.1223 |      0.9741 | \n",
      "   57 | 08m26s |   -0.15661 |              0.9221 |             0.9204 |    0.1298 |           9.7453 |      1.0000 |             8.5364 |      1134.5644 |      0.0026 |      70.0253 |      0.9571 | \n",
      "   58 | 06m54s |   -0.16011 |              0.9023 |             0.8913 |    0.2012 |           0.5790 |      1.0000 |            10.9478 |      1120.4105 |      0.2398 |      70.2010 |      0.9521 | \n",
      "   59 | 09m18s |   -0.15714 |              0.9082 |             0.9477 |    0.9826 |           0.5485 |      1.0000 |            10.4823 |      1120.0450 |      0.2870 |      81.5461 |      0.9134 | \n",
      "   60 | 09m45s |   -0.15742 |              0.9810 |             0.8392 |    0.7610 |           9.6595 |      1.0000 |             8.3866 |      1120.1162 |      0.0195 |      70.5155 |      0.9455 | \n",
      "   61 | 08m13s |   -0.15687 |              0.9221 |             0.8345 |    0.1845 |           6.7556 |      1.0000 |             9.3310 |      1134.9098 |      0.0562 |      72.7291 |      0.9901 | \n",
      "   62 | 11m30s |   -0.15580 |              0.9020 |             0.8299 |    0.0529 |           0.0014 |      1.0000 |            10.6273 |      1123.1017 |      0.2674 |      79.4758 |      0.9665 | \n",
      "   63 | 07m36s |   -0.15822 |              0.9447 |             0.8532 |    0.0054 |           3.4410 |      1.0000 |            10.9426 |      1135.0000 |      0.2707 |      83.4567 |      0.9779 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00034199]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   64 | 06m58s |   -0.15930 |              0.9413 |             0.8552 |    0.9211 |           0.0278 |      1.0000 |             8.6916 |      1124.2800 |      0.2563 |      75.3070 |      0.9353 | \n",
      "   65 | 13m38s |   -0.15472 |              0.9507 |             0.8426 |    0.0133 |           9.8662 |      1.0000 |            10.9664 |      1126.6908 |      0.2327 |      76.5238 |      0.9561 | \n",
      "   66 | 08m34s |   -0.15634 |              0.9053 |             0.8344 |    0.0454 |           8.5340 |      1.0000 |             9.1397 |      1120.0820 |      0.2619 |      73.4458 |      0.9654 | \n",
      "   67 | 08m20s |   -0.16011 |              0.9142 |             0.8586 |    0.4464 |           0.9264 |      1.0000 |             8.2572 |      1120.9024 |      0.2987 |      84.9881 |      0.9676 | \n",
      "   68 | 10m05s |   -0.16038 |              0.9075 |             0.8284 |    0.0112 |           9.7445 |      1.0000 |             9.6428 |      1130.6690 |      0.1602 |      73.7865 |      0.9020 | \n",
      "   69 | 09m55s |   -0.15633 |              0.9140 |             0.8495 |    0.7186 |           4.2870 |      1.0000 |             8.2242 |      1123.8236 |      0.2497 |      70.0411 |      0.9925 | \n",
      "   70 | 09m12s |   -0.15499 |              0.9632 |             0.9426 |    0.0376 |           8.1520 |      1.0000 |            10.8029 |      1125.2674 |      0.0200 |      70.6468 |      0.9983 | \n",
      "   71 | 08m30s |   -0.15929 |              0.9754 |             0.8891 |    0.0047 |           4.9656 |      1.0000 |             9.9907 |      1125.9563 |      0.2632 |      75.8544 |      0.9680 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00037316]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   72 | 08m44s |   -0.16037 |              0.9351 |             0.8542 |    0.7696 |           9.8155 |      1.0000 |             9.1683 |      1126.1299 |      0.1231 |      70.0763 |      0.9873 | \n",
      "   73 | 11m19s |   -0.15741 |              0.9945 |             0.9932 |    0.0043 |           8.1995 |      1.0000 |            10.4281 |      1120.0468 |      0.2912 |      83.7229 |      0.9894 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.001623]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 | 12m20s |   -0.15822 |              0.9193 |             0.8996 |    0.0129 |           9.9811 |      1.0000 |             8.5441 |      1133.2698 |      0.2074 |      81.0213 |      0.9933 | \n",
      "   75 | 09m49s |   -0.15660 |              0.9929 |             0.8169 |    0.0171 |           0.1171 |      1.0000 |             8.0182 |      1127.3348 |      0.0325 |      72.5799 |      0.9809 | \n",
      "   76 | 10m47s |   -0.15741 |              0.9010 |             0.8050 |    0.9769 |           9.7676 |      1.0000 |             8.4215 |      1134.8115 |      0.1410 |      84.5914 |      0.9322 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0003683]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00076285]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   77 | 09m24s |   -0.15741 |              0.9888 |             0.9987 |    0.1770 |           6.2418 |      1.0000 |             8.4432 |      1134.8631 |      0.2459 |      78.8741 |      0.9711 | \n",
      "   78 | 09m26s |   -0.15526 |              0.9710 |             0.9634 |    0.9974 |           0.3717 |      1.0000 |             8.9043 |      1134.7863 |      0.2881 |      84.9099 |      0.9403 | \n",
      "   79 | 08m51s |   -0.15984 |              0.9791 |             0.8185 |    0.1026 |           3.7699 |      1.0000 |            10.5741 |      1128.7227 |      0.1059 |      70.1830 |      0.9563 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00033459]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 46, 'nit': 2, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   80 | 08m37s |   -0.16145 |              0.9923 |             0.8319 |    0.9577 |           9.9157 |      1.0000 |            10.8645 |      1133.1978 |      0.0246 |      70.1214 |      0.9606 | \n",
      "   81 | 09m12s |   -0.15822 |              0.9758 |             0.8142 |    0.0600 |           0.6946 |      1.0000 |             9.5672 |      1122.5086 |      0.2743 |      73.0134 |      0.9743 | \n",
      "   82 | 09m54s |   -0.15633 |              0.9878 |             0.8068 |    0.0088 |           0.1876 |      1.0000 |            10.4840 |      1134.4222 |      0.2918 |      75.8264 |      0.9992 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00014814]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   83 | 09m06s |   -0.15903 |              0.9497 |             0.8267 |    0.0179 |           0.1987 |      1.0000 |            10.9285 |      1127.5296 |      0.0349 |      75.4574 |      0.9014 | \n",
      "   84 | 08m36s |   -0.15795 |              0.9866 |             0.8715 |    0.8973 |           9.2339 |      1.0000 |             8.2771 |      1120.0755 |      0.2889 |      82.2701 |      0.9318 | \n",
      "   85 | 10m07s |   -0.15984 |              0.9996 |             0.8677 |    0.0566 |           9.2053 |      1.0000 |             9.8233 |      1130.1831 |      0.2221 |      77.5093 |      0.9061 | \n",
      "   86 | 08m11s |   -0.15903 |              0.9168 |             0.8583 |    0.3859 |           9.8905 |      1.0000 |            10.8668 |      1123.4007 |      0.2455 |      73.1934 |      0.9836 | \n",
      "   87 | 12m22s |   -0.15849 |              0.9106 |             0.8741 |    0.0354 |           9.7504 |      1.0000 |             8.0013 |      1120.1998 |      0.2329 |      77.8937 |      0.9951 | \n",
      "   88 | 08m37s |   -0.15903 |              0.9643 |             0.8109 |    0.8446 |           6.0410 |      1.0000 |             8.0856 |      1134.8149 |      0.2923 |      81.6807 |      0.9256 | \n",
      "   89 | 08m13s |   -0.15903 |              0.9412 |             0.9997 |    0.4757 |           0.0121 |      1.0000 |             8.0936 |      1126.7734 |      0.1827 |      81.7238 |      0.9972 | \n",
      "   90 | 13m55s |   -0.15418 |              0.9076 |             0.8269 |    0.1010 |           5.0949 |      1.0000 |             8.0707 |      1126.2007 |      0.0002 |      71.6994 |      0.9981 | \n",
      "   91 | 10m46s |   -0.16092 |              0.9829 |             0.8388 |    0.9877 |           2.9191 |      1.0000 |             8.7455 |      1133.4125 |      0.2933 |      84.6001 |      0.9889 | \n",
      "   92 | 09m10s |   -0.15876 |              0.9434 |             0.9719 |    0.0031 |           9.8363 |      1.0000 |             8.3265 |      1125.8601 |      0.2857 |      78.8205 |      0.9896 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00039574]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   93 | 09m37s |   -0.15903 |              0.9120 |             0.8056 |    0.3695 |           9.9769 |      1.0000 |            10.9167 |      1120.2547 |      0.2635 |      81.6453 |      0.9970 | \n",
      "   94 | 13m18s | \u001b[35m  -0.15148\u001b[0m | \u001b[32m             0.9212\u001b[0m | \u001b[32m            0.8777\u001b[0m | \u001b[32m   0.0847\u001b[0m | \u001b[32m          6.4516\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.1044\u001b[0m | \u001b[32m     1126.1147\u001b[0m | \u001b[32m     0.1358\u001b[0m | \u001b[32m     70.0339\u001b[0m | \u001b[32m     0.9813\u001b[0m | \n",
      "   95 | 09m39s |   -0.15768 |              0.9227 |             0.8095 |    0.0910 |           7.8375 |      1.0000 |            10.9843 |      1120.0302 |      0.2738 |      77.1672 |      0.9130 | \n",
      "   96 | 08m02s |   -0.15957 |              0.9089 |             0.8054 |    0.1352 |           5.6957 |      1.0000 |            10.2898 |      1122.8001 |      0.0341 |      70.1625 |      0.9977 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([8.82289605e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   97 | 10m42s |   -0.15661 |              0.9957 |             0.9647 |    0.0243 |           0.0608 |      1.0000 |             8.0262 |      1129.8787 |      0.2993 |      74.5762 |      0.9397 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00075544]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   98 | 08m32s |   -0.16145 |              0.9849 |             0.9938 |    0.9703 |           6.0333 |      1.0000 |             8.0343 |      1127.2164 |      0.2393 |      70.0067 |      0.9969 | \n",
      "   99 | 08m40s |   -0.15903 |              0.9114 |             0.9655 |    0.1316 |           0.2711 |      1.0000 |             8.4069 |      1125.9549 |      0.1792 |      70.1998 |      0.9266 | \n",
      "  100 | 12m34s |   -0.15499 |              0.9726 |             0.8323 |    0.0137 |           9.8845 |      1.0000 |             8.0145 |      1126.7043 |      0.2952 |      73.3769 |      0.9954 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00013016]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00092323]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  101 | 10m19s |   -0.15902 |              0.9102 |             0.8103 |    0.3138 |           7.7139 |      1.0000 |            10.7575 |      1134.1688 |      0.2584 |      70.0072 |      0.9991 | \n",
      "  102 | 10m18s |   -0.16011 |              0.9625 |             0.8452 |    0.9726 |           2.3712 |      1.0000 |             8.0551 |      1120.0804 |      0.2951 |      74.0688 |      0.9449 | \n",
      "  103 | 09m43s |   -0.15903 |              0.9936 |             0.9820 |    0.2730 |           9.9946 |      1.0000 |            10.6057 |      1123.0909 |      0.2868 |      84.7561 |      0.9502 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00018757]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  104 | 10m09s |   -0.15957 |              0.9598 |             0.8828 |    0.0062 |           5.3605 |      1.0000 |            10.9331 |      1134.8686 |      0.0520 |      75.0854 |      0.9934 | \n",
      "  105 | 09m00s |   -0.15795 |              0.9695 |             0.9443 |    0.0026 |           2.4941 |      1.0000 |            10.8869 |      1124.4320 |      0.2972 |      80.9618 |      0.9118 | \n",
      "  106 | 10m23s |   -0.16227 |              0.9060 |             0.8530 |    0.0300 |           6.5359 |      1.0000 |             8.0296 |      1123.6590 |      0.2808 |      71.7270 |      0.9946 | \n",
      "2018-06-17 05:09:52,858 - logHandler - train - INFO - Iteration: 15, XGBoost max auc: -0.151484\n",
      "2018-06-17 05:09:52,860 - logHandler - train - INFO - Param max_delta_step: 6.451558067271115\n",
      "2018-06-17 05:09:52,862 - logHandler - train - INFO - Param reg_lambda: 70.03392814011352\n",
      "2018-06-17 05:09:52,864 - logHandler - train - INFO - Param reg_alpha: 0.13583875712624977\n",
      "2018-06-17 05:09:52,865 - logHandler - train - INFO - Param n_estimators: 1126.1146593549104\n",
      "2018-06-17 05:09:52,867 - logHandler - train - INFO - Param max_depth: 1.0\n",
      "2018-06-17 05:09:52,869 - logHandler - train - INFO - Param subsample: 0.9812649766457713\n",
      "2018-06-17 05:09:52,870 - logHandler - train - INFO - Param min_child_weight: 8.104405418495354\n",
      "2018-06-17 05:09:52,872 - logHandler - train - INFO - Param gamma: 0.08471816978887892\n",
      "2018-06-17 05:09:52,874 - logHandler - train - INFO - Param colsample_bytree: 0.8777332895695233\n",
      "2018-06-17 05:09:52,875 - logHandler - train - INFO - Param colsample_bylevel: 0.9211755287403359\n",
      "2018-06-17 05:09:52,877 - logHandler - train - INFO - Setting best parameters for BayesianOptimization\n",
      "2018-06-17 05:11:45,577 - logHandler - train - INFO - ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2018-06-17 05:11:45,579 - logHandler - train - INFO - Iteration 16, Current random seed: 16\n",
      "2018-06-17 05:11:45,610 - logHandler - train - INFO - Setting parameters for BayesianOptimaization\n",
      "2018-06-17 05:11:45,611 - logHandler - train - INFO - Running BayesianOptimization\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 04m07s | \u001b[35m  -0.16092\u001b[0m | \u001b[32m             0.9438\u001b[0m | \u001b[32m            0.8674\u001b[0m | \u001b[32m   0.5742\u001b[0m | \u001b[32m          0.0762\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.0902\u001b[0m | \u001b[32m     1132.2373\u001b[0m | \u001b[32m     0.1023\u001b[0m | \u001b[32m     78.0254\u001b[0m | \u001b[32m     0.9504\u001b[0m | \n",
      "    2 | 07m34s | \u001b[35m  -0.15903\u001b[0m | \u001b[32m             0.9920\u001b[0m | \u001b[32m            0.9324\u001b[0m | \u001b[32m   0.1293\u001b[0m | \u001b[32m          3.5003\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            8.9025\u001b[0m | \u001b[32m     1120.3261\u001b[0m | \u001b[32m     0.0529\u001b[0m | \u001b[32m     78.4462\u001b[0m | \u001b[32m     0.9974\u001b[0m | \n",
      "    3 | 05m32s |   -0.15929 |              0.9874 |             0.8625 |    0.9853 |           0.7472 |      1.0000 |             8.7066 |      1125.8212 |      0.1693 |      72.6980 |      0.9655 | \n",
      "    4 | 06m06s | \u001b[35m  -0.15391\u001b[0m | \u001b[32m             0.9244\u001b[0m | \u001b[32m            0.8188\u001b[0m | \u001b[32m   0.5982\u001b[0m | \u001b[32m          2.0595\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m            9.5033\u001b[0m | \u001b[32m     1130.1486\u001b[0m | \u001b[32m     0.0005\u001b[0m | \u001b[32m     79.4390\u001b[0m | \u001b[32m     0.9115\u001b[0m | \n",
      "    5 | 08m27s |   -0.15579 |              0.9739 |             0.9230 |    0.3624 |           8.7885 |      1.0000 |             8.2630 |      1131.2298 |      0.1739 |      70.5290 |      0.9480 | \n",
      "    6 | 06m30s |   -0.16280 |              0.9707 |             0.8556 |    0.9871 |           9.1898 |      1.0000 |             8.0186 |      1134.1570 |      0.1176 |      73.4367 |      0.9672 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bylevel |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   n_estimators |   reg_alpha |   reg_lambda |   subsample | \n",
      "    7 | 06m35s |   -0.15903 |              0.9119 |             0.8095 |    0.8984 |           9.8942 |      1.0000 |            10.9394 |      1120.3707 |      0.2444 |      70.5956 |      0.9295 | \n",
      "    8 | 06m46s |   -0.15687 |              0.9126 |             0.8929 |    0.2448 |           9.9583 |      1.0000 |            10.9911 |      1133.0952 |      0.2577 |      84.9456 |      0.9148 | \n",
      "    9 | 05m58s |   -0.15552 |              0.9715 |             0.8746 |    0.1536 |           9.0334 |      1.0000 |            10.9942 |      1134.9286 |      0.1221 |      70.1979 |      0.9004 | \n",
      "   10 | 05m37s |   -0.15714 |              0.9403 |             0.8330 |    0.5548 |           0.2331 |      1.0000 |            10.9385 |      1123.6258 |      0.0024 |      84.9766 |      0.9817 | \n",
      "   11 | 05m05s |   -0.16281 |              0.9777 |             0.8364 |    0.0226 |           9.9944 |      1.0000 |            10.6323 |      1122.7292 |      0.0711 |      84.3320 |      0.9419 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.20706781e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 09m36s | \u001b[35m  -0.15283\u001b[0m | \u001b[32m             0.9254\u001b[0m | \u001b[32m            0.9865\u001b[0m | \u001b[32m   0.0005\u001b[0m | \u001b[32m          5.2704\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m           10.7975\u001b[0m | \u001b[32m     1126.7751\u001b[0m | \u001b[32m     0.2920\u001b[0m | \u001b[32m     76.6580\u001b[0m | \u001b[32m     0.9008\u001b[0m | \n",
      "   13 | 06m38s |   -0.15391 |              0.9252 |             0.9521 |    0.0079 |           3.0021 |      1.0000 |            10.3237 |      1122.1357 |      0.0234 |      70.0133 |      0.9211 | \n",
      "   14 | 08m42s |   -0.15714 |              0.9934 |             0.8025 |    0.0845 |           9.8743 |      1.0000 |            10.6924 |      1127.1613 |      0.0126 |      70.0989 |      0.9189 | \n",
      "   15 | 08m37s |   -0.15661 |              0.9690 |             0.9741 |    0.6924 |           4.3214 |      1.0000 |             8.0972 |      1127.7970 |      0.2377 |      84.9516 |      0.9036 | \n",
      "   16 | 07m14s |   -0.15822 |              0.9900 |             0.8066 |    0.6966 |           2.8840 |      1.0000 |            10.9755 |      1134.4951 |      0.1606 |      84.8301 |      0.9644 | \n",
      "   17 | 07m03s |   -0.15660 |              0.9051 |             0.9770 |    0.0383 |           8.3837 |      1.0000 |             8.1359 |      1120.1794 |      0.0417 |      70.5331 |      0.9070 | \n",
      "   18 | 05m22s |   -0.15688 |              0.9381 |             0.8480 |    0.2652 |           2.7288 |      1.0000 |            10.5948 |      1134.1708 |      0.0253 |      70.0801 |      0.9123 | \n",
      "   19 | 08m55s |   -0.15552 |              0.9018 |             0.8339 |    0.0276 |           3.2608 |      1.0000 |            10.5089 |      1128.7249 |      0.2824 |      83.6728 |      0.9115 | \n",
      "   20 | 07m00s |   -0.16280 |              0.9629 |             0.9995 |    0.9785 |           4.3464 |      1.0000 |            10.8713 |      1130.5547 |      0.0483 |      81.7209 |      0.9548 | \n",
      "   21 | 06m41s |   -0.15957 |              0.9250 |             0.9441 |    0.0430 |           9.7333 |      1.0000 |             8.0726 |      1134.8970 |      0.1153 |      84.2881 |      0.9634 | \n",
      "   22 | 08m42s |   -0.15525 |              0.9417 |             0.8652 |    0.2127 |           0.2307 |      1.0000 |             8.4317 |      1120.5182 |      0.2145 |      84.9638 |      0.9349 | \n",
      "   23 | 08m07s |   -0.15337 |              0.9000 |             0.8000 |    0.0000 |           3.1761 |      1.0000 |             8.0000 |      1133.2499 |      0.3000 |      70.6726 |      0.9000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0001091]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 08m41s |   -0.15768 |              0.9000 |             0.8000 |    0.0000 |           0.0000 |      1.0000 |             8.0000 |      1135.0000 |      0.0000 |      85.0000 |      1.0000 | \n",
      "   25 | 06m01s |   -0.15553 |              0.9237 |             0.8184 |    0.0136 |           5.0273 |      1.0000 |             8.0433 |      1127.6614 |      0.1470 |      73.3809 |      0.9076 | \n",
      "   26 | 05m25s |   -0.16011 |              0.9000 |             0.8000 |    0.0000 |           0.0000 |      1.0000 |            10.4430 |      1120.0000 |      0.0000 |      76.3145 |      0.9000 | \n",
      "   27 | 07m39s |   -0.15364 |              0.9764 |             0.8499 |    0.0132 |           9.5364 |      1.0000 |             8.0383 |      1134.9658 |      0.2463 |      70.0166 |      0.9025 | \n",
      "   28 | 04m20s |   -0.15607 |              0.9534 |             0.9043 |    0.0133 |           0.1646 |      1.0000 |             8.3912 |      1126.3355 |      0.1971 |      81.1053 |      0.9015 | \n",
      "   29 | 08m21s |   -0.15579 |              0.9087 |             0.8035 |    0.1189 |           4.5397 |      1.0000 |            10.9197 |      1127.0321 |      0.2975 |      70.0068 |      0.9104 | \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9ae4fd1ae433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-67c0b609380f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running BayesianOptimization'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mxgb_bayesopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_xgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mxgb_bayesopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#10,50 #5 ,25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# get the best param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;31m# Append most recently generated values to X and Y arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mobserve_point\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# measure the target function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f05680b3aa03>\u001b[0m in \u001b[0;36mtrain_xgb\u001b[0;34m(max_delta_step, reg_lambda, reg_alpha, n_estimators, max_depth, subsample, min_child_weight, gamma, colsample_bytree, colsample_bylevel)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#針對eval_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# logger.info(score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    404\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 894\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = getPath()\n",
    "dTrain = []\n",
    "dTest = []\n",
    "logger = Logger().getLogger()\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8194070080862533"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.argmax(X_train,axis=1) == Y_train) / len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob',\n",
       "       predictor='gpu_predictor', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1, tree_method='gpu_hist')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = xgb.XGBClassifier(tree_method='gpu_hist',predictor='gpu_predictor',objective='multi:softmax')\n",
    "xgb1.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9982030548068284"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgb1.score(X_valid,Y_valid)\n",
    "xgb1.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_valid, Y_valid = split_valid_set(train_X, label, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8279569892473119 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8225806451612904 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0.8172043010752689 =============\n"
     ]
    }
   ],
   "source": [
    "prior_kk=0\n",
    "for _ in range(100):\n",
    "    xgb1 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb2 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb3 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb4 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb5 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb6 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb7 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb8 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb9 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb10 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb11 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb12 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb13 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb14 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "    xgb15 = XGBClassifier(n_estimators = 1120+int(15*np.random.random()),\n",
    "                        colsample_bylevel = 0.85 + 0.15 * np.random.random(),\n",
    "                        colsample_bytree = 0.9 + 0.1 * np.random.random(),\n",
    "                        max_depth = 1,\n",
    "                        subsample = 0.85 + 0.15 * np.random.random(),\n",
    "                        max_delta_step = int(10.9*np.random.random()),\n",
    "                        reg_lambda = 65+20*np.random.random(),\n",
    "                        reg_alpha = 0.31*np.random.random(),\n",
    "                        min_child_weight = 7+5*np.random.random(),\n",
    "                        gamma= 0.2*np.random.random(),\n",
    "                        learning_rate = 0.01+0.99*np.random.random(),\n",
    "                        eval_metric=['merror'],\n",
    "                        objective='multi:softmax',\n",
    "                        num_class=41,\n",
    "    #                     n_jobs = 2,\n",
    "                        )\n",
    "\n",
    "\n",
    "    vc2 = VotingClassifier(estimators=[('xgb1',xgb1),('xgb2',xgb2),('xgb3',xgb3),('xgb4',xgb4),('xgb5',xgb5),\n",
    "                                      ('xgb6',xgb6),('xgb7',xgb7),('xgb8',xgb8),('xgb9',xgb9),('xgb10',xgb10),\n",
    "                                      ('xgb11',xgb11),('xgb12',xgb12),('xgb13',xgb13),('xgb14',xgb14),('xgb15',xgb15)],\n",
    "                          n_jobs=-1,voting='soft',flatten_transform=True)\n",
    "    vc2.fit(X_train,Y_train) #n_jobs=2\n",
    "\n",
    "    kk = vc2.score(X_valid,Y_valid)\n",
    "    print('============',kk,'=============')\n",
    "\n",
    "    if kk>prior_kk:\n",
    "        pickle.dump(vc2,open('model/vc_strong_15xgb.pkl','wb'))\n",
    "#         break\n",
    "    #0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(41,))\n",
    "bn = BatchNormalization()(input_)\n",
    "dense = Dense(82,activation='selu',kernel_initializer='lecun_normal',kernel_regularizer=l2(0.005))(bn)\n",
    "# dense = Dense(82,kernel_initializer='uniform',kernel_regularizer=l2(0.008))(bn)\n",
    "# dense = LeakyReLU()(dense)\n",
    "dropout = Dropout(0.6)(dense)\n",
    "\n",
    "# dense = Dense(164,kernel_initializer='uniform',kernel_regularizer=l2(0.008))(dropout)\n",
    "bn = BatchNormalization()(dropout)\n",
    "dense = Dense(82,activation='selu',kernel_initializer='lecun_normal',kernel_regularizer=l2(0.005))(bn)\n",
    "# dense = LeakyReLU()(dense)\n",
    "dropout = Dropout(0.6)(dense)\n",
    "\n",
    "bn = BatchNormalization()(dropout)\n",
    "dense = Dense(41,activation='softmax',kernel_regularizer=l2(0.006),kernel_initializer='lecun_normal')(bn)\n",
    "# dense = Dense(41,activation='softmax',kernel_regularizer=l2(0.001))(bn)\n",
    "model = Model(inputs=input_, outputs=dense)\n",
    "# model = Sequential()\n",
    "# i\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(41,activation='linear',input_shape=(41,)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3339 samples, validate on 371 samples\n",
      "Epoch 1/5000\n",
      "3339/3339 [==============================] - 1s 299us/step - loss: 4.9256 - acc: 0.0270 - val_loss: 4.3500 - val_acc: 0.1375\n",
      "Epoch 2/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 4.5515 - acc: 0.0830 - val_loss: 3.9664 - val_acc: 0.4178\n",
      "Epoch 3/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 4.2301 - acc: 0.1518 - val_loss: 3.5931 - val_acc: 0.6361\n",
      "Epoch 4/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 3.8757 - acc: 0.2609 - val_loss: 3.2482 - val_acc: 0.7790\n",
      "Epoch 5/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 3.5712 - acc: 0.3609 - val_loss: 2.9389 - val_acc: 0.8167\n",
      "Epoch 6/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 3.2867 - acc: 0.4570 - val_loss: 2.6777 - val_acc: 0.8248\n",
      "Epoch 7/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 3.0528 - acc: 0.5190 - val_loss: 2.4622 - val_acc: 0.8248\n",
      "Epoch 8/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 2.8547 - acc: 0.5792 - val_loss: 2.2890 - val_acc: 0.8221\n",
      "Epoch 9/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 2.6971 - acc: 0.6271 - val_loss: 2.1505 - val_acc: 0.8248\n",
      "Epoch 10/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 2.5434 - acc: 0.6541 - val_loss: 2.0391 - val_acc: 0.8356\n",
      "Epoch 11/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 2.4407 - acc: 0.6834 - val_loss: 1.9459 - val_acc: 0.8383\n",
      "Epoch 12/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 2.3369 - acc: 0.7062 - val_loss: 1.8704 - val_acc: 0.8356\n",
      "Epoch 13/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 2.2252 - acc: 0.7284 - val_loss: 1.8073 - val_acc: 0.8410\n",
      "Epoch 14/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 2.1574 - acc: 0.7391 - val_loss: 1.7544 - val_acc: 0.8329\n",
      "Epoch 15/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 2.0797 - acc: 0.7490 - val_loss: 1.7098 - val_acc: 0.8383\n",
      "Epoch 16/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 2.0261 - acc: 0.7577 - val_loss: 1.6689 - val_acc: 0.8410\n",
      "Epoch 17/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.9693 - acc: 0.7649 - val_loss: 1.6350 - val_acc: 0.8356\n",
      "Epoch 18/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.9223 - acc: 0.7757 - val_loss: 1.6061 - val_acc: 0.8329\n",
      "Epoch 19/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.8671 - acc: 0.7670 - val_loss: 1.5798 - val_acc: 0.8302\n",
      "Epoch 20/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.8296 - acc: 0.7742 - val_loss: 1.5577 - val_acc: 0.8275\n",
      "Epoch 21/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.7821 - acc: 0.7841 - val_loss: 1.5388 - val_acc: 0.8275\n",
      "Epoch 22/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.7710 - acc: 0.7778 - val_loss: 1.5196 - val_acc: 0.8275\n",
      "Epoch 23/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.7210 - acc: 0.7868 - val_loss: 1.5062 - val_acc: 0.8275\n",
      "Epoch 24/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.6849 - acc: 0.7877 - val_loss: 1.4935 - val_acc: 0.8275\n",
      "Epoch 25/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.6780 - acc: 0.7826 - val_loss: 1.4826 - val_acc: 0.8275\n",
      "Epoch 26/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.6302 - acc: 0.7892 - val_loss: 1.4742 - val_acc: 0.8275\n",
      "Epoch 27/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.6265 - acc: 0.7871 - val_loss: 1.4627 - val_acc: 0.8248\n",
      "Epoch 28/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.5854 - acc: 0.7916 - val_loss: 1.4536 - val_acc: 0.8275\n",
      "Epoch 29/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.5821 - acc: 0.7883 - val_loss: 1.4440 - val_acc: 0.8275\n",
      "Epoch 30/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.5478 - acc: 0.7945 - val_loss: 1.4367 - val_acc: 0.8302\n",
      "Epoch 31/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.5217 - acc: 0.7969 - val_loss: 1.4344 - val_acc: 0.8302\n",
      "Epoch 32/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.5026 - acc: 0.8020 - val_loss: 1.4302 - val_acc: 0.8329\n",
      "Epoch 33/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.4893 - acc: 0.7996 - val_loss: 1.4254 - val_acc: 0.8302\n",
      "Epoch 34/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.4824 - acc: 0.7981 - val_loss: 1.4234 - val_acc: 0.8302\n",
      "Epoch 35/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.4662 - acc: 0.7990 - val_loss: 1.4199 - val_acc: 0.8302\n",
      "Epoch 36/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.4198 - acc: 0.8047 - val_loss: 1.4200 - val_acc: 0.8248\n",
      "Epoch 37/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.4372 - acc: 0.7987 - val_loss: 1.4164 - val_acc: 0.8248\n",
      "Epoch 38/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.4354 - acc: 0.7957 - val_loss: 1.4143 - val_acc: 0.8275\n",
      "Epoch 39/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.4046 - acc: 0.8008 - val_loss: 1.4097 - val_acc: 0.8302\n",
      "Epoch 40/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.4008 - acc: 0.7993 - val_loss: 1.4069 - val_acc: 0.8356\n",
      "Epoch 41/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.3860 - acc: 0.8047 - val_loss: 1.4075 - val_acc: 0.8302\n",
      "Epoch 42/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.3818 - acc: 0.7993 - val_loss: 1.4096 - val_acc: 0.8275\n",
      "Epoch 43/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.3681 - acc: 0.8017 - val_loss: 1.4138 - val_acc: 0.8248\n",
      "Epoch 44/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.3576 - acc: 0.8035 - val_loss: 1.4109 - val_acc: 0.8248\n",
      "Epoch 45/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.3469 - acc: 0.8005 - val_loss: 1.4057 - val_acc: 0.8194\n",
      "Epoch 46/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.3469 - acc: 0.8002 - val_loss: 1.4014 - val_acc: 0.8248\n",
      "Epoch 47/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.3315 - acc: 0.8038 - val_loss: 1.3992 - val_acc: 0.8275\n",
      "Epoch 48/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.3207 - acc: 0.8005 - val_loss: 1.4003 - val_acc: 0.8221\n",
      "Epoch 49/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.3012 - acc: 0.8068 - val_loss: 1.3970 - val_acc: 0.8194\n",
      "Epoch 50/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.3137 - acc: 0.8002 - val_loss: 1.3964 - val_acc: 0.8194\n",
      "Epoch 51/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2906 - acc: 0.8056 - val_loss: 1.3943 - val_acc: 0.8194\n",
      "Epoch 52/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.3058 - acc: 0.8026 - val_loss: 1.3858 - val_acc: 0.8248\n",
      "Epoch 53/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2754 - acc: 0.8056 - val_loss: 1.3819 - val_acc: 0.8275\n",
      "Epoch 54/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2739 - acc: 0.8044 - val_loss: 1.3776 - val_acc: 0.8221\n",
      "Epoch 55/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2658 - acc: 0.8122 - val_loss: 1.3781 - val_acc: 0.8275\n",
      "Epoch 56/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2692 - acc: 0.8017 - val_loss: 1.3735 - val_acc: 0.8275\n",
      "Epoch 57/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2689 - acc: 0.8101 - val_loss: 1.3653 - val_acc: 0.8329\n",
      "Epoch 58/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.2593 - acc: 0.8035 - val_loss: 1.3645 - val_acc: 0.8302\n",
      "Epoch 59/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2558 - acc: 0.8044 - val_loss: 1.3588 - val_acc: 0.8302\n",
      "Epoch 60/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2312 - acc: 0.8023 - val_loss: 1.3537 - val_acc: 0.8275\n",
      "Epoch 61/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2649 - acc: 0.8008 - val_loss: 1.3489 - val_acc: 0.8248\n",
      "Epoch 62/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2484 - acc: 0.8008 - val_loss: 1.3431 - val_acc: 0.8248\n",
      "Epoch 63/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2389 - acc: 0.8008 - val_loss: 1.3399 - val_acc: 0.8302\n",
      "Epoch 64/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2368 - acc: 0.7972 - val_loss: 1.3382 - val_acc: 0.8275\n",
      "Epoch 65/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.2316 - acc: 0.8050 - val_loss: 1.3239 - val_acc: 0.8194\n",
      "Epoch 66/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2253 - acc: 0.8032 - val_loss: 1.3153 - val_acc: 0.8221\n",
      "Epoch 67/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.2189 - acc: 0.8068 - val_loss: 1.3097 - val_acc: 0.8275\n",
      "Epoch 68/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.2166 - acc: 0.8038 - val_loss: 1.3030 - val_acc: 0.8302\n",
      "Epoch 69/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.2046 - acc: 0.8077 - val_loss: 1.2940 - val_acc: 0.8329\n",
      "Epoch 70/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1982 - acc: 0.8056 - val_loss: 1.2875 - val_acc: 0.8194\n",
      "Epoch 71/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2137 - acc: 0.8083 - val_loss: 1.2832 - val_acc: 0.8221\n",
      "Epoch 72/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1830 - acc: 0.8068 - val_loss: 1.2751 - val_acc: 0.8221\n",
      "Epoch 73/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.2009 - acc: 0.8020 - val_loss: 1.2651 - val_acc: 0.8302\n",
      "Epoch 74/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.2008 - acc: 0.8053 - val_loss: 1.2580 - val_acc: 0.8275\n",
      "Epoch 75/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1935 - acc: 0.7978 - val_loss: 1.2565 - val_acc: 0.8167\n",
      "Epoch 76/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1768 - acc: 0.8029 - val_loss: 1.2396 - val_acc: 0.8248\n",
      "Epoch 77/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.1729 - acc: 0.8053 - val_loss: 1.2301 - val_acc: 0.8248\n",
      "Epoch 78/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.1811 - acc: 0.8074 - val_loss: 1.2181 - val_acc: 0.8329\n",
      "Epoch 79/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1770 - acc: 0.8038 - val_loss: 1.2138 - val_acc: 0.8302\n",
      "Epoch 80/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1665 - acc: 0.8065 - val_loss: 1.2056 - val_acc: 0.8302\n",
      "Epoch 81/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1642 - acc: 0.8122 - val_loss: 1.2002 - val_acc: 0.8383\n",
      "Epoch 82/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1864 - acc: 0.8071 - val_loss: 1.1870 - val_acc: 0.8356\n",
      "Epoch 83/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1741 - acc: 0.8056 - val_loss: 1.1763 - val_acc: 0.8329\n",
      "Epoch 84/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1579 - acc: 0.8056 - val_loss: 1.1622 - val_acc: 0.8356\n",
      "Epoch 85/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1521 - acc: 0.8137 - val_loss: 1.1559 - val_acc: 0.8356\n",
      "Epoch 86/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1568 - acc: 0.8059 - val_loss: 1.1520 - val_acc: 0.8383\n",
      "Epoch 87/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1680 - acc: 0.8023 - val_loss: 1.1473 - val_acc: 0.8302\n",
      "Epoch 88/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1304 - acc: 0.8131 - val_loss: 1.1335 - val_acc: 0.8275\n",
      "Epoch 89/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1653 - acc: 0.8014 - val_loss: 1.1312 - val_acc: 0.8221\n",
      "Epoch 90/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1442 - acc: 0.8005 - val_loss: 1.1270 - val_acc: 0.8221\n",
      "Epoch 91/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1511 - acc: 0.8053 - val_loss: 1.1142 - val_acc: 0.8275\n",
      "Epoch 92/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.1503 - acc: 0.8095 - val_loss: 1.1048 - val_acc: 0.8302\n",
      "Epoch 93/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1397 - acc: 0.8029 - val_loss: 1.0991 - val_acc: 0.8329\n",
      "Epoch 94/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1375 - acc: 0.8065 - val_loss: 1.0999 - val_acc: 0.8167\n",
      "Epoch 95/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1334 - acc: 0.8077 - val_loss: 1.0860 - val_acc: 0.8194\n",
      "Epoch 96/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1338 - acc: 0.8104 - val_loss: 1.0693 - val_acc: 0.8275\n",
      "Epoch 97/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1259 - acc: 0.8065 - val_loss: 1.0668 - val_acc: 0.8248\n",
      "Epoch 98/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1467 - acc: 0.8068 - val_loss: 1.0571 - val_acc: 0.8275\n",
      "Epoch 99/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1043 - acc: 0.8134 - val_loss: 1.0558 - val_acc: 0.8194\n",
      "Epoch 100/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1395 - acc: 0.8074 - val_loss: 1.0595 - val_acc: 0.8140\n",
      "Epoch 101/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1274 - acc: 0.8065 - val_loss: 1.0443 - val_acc: 0.8221\n",
      "Epoch 102/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1216 - acc: 0.8053 - val_loss: 1.0387 - val_acc: 0.8248\n",
      "Epoch 103/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0999 - acc: 0.8023 - val_loss: 1.0332 - val_acc: 0.8275\n",
      "Epoch 104/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1187 - acc: 0.8086 - val_loss: 1.0251 - val_acc: 0.8221\n",
      "Epoch 105/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1048 - acc: 0.8068 - val_loss: 1.0241 - val_acc: 0.8248\n",
      "Epoch 106/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1085 - acc: 0.8074 - val_loss: 1.0308 - val_acc: 0.8194\n",
      "Epoch 107/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.1009 - acc: 0.8095 - val_loss: 1.0233 - val_acc: 0.8221\n",
      "Epoch 108/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.1179 - acc: 0.8011 - val_loss: 1.0222 - val_acc: 0.8221\n",
      "Epoch 109/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0872 - acc: 0.8137 - val_loss: 1.0071 - val_acc: 0.8248\n",
      "Epoch 110/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0983 - acc: 0.8047 - val_loss: 1.0004 - val_acc: 0.8329\n",
      "Epoch 111/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0966 - acc: 0.8110 - val_loss: 1.0019 - val_acc: 0.8302\n",
      "Epoch 112/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.1043 - acc: 0.8077 - val_loss: 1.0012 - val_acc: 0.8248\n",
      "Epoch 113/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0868 - acc: 0.8104 - val_loss: 0.9962 - val_acc: 0.8329\n",
      "Epoch 114/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0977 - acc: 0.8038 - val_loss: 0.9903 - val_acc: 0.8275\n",
      "Epoch 115/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0976 - acc: 0.8083 - val_loss: 0.9834 - val_acc: 0.8302\n",
      "Epoch 116/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0882 - acc: 0.8080 - val_loss: 0.9792 - val_acc: 0.8356\n",
      "Epoch 117/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0984 - acc: 0.8080 - val_loss: 0.9774 - val_acc: 0.8248\n",
      "Epoch 118/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0708 - acc: 0.8146 - val_loss: 0.9657 - val_acc: 0.8356\n",
      "Epoch 119/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0905 - acc: 0.8095 - val_loss: 0.9680 - val_acc: 0.8356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0913 - acc: 0.8080 - val_loss: 0.9605 - val_acc: 0.8275\n",
      "Epoch 121/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0902 - acc: 0.8059 - val_loss: 0.9660 - val_acc: 0.8167\n",
      "Epoch 122/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0954 - acc: 0.8065 - val_loss: 0.9588 - val_acc: 0.8275\n",
      "Epoch 123/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0897 - acc: 0.8092 - val_loss: 0.9547 - val_acc: 0.8302\n",
      "Epoch 124/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0842 - acc: 0.8074 - val_loss: 0.9604 - val_acc: 0.8275\n",
      "Epoch 125/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0779 - acc: 0.8038 - val_loss: 0.9548 - val_acc: 0.8248\n",
      "Epoch 126/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0735 - acc: 0.8008 - val_loss: 0.9574 - val_acc: 0.8248\n",
      "Epoch 127/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0640 - acc: 0.8149 - val_loss: 0.9487 - val_acc: 0.8194\n",
      "Epoch 128/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0882 - acc: 0.8026 - val_loss: 0.9487 - val_acc: 0.8302\n",
      "Epoch 129/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0734 - acc: 0.8083 - val_loss: 0.9468 - val_acc: 0.8248\n",
      "Epoch 130/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0770 - acc: 0.8053 - val_loss: 0.9390 - val_acc: 0.8275\n",
      "Epoch 131/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0741 - acc: 0.8089 - val_loss: 0.9423 - val_acc: 0.8221\n",
      "Epoch 132/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0620 - acc: 0.8092 - val_loss: 0.9332 - val_acc: 0.8248\n",
      "Epoch 133/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0572 - acc: 0.8125 - val_loss: 0.9285 - val_acc: 0.8329\n",
      "Epoch 134/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0622 - acc: 0.8149 - val_loss: 0.9319 - val_acc: 0.8356\n",
      "Epoch 135/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0703 - acc: 0.8074 - val_loss: 0.9353 - val_acc: 0.8248\n",
      "Epoch 136/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0602 - acc: 0.8065 - val_loss: 0.9301 - val_acc: 0.8302\n",
      "Epoch 137/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0649 - acc: 0.8053 - val_loss: 0.9277 - val_acc: 0.8275\n",
      "Epoch 138/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0463 - acc: 0.8065 - val_loss: 0.9258 - val_acc: 0.8275\n",
      "Epoch 139/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0516 - acc: 0.8173 - val_loss: 0.9279 - val_acc: 0.8221\n",
      "Epoch 140/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0778 - acc: 0.8110 - val_loss: 0.9160 - val_acc: 0.8248\n",
      "Epoch 141/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0508 - acc: 0.8101 - val_loss: 0.9136 - val_acc: 0.8302\n",
      "Epoch 142/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0416 - acc: 0.8110 - val_loss: 0.9177 - val_acc: 0.8329\n",
      "Epoch 143/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0647 - acc: 0.8077 - val_loss: 0.9129 - val_acc: 0.8356\n",
      "Epoch 144/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0714 - acc: 0.8053 - val_loss: 0.9122 - val_acc: 0.8302\n",
      "Epoch 145/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0566 - acc: 0.8071 - val_loss: 0.9121 - val_acc: 0.8302\n",
      "Epoch 146/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0584 - acc: 0.8101 - val_loss: 0.9120 - val_acc: 0.8275\n",
      "Epoch 147/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0590 - acc: 0.8095 - val_loss: 0.9135 - val_acc: 0.8248\n",
      "Epoch 148/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0508 - acc: 0.8089 - val_loss: 0.9037 - val_acc: 0.8302\n",
      "Epoch 149/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0602 - acc: 0.8089 - val_loss: 0.9119 - val_acc: 0.8302\n",
      "Epoch 150/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0516 - acc: 0.8020 - val_loss: 0.9104 - val_acc: 0.8302\n",
      "Epoch 151/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0349 - acc: 0.8071 - val_loss: 0.8997 - val_acc: 0.8302\n",
      "Epoch 152/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0384 - acc: 0.8161 - val_loss: 0.8995 - val_acc: 0.8275\n",
      "Epoch 153/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0416 - acc: 0.8143 - val_loss: 0.8965 - val_acc: 0.8302\n",
      "Epoch 154/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0549 - acc: 0.8101 - val_loss: 0.8993 - val_acc: 0.8248\n",
      "Epoch 155/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0401 - acc: 0.8131 - val_loss: 0.8910 - val_acc: 0.8275\n",
      "Epoch 156/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0463 - acc: 0.8110 - val_loss: 0.8928 - val_acc: 0.8329\n",
      "Epoch 157/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0418 - acc: 0.8083 - val_loss: 0.8915 - val_acc: 0.8302\n",
      "Epoch 158/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0349 - acc: 0.8101 - val_loss: 0.8958 - val_acc: 0.8302\n",
      "Epoch 159/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0386 - acc: 0.8077 - val_loss: 0.8961 - val_acc: 0.8383\n",
      "Epoch 160/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0617 - acc: 0.8071 - val_loss: 0.8870 - val_acc: 0.8356\n",
      "Epoch 161/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0456 - acc: 0.8053 - val_loss: 0.8972 - val_acc: 0.8248\n",
      "Epoch 162/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0269 - acc: 0.8083 - val_loss: 0.8999 - val_acc: 0.8275\n",
      "Epoch 163/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0424 - acc: 0.8074 - val_loss: 0.8907 - val_acc: 0.8302\n",
      "Epoch 164/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0419 - acc: 0.8044 - val_loss: 0.8900 - val_acc: 0.8275\n",
      "Epoch 165/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0336 - acc: 0.8116 - val_loss: 0.8981 - val_acc: 0.8221\n",
      "Epoch 166/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0332 - acc: 0.8062 - val_loss: 0.8923 - val_acc: 0.8302\n",
      "Epoch 167/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0282 - acc: 0.8161 - val_loss: 0.8955 - val_acc: 0.8275\n",
      "Epoch 168/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0203 - acc: 0.8086 - val_loss: 0.8824 - val_acc: 0.8329\n",
      "Epoch 169/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0263 - acc: 0.8128 - val_loss: 0.8906 - val_acc: 0.8248\n",
      "Epoch 170/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0353 - acc: 0.8140 - val_loss: 0.8896 - val_acc: 0.8275\n",
      "Epoch 171/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0431 - acc: 0.8131 - val_loss: 0.8893 - val_acc: 0.8248\n",
      "Epoch 172/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0308 - acc: 0.8101 - val_loss: 0.8901 - val_acc: 0.8221\n",
      "Epoch 173/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0242 - acc: 0.8128 - val_loss: 0.8898 - val_acc: 0.8221\n",
      "Epoch 174/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0203 - acc: 0.8110 - val_loss: 0.8925 - val_acc: 0.8140\n",
      "Epoch 175/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0297 - acc: 0.8083 - val_loss: 0.8812 - val_acc: 0.8329\n",
      "Epoch 176/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0220 - acc: 0.8143 - val_loss: 0.8872 - val_acc: 0.8383\n",
      "Epoch 177/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0262 - acc: 0.8074 - val_loss: 0.8876 - val_acc: 0.8356\n",
      "Epoch 178/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0258 - acc: 0.8119 - val_loss: 0.8885 - val_acc: 0.8302\n",
      "Epoch 179/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0304 - acc: 0.8128 - val_loss: 0.8888 - val_acc: 0.8329\n",
      "Epoch 180/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0071 - acc: 0.8140 - val_loss: 0.8754 - val_acc: 0.8356\n",
      "Epoch 181/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0066 - acc: 0.8149 - val_loss: 0.8820 - val_acc: 0.8302\n",
      "Epoch 182/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0163 - acc: 0.8101 - val_loss: 0.8795 - val_acc: 0.8329\n",
      "Epoch 183/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0187 - acc: 0.8128 - val_loss: 0.8776 - val_acc: 0.8356\n",
      "Epoch 184/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0040 - acc: 0.8104 - val_loss: 0.8886 - val_acc: 0.8275\n",
      "Epoch 185/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0186 - acc: 0.8092 - val_loss: 0.8896 - val_acc: 0.8329\n",
      "Epoch 186/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0142 - acc: 0.8065 - val_loss: 0.8834 - val_acc: 0.8302\n",
      "Epoch 187/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9960 - acc: 0.8173 - val_loss: 0.8781 - val_acc: 0.8275\n",
      "Epoch 188/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9958 - acc: 0.8143 - val_loss: 0.8790 - val_acc: 0.8248\n",
      "Epoch 189/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0155 - acc: 0.8086 - val_loss: 0.8781 - val_acc: 0.8302\n",
      "Epoch 190/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0084 - acc: 0.8128 - val_loss: 0.8856 - val_acc: 0.8329\n",
      "Epoch 191/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0057 - acc: 0.8149 - val_loss: 0.8882 - val_acc: 0.8329\n",
      "Epoch 192/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0082 - acc: 0.8173 - val_loss: 0.8925 - val_acc: 0.8302\n",
      "Epoch 193/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0160 - acc: 0.8128 - val_loss: 0.8893 - val_acc: 0.8221\n",
      "Epoch 194/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9883 - acc: 0.8206 - val_loss: 0.8905 - val_acc: 0.8248\n",
      "Epoch 195/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0005 - acc: 0.8089 - val_loss: 0.8835 - val_acc: 0.8275\n",
      "Epoch 196/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0110 - acc: 0.8074 - val_loss: 0.8790 - val_acc: 0.8302\n",
      "Epoch 197/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9877 - acc: 0.8149 - val_loss: 0.8753 - val_acc: 0.8302\n",
      "Epoch 198/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0150 - acc: 0.8068 - val_loss: 0.8761 - val_acc: 0.8302\n",
      "Epoch 199/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9984 - acc: 0.8101 - val_loss: 0.8720 - val_acc: 0.8356\n",
      "Epoch 200/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0115 - acc: 0.8149 - val_loss: 0.8721 - val_acc: 0.8356\n",
      "Epoch 201/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9823 - acc: 0.8128 - val_loss: 0.8732 - val_acc: 0.8248\n",
      "Epoch 202/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0012 - acc: 0.8083 - val_loss: 0.8708 - val_acc: 0.8248\n",
      "Epoch 203/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0109 - acc: 0.8044 - val_loss: 0.8563 - val_acc: 0.8356\n",
      "Epoch 204/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0071 - acc: 0.8092 - val_loss: 0.8631 - val_acc: 0.8356\n",
      "Epoch 205/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9999 - acc: 0.8068 - val_loss: 0.8724 - val_acc: 0.8302\n",
      "Epoch 206/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0080 - acc: 0.8158 - val_loss: 0.8771 - val_acc: 0.8302\n",
      "Epoch 207/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9993 - acc: 0.8140 - val_loss: 0.8740 - val_acc: 0.8356\n",
      "Epoch 208/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 1.0068 - acc: 0.8116 - val_loss: 0.8737 - val_acc: 0.8275\n",
      "Epoch 209/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9917 - acc: 0.8134 - val_loss: 0.8728 - val_acc: 0.8329\n",
      "Epoch 210/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9865 - acc: 0.8128 - val_loss: 0.8791 - val_acc: 0.8248\n",
      "Epoch 211/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 1.0039 - acc: 0.8074 - val_loss: 0.8767 - val_acc: 0.8275\n",
      "Epoch 212/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9933 - acc: 0.8143 - val_loss: 0.8769 - val_acc: 0.8275\n",
      "Epoch 213/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9952 - acc: 0.8134 - val_loss: 0.8658 - val_acc: 0.8275\n",
      "Epoch 214/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9830 - acc: 0.8161 - val_loss: 0.8616 - val_acc: 0.8329\n",
      "Epoch 215/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9767 - acc: 0.8206 - val_loss: 0.8639 - val_acc: 0.8329\n",
      "Epoch 216/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9808 - acc: 0.8113 - val_loss: 0.8618 - val_acc: 0.8248\n",
      "Epoch 217/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9964 - acc: 0.8116 - val_loss: 0.8671 - val_acc: 0.8221\n",
      "Epoch 218/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9755 - acc: 0.8110 - val_loss: 0.8709 - val_acc: 0.8194\n",
      "Epoch 219/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9861 - acc: 0.8191 - val_loss: 0.8713 - val_acc: 0.8248\n",
      "Epoch 220/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9721 - acc: 0.8110 - val_loss: 0.8677 - val_acc: 0.8248\n",
      "Epoch 221/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9910 - acc: 0.8110 - val_loss: 0.8577 - val_acc: 0.8302\n",
      "Epoch 222/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9688 - acc: 0.8197 - val_loss: 0.8584 - val_acc: 0.8329\n",
      "Epoch 223/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9712 - acc: 0.8128 - val_loss: 0.8624 - val_acc: 0.8329\n",
      "Epoch 224/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9744 - acc: 0.8107 - val_loss: 0.8705 - val_acc: 0.8275\n",
      "Epoch 225/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9841 - acc: 0.8131 - val_loss: 0.8688 - val_acc: 0.8221\n",
      "Epoch 226/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9614 - acc: 0.8137 - val_loss: 0.8706 - val_acc: 0.8275\n",
      "Epoch 227/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9761 - acc: 0.8143 - val_loss: 0.8628 - val_acc: 0.8302\n",
      "Epoch 228/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9806 - acc: 0.8134 - val_loss: 0.8681 - val_acc: 0.8221\n",
      "Epoch 229/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9803 - acc: 0.8110 - val_loss: 0.8642 - val_acc: 0.8167\n",
      "Epoch 230/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9780 - acc: 0.8128 - val_loss: 0.8666 - val_acc: 0.8194\n",
      "Epoch 231/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9817 - acc: 0.8095 - val_loss: 0.8676 - val_acc: 0.8275\n",
      "Epoch 232/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9759 - acc: 0.8116 - val_loss: 0.8658 - val_acc: 0.8275\n",
      "Epoch 233/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9861 - acc: 0.8056 - val_loss: 0.8627 - val_acc: 0.8302\n",
      "Epoch 234/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9683 - acc: 0.8137 - val_loss: 0.8596 - val_acc: 0.8248\n",
      "Epoch 235/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9748 - acc: 0.8152 - val_loss: 0.8636 - val_acc: 0.8275\n",
      "Epoch 236/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9705 - acc: 0.8095 - val_loss: 0.8575 - val_acc: 0.8302\n",
      "Epoch 237/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9709 - acc: 0.8155 - val_loss: 0.8600 - val_acc: 0.8302\n",
      "Epoch 238/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9812 - acc: 0.8104 - val_loss: 0.8593 - val_acc: 0.8302\n",
      "Epoch 239/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9702 - acc: 0.8179 - val_loss: 0.8574 - val_acc: 0.8302\n",
      "Epoch 240/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9814 - acc: 0.8122 - val_loss: 0.8520 - val_acc: 0.8275\n",
      "Epoch 241/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9842 - acc: 0.8080 - val_loss: 0.8447 - val_acc: 0.8329\n",
      "Epoch 242/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9613 - acc: 0.8158 - val_loss: 0.8441 - val_acc: 0.8356\n",
      "Epoch 243/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9687 - acc: 0.8113 - val_loss: 0.8495 - val_acc: 0.8302\n",
      "Epoch 244/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9851 - acc: 0.8086 - val_loss: 0.8551 - val_acc: 0.8221\n",
      "Epoch 245/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9510 - acc: 0.8074 - val_loss: 0.8507 - val_acc: 0.8275\n",
      "Epoch 246/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9708 - acc: 0.8137 - val_loss: 0.8508 - val_acc: 0.8302\n",
      "Epoch 247/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9776 - acc: 0.8143 - val_loss: 0.8593 - val_acc: 0.8248\n",
      "Epoch 248/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9623 - acc: 0.8128 - val_loss: 0.8479 - val_acc: 0.8275\n",
      "Epoch 249/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9798 - acc: 0.8083 - val_loss: 0.8543 - val_acc: 0.8302\n",
      "Epoch 250/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9847 - acc: 0.8047 - val_loss: 0.8449 - val_acc: 0.8302\n",
      "Epoch 251/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9544 - acc: 0.8158 - val_loss: 0.8616 - val_acc: 0.8275\n",
      "Epoch 252/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9698 - acc: 0.8134 - val_loss: 0.8589 - val_acc: 0.8221\n",
      "Epoch 253/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9671 - acc: 0.8113 - val_loss: 0.8621 - val_acc: 0.8248\n",
      "Epoch 254/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9608 - acc: 0.8131 - val_loss: 0.8411 - val_acc: 0.8329\n",
      "Epoch 255/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.9756 - acc: 0.8104 - val_loss: 0.8409 - val_acc: 0.8275\n",
      "Epoch 256/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9665 - acc: 0.8086 - val_loss: 0.8425 - val_acc: 0.8248\n",
      "Epoch 257/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9576 - acc: 0.8155 - val_loss: 0.8600 - val_acc: 0.8221\n",
      "Epoch 258/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9463 - acc: 0.8092 - val_loss: 0.8587 - val_acc: 0.8275\n",
      "Epoch 259/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9686 - acc: 0.8098 - val_loss: 0.8568 - val_acc: 0.8275\n",
      "Epoch 260/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9639 - acc: 0.8188 - val_loss: 0.8571 - val_acc: 0.8248\n",
      "Epoch 261/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9663 - acc: 0.8131 - val_loss: 0.8582 - val_acc: 0.8194\n",
      "Epoch 262/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9449 - acc: 0.8173 - val_loss: 0.8514 - val_acc: 0.8221\n",
      "Epoch 263/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9795 - acc: 0.8164 - val_loss: 0.8526 - val_acc: 0.8275\n",
      "Epoch 264/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9701 - acc: 0.8107 - val_loss: 0.8591 - val_acc: 0.8248\n",
      "Epoch 265/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9708 - acc: 0.8125 - val_loss: 0.8611 - val_acc: 0.8221\n",
      "Epoch 266/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9534 - acc: 0.8128 - val_loss: 0.8515 - val_acc: 0.8275\n",
      "Epoch 267/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9745 - acc: 0.8116 - val_loss: 0.8514 - val_acc: 0.8356\n",
      "Epoch 268/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9656 - acc: 0.8065 - val_loss: 0.8489 - val_acc: 0.8302\n",
      "Epoch 269/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9454 - acc: 0.8149 - val_loss: 0.8530 - val_acc: 0.8302\n",
      "Epoch 270/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9592 - acc: 0.8128 - val_loss: 0.8429 - val_acc: 0.8329\n",
      "Epoch 271/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9559 - acc: 0.8161 - val_loss: 0.8422 - val_acc: 0.8329\n",
      "Epoch 272/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9584 - acc: 0.8134 - val_loss: 0.8427 - val_acc: 0.8356\n",
      "Epoch 273/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9862 - acc: 0.8110 - val_loss: 0.8421 - val_acc: 0.8329\n",
      "Epoch 274/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9589 - acc: 0.8167 - val_loss: 0.8390 - val_acc: 0.8302\n",
      "Epoch 275/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9471 - acc: 0.8134 - val_loss: 0.8460 - val_acc: 0.8275\n",
      "Epoch 276/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9648 - acc: 0.8143 - val_loss: 0.8469 - val_acc: 0.8302\n",
      "Epoch 277/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9517 - acc: 0.8113 - val_loss: 0.8522 - val_acc: 0.8248\n",
      "Epoch 278/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9494 - acc: 0.8200 - val_loss: 0.8499 - val_acc: 0.8302\n",
      "Epoch 279/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9476 - acc: 0.8167 - val_loss: 0.8454 - val_acc: 0.8302\n",
      "Epoch 280/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9506 - acc: 0.8083 - val_loss: 0.8426 - val_acc: 0.8383\n",
      "Epoch 281/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9548 - acc: 0.8176 - val_loss: 0.8407 - val_acc: 0.8275\n",
      "Epoch 282/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9637 - acc: 0.8125 - val_loss: 0.8378 - val_acc: 0.8302\n",
      "Epoch 283/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9466 - acc: 0.8185 - val_loss: 0.8511 - val_acc: 0.8275\n",
      "Epoch 284/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9469 - acc: 0.8119 - val_loss: 0.8492 - val_acc: 0.8248\n",
      "Epoch 285/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9626 - acc: 0.8125 - val_loss: 0.8429 - val_acc: 0.8302\n",
      "Epoch 286/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9492 - acc: 0.8059 - val_loss: 0.8443 - val_acc: 0.8248\n",
      "Epoch 287/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9498 - acc: 0.8167 - val_loss: 0.8416 - val_acc: 0.8275\n",
      "Epoch 288/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9456 - acc: 0.8170 - val_loss: 0.8419 - val_acc: 0.8329\n",
      "Epoch 289/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9420 - acc: 0.8149 - val_loss: 0.8439 - val_acc: 0.8356\n",
      "Epoch 290/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9413 - acc: 0.8125 - val_loss: 0.8452 - val_acc: 0.8248\n",
      "Epoch 291/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9502 - acc: 0.8137 - val_loss: 0.8401 - val_acc: 0.8329\n",
      "Epoch 292/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9397 - acc: 0.8170 - val_loss: 0.8452 - val_acc: 0.8248\n",
      "Epoch 293/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9467 - acc: 0.8122 - val_loss: 0.8439 - val_acc: 0.8329\n",
      "Epoch 294/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9518 - acc: 0.8134 - val_loss: 0.8527 - val_acc: 0.8302\n",
      "Epoch 295/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9505 - acc: 0.8137 - val_loss: 0.8400 - val_acc: 0.8302\n",
      "Epoch 296/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9429 - acc: 0.8101 - val_loss: 0.8446 - val_acc: 0.8248\n",
      "Epoch 297/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9498 - acc: 0.8113 - val_loss: 0.8412 - val_acc: 0.8302\n",
      "Epoch 298/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9673 - acc: 0.8101 - val_loss: 0.8454 - val_acc: 0.8275\n",
      "Epoch 299/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9480 - acc: 0.8188 - val_loss: 0.8478 - val_acc: 0.8248\n",
      "Epoch 300/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9403 - acc: 0.8182 - val_loss: 0.8513 - val_acc: 0.8248\n",
      "Epoch 301/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9389 - acc: 0.8119 - val_loss: 0.8409 - val_acc: 0.8302\n",
      "Epoch 302/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9492 - acc: 0.8095 - val_loss: 0.8392 - val_acc: 0.8221\n",
      "Epoch 303/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9418 - acc: 0.8161 - val_loss: 0.8382 - val_acc: 0.8302\n",
      "Epoch 304/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9409 - acc: 0.8161 - val_loss: 0.8454 - val_acc: 0.8248\n",
      "Epoch 305/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9460 - acc: 0.8158 - val_loss: 0.8474 - val_acc: 0.8302\n",
      "Epoch 306/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9501 - acc: 0.8170 - val_loss: 0.8348 - val_acc: 0.8275\n",
      "Epoch 307/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9507 - acc: 0.8158 - val_loss: 0.8336 - val_acc: 0.8302\n",
      "Epoch 308/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9418 - acc: 0.8116 - val_loss: 0.8449 - val_acc: 0.8248\n",
      "Epoch 309/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9387 - acc: 0.8134 - val_loss: 0.8440 - val_acc: 0.8329\n",
      "Epoch 310/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9292 - acc: 0.8119 - val_loss: 0.8451 - val_acc: 0.8275\n",
      "Epoch 311/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9398 - acc: 0.8170 - val_loss: 0.8442 - val_acc: 0.8302\n",
      "Epoch 312/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9505 - acc: 0.8119 - val_loss: 0.8405 - val_acc: 0.8302\n",
      "Epoch 313/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9280 - acc: 0.8179 - val_loss: 0.8384 - val_acc: 0.8221\n",
      "Epoch 314/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9197 - acc: 0.8176 - val_loss: 0.8429 - val_acc: 0.8167\n",
      "Epoch 315/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9342 - acc: 0.8164 - val_loss: 0.8459 - val_acc: 0.8275\n",
      "Epoch 316/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9407 - acc: 0.8104 - val_loss: 0.8441 - val_acc: 0.8302\n",
      "Epoch 317/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9406 - acc: 0.8116 - val_loss: 0.8419 - val_acc: 0.8221\n",
      "Epoch 318/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9446 - acc: 0.8149 - val_loss: 0.8418 - val_acc: 0.8329\n",
      "Epoch 319/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9325 - acc: 0.8122 - val_loss: 0.8504 - val_acc: 0.8221\n",
      "Epoch 320/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9334 - acc: 0.8152 - val_loss: 0.8436 - val_acc: 0.8329\n",
      "Epoch 321/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9307 - acc: 0.8164 - val_loss: 0.8425 - val_acc: 0.8329\n",
      "Epoch 322/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9462 - acc: 0.8101 - val_loss: 0.8361 - val_acc: 0.8329\n",
      "Epoch 323/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9411 - acc: 0.8155 - val_loss: 0.8317 - val_acc: 0.8356\n",
      "Epoch 324/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9344 - acc: 0.8122 - val_loss: 0.8352 - val_acc: 0.8356\n",
      "Epoch 325/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9488 - acc: 0.8134 - val_loss: 0.8435 - val_acc: 0.8329\n",
      "Epoch 326/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9360 - acc: 0.8143 - val_loss: 0.8421 - val_acc: 0.8329\n",
      "Epoch 327/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9196 - acc: 0.8119 - val_loss: 0.8344 - val_acc: 0.8302\n",
      "Epoch 328/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9454 - acc: 0.8098 - val_loss: 0.8415 - val_acc: 0.8329\n",
      "Epoch 329/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9280 - acc: 0.8098 - val_loss: 0.8423 - val_acc: 0.8329\n",
      "Epoch 330/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9363 - acc: 0.8191 - val_loss: 0.8394 - val_acc: 0.8302\n",
      "Epoch 331/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9349 - acc: 0.8128 - val_loss: 0.8384 - val_acc: 0.8329\n",
      "Epoch 332/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9148 - acc: 0.8191 - val_loss: 0.8375 - val_acc: 0.8275\n",
      "Epoch 333/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9069 - acc: 0.8221 - val_loss: 0.8373 - val_acc: 0.8221\n",
      "Epoch 334/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9277 - acc: 0.8140 - val_loss: 0.8373 - val_acc: 0.8248\n",
      "Epoch 335/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9338 - acc: 0.8098 - val_loss: 0.8415 - val_acc: 0.8248\n",
      "Epoch 336/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9391 - acc: 0.8110 - val_loss: 0.8361 - val_acc: 0.8329\n",
      "Epoch 337/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9373 - acc: 0.8143 - val_loss: 0.8325 - val_acc: 0.8329\n",
      "Epoch 338/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9321 - acc: 0.8137 - val_loss: 0.8338 - val_acc: 0.8329\n",
      "Epoch 339/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9307 - acc: 0.8149 - val_loss: 0.8282 - val_acc: 0.8302\n",
      "Epoch 340/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9223 - acc: 0.8101 - val_loss: 0.8257 - val_acc: 0.8275\n",
      "Epoch 341/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9347 - acc: 0.8125 - val_loss: 0.8326 - val_acc: 0.8248\n",
      "Epoch 342/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9266 - acc: 0.8131 - val_loss: 0.8334 - val_acc: 0.8275\n",
      "Epoch 343/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9436 - acc: 0.8089 - val_loss: 0.8395 - val_acc: 0.8275\n",
      "Epoch 344/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9305 - acc: 0.8083 - val_loss: 0.8329 - val_acc: 0.8248\n",
      "Epoch 345/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9297 - acc: 0.8092 - val_loss: 0.8299 - val_acc: 0.8194\n",
      "Epoch 346/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9259 - acc: 0.8146 - val_loss: 0.8341 - val_acc: 0.8167\n",
      "Epoch 347/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9296 - acc: 0.8149 - val_loss: 0.8318 - val_acc: 0.8248\n",
      "Epoch 348/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9268 - acc: 0.8143 - val_loss: 0.8291 - val_acc: 0.8329\n",
      "Epoch 349/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9406 - acc: 0.8140 - val_loss: 0.8153 - val_acc: 0.8383\n",
      "Epoch 350/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9344 - acc: 0.8125 - val_loss: 0.8250 - val_acc: 0.8302\n",
      "Epoch 351/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9261 - acc: 0.8131 - val_loss: 0.8290 - val_acc: 0.8302\n",
      "Epoch 352/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9192 - acc: 0.8155 - val_loss: 0.8240 - val_acc: 0.8302\n",
      "Epoch 353/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9290 - acc: 0.8113 - val_loss: 0.8258 - val_acc: 0.8302\n",
      "Epoch 354/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9246 - acc: 0.8101 - val_loss: 0.8265 - val_acc: 0.8275\n",
      "Epoch 355/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9253 - acc: 0.8113 - val_loss: 0.8239 - val_acc: 0.8329\n",
      "Epoch 356/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9304 - acc: 0.8137 - val_loss: 0.8240 - val_acc: 0.8302\n",
      "Epoch 357/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9178 - acc: 0.8191 - val_loss: 0.8314 - val_acc: 0.8275\n",
      "Epoch 358/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9249 - acc: 0.8149 - val_loss: 0.8271 - val_acc: 0.8275\n",
      "Epoch 359/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9187 - acc: 0.8176 - val_loss: 0.8297 - val_acc: 0.8383\n",
      "Epoch 360/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9212 - acc: 0.8098 - val_loss: 0.8379 - val_acc: 0.8248\n",
      "Epoch 361/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9129 - acc: 0.8188 - val_loss: 0.8319 - val_acc: 0.8329\n",
      "Epoch 362/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9244 - acc: 0.8092 - val_loss: 0.8317 - val_acc: 0.8329\n",
      "Epoch 363/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9232 - acc: 0.8158 - val_loss: 0.8332 - val_acc: 0.8302\n",
      "Epoch 364/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9484 - acc: 0.8077 - val_loss: 0.8247 - val_acc: 0.8329\n",
      "Epoch 365/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9250 - acc: 0.8125 - val_loss: 0.8363 - val_acc: 0.8248\n",
      "Epoch 366/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8888 - acc: 0.8200 - val_loss: 0.8332 - val_acc: 0.8329\n",
      "Epoch 367/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9133 - acc: 0.8182 - val_loss: 0.8343 - val_acc: 0.8275\n",
      "Epoch 368/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9098 - acc: 0.8152 - val_loss: 0.8380 - val_acc: 0.8221\n",
      "Epoch 369/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9199 - acc: 0.8077 - val_loss: 0.8294 - val_acc: 0.8302\n",
      "Epoch 370/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9124 - acc: 0.8164 - val_loss: 0.8254 - val_acc: 0.8302\n",
      "Epoch 371/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9056 - acc: 0.8146 - val_loss: 0.8330 - val_acc: 0.8221\n",
      "Epoch 372/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9068 - acc: 0.8182 - val_loss: 0.8381 - val_acc: 0.8194\n",
      "Epoch 373/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9295 - acc: 0.8128 - val_loss: 0.8363 - val_acc: 0.8248\n",
      "Epoch 374/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9210 - acc: 0.8113 - val_loss: 0.8256 - val_acc: 0.8302\n",
      "Epoch 375/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9366 - acc: 0.8146 - val_loss: 0.8372 - val_acc: 0.8167\n",
      "Epoch 376/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9136 - acc: 0.8143 - val_loss: 0.8355 - val_acc: 0.8275\n",
      "Epoch 377/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9285 - acc: 0.8131 - val_loss: 0.8309 - val_acc: 0.8329\n",
      "Epoch 378/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9061 - acc: 0.8131 - val_loss: 0.8346 - val_acc: 0.8302\n",
      "Epoch 379/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9292 - acc: 0.8071 - val_loss: 0.8385 - val_acc: 0.8275\n",
      "Epoch 380/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9192 - acc: 0.8176 - val_loss: 0.8408 - val_acc: 0.8248\n",
      "Epoch 381/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9208 - acc: 0.8134 - val_loss: 0.8408 - val_acc: 0.8221\n",
      "Epoch 382/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9138 - acc: 0.8167 - val_loss: 0.8435 - val_acc: 0.8194\n",
      "Epoch 383/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9212 - acc: 0.8137 - val_loss: 0.8327 - val_acc: 0.8221\n",
      "Epoch 384/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9192 - acc: 0.8143 - val_loss: 0.8333 - val_acc: 0.8248\n",
      "Epoch 385/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9057 - acc: 0.8167 - val_loss: 0.8359 - val_acc: 0.8302\n",
      "Epoch 386/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9210 - acc: 0.8110 - val_loss: 0.8305 - val_acc: 0.8248\n",
      "Epoch 387/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9016 - acc: 0.8158 - val_loss: 0.8350 - val_acc: 0.8302\n",
      "Epoch 388/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9229 - acc: 0.8194 - val_loss: 0.8342 - val_acc: 0.8302\n",
      "Epoch 389/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9015 - acc: 0.8167 - val_loss: 0.8319 - val_acc: 0.8248\n",
      "Epoch 390/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9074 - acc: 0.8128 - val_loss: 0.8391 - val_acc: 0.8221\n",
      "Epoch 391/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9124 - acc: 0.8158 - val_loss: 0.8313 - val_acc: 0.8275\n",
      "Epoch 392/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9127 - acc: 0.8128 - val_loss: 0.8409 - val_acc: 0.8194\n",
      "Epoch 393/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9163 - acc: 0.8092 - val_loss: 0.8177 - val_acc: 0.8221\n",
      "Epoch 394/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9254 - acc: 0.8071 - val_loss: 0.8170 - val_acc: 0.8329\n",
      "Epoch 395/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9147 - acc: 0.8167 - val_loss: 0.8215 - val_acc: 0.8275\n",
      "Epoch 396/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9203 - acc: 0.8164 - val_loss: 0.8260 - val_acc: 0.8248\n",
      "Epoch 397/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9010 - acc: 0.8185 - val_loss: 0.8340 - val_acc: 0.8167\n",
      "Epoch 398/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9229 - acc: 0.8116 - val_loss: 0.8327 - val_acc: 0.8221\n",
      "Epoch 399/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9029 - acc: 0.8173 - val_loss: 0.8363 - val_acc: 0.8248\n",
      "Epoch 400/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9093 - acc: 0.8155 - val_loss: 0.8350 - val_acc: 0.8302\n",
      "Epoch 401/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8955 - acc: 0.8209 - val_loss: 0.8313 - val_acc: 0.8275\n",
      "Epoch 402/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9001 - acc: 0.8155 - val_loss: 0.8358 - val_acc: 0.8302\n",
      "Epoch 403/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9095 - acc: 0.8152 - val_loss: 0.8344 - val_acc: 0.8329\n",
      "Epoch 404/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9054 - acc: 0.8143 - val_loss: 0.8312 - val_acc: 0.8329\n",
      "Epoch 405/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9109 - acc: 0.8161 - val_loss: 0.8222 - val_acc: 0.8275\n",
      "Epoch 406/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9113 - acc: 0.8122 - val_loss: 0.8244 - val_acc: 0.8275\n",
      "Epoch 407/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9015 - acc: 0.8152 - val_loss: 0.8253 - val_acc: 0.8248\n",
      "Epoch 408/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8961 - acc: 0.8119 - val_loss: 0.8295 - val_acc: 0.8194\n",
      "Epoch 409/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9108 - acc: 0.8101 - val_loss: 0.8279 - val_acc: 0.8194\n",
      "Epoch 410/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9208 - acc: 0.8152 - val_loss: 0.8094 - val_acc: 0.8302\n",
      "Epoch 411/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9084 - acc: 0.8116 - val_loss: 0.8095 - val_acc: 0.8329\n",
      "Epoch 412/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8915 - acc: 0.8107 - val_loss: 0.8169 - val_acc: 0.8329\n",
      "Epoch 413/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9068 - acc: 0.8110 - val_loss: 0.8193 - val_acc: 0.8329\n",
      "Epoch 414/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9120 - acc: 0.8188 - val_loss: 0.8249 - val_acc: 0.8248\n",
      "Epoch 415/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9178 - acc: 0.8092 - val_loss: 0.8294 - val_acc: 0.8275\n",
      "Epoch 416/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9200 - acc: 0.8134 - val_loss: 0.8373 - val_acc: 0.8248\n",
      "Epoch 417/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8948 - acc: 0.8143 - val_loss: 0.8312 - val_acc: 0.8275\n",
      "Epoch 418/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9201 - acc: 0.8131 - val_loss: 0.8326 - val_acc: 0.8275\n",
      "Epoch 419/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9087 - acc: 0.8080 - val_loss: 0.8310 - val_acc: 0.8221\n",
      "Epoch 420/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9018 - acc: 0.8200 - val_loss: 0.8325 - val_acc: 0.8275\n",
      "Epoch 421/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9078 - acc: 0.8182 - val_loss: 0.8366 - val_acc: 0.8194\n",
      "Epoch 422/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9029 - acc: 0.8128 - val_loss: 0.8326 - val_acc: 0.8275\n",
      "Epoch 423/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9254 - acc: 0.8152 - val_loss: 0.8253 - val_acc: 0.8194\n",
      "Epoch 424/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9064 - acc: 0.8152 - val_loss: 0.8266 - val_acc: 0.8221\n",
      "Epoch 425/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9075 - acc: 0.8149 - val_loss: 0.8171 - val_acc: 0.8329\n",
      "Epoch 426/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9074 - acc: 0.8164 - val_loss: 0.8296 - val_acc: 0.8302\n",
      "Epoch 427/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9051 - acc: 0.8125 - val_loss: 0.8250 - val_acc: 0.8248\n",
      "Epoch 428/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9068 - acc: 0.8095 - val_loss: 0.8376 - val_acc: 0.8167\n",
      "Epoch 429/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9183 - acc: 0.8089 - val_loss: 0.8280 - val_acc: 0.8248\n",
      "Epoch 430/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9103 - acc: 0.8155 - val_loss: 0.8195 - val_acc: 0.8248\n",
      "Epoch 431/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8922 - acc: 0.8191 - val_loss: 0.8175 - val_acc: 0.8194\n",
      "Epoch 432/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8974 - acc: 0.8143 - val_loss: 0.8137 - val_acc: 0.8248\n",
      "Epoch 433/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8832 - acc: 0.8143 - val_loss: 0.8165 - val_acc: 0.8248\n",
      "Epoch 434/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8939 - acc: 0.8152 - val_loss: 0.8210 - val_acc: 0.8275\n",
      "Epoch 435/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8889 - acc: 0.8149 - val_loss: 0.8125 - val_acc: 0.8248\n",
      "Epoch 436/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9083 - acc: 0.8122 - val_loss: 0.8185 - val_acc: 0.8248\n",
      "Epoch 437/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8990 - acc: 0.8152 - val_loss: 0.8161 - val_acc: 0.8275\n",
      "Epoch 438/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8937 - acc: 0.8206 - val_loss: 0.8097 - val_acc: 0.8302\n",
      "Epoch 439/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9071 - acc: 0.8182 - val_loss: 0.8095 - val_acc: 0.8275\n",
      "Epoch 440/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9120 - acc: 0.8146 - val_loss: 0.8134 - val_acc: 0.8275\n",
      "Epoch 441/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8930 - acc: 0.8161 - val_loss: 0.8150 - val_acc: 0.8248\n",
      "Epoch 442/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9101 - acc: 0.8158 - val_loss: 0.8224 - val_acc: 0.8248\n",
      "Epoch 443/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8966 - acc: 0.8182 - val_loss: 0.8307 - val_acc: 0.8194\n",
      "Epoch 444/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9070 - acc: 0.8095 - val_loss: 0.8228 - val_acc: 0.8248\n",
      "Epoch 445/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8864 - acc: 0.8164 - val_loss: 0.8272 - val_acc: 0.8167\n",
      "Epoch 446/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9000 - acc: 0.8143 - val_loss: 0.8217 - val_acc: 0.8275\n",
      "Epoch 447/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9106 - acc: 0.8152 - val_loss: 0.8295 - val_acc: 0.8221\n",
      "Epoch 448/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9037 - acc: 0.8161 - val_loss: 0.8278 - val_acc: 0.8248\n",
      "Epoch 449/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9103 - acc: 0.8158 - val_loss: 0.8232 - val_acc: 0.8248\n",
      "Epoch 450/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9133 - acc: 0.8116 - val_loss: 0.8213 - val_acc: 0.8248\n",
      "Epoch 451/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8935 - acc: 0.8137 - val_loss: 0.8265 - val_acc: 0.8248\n",
      "Epoch 452/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8924 - acc: 0.8149 - val_loss: 0.8246 - val_acc: 0.8248\n",
      "Epoch 453/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8867 - acc: 0.8170 - val_loss: 0.8241 - val_acc: 0.8194\n",
      "Epoch 454/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9005 - acc: 0.8122 - val_loss: 0.8285 - val_acc: 0.8221\n",
      "Epoch 455/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8762 - acc: 0.8200 - val_loss: 0.8186 - val_acc: 0.8302\n",
      "Epoch 456/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8960 - acc: 0.8098 - val_loss: 0.8199 - val_acc: 0.8194\n",
      "Epoch 457/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9066 - acc: 0.8113 - val_loss: 0.8136 - val_acc: 0.8302\n",
      "Epoch 458/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8888 - acc: 0.8137 - val_loss: 0.8161 - val_acc: 0.8356\n",
      "Epoch 459/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9053 - acc: 0.8161 - val_loss: 0.8274 - val_acc: 0.8302\n",
      "Epoch 460/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9028 - acc: 0.8173 - val_loss: 0.8211 - val_acc: 0.8302\n",
      "Epoch 461/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9013 - acc: 0.8176 - val_loss: 0.8082 - val_acc: 0.8383\n",
      "Epoch 462/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8843 - acc: 0.8119 - val_loss: 0.8198 - val_acc: 0.8329\n",
      "Epoch 463/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8978 - acc: 0.8083 - val_loss: 0.8249 - val_acc: 0.8302\n",
      "Epoch 464/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8999 - acc: 0.8164 - val_loss: 0.8227 - val_acc: 0.8248\n",
      "Epoch 465/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9112 - acc: 0.8128 - val_loss: 0.8219 - val_acc: 0.8248\n",
      "Epoch 466/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8924 - acc: 0.8203 - val_loss: 0.8226 - val_acc: 0.8248\n",
      "Epoch 467/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8826 - acc: 0.8200 - val_loss: 0.8244 - val_acc: 0.8221\n",
      "Epoch 468/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8979 - acc: 0.8089 - val_loss: 0.8232 - val_acc: 0.8221\n",
      "Epoch 469/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8890 - acc: 0.8260 - val_loss: 0.8183 - val_acc: 0.8221\n",
      "Epoch 470/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8992 - acc: 0.8086 - val_loss: 0.8147 - val_acc: 0.8248\n",
      "Epoch 471/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8765 - acc: 0.8143 - val_loss: 0.8171 - val_acc: 0.8248\n",
      "Epoch 472/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8999 - acc: 0.8170 - val_loss: 0.8267 - val_acc: 0.8248\n",
      "Epoch 473/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8981 - acc: 0.8104 - val_loss: 0.8257 - val_acc: 0.8248\n",
      "Epoch 474/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8901 - acc: 0.8110 - val_loss: 0.8326 - val_acc: 0.8194\n",
      "Epoch 475/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9002 - acc: 0.8161 - val_loss: 0.8254 - val_acc: 0.8248\n",
      "Epoch 476/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8915 - acc: 0.8095 - val_loss: 0.8276 - val_acc: 0.8194\n",
      "Epoch 477/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8914 - acc: 0.8155 - val_loss: 0.8232 - val_acc: 0.8194\n",
      "Epoch 478/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8927 - acc: 0.8080 - val_loss: 0.8262 - val_acc: 0.8248\n",
      "Epoch 479/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8944 - acc: 0.8092 - val_loss: 0.8164 - val_acc: 0.8275\n",
      "Epoch 480/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8796 - acc: 0.8122 - val_loss: 0.8241 - val_acc: 0.8140\n",
      "Epoch 481/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9055 - acc: 0.8134 - val_loss: 0.8181 - val_acc: 0.8302\n",
      "Epoch 482/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8800 - acc: 0.8146 - val_loss: 0.8206 - val_acc: 0.8248\n",
      "Epoch 483/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8918 - acc: 0.8131 - val_loss: 0.8189 - val_acc: 0.8221\n",
      "Epoch 484/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8974 - acc: 0.8128 - val_loss: 0.8196 - val_acc: 0.8221\n",
      "Epoch 485/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8834 - acc: 0.8164 - val_loss: 0.8356 - val_acc: 0.8140\n",
      "Epoch 486/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9052 - acc: 0.8125 - val_loss: 0.8368 - val_acc: 0.8167\n",
      "Epoch 487/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8868 - acc: 0.8119 - val_loss: 0.8302 - val_acc: 0.8221\n",
      "Epoch 488/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8967 - acc: 0.8119 - val_loss: 0.8294 - val_acc: 0.8221\n",
      "Epoch 489/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8921 - acc: 0.8170 - val_loss: 0.8184 - val_acc: 0.8329\n",
      "Epoch 490/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8870 - acc: 0.8122 - val_loss: 0.8146 - val_acc: 0.8194\n",
      "Epoch 491/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8858 - acc: 0.8149 - val_loss: 0.8167 - val_acc: 0.8248\n",
      "Epoch 492/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9039 - acc: 0.8176 - val_loss: 0.8165 - val_acc: 0.8221\n",
      "Epoch 493/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9008 - acc: 0.8092 - val_loss: 0.8214 - val_acc: 0.8275\n",
      "Epoch 494/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9027 - acc: 0.8089 - val_loss: 0.8175 - val_acc: 0.8275\n",
      "Epoch 495/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8823 - acc: 0.8227 - val_loss: 0.8151 - val_acc: 0.8302\n",
      "Epoch 496/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9131 - acc: 0.8098 - val_loss: 0.8210 - val_acc: 0.8221\n",
      "Epoch 497/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8894 - acc: 0.8146 - val_loss: 0.8191 - val_acc: 0.8248\n",
      "Epoch 498/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8882 - acc: 0.8134 - val_loss: 0.8160 - val_acc: 0.8275\n",
      "Epoch 499/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8811 - acc: 0.8179 - val_loss: 0.8291 - val_acc: 0.8275\n",
      "Epoch 500/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8949 - acc: 0.8179 - val_loss: 0.8208 - val_acc: 0.8356\n",
      "Epoch 501/5000\n",
      "3339/3339 [==============================] - 0s 10us/step - loss: 0.8818 - acc: 0.8155 - val_loss: 0.8263 - val_acc: 0.8302\n",
      "Epoch 502/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.9015 - acc: 0.8143 - val_loss: 0.8151 - val_acc: 0.8275\n",
      "Epoch 503/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9063 - acc: 0.8119 - val_loss: 0.8118 - val_acc: 0.8248\n",
      "Epoch 504/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8893 - acc: 0.8125 - val_loss: 0.8130 - val_acc: 0.8275\n",
      "Epoch 505/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8835 - acc: 0.8149 - val_loss: 0.8103 - val_acc: 0.8275\n",
      "Epoch 506/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8899 - acc: 0.8125 - val_loss: 0.8179 - val_acc: 0.8221\n",
      "Epoch 507/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9035 - acc: 0.8110 - val_loss: 0.8192 - val_acc: 0.8248\n",
      "Epoch 508/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8822 - acc: 0.8149 - val_loss: 0.8228 - val_acc: 0.8221\n",
      "Epoch 509/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8828 - acc: 0.8077 - val_loss: 0.8148 - val_acc: 0.8221\n",
      "Epoch 510/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8737 - acc: 0.8218 - val_loss: 0.8125 - val_acc: 0.8275\n",
      "Epoch 511/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8902 - acc: 0.8077 - val_loss: 0.8156 - val_acc: 0.8248\n",
      "Epoch 512/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8866 - acc: 0.8155 - val_loss: 0.8160 - val_acc: 0.8248\n",
      "Epoch 513/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8938 - acc: 0.8125 - val_loss: 0.8162 - val_acc: 0.8275\n",
      "Epoch 514/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8894 - acc: 0.8125 - val_loss: 0.8172 - val_acc: 0.8221\n",
      "Epoch 515/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8821 - acc: 0.8122 - val_loss: 0.8101 - val_acc: 0.8329\n",
      "Epoch 516/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8993 - acc: 0.8131 - val_loss: 0.8211 - val_acc: 0.8248\n",
      "Epoch 517/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8812 - acc: 0.8152 - val_loss: 0.8139 - val_acc: 0.8194\n",
      "Epoch 518/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8870 - acc: 0.8116 - val_loss: 0.8187 - val_acc: 0.8167\n",
      "Epoch 519/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8800 - acc: 0.8119 - val_loss: 0.8215 - val_acc: 0.8194\n",
      "Epoch 520/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8849 - acc: 0.8170 - val_loss: 0.8211 - val_acc: 0.8194\n",
      "Epoch 521/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8707 - acc: 0.8227 - val_loss: 0.8084 - val_acc: 0.8275\n",
      "Epoch 522/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8790 - acc: 0.8137 - val_loss: 0.8109 - val_acc: 0.8248\n",
      "Epoch 523/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8850 - acc: 0.8104 - val_loss: 0.8035 - val_acc: 0.8248\n",
      "Epoch 524/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8707 - acc: 0.8185 - val_loss: 0.8041 - val_acc: 0.8275\n",
      "Epoch 525/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8968 - acc: 0.8143 - val_loss: 0.8072 - val_acc: 0.8248\n",
      "Epoch 526/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8780 - acc: 0.8113 - val_loss: 0.8124 - val_acc: 0.8194\n",
      "Epoch 527/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8882 - acc: 0.8149 - val_loss: 0.8174 - val_acc: 0.8221\n",
      "Epoch 528/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8743 - acc: 0.8161 - val_loss: 0.8090 - val_acc: 0.8329\n",
      "Epoch 529/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8925 - acc: 0.8095 - val_loss: 0.8095 - val_acc: 0.8329\n",
      "Epoch 530/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8858 - acc: 0.8110 - val_loss: 0.8085 - val_acc: 0.8356\n",
      "Epoch 531/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8904 - acc: 0.8170 - val_loss: 0.8248 - val_acc: 0.8275\n",
      "Epoch 532/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8708 - acc: 0.8158 - val_loss: 0.8116 - val_acc: 0.8329\n",
      "Epoch 533/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8747 - acc: 0.8074 - val_loss: 0.7915 - val_acc: 0.8329\n",
      "Epoch 534/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8719 - acc: 0.8128 - val_loss: 0.8047 - val_acc: 0.8275\n",
      "Epoch 535/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8689 - acc: 0.8182 - val_loss: 0.8040 - val_acc: 0.8329\n",
      "Epoch 536/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8948 - acc: 0.8122 - val_loss: 0.8042 - val_acc: 0.8248\n",
      "Epoch 537/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8851 - acc: 0.8197 - val_loss: 0.8091 - val_acc: 0.8248\n",
      "Epoch 538/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8863 - acc: 0.8164 - val_loss: 0.8106 - val_acc: 0.8302\n",
      "Epoch 539/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8930 - acc: 0.8107 - val_loss: 0.8081 - val_acc: 0.8221\n",
      "Epoch 540/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8708 - acc: 0.8155 - val_loss: 0.8112 - val_acc: 0.8194\n",
      "Epoch 541/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8936 - acc: 0.8143 - val_loss: 0.8137 - val_acc: 0.8221\n",
      "Epoch 542/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8786 - acc: 0.8161 - val_loss: 0.8115 - val_acc: 0.8167\n",
      "Epoch 543/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8902 - acc: 0.8116 - val_loss: 0.8079 - val_acc: 0.8221\n",
      "Epoch 544/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8794 - acc: 0.8107 - val_loss: 0.8097 - val_acc: 0.8221\n",
      "Epoch 545/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8705 - acc: 0.8191 - val_loss: 0.8101 - val_acc: 0.8194\n",
      "Epoch 546/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8866 - acc: 0.8092 - val_loss: 0.8046 - val_acc: 0.8221\n",
      "Epoch 547/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8839 - acc: 0.8125 - val_loss: 0.7974 - val_acc: 0.8248\n",
      "Epoch 548/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8837 - acc: 0.8164 - val_loss: 0.8090 - val_acc: 0.8167\n",
      "Epoch 549/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8986 - acc: 0.8137 - val_loss: 0.8031 - val_acc: 0.8221\n",
      "Epoch 550/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8756 - acc: 0.8161 - val_loss: 0.8114 - val_acc: 0.8167\n",
      "Epoch 551/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8688 - acc: 0.8242 - val_loss: 0.8121 - val_acc: 0.8221\n",
      "Epoch 552/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8936 - acc: 0.8170 - val_loss: 0.8055 - val_acc: 0.8248\n",
      "Epoch 553/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8812 - acc: 0.8119 - val_loss: 0.7983 - val_acc: 0.8221\n",
      "Epoch 554/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8824 - acc: 0.8095 - val_loss: 0.8125 - val_acc: 0.8167\n",
      "Epoch 555/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8770 - acc: 0.8167 - val_loss: 0.8032 - val_acc: 0.8221\n",
      "Epoch 556/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8869 - acc: 0.8134 - val_loss: 0.8029 - val_acc: 0.8221\n",
      "Epoch 557/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8779 - acc: 0.8167 - val_loss: 0.7994 - val_acc: 0.8194\n",
      "Epoch 558/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8803 - acc: 0.8137 - val_loss: 0.8016 - val_acc: 0.8248\n",
      "Epoch 559/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8789 - acc: 0.8149 - val_loss: 0.8035 - val_acc: 0.8302\n",
      "Epoch 560/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8961 - acc: 0.8113 - val_loss: 0.8127 - val_acc: 0.8275\n",
      "Epoch 561/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8765 - acc: 0.8140 - val_loss: 0.8064 - val_acc: 0.8275\n",
      "Epoch 562/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8710 - acc: 0.8167 - val_loss: 0.8070 - val_acc: 0.8248\n",
      "Epoch 563/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8674 - acc: 0.8179 - val_loss: 0.8124 - val_acc: 0.8248\n",
      "Epoch 564/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8804 - acc: 0.8155 - val_loss: 0.8147 - val_acc: 0.8275\n",
      "Epoch 565/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8770 - acc: 0.8125 - val_loss: 0.8123 - val_acc: 0.8275\n",
      "Epoch 566/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8757 - acc: 0.8095 - val_loss: 0.8100 - val_acc: 0.8275\n",
      "Epoch 567/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8856 - acc: 0.8074 - val_loss: 0.8186 - val_acc: 0.8221\n",
      "Epoch 568/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8765 - acc: 0.8137 - val_loss: 0.8104 - val_acc: 0.8248\n",
      "Epoch 569/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8702 - acc: 0.8119 - val_loss: 0.8045 - val_acc: 0.8248\n",
      "Epoch 570/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8783 - acc: 0.8134 - val_loss: 0.8020 - val_acc: 0.8275\n",
      "Epoch 571/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8660 - acc: 0.8122 - val_loss: 0.8008 - val_acc: 0.8275\n",
      "Epoch 572/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8766 - acc: 0.8092 - val_loss: 0.8043 - val_acc: 0.8275\n",
      "Epoch 573/5000\n",
      "3339/3339 [==============================] - 0s 10us/step - loss: 0.8711 - acc: 0.8161 - val_loss: 0.8160 - val_acc: 0.8140\n",
      "Epoch 574/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8737 - acc: 0.8164 - val_loss: 0.8099 - val_acc: 0.8194\n",
      "Epoch 575/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8629 - acc: 0.8140 - val_loss: 0.8140 - val_acc: 0.8194\n",
      "Epoch 576/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8873 - acc: 0.8122 - val_loss: 0.8120 - val_acc: 0.8248\n",
      "Epoch 577/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.9059 - acc: 0.8086 - val_loss: 0.8127 - val_acc: 0.8140\n",
      "Epoch 578/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8751 - acc: 0.8137 - val_loss: 0.8091 - val_acc: 0.8275\n",
      "Epoch 579/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8769 - acc: 0.8140 - val_loss: 0.8145 - val_acc: 0.8248\n",
      "Epoch 580/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8726 - acc: 0.8131 - val_loss: 0.8177 - val_acc: 0.8140\n",
      "Epoch 581/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8816 - acc: 0.8125 - val_loss: 0.8147 - val_acc: 0.8167\n",
      "Epoch 582/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8806 - acc: 0.8146 - val_loss: 0.8058 - val_acc: 0.8248\n",
      "Epoch 583/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8835 - acc: 0.8203 - val_loss: 0.8095 - val_acc: 0.8248\n",
      "Epoch 584/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8729 - acc: 0.8173 - val_loss: 0.8133 - val_acc: 0.8221\n",
      "Epoch 585/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8745 - acc: 0.8152 - val_loss: 0.8085 - val_acc: 0.8275\n",
      "Epoch 586/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8940 - acc: 0.8095 - val_loss: 0.8178 - val_acc: 0.8275\n",
      "Epoch 587/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.8647 - acc: 0.8134 - val_loss: 0.8158 - val_acc: 0.8275\n",
      "Epoch 588/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8598 - acc: 0.8143 - val_loss: 0.8141 - val_acc: 0.8248\n",
      "Epoch 589/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8617 - acc: 0.8128 - val_loss: 0.8130 - val_acc: 0.8302\n",
      "Epoch 590/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8543 - acc: 0.8197 - val_loss: 0.8100 - val_acc: 0.8221\n",
      "Epoch 591/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8550 - acc: 0.8185 - val_loss: 0.8105 - val_acc: 0.8221\n",
      "Epoch 592/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8844 - acc: 0.8086 - val_loss: 0.8139 - val_acc: 0.8248\n",
      "Epoch 593/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8749 - acc: 0.8140 - val_loss: 0.8202 - val_acc: 0.8194\n",
      "Epoch 594/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8700 - acc: 0.8158 - val_loss: 0.8235 - val_acc: 0.8194\n",
      "Epoch 595/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8721 - acc: 0.8143 - val_loss: 0.8221 - val_acc: 0.8248\n",
      "Epoch 596/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8587 - acc: 0.8176 - val_loss: 0.8080 - val_acc: 0.8248\n",
      "Epoch 597/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8827 - acc: 0.8152 - val_loss: 0.8034 - val_acc: 0.8302\n",
      "Epoch 598/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8513 - acc: 0.8221 - val_loss: 0.8065 - val_acc: 0.8275\n",
      "Epoch 599/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8724 - acc: 0.8137 - val_loss: 0.8123 - val_acc: 0.8275\n",
      "Epoch 600/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8773 - acc: 0.8200 - val_loss: 0.8100 - val_acc: 0.8248\n",
      "Epoch 601/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8725 - acc: 0.8137 - val_loss: 0.8111 - val_acc: 0.8275\n",
      "Epoch 602/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8771 - acc: 0.8200 - val_loss: 0.8216 - val_acc: 0.8221\n",
      "Epoch 603/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8677 - acc: 0.8191 - val_loss: 0.8187 - val_acc: 0.8248\n",
      "Epoch 604/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8805 - acc: 0.8107 - val_loss: 0.8246 - val_acc: 0.8221\n",
      "Epoch 605/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8834 - acc: 0.8101 - val_loss: 0.8251 - val_acc: 0.8221\n",
      "Epoch 606/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8741 - acc: 0.8128 - val_loss: 0.8164 - val_acc: 0.8248\n",
      "Epoch 607/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8695 - acc: 0.8149 - val_loss: 0.8103 - val_acc: 0.8248\n",
      "Epoch 608/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8694 - acc: 0.8191 - val_loss: 0.8160 - val_acc: 0.8221\n",
      "Epoch 609/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8876 - acc: 0.8140 - val_loss: 0.8191 - val_acc: 0.8248\n",
      "Epoch 610/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8627 - acc: 0.8221 - val_loss: 0.8147 - val_acc: 0.8248\n",
      "Epoch 611/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8687 - acc: 0.8149 - val_loss: 0.8123 - val_acc: 0.8275\n",
      "Epoch 612/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8739 - acc: 0.8137 - val_loss: 0.8186 - val_acc: 0.8221\n",
      "Epoch 613/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8903 - acc: 0.8107 - val_loss: 0.8096 - val_acc: 0.8329\n",
      "Epoch 614/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8592 - acc: 0.8161 - val_loss: 0.8163 - val_acc: 0.8302\n",
      "Epoch 615/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8823 - acc: 0.8104 - val_loss: 0.8124 - val_acc: 0.8275\n",
      "Epoch 616/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8727 - acc: 0.8155 - val_loss: 0.8151 - val_acc: 0.8194\n",
      "Epoch 617/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8649 - acc: 0.8134 - val_loss: 0.8124 - val_acc: 0.8194\n",
      "Epoch 618/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8626 - acc: 0.8233 - val_loss: 0.8007 - val_acc: 0.8248\n",
      "Epoch 619/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8720 - acc: 0.8161 - val_loss: 0.7917 - val_acc: 0.8302\n",
      "Epoch 620/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8756 - acc: 0.8125 - val_loss: 0.7925 - val_acc: 0.8248\n",
      "Epoch 621/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8775 - acc: 0.8158 - val_loss: 0.7957 - val_acc: 0.8329\n",
      "Epoch 622/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8657 - acc: 0.8158 - val_loss: 0.8136 - val_acc: 0.8248\n",
      "Epoch 623/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8650 - acc: 0.8140 - val_loss: 0.8090 - val_acc: 0.8248\n",
      "Epoch 624/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8776 - acc: 0.8206 - val_loss: 0.8034 - val_acc: 0.8248\n",
      "Epoch 625/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8464 - acc: 0.8203 - val_loss: 0.8025 - val_acc: 0.8248\n",
      "Epoch 626/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8721 - acc: 0.8107 - val_loss: 0.8053 - val_acc: 0.8302\n",
      "Epoch 627/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8565 - acc: 0.8143 - val_loss: 0.8110 - val_acc: 0.8248\n",
      "Epoch 628/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8556 - acc: 0.8152 - val_loss: 0.8067 - val_acc: 0.8275\n",
      "Epoch 629/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8665 - acc: 0.8170 - val_loss: 0.8091 - val_acc: 0.8275\n",
      "Epoch 630/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8693 - acc: 0.8176 - val_loss: 0.8203 - val_acc: 0.8248\n",
      "Epoch 631/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8864 - acc: 0.8137 - val_loss: 0.8207 - val_acc: 0.8194\n",
      "Epoch 632/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8547 - acc: 0.8146 - val_loss: 0.8060 - val_acc: 0.8302\n",
      "Epoch 633/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8551 - acc: 0.8167 - val_loss: 0.8012 - val_acc: 0.8356\n",
      "Epoch 634/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8675 - acc: 0.8155 - val_loss: 0.8008 - val_acc: 0.8383\n",
      "Epoch 635/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8731 - acc: 0.8128 - val_loss: 0.8094 - val_acc: 0.8329\n",
      "Epoch 636/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8690 - acc: 0.8206 - val_loss: 0.8128 - val_acc: 0.8167\n",
      "Epoch 637/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8660 - acc: 0.8164 - val_loss: 0.8155 - val_acc: 0.8194\n",
      "Epoch 638/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8750 - acc: 0.8134 - val_loss: 0.8231 - val_acc: 0.8140\n",
      "Epoch 639/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8672 - acc: 0.8074 - val_loss: 0.8129 - val_acc: 0.8248\n",
      "Epoch 640/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8769 - acc: 0.8125 - val_loss: 0.8064 - val_acc: 0.8275\n",
      "Epoch 641/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8735 - acc: 0.8140 - val_loss: 0.8051 - val_acc: 0.8302\n",
      "Epoch 642/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8551 - acc: 0.8161 - val_loss: 0.8068 - val_acc: 0.8275\n",
      "Epoch 643/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8736 - acc: 0.8137 - val_loss: 0.8096 - val_acc: 0.8167\n",
      "Epoch 644/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8720 - acc: 0.8137 - val_loss: 0.8123 - val_acc: 0.8140\n",
      "Epoch 645/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8576 - acc: 0.8173 - val_loss: 0.8096 - val_acc: 0.8194\n",
      "Epoch 646/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8701 - acc: 0.8140 - val_loss: 0.8124 - val_acc: 0.8248\n",
      "Epoch 647/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8680 - acc: 0.8170 - val_loss: 0.8122 - val_acc: 0.8302\n",
      "Epoch 648/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8679 - acc: 0.8134 - val_loss: 0.8061 - val_acc: 0.8302\n",
      "Epoch 649/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8707 - acc: 0.8131 - val_loss: 0.8178 - val_acc: 0.8248\n",
      "Epoch 650/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8669 - acc: 0.8098 - val_loss: 0.8087 - val_acc: 0.8194\n",
      "Epoch 651/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8660 - acc: 0.8110 - val_loss: 0.7955 - val_acc: 0.8248\n",
      "Epoch 652/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8749 - acc: 0.8179 - val_loss: 0.7990 - val_acc: 0.8275\n",
      "Epoch 653/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8626 - acc: 0.8116 - val_loss: 0.8084 - val_acc: 0.8221\n",
      "Epoch 654/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8711 - acc: 0.8200 - val_loss: 0.8018 - val_acc: 0.8248\n",
      "Epoch 655/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8814 - acc: 0.8149 - val_loss: 0.8069 - val_acc: 0.8248\n",
      "Epoch 656/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8513 - acc: 0.8173 - val_loss: 0.8012 - val_acc: 0.8221\n",
      "Epoch 657/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8666 - acc: 0.8143 - val_loss: 0.7974 - val_acc: 0.8221\n",
      "Epoch 658/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8645 - acc: 0.8158 - val_loss: 0.7938 - val_acc: 0.8275\n",
      "Epoch 659/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8576 - acc: 0.8137 - val_loss: 0.7934 - val_acc: 0.8248\n",
      "Epoch 660/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8507 - acc: 0.8134 - val_loss: 0.7962 - val_acc: 0.8248\n",
      "Epoch 661/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8726 - acc: 0.8140 - val_loss: 0.8006 - val_acc: 0.8194\n",
      "Epoch 662/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8824 - acc: 0.8158 - val_loss: 0.7998 - val_acc: 0.8248\n",
      "Epoch 663/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8538 - acc: 0.8170 - val_loss: 0.8025 - val_acc: 0.8275\n",
      "Epoch 664/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8606 - acc: 0.8206 - val_loss: 0.7993 - val_acc: 0.8329\n",
      "Epoch 665/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8598 - acc: 0.8128 - val_loss: 0.8071 - val_acc: 0.8275\n",
      "Epoch 666/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8638 - acc: 0.8182 - val_loss: 0.8056 - val_acc: 0.8221\n",
      "Epoch 667/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8598 - acc: 0.8194 - val_loss: 0.8006 - val_acc: 0.8275\n",
      "Epoch 668/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8550 - acc: 0.8170 - val_loss: 0.7964 - val_acc: 0.8248\n",
      "Epoch 669/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8577 - acc: 0.8107 - val_loss: 0.8064 - val_acc: 0.8275\n",
      "Epoch 670/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8612 - acc: 0.8080 - val_loss: 0.8047 - val_acc: 0.8275\n",
      "Epoch 671/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8616 - acc: 0.8146 - val_loss: 0.8033 - val_acc: 0.8221\n",
      "Epoch 672/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8612 - acc: 0.8101 - val_loss: 0.8029 - val_acc: 0.8221\n",
      "Epoch 673/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8740 - acc: 0.8191 - val_loss: 0.8039 - val_acc: 0.8248\n",
      "Epoch 674/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8472 - acc: 0.8212 - val_loss: 0.7944 - val_acc: 0.8329\n",
      "Epoch 675/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8641 - acc: 0.8083 - val_loss: 0.8060 - val_acc: 0.8248\n",
      "Epoch 676/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8568 - acc: 0.8221 - val_loss: 0.8098 - val_acc: 0.8167\n",
      "Epoch 677/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8552 - acc: 0.8191 - val_loss: 0.8080 - val_acc: 0.8221\n",
      "Epoch 678/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8623 - acc: 0.8173 - val_loss: 0.8017 - val_acc: 0.8248\n",
      "Epoch 679/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8554 - acc: 0.8140 - val_loss: 0.7944 - val_acc: 0.8275\n",
      "Epoch 680/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8620 - acc: 0.8068 - val_loss: 0.8018 - val_acc: 0.8248\n",
      "Epoch 681/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8738 - acc: 0.8137 - val_loss: 0.7990 - val_acc: 0.8302\n",
      "Epoch 682/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8619 - acc: 0.8152 - val_loss: 0.7936 - val_acc: 0.8275\n",
      "Epoch 683/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8713 - acc: 0.8167 - val_loss: 0.7927 - val_acc: 0.8302\n",
      "Epoch 684/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8574 - acc: 0.8203 - val_loss: 0.7892 - val_acc: 0.8248\n",
      "Epoch 685/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8605 - acc: 0.8167 - val_loss: 0.7798 - val_acc: 0.8275\n",
      "Epoch 686/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8578 - acc: 0.8143 - val_loss: 0.7856 - val_acc: 0.8275\n",
      "Epoch 687/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8576 - acc: 0.8167 - val_loss: 0.7948 - val_acc: 0.8275\n",
      "Epoch 688/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8641 - acc: 0.8146 - val_loss: 0.7869 - val_acc: 0.8329\n",
      "Epoch 689/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8627 - acc: 0.8173 - val_loss: 0.8034 - val_acc: 0.8194\n",
      "Epoch 690/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8782 - acc: 0.8053 - val_loss: 0.8090 - val_acc: 0.8275\n",
      "Epoch 691/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8416 - acc: 0.8173 - val_loss: 0.8013 - val_acc: 0.8302\n",
      "Epoch 692/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8581 - acc: 0.8119 - val_loss: 0.7994 - val_acc: 0.8329\n",
      "Epoch 693/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8364 - acc: 0.8197 - val_loss: 0.8088 - val_acc: 0.8302\n",
      "Epoch 694/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8531 - acc: 0.8134 - val_loss: 0.8076 - val_acc: 0.8248\n",
      "Epoch 695/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8543 - acc: 0.8137 - val_loss: 0.8084 - val_acc: 0.8275\n",
      "Epoch 696/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8559 - acc: 0.8152 - val_loss: 0.8024 - val_acc: 0.8302\n",
      "Epoch 697/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8734 - acc: 0.8161 - val_loss: 0.7986 - val_acc: 0.8302\n",
      "Epoch 698/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8587 - acc: 0.8173 - val_loss: 0.7899 - val_acc: 0.8356\n",
      "Epoch 699/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8565 - acc: 0.8116 - val_loss: 0.7952 - val_acc: 0.8248\n",
      "Epoch 700/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8624 - acc: 0.8080 - val_loss: 0.8077 - val_acc: 0.8248\n",
      "Epoch 701/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8501 - acc: 0.8098 - val_loss: 0.8073 - val_acc: 0.8302\n",
      "Epoch 702/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8605 - acc: 0.8137 - val_loss: 0.8082 - val_acc: 0.8221\n",
      "Epoch 703/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8444 - acc: 0.8182 - val_loss: 0.7998 - val_acc: 0.8302\n",
      "Epoch 704/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8613 - acc: 0.8131 - val_loss: 0.8070 - val_acc: 0.8275\n",
      "Epoch 705/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8612 - acc: 0.8152 - val_loss: 0.8057 - val_acc: 0.8248\n",
      "Epoch 706/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8533 - acc: 0.8146 - val_loss: 0.8007 - val_acc: 0.8221\n",
      "Epoch 707/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8631 - acc: 0.8122 - val_loss: 0.8004 - val_acc: 0.8275\n",
      "Epoch 708/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8527 - acc: 0.8125 - val_loss: 0.8034 - val_acc: 0.8275\n",
      "Epoch 709/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8424 - acc: 0.8185 - val_loss: 0.7917 - val_acc: 0.8302\n",
      "Epoch 710/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8520 - acc: 0.8146 - val_loss: 0.7880 - val_acc: 0.8356\n",
      "Epoch 711/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8568 - acc: 0.8158 - val_loss: 0.7921 - val_acc: 0.8329\n",
      "Epoch 712/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8612 - acc: 0.8155 - val_loss: 0.8008 - val_acc: 0.8194\n",
      "Epoch 713/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8555 - acc: 0.8107 - val_loss: 0.7936 - val_acc: 0.8302\n",
      "Epoch 714/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8702 - acc: 0.8101 - val_loss: 0.8011 - val_acc: 0.8194\n",
      "Epoch 715/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8514 - acc: 0.8155 - val_loss: 0.8062 - val_acc: 0.8140\n",
      "Epoch 716/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8636 - acc: 0.8155 - val_loss: 0.8037 - val_acc: 0.8194\n",
      "Epoch 717/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8518 - acc: 0.8170 - val_loss: 0.8044 - val_acc: 0.8248\n",
      "Epoch 718/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8573 - acc: 0.8116 - val_loss: 0.7953 - val_acc: 0.8248\n",
      "Epoch 719/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8460 - acc: 0.8155 - val_loss: 0.7960 - val_acc: 0.8302\n",
      "Epoch 720/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8673 - acc: 0.8152 - val_loss: 0.7940 - val_acc: 0.8275\n",
      "Epoch 721/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8621 - acc: 0.8158 - val_loss: 0.7992 - val_acc: 0.8248\n",
      "Epoch 722/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8472 - acc: 0.8179 - val_loss: 0.7965 - val_acc: 0.8275\n",
      "Epoch 723/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8560 - acc: 0.8119 - val_loss: 0.7916 - val_acc: 0.8329\n",
      "Epoch 724/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8663 - acc: 0.8149 - val_loss: 0.7968 - val_acc: 0.8329\n",
      "Epoch 725/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8657 - acc: 0.8152 - val_loss: 0.7998 - val_acc: 0.8275\n",
      "Epoch 726/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8669 - acc: 0.8125 - val_loss: 0.7930 - val_acc: 0.8221\n",
      "Epoch 727/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8595 - acc: 0.8146 - val_loss: 0.7909 - val_acc: 0.8275\n",
      "Epoch 728/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8662 - acc: 0.8083 - val_loss: 0.8038 - val_acc: 0.8248\n",
      "Epoch 729/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8521 - acc: 0.8149 - val_loss: 0.7970 - val_acc: 0.8248\n",
      "Epoch 730/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8610 - acc: 0.8170 - val_loss: 0.7916 - val_acc: 0.8248\n",
      "Epoch 731/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8567 - acc: 0.8152 - val_loss: 0.7851 - val_acc: 0.8248\n",
      "Epoch 732/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8545 - acc: 0.8164 - val_loss: 0.7824 - val_acc: 0.8275\n",
      "Epoch 733/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8526 - acc: 0.8119 - val_loss: 0.7910 - val_acc: 0.8221\n",
      "Epoch 734/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8501 - acc: 0.8179 - val_loss: 0.7895 - val_acc: 0.8221\n",
      "Epoch 735/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8665 - acc: 0.8137 - val_loss: 0.7877 - val_acc: 0.8248\n",
      "Epoch 736/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8551 - acc: 0.8116 - val_loss: 0.7911 - val_acc: 0.8275\n",
      "Epoch 737/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8530 - acc: 0.8185 - val_loss: 0.7967 - val_acc: 0.8248\n",
      "Epoch 738/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8613 - acc: 0.8131 - val_loss: 0.8055 - val_acc: 0.8275\n",
      "Epoch 739/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8580 - acc: 0.8119 - val_loss: 0.8035 - val_acc: 0.8248\n",
      "Epoch 740/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8553 - acc: 0.8131 - val_loss: 0.8040 - val_acc: 0.8221\n",
      "Epoch 741/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8777 - acc: 0.8125 - val_loss: 0.8013 - val_acc: 0.8275\n",
      "Epoch 742/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8407 - acc: 0.8131 - val_loss: 0.7994 - val_acc: 0.8167\n",
      "Epoch 743/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8593 - acc: 0.8134 - val_loss: 0.7998 - val_acc: 0.8221\n",
      "Epoch 744/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8503 - acc: 0.8122 - val_loss: 0.8000 - val_acc: 0.8194\n",
      "Epoch 745/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8519 - acc: 0.8107 - val_loss: 0.8008 - val_acc: 0.8221\n",
      "Epoch 746/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8557 - acc: 0.8116 - val_loss: 0.8133 - val_acc: 0.8167\n",
      "Epoch 747/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8588 - acc: 0.8062 - val_loss: 0.8040 - val_acc: 0.8275\n",
      "Epoch 748/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8585 - acc: 0.8152 - val_loss: 0.7935 - val_acc: 0.8221\n",
      "Epoch 749/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8493 - acc: 0.8128 - val_loss: 0.7937 - val_acc: 0.8275\n",
      "Epoch 750/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8473 - acc: 0.8155 - val_loss: 0.8032 - val_acc: 0.8248\n",
      "Epoch 751/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8534 - acc: 0.8167 - val_loss: 0.7996 - val_acc: 0.8302\n",
      "Epoch 752/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8548 - acc: 0.8137 - val_loss: 0.8001 - val_acc: 0.8302\n",
      "Epoch 753/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8504 - acc: 0.8140 - val_loss: 0.8010 - val_acc: 0.8221\n",
      "Epoch 754/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8446 - acc: 0.8185 - val_loss: 0.7940 - val_acc: 0.8302\n",
      "Epoch 755/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8435 - acc: 0.8176 - val_loss: 0.7940 - val_acc: 0.8221\n",
      "Epoch 756/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8400 - acc: 0.8179 - val_loss: 0.7935 - val_acc: 0.8221\n",
      "Epoch 757/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8466 - acc: 0.8251 - val_loss: 0.7909 - val_acc: 0.8248\n",
      "Epoch 758/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8533 - acc: 0.8107 - val_loss: 0.7890 - val_acc: 0.8221\n",
      "Epoch 759/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8511 - acc: 0.8137 - val_loss: 0.7849 - val_acc: 0.8275\n",
      "Epoch 760/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8468 - acc: 0.8185 - val_loss: 0.7821 - val_acc: 0.8302\n",
      "Epoch 761/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8473 - acc: 0.8164 - val_loss: 0.7860 - val_acc: 0.8329\n",
      "Epoch 762/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8550 - acc: 0.8185 - val_loss: 0.7972 - val_acc: 0.8221\n",
      "Epoch 763/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8507 - acc: 0.8149 - val_loss: 0.7996 - val_acc: 0.8167\n",
      "Epoch 764/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8446 - acc: 0.8188 - val_loss: 0.8024 - val_acc: 0.8194\n",
      "Epoch 765/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8600 - acc: 0.8167 - val_loss: 0.8051 - val_acc: 0.8194\n",
      "Epoch 766/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8655 - acc: 0.8095 - val_loss: 0.8106 - val_acc: 0.8194\n",
      "Epoch 767/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8611 - acc: 0.8134 - val_loss: 0.8042 - val_acc: 0.8302\n",
      "Epoch 768/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8520 - acc: 0.8215 - val_loss: 0.8021 - val_acc: 0.8275\n",
      "Epoch 769/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8483 - acc: 0.8134 - val_loss: 0.8008 - val_acc: 0.8275\n",
      "Epoch 770/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8357 - acc: 0.8182 - val_loss: 0.8040 - val_acc: 0.8221\n",
      "Epoch 771/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8608 - acc: 0.8128 - val_loss: 0.8047 - val_acc: 0.8221\n",
      "Epoch 772/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8736 - acc: 0.8143 - val_loss: 0.8086 - val_acc: 0.8221\n",
      "Epoch 773/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8514 - acc: 0.8152 - val_loss: 0.7929 - val_acc: 0.8248\n",
      "Epoch 774/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8468 - acc: 0.8182 - val_loss: 0.8092 - val_acc: 0.8167\n",
      "Epoch 775/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8636 - acc: 0.8164 - val_loss: 0.8106 - val_acc: 0.8140\n",
      "Epoch 776/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8711 - acc: 0.8128 - val_loss: 0.8090 - val_acc: 0.8194\n",
      "Epoch 777/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8510 - acc: 0.8077 - val_loss: 0.8004 - val_acc: 0.8248\n",
      "Epoch 778/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8485 - acc: 0.8092 - val_loss: 0.8030 - val_acc: 0.8221\n",
      "Epoch 779/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8435 - acc: 0.8155 - val_loss: 0.8020 - val_acc: 0.8221\n",
      "Epoch 780/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8582 - acc: 0.8125 - val_loss: 0.7873 - val_acc: 0.8275\n",
      "Epoch 781/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8588 - acc: 0.8110 - val_loss: 0.7845 - val_acc: 0.8248\n",
      "Epoch 782/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8563 - acc: 0.8152 - val_loss: 0.7892 - val_acc: 0.8194\n",
      "Epoch 783/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8424 - acc: 0.8131 - val_loss: 0.7948 - val_acc: 0.8221\n",
      "Epoch 784/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8612 - acc: 0.8176 - val_loss: 0.7991 - val_acc: 0.8221\n",
      "Epoch 785/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8452 - acc: 0.8122 - val_loss: 0.8058 - val_acc: 0.8140\n",
      "Epoch 786/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8577 - acc: 0.8167 - val_loss: 0.8196 - val_acc: 0.8113\n",
      "Epoch 787/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8596 - acc: 0.8098 - val_loss: 0.8124 - val_acc: 0.8113\n",
      "Epoch 788/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8500 - acc: 0.8158 - val_loss: 0.8058 - val_acc: 0.8221\n",
      "Epoch 789/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8465 - acc: 0.8188 - val_loss: 0.7972 - val_acc: 0.8221\n",
      "Epoch 790/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8399 - acc: 0.8218 - val_loss: 0.7941 - val_acc: 0.8302\n",
      "Epoch 791/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8552 - acc: 0.8161 - val_loss: 0.7974 - val_acc: 0.8275\n",
      "Epoch 792/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8516 - acc: 0.8167 - val_loss: 0.8106 - val_acc: 0.8194\n",
      "Epoch 793/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8581 - acc: 0.8158 - val_loss: 0.7995 - val_acc: 0.8167\n",
      "Epoch 794/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8522 - acc: 0.8167 - val_loss: 0.7966 - val_acc: 0.8248\n",
      "Epoch 795/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8541 - acc: 0.8188 - val_loss: 0.7892 - val_acc: 0.8275\n",
      "Epoch 796/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8459 - acc: 0.8128 - val_loss: 0.7942 - val_acc: 0.8194\n",
      "Epoch 797/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8435 - acc: 0.8182 - val_loss: 0.7947 - val_acc: 0.8275\n",
      "Epoch 798/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8641 - acc: 0.8158 - val_loss: 0.7900 - val_acc: 0.8248\n",
      "Epoch 799/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8497 - acc: 0.8176 - val_loss: 0.7945 - val_acc: 0.8194\n",
      "Epoch 800/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8519 - acc: 0.8200 - val_loss: 0.7947 - val_acc: 0.8194\n",
      "Epoch 801/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8409 - acc: 0.8107 - val_loss: 0.7937 - val_acc: 0.8248\n",
      "Epoch 802/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8393 - acc: 0.8158 - val_loss: 0.7934 - val_acc: 0.8248\n",
      "Epoch 803/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8343 - acc: 0.8137 - val_loss: 0.7886 - val_acc: 0.8275\n",
      "Epoch 804/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8393 - acc: 0.8188 - val_loss: 0.7975 - val_acc: 0.8302\n",
      "Epoch 805/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8391 - acc: 0.8194 - val_loss: 0.7902 - val_acc: 0.8329\n",
      "Epoch 806/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8334 - acc: 0.8215 - val_loss: 0.7871 - val_acc: 0.8383\n",
      "Epoch 807/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8547 - acc: 0.8179 - val_loss: 0.7896 - val_acc: 0.8275\n",
      "Epoch 808/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8357 - acc: 0.8200 - val_loss: 0.7965 - val_acc: 0.8248\n",
      "Epoch 809/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8622 - acc: 0.8095 - val_loss: 0.7930 - val_acc: 0.8221\n",
      "Epoch 810/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8402 - acc: 0.8137 - val_loss: 0.7975 - val_acc: 0.8194\n",
      "Epoch 811/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8527 - acc: 0.8161 - val_loss: 0.7936 - val_acc: 0.8248\n",
      "Epoch 812/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8621 - acc: 0.8167 - val_loss: 0.7889 - val_acc: 0.8302\n",
      "Epoch 813/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8537 - acc: 0.8158 - val_loss: 0.7938 - val_acc: 0.8221\n",
      "Epoch 814/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8485 - acc: 0.8125 - val_loss: 0.7995 - val_acc: 0.8194\n",
      "Epoch 815/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8430 - acc: 0.8107 - val_loss: 0.8045 - val_acc: 0.8194\n",
      "Epoch 816/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8401 - acc: 0.8155 - val_loss: 0.7965 - val_acc: 0.8248\n",
      "Epoch 817/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8585 - acc: 0.8146 - val_loss: 0.7946 - val_acc: 0.8302\n",
      "Epoch 818/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8400 - acc: 0.8194 - val_loss: 0.8032 - val_acc: 0.8275\n",
      "Epoch 819/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8359 - acc: 0.8146 - val_loss: 0.8020 - val_acc: 0.8194\n",
      "Epoch 820/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8464 - acc: 0.8167 - val_loss: 0.7940 - val_acc: 0.8302\n",
      "Epoch 821/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8437 - acc: 0.8161 - val_loss: 0.8013 - val_acc: 0.8248\n",
      "Epoch 822/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8481 - acc: 0.8158 - val_loss: 0.8024 - val_acc: 0.8248\n",
      "Epoch 823/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8615 - acc: 0.8125 - val_loss: 0.8160 - val_acc: 0.8194\n",
      "Epoch 824/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8445 - acc: 0.8149 - val_loss: 0.8133 - val_acc: 0.8194\n",
      "Epoch 825/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8420 - acc: 0.8122 - val_loss: 0.8047 - val_acc: 0.8221\n",
      "Epoch 826/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8604 - acc: 0.8143 - val_loss: 0.7995 - val_acc: 0.8275\n",
      "Epoch 827/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8547 - acc: 0.8122 - val_loss: 0.8072 - val_acc: 0.8167\n",
      "Epoch 828/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8422 - acc: 0.8164 - val_loss: 0.8095 - val_acc: 0.8140\n",
      "Epoch 829/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8388 - acc: 0.8173 - val_loss: 0.7941 - val_acc: 0.8221\n",
      "Epoch 830/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8483 - acc: 0.8125 - val_loss: 0.7878 - val_acc: 0.8302\n",
      "Epoch 831/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8569 - acc: 0.8137 - val_loss: 0.7871 - val_acc: 0.8221\n",
      "Epoch 832/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8468 - acc: 0.8191 - val_loss: 0.7816 - val_acc: 0.8275\n",
      "Epoch 833/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8407 - acc: 0.8188 - val_loss: 0.7947 - val_acc: 0.8248\n",
      "Epoch 834/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8447 - acc: 0.8137 - val_loss: 0.7958 - val_acc: 0.8248\n",
      "Epoch 835/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8337 - acc: 0.8191 - val_loss: 0.7986 - val_acc: 0.8167\n",
      "Epoch 836/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8477 - acc: 0.8140 - val_loss: 0.8023 - val_acc: 0.8194\n",
      "Epoch 837/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8598 - acc: 0.8143 - val_loss: 0.8013 - val_acc: 0.8194\n",
      "Epoch 838/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8493 - acc: 0.8119 - val_loss: 0.7989 - val_acc: 0.8248\n",
      "Epoch 839/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8343 - acc: 0.8188 - val_loss: 0.8001 - val_acc: 0.8275\n",
      "Epoch 840/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8464 - acc: 0.8137 - val_loss: 0.8094 - val_acc: 0.8221\n",
      "Epoch 841/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8645 - acc: 0.8122 - val_loss: 0.8171 - val_acc: 0.8167\n",
      "Epoch 842/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8469 - acc: 0.8137 - val_loss: 0.8052 - val_acc: 0.8275\n",
      "Epoch 843/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8500 - acc: 0.8101 - val_loss: 0.7883 - val_acc: 0.8329\n",
      "Epoch 844/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8441 - acc: 0.8140 - val_loss: 0.7858 - val_acc: 0.8383\n",
      "Epoch 845/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8361 - acc: 0.8203 - val_loss: 0.7844 - val_acc: 0.8437\n",
      "Epoch 846/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8393 - acc: 0.8164 - val_loss: 0.7903 - val_acc: 0.8248\n",
      "Epoch 847/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8632 - acc: 0.8149 - val_loss: 0.7952 - val_acc: 0.8248\n",
      "Epoch 848/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8532 - acc: 0.8173 - val_loss: 0.7957 - val_acc: 0.8329\n",
      "Epoch 849/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8637 - acc: 0.8080 - val_loss: 0.7993 - val_acc: 0.8221\n",
      "Epoch 850/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8692 - acc: 0.8173 - val_loss: 0.7922 - val_acc: 0.8221\n",
      "Epoch 851/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8352 - acc: 0.8224 - val_loss: 0.7925 - val_acc: 0.8275\n",
      "Epoch 852/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8440 - acc: 0.8164 - val_loss: 0.7916 - val_acc: 0.8302\n",
      "Epoch 853/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8331 - acc: 0.8260 - val_loss: 0.7885 - val_acc: 0.8275\n",
      "Epoch 854/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8514 - acc: 0.8137 - val_loss: 0.7802 - val_acc: 0.8275\n",
      "Epoch 855/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8471 - acc: 0.8173 - val_loss: 0.7823 - val_acc: 0.8221\n",
      "Epoch 856/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8289 - acc: 0.8149 - val_loss: 0.7823 - val_acc: 0.8248\n",
      "Epoch 857/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8557 - acc: 0.8095 - val_loss: 0.7883 - val_acc: 0.8248\n",
      "Epoch 858/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8347 - acc: 0.8176 - val_loss: 0.7947 - val_acc: 0.8275\n",
      "Epoch 859/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8476 - acc: 0.8173 - val_loss: 0.7879 - val_acc: 0.8302\n",
      "Epoch 860/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8395 - acc: 0.8104 - val_loss: 0.7930 - val_acc: 0.8275\n",
      "Epoch 861/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8324 - acc: 0.8143 - val_loss: 0.7879 - val_acc: 0.8275\n",
      "Epoch 862/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8372 - acc: 0.8143 - val_loss: 0.7908 - val_acc: 0.8275\n",
      "Epoch 863/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8340 - acc: 0.8185 - val_loss: 0.8000 - val_acc: 0.8275\n",
      "Epoch 864/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8444 - acc: 0.8152 - val_loss: 0.8015 - val_acc: 0.8248\n",
      "Epoch 865/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8263 - acc: 0.8143 - val_loss: 0.7936 - val_acc: 0.8302\n",
      "Epoch 866/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8474 - acc: 0.8065 - val_loss: 0.7923 - val_acc: 0.8275\n",
      "Epoch 867/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8541 - acc: 0.8137 - val_loss: 0.7874 - val_acc: 0.8302\n",
      "Epoch 868/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8352 - acc: 0.8209 - val_loss: 0.7858 - val_acc: 0.8248\n",
      "Epoch 869/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8477 - acc: 0.8116 - val_loss: 0.7906 - val_acc: 0.8194\n",
      "Epoch 870/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8569 - acc: 0.8188 - val_loss: 0.7956 - val_acc: 0.8221\n",
      "Epoch 871/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8445 - acc: 0.8095 - val_loss: 0.7917 - val_acc: 0.8248\n",
      "Epoch 872/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8514 - acc: 0.8152 - val_loss: 0.7864 - val_acc: 0.8329\n",
      "Epoch 873/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8409 - acc: 0.8155 - val_loss: 0.7926 - val_acc: 0.8275\n",
      "Epoch 874/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8391 - acc: 0.8119 - val_loss: 0.7900 - val_acc: 0.8275\n",
      "Epoch 875/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8446 - acc: 0.8188 - val_loss: 0.7889 - val_acc: 0.8302\n",
      "Epoch 876/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8509 - acc: 0.8158 - val_loss: 0.7920 - val_acc: 0.8302\n",
      "Epoch 877/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8353 - acc: 0.8077 - val_loss: 0.7982 - val_acc: 0.8221\n",
      "Epoch 878/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8417 - acc: 0.8173 - val_loss: 0.7885 - val_acc: 0.8248\n",
      "Epoch 879/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8486 - acc: 0.8116 - val_loss: 0.7867 - val_acc: 0.8275\n",
      "Epoch 880/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8577 - acc: 0.8116 - val_loss: 0.7850 - val_acc: 0.8329\n",
      "Epoch 881/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8396 - acc: 0.8191 - val_loss: 0.7886 - val_acc: 0.8302\n",
      "Epoch 882/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8332 - acc: 0.8212 - val_loss: 0.7970 - val_acc: 0.8248\n",
      "Epoch 883/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8444 - acc: 0.8125 - val_loss: 0.7960 - val_acc: 0.8275\n",
      "Epoch 884/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8530 - acc: 0.8182 - val_loss: 0.7953 - val_acc: 0.8248\n",
      "Epoch 885/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8473 - acc: 0.8128 - val_loss: 0.8004 - val_acc: 0.8167\n",
      "Epoch 886/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8380 - acc: 0.8152 - val_loss: 0.7946 - val_acc: 0.8248\n",
      "Epoch 887/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8354 - acc: 0.8194 - val_loss: 0.7837 - val_acc: 0.8329\n",
      "Epoch 888/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8581 - acc: 0.8206 - val_loss: 0.7994 - val_acc: 0.8248\n",
      "Epoch 889/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8554 - acc: 0.8131 - val_loss: 0.7958 - val_acc: 0.8275\n",
      "Epoch 890/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8402 - acc: 0.8125 - val_loss: 0.7912 - val_acc: 0.8248\n",
      "Epoch 891/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8454 - acc: 0.8137 - val_loss: 0.7872 - val_acc: 0.8302\n",
      "Epoch 892/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8445 - acc: 0.8167 - val_loss: 0.7934 - val_acc: 0.8302\n",
      "Epoch 893/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8550 - acc: 0.8128 - val_loss: 0.7909 - val_acc: 0.8329\n",
      "Epoch 894/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8402 - acc: 0.8134 - val_loss: 0.7833 - val_acc: 0.8383\n",
      "Epoch 895/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8141 - acc: 0.8269 - val_loss: 0.7889 - val_acc: 0.8356\n",
      "Epoch 896/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8170 - acc: 0.8164 - val_loss: 0.7896 - val_acc: 0.8329\n",
      "Epoch 897/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8443 - acc: 0.8152 - val_loss: 0.7924 - val_acc: 0.8302\n",
      "Epoch 898/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8528 - acc: 0.8107 - val_loss: 0.7945 - val_acc: 0.8248\n",
      "Epoch 899/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8385 - acc: 0.8188 - val_loss: 0.7906 - val_acc: 0.8248\n",
      "Epoch 900/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8615 - acc: 0.8041 - val_loss: 0.7957 - val_acc: 0.8221\n",
      "Epoch 901/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8414 - acc: 0.8149 - val_loss: 0.7972 - val_acc: 0.8167\n",
      "Epoch 902/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8422 - acc: 0.8125 - val_loss: 0.7958 - val_acc: 0.8167\n",
      "Epoch 903/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8384 - acc: 0.8164 - val_loss: 0.7913 - val_acc: 0.8194\n",
      "Epoch 904/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8392 - acc: 0.8134 - val_loss: 0.7904 - val_acc: 0.8275\n",
      "Epoch 905/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8332 - acc: 0.8110 - val_loss: 0.7830 - val_acc: 0.8275\n",
      "Epoch 906/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8274 - acc: 0.8104 - val_loss: 0.7902 - val_acc: 0.8221\n",
      "Epoch 907/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8447 - acc: 0.8119 - val_loss: 0.8043 - val_acc: 0.8194\n",
      "Epoch 908/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8451 - acc: 0.8119 - val_loss: 0.8021 - val_acc: 0.8167\n",
      "Epoch 909/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8419 - acc: 0.8152 - val_loss: 0.8009 - val_acc: 0.8194\n",
      "Epoch 910/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8303 - acc: 0.8155 - val_loss: 0.8038 - val_acc: 0.8275\n",
      "Epoch 911/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8302 - acc: 0.8182 - val_loss: 0.8025 - val_acc: 0.8275\n",
      "Epoch 912/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8430 - acc: 0.8185 - val_loss: 0.7931 - val_acc: 0.8221\n",
      "Epoch 913/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8329 - acc: 0.8188 - val_loss: 0.7964 - val_acc: 0.8356\n",
      "Epoch 914/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8447 - acc: 0.8170 - val_loss: 0.8085 - val_acc: 0.8329\n",
      "Epoch 915/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8609 - acc: 0.8137 - val_loss: 0.7978 - val_acc: 0.8248\n",
      "Epoch 916/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8564 - acc: 0.8107 - val_loss: 0.7946 - val_acc: 0.8248\n",
      "Epoch 917/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8566 - acc: 0.8101 - val_loss: 0.7858 - val_acc: 0.8302\n",
      "Epoch 918/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8467 - acc: 0.8140 - val_loss: 0.7997 - val_acc: 0.8275\n",
      "Epoch 919/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8314 - acc: 0.8122 - val_loss: 0.7917 - val_acc: 0.8275\n",
      "Epoch 920/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8491 - acc: 0.8140 - val_loss: 0.7892 - val_acc: 0.8302\n",
      "Epoch 921/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8550 - acc: 0.8140 - val_loss: 0.7900 - val_acc: 0.8302\n",
      "Epoch 922/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8380 - acc: 0.8107 - val_loss: 0.7972 - val_acc: 0.8248\n",
      "Epoch 923/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8436 - acc: 0.8134 - val_loss: 0.7986 - val_acc: 0.8302\n",
      "Epoch 924/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8422 - acc: 0.8158 - val_loss: 0.8012 - val_acc: 0.8275\n",
      "Epoch 925/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8359 - acc: 0.8146 - val_loss: 0.8072 - val_acc: 0.8275\n",
      "Epoch 926/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8376 - acc: 0.8164 - val_loss: 0.8040 - val_acc: 0.8221\n",
      "Epoch 927/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8402 - acc: 0.8170 - val_loss: 0.7953 - val_acc: 0.8221\n",
      "Epoch 928/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8487 - acc: 0.8131 - val_loss: 0.7975 - val_acc: 0.8194\n",
      "Epoch 929/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8449 - acc: 0.8209 - val_loss: 0.8015 - val_acc: 0.8221\n",
      "Epoch 930/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8347 - acc: 0.8227 - val_loss: 0.7985 - val_acc: 0.8248\n",
      "Epoch 931/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8548 - acc: 0.8131 - val_loss: 0.8031 - val_acc: 0.8248\n",
      "Epoch 932/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8404 - acc: 0.8113 - val_loss: 0.8066 - val_acc: 0.8167\n",
      "Epoch 933/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8358 - acc: 0.8155 - val_loss: 0.8044 - val_acc: 0.8194\n",
      "Epoch 934/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8220 - acc: 0.8167 - val_loss: 0.8054 - val_acc: 0.8221\n",
      "Epoch 935/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8429 - acc: 0.8155 - val_loss: 0.8086 - val_acc: 0.8194\n",
      "Epoch 936/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8281 - acc: 0.8197 - val_loss: 0.7945 - val_acc: 0.8275\n",
      "Epoch 937/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8365 - acc: 0.8134 - val_loss: 0.7895 - val_acc: 0.8248\n",
      "Epoch 938/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8485 - acc: 0.8071 - val_loss: 0.7845 - val_acc: 0.8329\n",
      "Epoch 939/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8447 - acc: 0.8116 - val_loss: 0.7887 - val_acc: 0.8275\n",
      "Epoch 940/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8435 - acc: 0.8158 - val_loss: 0.8015 - val_acc: 0.8194\n",
      "Epoch 941/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8394 - acc: 0.8098 - val_loss: 0.8020 - val_acc: 0.8221\n",
      "Epoch 942/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8328 - acc: 0.8176 - val_loss: 0.7957 - val_acc: 0.8248\n",
      "Epoch 943/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8342 - acc: 0.8173 - val_loss: 0.7940 - val_acc: 0.8275\n",
      "Epoch 944/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8209 - acc: 0.8128 - val_loss: 0.7951 - val_acc: 0.8248\n",
      "Epoch 945/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8367 - acc: 0.8152 - val_loss: 0.8034 - val_acc: 0.8275\n",
      "Epoch 946/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8423 - acc: 0.8149 - val_loss: 0.8042 - val_acc: 0.8221\n",
      "Epoch 947/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8415 - acc: 0.8176 - val_loss: 0.7960 - val_acc: 0.8221\n",
      "Epoch 948/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8429 - acc: 0.8152 - val_loss: 0.7856 - val_acc: 0.8302\n",
      "Epoch 949/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8261 - acc: 0.8176 - val_loss: 0.7848 - val_acc: 0.8302\n",
      "Epoch 950/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8335 - acc: 0.8167 - val_loss: 0.7877 - val_acc: 0.8302\n",
      "Epoch 951/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8280 - acc: 0.8101 - val_loss: 0.7977 - val_acc: 0.8140\n",
      "Epoch 952/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8370 - acc: 0.8140 - val_loss: 0.7936 - val_acc: 0.8194\n",
      "Epoch 953/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8356 - acc: 0.8161 - val_loss: 0.7924 - val_acc: 0.8194\n",
      "Epoch 954/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8153 - acc: 0.8191 - val_loss: 0.7932 - val_acc: 0.8167\n",
      "Epoch 955/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8250 - acc: 0.8239 - val_loss: 0.8011 - val_acc: 0.8140\n",
      "Epoch 956/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8497 - acc: 0.8119 - val_loss: 0.8062 - val_acc: 0.8140\n",
      "Epoch 957/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8371 - acc: 0.8092 - val_loss: 0.7949 - val_acc: 0.8140\n",
      "Epoch 958/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8473 - acc: 0.8131 - val_loss: 0.8018 - val_acc: 0.8194\n",
      "Epoch 959/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8465 - acc: 0.8164 - val_loss: 0.7947 - val_acc: 0.8248\n",
      "Epoch 960/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8384 - acc: 0.8194 - val_loss: 0.7935 - val_acc: 0.8221\n",
      "Epoch 961/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8167 - acc: 0.8179 - val_loss: 0.7876 - val_acc: 0.8275\n",
      "Epoch 962/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8499 - acc: 0.8149 - val_loss: 0.8038 - val_acc: 0.8248\n",
      "Epoch 963/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8139 - acc: 0.8224 - val_loss: 0.8126 - val_acc: 0.8194\n",
      "Epoch 964/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8308 - acc: 0.8179 - val_loss: 0.8080 - val_acc: 0.8221\n",
      "Epoch 965/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8429 - acc: 0.8158 - val_loss: 0.8056 - val_acc: 0.8275\n",
      "Epoch 966/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8414 - acc: 0.8143 - val_loss: 0.8055 - val_acc: 0.8221\n",
      "Epoch 967/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8382 - acc: 0.8203 - val_loss: 0.7992 - val_acc: 0.8194\n",
      "Epoch 968/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8240 - acc: 0.8185 - val_loss: 0.8040 - val_acc: 0.8194\n",
      "Epoch 969/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8386 - acc: 0.8134 - val_loss: 0.8094 - val_acc: 0.8140\n",
      "Epoch 970/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8285 - acc: 0.8164 - val_loss: 0.8093 - val_acc: 0.8167\n",
      "Epoch 971/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8380 - acc: 0.8122 - val_loss: 0.7994 - val_acc: 0.8275\n",
      "Epoch 972/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8272 - acc: 0.8197 - val_loss: 0.8019 - val_acc: 0.8248\n",
      "Epoch 973/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8511 - acc: 0.8092 - val_loss: 0.8169 - val_acc: 0.8194\n",
      "Epoch 974/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8193 - acc: 0.8167 - val_loss: 0.7995 - val_acc: 0.8302\n",
      "Epoch 975/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8438 - acc: 0.8134 - val_loss: 0.7972 - val_acc: 0.8329\n",
      "Epoch 976/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8543 - acc: 0.8203 - val_loss: 0.8114 - val_acc: 0.8140\n",
      "Epoch 977/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8189 - acc: 0.8200 - val_loss: 0.8021 - val_acc: 0.8221\n",
      "Epoch 978/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8311 - acc: 0.8101 - val_loss: 0.7974 - val_acc: 0.8194\n",
      "Epoch 979/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8447 - acc: 0.8116 - val_loss: 0.7886 - val_acc: 0.8194\n",
      "Epoch 980/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8405 - acc: 0.8095 - val_loss: 0.7936 - val_acc: 0.8194\n",
      "Epoch 981/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8250 - acc: 0.8140 - val_loss: 0.7998 - val_acc: 0.8167\n",
      "Epoch 982/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.8188 - acc: 0.8143 - val_loss: 0.7992 - val_acc: 0.8140\n",
      "Epoch 983/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8480 - acc: 0.8146 - val_loss: 0.7951 - val_acc: 0.8248\n",
      "Epoch 984/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8359 - acc: 0.8119 - val_loss: 0.7965 - val_acc: 0.8194\n",
      "Epoch 985/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8360 - acc: 0.8176 - val_loss: 0.7981 - val_acc: 0.8194\n",
      "Epoch 986/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8295 - acc: 0.8164 - val_loss: 0.7980 - val_acc: 0.8221\n",
      "Epoch 987/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8466 - acc: 0.8146 - val_loss: 0.8007 - val_acc: 0.8275\n",
      "Epoch 988/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8438 - acc: 0.8101 - val_loss: 0.7990 - val_acc: 0.8221\n",
      "Epoch 989/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8322 - acc: 0.8122 - val_loss: 0.8003 - val_acc: 0.8167\n",
      "Epoch 990/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8311 - acc: 0.8140 - val_loss: 0.8103 - val_acc: 0.8140\n",
      "Epoch 991/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8461 - acc: 0.8080 - val_loss: 0.8084 - val_acc: 0.8140\n",
      "Epoch 992/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8419 - acc: 0.8134 - val_loss: 0.7995 - val_acc: 0.8221\n",
      "Epoch 993/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8384 - acc: 0.8122 - val_loss: 0.7935 - val_acc: 0.8194\n",
      "Epoch 994/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8232 - acc: 0.8158 - val_loss: 0.7841 - val_acc: 0.8275\n",
      "Epoch 995/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8228 - acc: 0.8134 - val_loss: 0.7916 - val_acc: 0.8248\n",
      "Epoch 996/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8371 - acc: 0.8098 - val_loss: 0.7837 - val_acc: 0.8248\n",
      "Epoch 997/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8461 - acc: 0.8122 - val_loss: 0.7802 - val_acc: 0.8275\n",
      "Epoch 998/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8221 - acc: 0.8170 - val_loss: 0.7816 - val_acc: 0.8329\n",
      "Epoch 999/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8367 - acc: 0.8137 - val_loss: 0.7836 - val_acc: 0.8275\n",
      "Epoch 1000/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8414 - acc: 0.8149 - val_loss: 0.7903 - val_acc: 0.8302\n",
      "Epoch 1001/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8348 - acc: 0.8137 - val_loss: 0.7877 - val_acc: 0.8194\n",
      "Epoch 1002/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8281 - acc: 0.8119 - val_loss: 0.7813 - val_acc: 0.8302\n",
      "Epoch 1003/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8381 - acc: 0.8143 - val_loss: 0.7786 - val_acc: 0.8275\n",
      "Epoch 1004/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8316 - acc: 0.8110 - val_loss: 0.7747 - val_acc: 0.8329\n",
      "Epoch 1005/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8274 - acc: 0.8167 - val_loss: 0.7803 - val_acc: 0.8275\n",
      "Epoch 1006/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8306 - acc: 0.8161 - val_loss: 0.7923 - val_acc: 0.8221\n",
      "Epoch 1007/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8435 - acc: 0.8143 - val_loss: 0.7876 - val_acc: 0.8248\n",
      "Epoch 1008/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8366 - acc: 0.8131 - val_loss: 0.7993 - val_acc: 0.8248\n",
      "Epoch 1009/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8479 - acc: 0.8098 - val_loss: 0.8004 - val_acc: 0.8248\n",
      "Epoch 1010/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8228 - acc: 0.8170 - val_loss: 0.7989 - val_acc: 0.8194\n",
      "Epoch 1011/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8327 - acc: 0.8137 - val_loss: 0.7978 - val_acc: 0.8248\n",
      "Epoch 1012/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8437 - acc: 0.8164 - val_loss: 0.7914 - val_acc: 0.8194\n",
      "Epoch 1013/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8374 - acc: 0.8152 - val_loss: 0.7871 - val_acc: 0.8140\n",
      "Epoch 1014/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8125 - acc: 0.8152 - val_loss: 0.7862 - val_acc: 0.8275\n",
      "Epoch 1015/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8264 - acc: 0.8230 - val_loss: 0.7880 - val_acc: 0.8194\n",
      "Epoch 1016/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8357 - acc: 0.8137 - val_loss: 0.7837 - val_acc: 0.8275\n",
      "Epoch 1017/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8483 - acc: 0.8188 - val_loss: 0.7829 - val_acc: 0.8221\n",
      "Epoch 1018/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8247 - acc: 0.8203 - val_loss: 0.7903 - val_acc: 0.8221\n",
      "Epoch 1019/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8249 - acc: 0.8155 - val_loss: 0.7910 - val_acc: 0.8221\n",
      "Epoch 1020/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8378 - acc: 0.8185 - val_loss: 0.7920 - val_acc: 0.8221\n",
      "Epoch 1021/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8297 - acc: 0.8080 - val_loss: 0.7811 - val_acc: 0.8302\n",
      "Epoch 1022/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8324 - acc: 0.8212 - val_loss: 0.7780 - val_acc: 0.8383\n",
      "Epoch 1023/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8414 - acc: 0.8113 - val_loss: 0.7854 - val_acc: 0.8356\n",
      "Epoch 1024/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8399 - acc: 0.8143 - val_loss: 0.7841 - val_acc: 0.8194\n",
      "Epoch 1025/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8378 - acc: 0.8131 - val_loss: 0.7823 - val_acc: 0.8194\n",
      "Epoch 1026/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8278 - acc: 0.8152 - val_loss: 0.7904 - val_acc: 0.8302\n",
      "Epoch 1027/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8212 - acc: 0.8167 - val_loss: 0.7950 - val_acc: 0.8302\n",
      "Epoch 1028/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8273 - acc: 0.8182 - val_loss: 0.7912 - val_acc: 0.8302\n",
      "Epoch 1029/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8266 - acc: 0.8107 - val_loss: 0.7885 - val_acc: 0.8248\n",
      "Epoch 1030/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8075 - acc: 0.8185 - val_loss: 0.7797 - val_acc: 0.8329\n",
      "Epoch 1031/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8244 - acc: 0.8173 - val_loss: 0.7878 - val_acc: 0.8329\n",
      "Epoch 1032/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8334 - acc: 0.8128 - val_loss: 0.8007 - val_acc: 0.8221\n",
      "Epoch 1033/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8301 - acc: 0.8143 - val_loss: 0.7973 - val_acc: 0.8140\n",
      "Epoch 1034/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8434 - acc: 0.8092 - val_loss: 0.8062 - val_acc: 0.8167\n",
      "Epoch 1035/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8285 - acc: 0.8101 - val_loss: 0.8025 - val_acc: 0.8167\n",
      "Epoch 1036/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8304 - acc: 0.8179 - val_loss: 0.7986 - val_acc: 0.8221\n",
      "Epoch 1037/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8508 - acc: 0.8191 - val_loss: 0.7992 - val_acc: 0.8167\n",
      "Epoch 1038/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8299 - acc: 0.8173 - val_loss: 0.7974 - val_acc: 0.8194\n",
      "Epoch 1039/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8271 - acc: 0.8236 - val_loss: 0.7813 - val_acc: 0.8248\n",
      "Epoch 1040/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8326 - acc: 0.8167 - val_loss: 0.7875 - val_acc: 0.8221\n",
      "Epoch 1041/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8338 - acc: 0.8104 - val_loss: 0.8003 - val_acc: 0.8329\n",
      "Epoch 1042/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8188 - acc: 0.8164 - val_loss: 0.8105 - val_acc: 0.8221\n",
      "Epoch 1043/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8272 - acc: 0.8158 - val_loss: 0.8158 - val_acc: 0.8113\n",
      "Epoch 1044/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8343 - acc: 0.8155 - val_loss: 0.8018 - val_acc: 0.8248\n",
      "Epoch 1045/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8436 - acc: 0.8104 - val_loss: 0.7919 - val_acc: 0.8275\n",
      "Epoch 1046/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8288 - acc: 0.8167 - val_loss: 0.7918 - val_acc: 0.8248\n",
      "Epoch 1047/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8456 - acc: 0.8146 - val_loss: 0.8009 - val_acc: 0.8221\n",
      "Epoch 1048/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8304 - acc: 0.8194 - val_loss: 0.8050 - val_acc: 0.8113\n",
      "Epoch 1049/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8206 - acc: 0.8092 - val_loss: 0.8069 - val_acc: 0.8140\n",
      "Epoch 1050/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8479 - acc: 0.8131 - val_loss: 0.7969 - val_acc: 0.8248\n",
      "Epoch 1051/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8465 - acc: 0.8125 - val_loss: 0.8041 - val_acc: 0.8275\n",
      "Epoch 1052/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8511 - acc: 0.8197 - val_loss: 0.7968 - val_acc: 0.8275\n",
      "Epoch 1053/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8287 - acc: 0.8152 - val_loss: 0.8054 - val_acc: 0.8329\n",
      "Epoch 1054/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8337 - acc: 0.8128 - val_loss: 0.7953 - val_acc: 0.8275\n",
      "Epoch 1055/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8384 - acc: 0.8155 - val_loss: 0.8026 - val_acc: 0.8221\n",
      "Epoch 1056/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8399 - acc: 0.8083 - val_loss: 0.7988 - val_acc: 0.8221\n",
      "Epoch 1057/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8307 - acc: 0.8233 - val_loss: 0.8019 - val_acc: 0.8248\n",
      "Epoch 1058/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8244 - acc: 0.8182 - val_loss: 0.8029 - val_acc: 0.8302\n",
      "Epoch 1059/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8243 - acc: 0.8161 - val_loss: 0.8018 - val_acc: 0.8275\n",
      "Epoch 1060/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8247 - acc: 0.8179 - val_loss: 0.8106 - val_acc: 0.8194\n",
      "Epoch 1061/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8163 - acc: 0.8245 - val_loss: 0.8130 - val_acc: 0.8194\n",
      "Epoch 1062/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8267 - acc: 0.8200 - val_loss: 0.8132 - val_acc: 0.8221\n",
      "Epoch 1063/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8570 - acc: 0.8104 - val_loss: 0.8101 - val_acc: 0.8194\n",
      "Epoch 1064/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8156 - acc: 0.8185 - val_loss: 0.8092 - val_acc: 0.8221\n",
      "Epoch 1065/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8548 - acc: 0.8188 - val_loss: 0.8024 - val_acc: 0.8275\n",
      "Epoch 1066/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8468 - acc: 0.8128 - val_loss: 0.7910 - val_acc: 0.8275\n",
      "Epoch 1067/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8301 - acc: 0.8095 - val_loss: 0.7955 - val_acc: 0.8248\n",
      "Epoch 1068/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8282 - acc: 0.8173 - val_loss: 0.7936 - val_acc: 0.8275\n",
      "Epoch 1069/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8250 - acc: 0.8176 - val_loss: 0.7962 - val_acc: 0.8248\n",
      "Epoch 1070/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8233 - acc: 0.8104 - val_loss: 0.8010 - val_acc: 0.8194\n",
      "Epoch 1071/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8317 - acc: 0.8158 - val_loss: 0.8016 - val_acc: 0.8167\n",
      "Epoch 1072/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8127 - acc: 0.8134 - val_loss: 0.7924 - val_acc: 0.8329\n",
      "Epoch 1073/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8213 - acc: 0.8173 - val_loss: 0.7874 - val_acc: 0.8302\n",
      "Epoch 1074/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8366 - acc: 0.8116 - val_loss: 0.7923 - val_acc: 0.8302\n",
      "Epoch 1075/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8168 - acc: 0.8146 - val_loss: 0.7818 - val_acc: 0.8302\n",
      "Epoch 1076/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8252 - acc: 0.8200 - val_loss: 0.7856 - val_acc: 0.8275\n",
      "Epoch 1077/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8253 - acc: 0.8143 - val_loss: 0.7846 - val_acc: 0.8275\n",
      "Epoch 1078/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8235 - acc: 0.8185 - val_loss: 0.7790 - val_acc: 0.8302\n",
      "Epoch 1079/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8615 - acc: 0.8119 - val_loss: 0.7709 - val_acc: 0.8329\n",
      "Epoch 1080/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8078 - acc: 0.8161 - val_loss: 0.7730 - val_acc: 0.8275\n",
      "Epoch 1081/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8140 - acc: 0.8179 - val_loss: 0.7841 - val_acc: 0.8248\n",
      "Epoch 1082/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8305 - acc: 0.8116 - val_loss: 0.7903 - val_acc: 0.8302\n",
      "Epoch 1083/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8267 - acc: 0.8170 - val_loss: 0.8061 - val_acc: 0.8221\n",
      "Epoch 1084/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8291 - acc: 0.8173 - val_loss: 0.7878 - val_acc: 0.8248\n",
      "Epoch 1085/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8273 - acc: 0.8122 - val_loss: 0.7892 - val_acc: 0.8275\n",
      "Epoch 1086/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8302 - acc: 0.8089 - val_loss: 0.7928 - val_acc: 0.8221\n",
      "Epoch 1087/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8466 - acc: 0.8134 - val_loss: 0.7823 - val_acc: 0.8248\n",
      "Epoch 1088/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8296 - acc: 0.8188 - val_loss: 0.7791 - val_acc: 0.8275\n",
      "Epoch 1089/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8170 - acc: 0.8098 - val_loss: 0.7897 - val_acc: 0.8221\n",
      "Epoch 1090/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8431 - acc: 0.8131 - val_loss: 0.8041 - val_acc: 0.8194\n",
      "Epoch 1091/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8435 - acc: 0.8143 - val_loss: 0.8052 - val_acc: 0.8167\n",
      "Epoch 1092/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8217 - acc: 0.8152 - val_loss: 0.8020 - val_acc: 0.8167\n",
      "Epoch 1093/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8218 - acc: 0.8182 - val_loss: 0.7861 - val_acc: 0.8275\n",
      "Epoch 1094/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8299 - acc: 0.8125 - val_loss: 0.7880 - val_acc: 0.8248\n",
      "Epoch 1095/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8353 - acc: 0.8179 - val_loss: 0.7926 - val_acc: 0.8248\n",
      "Epoch 1096/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8323 - acc: 0.8149 - val_loss: 0.7899 - val_acc: 0.8275\n",
      "Epoch 1097/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8248 - acc: 0.8176 - val_loss: 0.7935 - val_acc: 0.8194\n",
      "Epoch 1098/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8416 - acc: 0.8140 - val_loss: 0.7921 - val_acc: 0.8221\n",
      "Epoch 1099/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8213 - acc: 0.8161 - val_loss: 0.7868 - val_acc: 0.8167\n",
      "Epoch 1100/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8373 - acc: 0.8068 - val_loss: 0.7858 - val_acc: 0.8248\n",
      "Epoch 1101/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8380 - acc: 0.8083 - val_loss: 0.7901 - val_acc: 0.8221\n",
      "Epoch 1102/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8280 - acc: 0.8125 - val_loss: 0.7879 - val_acc: 0.8221\n",
      "Epoch 1103/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8464 - acc: 0.8140 - val_loss: 0.7841 - val_acc: 0.8329\n",
      "Epoch 1104/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8302 - acc: 0.8134 - val_loss: 0.7886 - val_acc: 0.8275\n",
      "Epoch 1105/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8220 - acc: 0.8146 - val_loss: 0.7925 - val_acc: 0.8248\n",
      "Epoch 1106/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8521 - acc: 0.8095 - val_loss: 0.7888 - val_acc: 0.8248\n",
      "Epoch 1107/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8179 - acc: 0.8152 - val_loss: 0.7884 - val_acc: 0.8302\n",
      "Epoch 1108/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8336 - acc: 0.8122 - val_loss: 0.7781 - val_acc: 0.8302\n",
      "Epoch 1109/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8154 - acc: 0.8137 - val_loss: 0.7837 - val_acc: 0.8248\n",
      "Epoch 1110/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8219 - acc: 0.8248 - val_loss: 0.7914 - val_acc: 0.8248\n",
      "Epoch 1111/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8398 - acc: 0.8113 - val_loss: 0.7914 - val_acc: 0.8302\n",
      "Epoch 1112/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8243 - acc: 0.8146 - val_loss: 0.7902 - val_acc: 0.8275\n",
      "Epoch 1113/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8334 - acc: 0.8134 - val_loss: 0.7963 - val_acc: 0.8194\n",
      "Epoch 1114/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8264 - acc: 0.8140 - val_loss: 0.7932 - val_acc: 0.8248\n",
      "Epoch 1115/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8225 - acc: 0.8170 - val_loss: 0.7938 - val_acc: 0.8275\n",
      "Epoch 1116/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8081 - acc: 0.8200 - val_loss: 0.7930 - val_acc: 0.8275\n",
      "Epoch 1117/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8111 - acc: 0.8185 - val_loss: 0.7828 - val_acc: 0.8356\n",
      "Epoch 1118/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8325 - acc: 0.8140 - val_loss: 0.7835 - val_acc: 0.8248\n",
      "Epoch 1119/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8278 - acc: 0.8158 - val_loss: 0.7901 - val_acc: 0.8275\n",
      "Epoch 1120/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8272 - acc: 0.8149 - val_loss: 0.7975 - val_acc: 0.8194\n",
      "Epoch 1121/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8299 - acc: 0.8137 - val_loss: 0.7909 - val_acc: 0.8248\n",
      "Epoch 1122/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8249 - acc: 0.8182 - val_loss: 0.7884 - val_acc: 0.8221\n",
      "Epoch 1123/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8128 - acc: 0.8188 - val_loss: 0.7834 - val_acc: 0.8356\n",
      "Epoch 1124/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8261 - acc: 0.8182 - val_loss: 0.7882 - val_acc: 0.8248\n",
      "Epoch 1125/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8210 - acc: 0.8197 - val_loss: 0.7928 - val_acc: 0.8221\n",
      "Epoch 1126/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8297 - acc: 0.8119 - val_loss: 0.7914 - val_acc: 0.8194\n",
      "Epoch 1127/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8264 - acc: 0.8143 - val_loss: 0.7941 - val_acc: 0.8248\n",
      "Epoch 1128/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8221 - val_loss: 0.7937 - val_acc: 0.8248\n",
      "Epoch 1129/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8327 - acc: 0.8161 - val_loss: 0.7865 - val_acc: 0.8302\n",
      "Epoch 1130/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8362 - acc: 0.8176 - val_loss: 0.7885 - val_acc: 0.8275\n",
      "Epoch 1131/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8334 - acc: 0.8203 - val_loss: 0.7812 - val_acc: 0.8302\n",
      "Epoch 1132/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8170 - acc: 0.8158 - val_loss: 0.7766 - val_acc: 0.8329\n",
      "Epoch 1133/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8171 - acc: 0.8185 - val_loss: 0.7817 - val_acc: 0.8356\n",
      "Epoch 1134/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8395 - acc: 0.8173 - val_loss: 0.7864 - val_acc: 0.8275\n",
      "Epoch 1135/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8073 - acc: 0.8146 - val_loss: 0.7840 - val_acc: 0.8275\n",
      "Epoch 1136/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8365 - acc: 0.8152 - val_loss: 0.7792 - val_acc: 0.8194\n",
      "Epoch 1137/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8241 - acc: 0.8116 - val_loss: 0.7849 - val_acc: 0.8167\n",
      "Epoch 1138/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8421 - acc: 0.8098 - val_loss: 0.7742 - val_acc: 0.8221\n",
      "Epoch 1139/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8394 - acc: 0.8182 - val_loss: 0.7699 - val_acc: 0.8248\n",
      "Epoch 1140/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8236 - acc: 0.8179 - val_loss: 0.7784 - val_acc: 0.8194\n",
      "Epoch 1141/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8254 - acc: 0.8149 - val_loss: 0.7853 - val_acc: 0.8194\n",
      "Epoch 1142/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8232 - acc: 0.8128 - val_loss: 0.7880 - val_acc: 0.8167\n",
      "Epoch 1143/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8408 - acc: 0.8167 - val_loss: 0.7913 - val_acc: 0.8194\n",
      "Epoch 1144/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8276 - acc: 0.8149 - val_loss: 0.7794 - val_acc: 0.8194\n",
      "Epoch 1145/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8174 - acc: 0.8125 - val_loss: 0.7804 - val_acc: 0.8167\n",
      "Epoch 1146/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8226 - acc: 0.8143 - val_loss: 0.7795 - val_acc: 0.8194\n",
      "Epoch 1147/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8102 - acc: 0.8101 - val_loss: 0.7742 - val_acc: 0.8248\n",
      "Epoch 1148/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8295 - acc: 0.8197 - val_loss: 0.7776 - val_acc: 0.8194\n",
      "Epoch 1149/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8300 - acc: 0.8110 - val_loss: 0.7863 - val_acc: 0.8194\n",
      "Epoch 1150/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8313 - acc: 0.8119 - val_loss: 0.7796 - val_acc: 0.8194\n",
      "Epoch 1151/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8385 - acc: 0.8134 - val_loss: 0.7750 - val_acc: 0.8275\n",
      "Epoch 1152/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8372 - acc: 0.8146 - val_loss: 0.7796 - val_acc: 0.8248\n",
      "Epoch 1153/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8190 - acc: 0.8161 - val_loss: 0.7882 - val_acc: 0.8221\n",
      "Epoch 1154/5000\n",
      "3339/3339 [==============================] - 0s 10us/step - loss: 0.8310 - acc: 0.8107 - val_loss: 0.7894 - val_acc: 0.8248\n",
      "Epoch 1155/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8161 - acc: 0.8191 - val_loss: 0.7925 - val_acc: 0.8221\n",
      "Epoch 1156/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8066 - acc: 0.8188 - val_loss: 0.7885 - val_acc: 0.8356\n",
      "Epoch 1157/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8279 - acc: 0.8158 - val_loss: 0.7942 - val_acc: 0.8275\n",
      "Epoch 1158/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8310 - acc: 0.8161 - val_loss: 0.7866 - val_acc: 0.8248\n",
      "Epoch 1159/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8146 - acc: 0.8185 - val_loss: 0.7806 - val_acc: 0.8329\n",
      "Epoch 1160/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8284 - acc: 0.8203 - val_loss: 0.7796 - val_acc: 0.8356\n",
      "Epoch 1161/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8150 - acc: 0.8116 - val_loss: 0.7788 - val_acc: 0.8275\n",
      "Epoch 1162/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8366 - acc: 0.8104 - val_loss: 0.7882 - val_acc: 0.8302\n",
      "Epoch 1163/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8309 - acc: 0.8116 - val_loss: 0.7876 - val_acc: 0.8275\n",
      "Epoch 1164/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8084 - acc: 0.8200 - val_loss: 0.7886 - val_acc: 0.8275\n",
      "Epoch 1165/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8157 - acc: 0.8152 - val_loss: 0.7865 - val_acc: 0.8248\n",
      "Epoch 1166/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8449 - acc: 0.8143 - val_loss: 0.7907 - val_acc: 0.8329\n",
      "Epoch 1167/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8378 - acc: 0.8119 - val_loss: 0.7893 - val_acc: 0.8275\n",
      "Epoch 1168/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8275 - acc: 0.8146 - val_loss: 0.7860 - val_acc: 0.8221\n",
      "Epoch 1169/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8282 - acc: 0.8158 - val_loss: 0.7789 - val_acc: 0.8221\n",
      "Epoch 1170/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8350 - acc: 0.8131 - val_loss: 0.7854 - val_acc: 0.8194\n",
      "Epoch 1171/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8174 - acc: 0.8110 - val_loss: 0.7882 - val_acc: 0.8167\n",
      "Epoch 1172/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8199 - acc: 0.8149 - val_loss: 0.7867 - val_acc: 0.8194\n",
      "Epoch 1173/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8403 - acc: 0.8095 - val_loss: 0.7913 - val_acc: 0.8248\n",
      "Epoch 1174/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8306 - acc: 0.8116 - val_loss: 0.7822 - val_acc: 0.8302\n",
      "Epoch 1175/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8463 - acc: 0.8095 - val_loss: 0.7791 - val_acc: 0.8275\n",
      "Epoch 1176/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8505 - acc: 0.8080 - val_loss: 0.7766 - val_acc: 0.8275\n",
      "Epoch 1177/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8176 - acc: 0.8179 - val_loss: 0.7703 - val_acc: 0.8356\n",
      "Epoch 1178/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8390 - acc: 0.8173 - val_loss: 0.7745 - val_acc: 0.8275\n",
      "Epoch 1179/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8249 - acc: 0.8164 - val_loss: 0.7753 - val_acc: 0.8248\n",
      "Epoch 1180/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8194 - acc: 0.8158 - val_loss: 0.7793 - val_acc: 0.8275\n",
      "Epoch 1181/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8200 - acc: 0.8104 - val_loss: 0.7779 - val_acc: 0.8221\n",
      "Epoch 1182/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8149 - acc: 0.8218 - val_loss: 0.7840 - val_acc: 0.8194\n",
      "Epoch 1183/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8236 - acc: 0.8134 - val_loss: 0.7798 - val_acc: 0.8221\n",
      "Epoch 1184/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8137 - acc: 0.8146 - val_loss: 0.7728 - val_acc: 0.8356\n",
      "Epoch 1185/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8292 - acc: 0.8182 - val_loss: 0.7792 - val_acc: 0.8329\n",
      "Epoch 1186/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8430 - acc: 0.8155 - val_loss: 0.7802 - val_acc: 0.8221\n",
      "Epoch 1187/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8245 - acc: 0.8131 - val_loss: 0.7835 - val_acc: 0.8194\n",
      "Epoch 1188/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8280 - acc: 0.8164 - val_loss: 0.7824 - val_acc: 0.8248\n",
      "Epoch 1189/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8196 - acc: 0.8179 - val_loss: 0.7876 - val_acc: 0.8248\n",
      "Epoch 1190/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8283 - acc: 0.8077 - val_loss: 0.7897 - val_acc: 0.8221\n",
      "Epoch 1191/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8234 - acc: 0.8137 - val_loss: 0.7837 - val_acc: 0.8302\n",
      "Epoch 1192/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8116 - acc: 0.8164 - val_loss: 0.7872 - val_acc: 0.8302\n",
      "Epoch 1193/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8289 - acc: 0.8167 - val_loss: 0.7865 - val_acc: 0.8275\n",
      "Epoch 1194/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8508 - acc: 0.8173 - val_loss: 0.7878 - val_acc: 0.8248\n",
      "Epoch 1195/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8251 - acc: 0.8128 - val_loss: 0.7849 - val_acc: 0.8275\n",
      "Epoch 1196/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8242 - acc: 0.8248 - val_loss: 0.7912 - val_acc: 0.8275\n",
      "Epoch 1197/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8268 - acc: 0.8176 - val_loss: 0.8030 - val_acc: 0.8275\n",
      "Epoch 1198/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8347 - acc: 0.8134 - val_loss: 0.7923 - val_acc: 0.8221\n",
      "Epoch 1199/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8329 - acc: 0.8140 - val_loss: 0.7790 - val_acc: 0.8248\n",
      "Epoch 1200/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8445 - acc: 0.8119 - val_loss: 0.7792 - val_acc: 0.8275\n",
      "Epoch 1201/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8183 - acc: 0.8119 - val_loss: 0.7850 - val_acc: 0.8275\n",
      "Epoch 1202/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8252 - acc: 0.8062 - val_loss: 0.7841 - val_acc: 0.8329\n",
      "Epoch 1203/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8374 - acc: 0.8104 - val_loss: 0.7834 - val_acc: 0.8302\n",
      "Epoch 1204/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8353 - acc: 0.8158 - val_loss: 0.7892 - val_acc: 0.8302\n",
      "Epoch 1205/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8367 - acc: 0.8158 - val_loss: 0.7770 - val_acc: 0.8248\n",
      "Epoch 1206/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8143 - acc: 0.8125 - val_loss: 0.7735 - val_acc: 0.8275\n",
      "Epoch 1207/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8259 - acc: 0.8143 - val_loss: 0.7738 - val_acc: 0.8329\n",
      "Epoch 1208/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8344 - acc: 0.8170 - val_loss: 0.7853 - val_acc: 0.8221\n",
      "Epoch 1209/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8309 - acc: 0.8179 - val_loss: 0.7759 - val_acc: 0.8248\n",
      "Epoch 1210/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8225 - acc: 0.8116 - val_loss: 0.7739 - val_acc: 0.8302\n",
      "Epoch 1211/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8107 - acc: 0.8131 - val_loss: 0.7689 - val_acc: 0.8221\n",
      "Epoch 1212/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8201 - acc: 0.8143 - val_loss: 0.7870 - val_acc: 0.8194\n",
      "Epoch 1213/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8313 - acc: 0.8113 - val_loss: 0.7866 - val_acc: 0.8248\n",
      "Epoch 1214/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8330 - acc: 0.8059 - val_loss: 0.7877 - val_acc: 0.8221\n",
      "Epoch 1215/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8229 - acc: 0.8140 - val_loss: 0.7835 - val_acc: 0.8194\n",
      "Epoch 1216/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8136 - acc: 0.8203 - val_loss: 0.7713 - val_acc: 0.8275\n",
      "Epoch 1217/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8415 - acc: 0.8179 - val_loss: 0.7888 - val_acc: 0.8194\n",
      "Epoch 1218/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.8299 - acc: 0.8131 - val_loss: 0.7880 - val_acc: 0.8275\n",
      "Epoch 1219/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8273 - acc: 0.8137 - val_loss: 0.7916 - val_acc: 0.8275\n",
      "Epoch 1220/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8356 - acc: 0.8110 - val_loss: 0.7920 - val_acc: 0.8302\n",
      "Epoch 1221/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8319 - acc: 0.8128 - val_loss: 0.7922 - val_acc: 0.8275\n",
      "Epoch 1222/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8277 - acc: 0.8149 - val_loss: 0.7952 - val_acc: 0.8248\n",
      "Epoch 1223/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8253 - acc: 0.8119 - val_loss: 0.7968 - val_acc: 0.8302\n",
      "Epoch 1224/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8016 - acc: 0.8164 - val_loss: 0.7926 - val_acc: 0.8221\n",
      "Epoch 1225/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8101 - acc: 0.8203 - val_loss: 0.7928 - val_acc: 0.8275\n",
      "Epoch 1226/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8023 - acc: 0.8227 - val_loss: 0.7941 - val_acc: 0.8275\n",
      "Epoch 1227/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8312 - acc: 0.8152 - val_loss: 0.7948 - val_acc: 0.8194\n",
      "Epoch 1228/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8283 - acc: 0.8095 - val_loss: 0.7950 - val_acc: 0.8167\n",
      "Epoch 1229/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8330 - acc: 0.8143 - val_loss: 0.7973 - val_acc: 0.8248\n",
      "Epoch 1230/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8310 - acc: 0.8116 - val_loss: 0.7938 - val_acc: 0.8275\n",
      "Epoch 1231/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8177 - acc: 0.8197 - val_loss: 0.7944 - val_acc: 0.8221\n",
      "Epoch 1232/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8183 - acc: 0.8152 - val_loss: 0.7893 - val_acc: 0.8275\n",
      "Epoch 1233/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8162 - acc: 0.8146 - val_loss: 0.7906 - val_acc: 0.8221\n",
      "Epoch 1234/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8217 - acc: 0.8164 - val_loss: 0.7938 - val_acc: 0.8221\n",
      "Epoch 1235/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8249 - acc: 0.8128 - val_loss: 0.7946 - val_acc: 0.8221\n",
      "Epoch 1236/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8107 - acc: 0.8137 - val_loss: 0.7927 - val_acc: 0.8221\n",
      "Epoch 1237/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8095 - acc: 0.8200 - val_loss: 0.7830 - val_acc: 0.8302\n",
      "Epoch 1238/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8261 - acc: 0.8188 - val_loss: 0.7806 - val_acc: 0.8356\n",
      "Epoch 1239/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8332 - acc: 0.8116 - val_loss: 0.7793 - val_acc: 0.8329\n",
      "Epoch 1240/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8198 - acc: 0.8176 - val_loss: 0.7834 - val_acc: 0.8248\n",
      "Epoch 1241/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7986 - acc: 0.8200 - val_loss: 0.7865 - val_acc: 0.8221\n",
      "Epoch 1242/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8163 - acc: 0.8167 - val_loss: 0.7814 - val_acc: 0.8275\n",
      "Epoch 1243/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8317 - acc: 0.8119 - val_loss: 0.7865 - val_acc: 0.8221\n",
      "Epoch 1244/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8025 - acc: 0.8188 - val_loss: 0.7849 - val_acc: 0.8221\n",
      "Epoch 1245/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8137 - acc: 0.8128 - val_loss: 0.7869 - val_acc: 0.8221\n",
      "Epoch 1246/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8260 - acc: 0.8149 - val_loss: 0.7844 - val_acc: 0.8302\n",
      "Epoch 1247/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8317 - acc: 0.8182 - val_loss: 0.7827 - val_acc: 0.8329\n",
      "Epoch 1248/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8135 - acc: 0.8146 - val_loss: 0.7801 - val_acc: 0.8275\n",
      "Epoch 1249/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8263 - acc: 0.8107 - val_loss: 0.7775 - val_acc: 0.8302\n",
      "Epoch 1250/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8298 - acc: 0.8137 - val_loss: 0.7796 - val_acc: 0.8356\n",
      "Epoch 1251/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8229 - acc: 0.8161 - val_loss: 0.7818 - val_acc: 0.8275\n",
      "Epoch 1252/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8221 - acc: 0.8152 - val_loss: 0.7874 - val_acc: 0.8302\n",
      "Epoch 1253/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8212 - acc: 0.8122 - val_loss: 0.7903 - val_acc: 0.8302\n",
      "Epoch 1254/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8213 - acc: 0.8146 - val_loss: 0.7827 - val_acc: 0.8329\n",
      "Epoch 1255/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8167 - acc: 0.8152 - val_loss: 0.7726 - val_acc: 0.8329\n",
      "Epoch 1256/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8237 - acc: 0.8149 - val_loss: 0.7720 - val_acc: 0.8383\n",
      "Epoch 1257/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8082 - acc: 0.8215 - val_loss: 0.7706 - val_acc: 0.8275\n",
      "Epoch 1258/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8154 - acc: 0.8131 - val_loss: 0.7814 - val_acc: 0.8194\n",
      "Epoch 1259/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8290 - acc: 0.8140 - val_loss: 0.7926 - val_acc: 0.8140\n",
      "Epoch 1260/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8192 - acc: 0.8167 - val_loss: 0.7790 - val_acc: 0.8275\n",
      "Epoch 1261/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8252 - acc: 0.8206 - val_loss: 0.7699 - val_acc: 0.8302\n",
      "Epoch 1262/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8215 - acc: 0.8125 - val_loss: 0.7712 - val_acc: 0.8329\n",
      "Epoch 1263/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8074 - acc: 0.8161 - val_loss: 0.7748 - val_acc: 0.8275\n",
      "Epoch 1264/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8363 - acc: 0.8077 - val_loss: 0.7746 - val_acc: 0.8302\n",
      "Epoch 1265/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8212 - acc: 0.8119 - val_loss: 0.7654 - val_acc: 0.8329\n",
      "Epoch 1266/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8108 - acc: 0.8143 - val_loss: 0.7597 - val_acc: 0.8302\n",
      "Epoch 1267/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8307 - acc: 0.8131 - val_loss: 0.7668 - val_acc: 0.8275\n",
      "Epoch 1268/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8145 - acc: 0.8158 - val_loss: 0.7739 - val_acc: 0.8302\n",
      "Epoch 1269/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8191 - acc: 0.8152 - val_loss: 0.7777 - val_acc: 0.8302\n",
      "Epoch 1270/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8306 - acc: 0.8158 - val_loss: 0.7814 - val_acc: 0.8275\n",
      "Epoch 1271/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8318 - acc: 0.8143 - val_loss: 0.7759 - val_acc: 0.8302\n",
      "Epoch 1272/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8323 - acc: 0.8140 - val_loss: 0.7748 - val_acc: 0.8329\n",
      "Epoch 1273/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8351 - acc: 0.8134 - val_loss: 0.7792 - val_acc: 0.8329\n",
      "Epoch 1274/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8102 - acc: 0.8119 - val_loss: 0.7867 - val_acc: 0.8356\n",
      "Epoch 1275/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8171 - acc: 0.8152 - val_loss: 0.7842 - val_acc: 0.8302\n",
      "Epoch 1276/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8090 - acc: 0.8215 - val_loss: 0.7919 - val_acc: 0.8275\n",
      "Epoch 1277/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8158 - acc: 0.8137 - val_loss: 0.7886 - val_acc: 0.8221\n",
      "Epoch 1278/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8246 - acc: 0.8176 - val_loss: 0.7896 - val_acc: 0.8248\n",
      "Epoch 1279/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8223 - acc: 0.8158 - val_loss: 0.7835 - val_acc: 0.8248\n",
      "Epoch 1280/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8237 - acc: 0.8173 - val_loss: 0.7951 - val_acc: 0.8248\n",
      "Epoch 1281/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8183 - acc: 0.8179 - val_loss: 0.7976 - val_acc: 0.8194\n",
      "Epoch 1282/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8184 - acc: 0.8155 - val_loss: 0.7892 - val_acc: 0.8194\n",
      "Epoch 1283/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8093 - acc: 0.8239 - val_loss: 0.7884 - val_acc: 0.8248\n",
      "Epoch 1284/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8343 - acc: 0.8104 - val_loss: 0.7882 - val_acc: 0.8302\n",
      "Epoch 1285/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8380 - acc: 0.8173 - val_loss: 0.7853 - val_acc: 0.8275\n",
      "Epoch 1286/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8160 - acc: 0.8086 - val_loss: 0.7803 - val_acc: 0.8275\n",
      "Epoch 1287/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8057 - acc: 0.8146 - val_loss: 0.7868 - val_acc: 0.8248\n",
      "Epoch 1288/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8383 - acc: 0.8086 - val_loss: 0.7923 - val_acc: 0.8194\n",
      "Epoch 1289/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8245 - acc: 0.8149 - val_loss: 0.7809 - val_acc: 0.8248\n",
      "Epoch 1290/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8345 - acc: 0.8188 - val_loss: 0.7743 - val_acc: 0.8275\n",
      "Epoch 1291/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8348 - acc: 0.8188 - val_loss: 0.7738 - val_acc: 0.8302\n",
      "Epoch 1292/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8097 - acc: 0.8146 - val_loss: 0.7807 - val_acc: 0.8248\n",
      "Epoch 1293/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8248 - acc: 0.8191 - val_loss: 0.7811 - val_acc: 0.8275\n",
      "Epoch 1294/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8194 - acc: 0.8149 - val_loss: 0.7782 - val_acc: 0.8113\n",
      "Epoch 1295/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8194 - acc: 0.8092 - val_loss: 0.7759 - val_acc: 0.8167\n",
      "Epoch 1296/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8228 - acc: 0.8215 - val_loss: 0.7630 - val_acc: 0.8248\n",
      "Epoch 1297/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8281 - acc: 0.8140 - val_loss: 0.7619 - val_acc: 0.8248\n",
      "Epoch 1298/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8128 - acc: 0.8125 - val_loss: 0.7649 - val_acc: 0.8302\n",
      "Epoch 1299/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8225 - acc: 0.8104 - val_loss: 0.7775 - val_acc: 0.8194\n",
      "Epoch 1300/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8147 - acc: 0.8119 - val_loss: 0.7826 - val_acc: 0.8194\n",
      "Epoch 1301/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8183 - acc: 0.8161 - val_loss: 0.7853 - val_acc: 0.8248\n",
      "Epoch 1302/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8180 - acc: 0.8128 - val_loss: 0.7857 - val_acc: 0.8221\n",
      "Epoch 1303/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8248 - acc: 0.8173 - val_loss: 0.7886 - val_acc: 0.8248\n",
      "Epoch 1304/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8298 - acc: 0.8143 - val_loss: 0.7837 - val_acc: 0.8167\n",
      "Epoch 1305/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7974 - acc: 0.8185 - val_loss: 0.7720 - val_acc: 0.8221\n",
      "Epoch 1306/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8214 - acc: 0.8197 - val_loss: 0.7685 - val_acc: 0.8275\n",
      "Epoch 1307/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8195 - acc: 0.8215 - val_loss: 0.7656 - val_acc: 0.8275\n",
      "Epoch 1308/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8210 - acc: 0.8161 - val_loss: 0.7692 - val_acc: 0.8275\n",
      "Epoch 1309/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8190 - acc: 0.8161 - val_loss: 0.7667 - val_acc: 0.8302\n",
      "Epoch 1310/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8171 - acc: 0.8155 - val_loss: 0.7822 - val_acc: 0.8221\n",
      "Epoch 1311/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8132 - acc: 0.8194 - val_loss: 0.7843 - val_acc: 0.8329\n",
      "Epoch 1312/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8040 - acc: 0.8158 - val_loss: 0.7919 - val_acc: 0.8275\n",
      "Epoch 1313/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8329 - acc: 0.8101 - val_loss: 0.7837 - val_acc: 0.8302\n",
      "Epoch 1314/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8238 - acc: 0.8083 - val_loss: 0.7758 - val_acc: 0.8275\n",
      "Epoch 1315/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8210 - acc: 0.8083 - val_loss: 0.7745 - val_acc: 0.8383\n",
      "Epoch 1316/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8302 - acc: 0.8101 - val_loss: 0.7749 - val_acc: 0.8248\n",
      "Epoch 1317/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8254 - acc: 0.8173 - val_loss: 0.7736 - val_acc: 0.8248\n",
      "Epoch 1318/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8215 - acc: 0.8098 - val_loss: 0.7743 - val_acc: 0.8221\n",
      "Epoch 1319/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8241 - acc: 0.8203 - val_loss: 0.7746 - val_acc: 0.8221\n",
      "Epoch 1320/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8123 - acc: 0.8125 - val_loss: 0.7712 - val_acc: 0.8275\n",
      "Epoch 1321/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8105 - acc: 0.8149 - val_loss: 0.7728 - val_acc: 0.8275\n",
      "Epoch 1322/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8141 - acc: 0.8206 - val_loss: 0.7773 - val_acc: 0.8302\n",
      "Epoch 1323/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8140 - acc: 0.8188 - val_loss: 0.7774 - val_acc: 0.8221\n",
      "Epoch 1324/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8075 - acc: 0.8098 - val_loss: 0.7728 - val_acc: 0.8302\n",
      "Epoch 1325/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8001 - acc: 0.8149 - val_loss: 0.7697 - val_acc: 0.8302\n",
      "Epoch 1326/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8160 - acc: 0.8179 - val_loss: 0.7703 - val_acc: 0.8248\n",
      "Epoch 1327/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8083 - acc: 0.8188 - val_loss: 0.7725 - val_acc: 0.8275\n",
      "Epoch 1328/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8176 - acc: 0.8179 - val_loss: 0.7789 - val_acc: 0.8167\n",
      "Epoch 1329/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8135 - acc: 0.8224 - val_loss: 0.7865 - val_acc: 0.8194\n",
      "Epoch 1330/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8330 - acc: 0.8089 - val_loss: 0.7837 - val_acc: 0.8302\n",
      "Epoch 1331/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8119 - acc: 0.8152 - val_loss: 0.7788 - val_acc: 0.8356\n",
      "Epoch 1332/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8378 - acc: 0.8077 - val_loss: 0.7803 - val_acc: 0.8248\n",
      "Epoch 1333/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8267 - acc: 0.8089 - val_loss: 0.7795 - val_acc: 0.8221\n",
      "Epoch 1334/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8175 - acc: 0.8146 - val_loss: 0.7840 - val_acc: 0.8194\n",
      "Epoch 1335/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8196 - acc: 0.8110 - val_loss: 0.7857 - val_acc: 0.8221\n",
      "Epoch 1336/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8131 - acc: 0.8128 - val_loss: 0.7788 - val_acc: 0.8194\n",
      "Epoch 1337/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8157 - acc: 0.8143 - val_loss: 0.7803 - val_acc: 0.8248\n",
      "Epoch 1338/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8225 - acc: 0.8191 - val_loss: 0.7814 - val_acc: 0.8329\n",
      "Epoch 1339/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8305 - acc: 0.8131 - val_loss: 0.7845 - val_acc: 0.8302\n",
      "Epoch 1340/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8358 - acc: 0.8110 - val_loss: 0.7838 - val_acc: 0.8302\n",
      "Epoch 1341/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8373 - acc: 0.8110 - val_loss: 0.7908 - val_acc: 0.8329\n",
      "Epoch 1342/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8158 - acc: 0.8161 - val_loss: 0.7876 - val_acc: 0.8302\n",
      "Epoch 1343/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8145 - acc: 0.8110 - val_loss: 0.7904 - val_acc: 0.8248\n",
      "Epoch 1344/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8253 - acc: 0.8149 - val_loss: 0.7840 - val_acc: 0.8302\n",
      "Epoch 1345/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8118 - acc: 0.8104 - val_loss: 0.7869 - val_acc: 0.8275\n",
      "Epoch 1346/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8257 - acc: 0.8185 - val_loss: 0.7914 - val_acc: 0.8275\n",
      "Epoch 1347/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8268 - acc: 0.8155 - val_loss: 0.7879 - val_acc: 0.8302\n",
      "Epoch 1348/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8306 - acc: 0.8125 - val_loss: 0.7955 - val_acc: 0.8221\n",
      "Epoch 1349/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8233 - acc: 0.8119 - val_loss: 0.7940 - val_acc: 0.8248\n",
      "Epoch 1350/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8099 - acc: 0.8179 - val_loss: 0.7866 - val_acc: 0.8221\n",
      "Epoch 1351/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8175 - acc: 0.8155 - val_loss: 0.7898 - val_acc: 0.8221\n",
      "Epoch 1352/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8087 - acc: 0.8185 - val_loss: 0.7900 - val_acc: 0.8221\n",
      "Epoch 1353/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8229 - acc: 0.8107 - val_loss: 0.7880 - val_acc: 0.8275\n",
      "Epoch 1354/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8222 - acc: 0.8140 - val_loss: 0.7906 - val_acc: 0.8167\n",
      "Epoch 1355/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8121 - acc: 0.8131 - val_loss: 0.7957 - val_acc: 0.8167\n",
      "Epoch 1356/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8297 - acc: 0.8041 - val_loss: 0.8013 - val_acc: 0.8167\n",
      "Epoch 1357/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8348 - acc: 0.8098 - val_loss: 0.7986 - val_acc: 0.8221\n",
      "Epoch 1358/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8217 - acc: 0.8167 - val_loss: 0.7899 - val_acc: 0.8248\n",
      "Epoch 1359/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8174 - acc: 0.8146 - val_loss: 0.8036 - val_acc: 0.8167\n",
      "Epoch 1360/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8301 - acc: 0.8143 - val_loss: 0.7972 - val_acc: 0.8221\n",
      "Epoch 1361/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8150 - acc: 0.8083 - val_loss: 0.7840 - val_acc: 0.8248\n",
      "Epoch 1362/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8199 - acc: 0.8071 - val_loss: 0.7809 - val_acc: 0.8275\n",
      "Epoch 1363/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8274 - acc: 0.8182 - val_loss: 0.7857 - val_acc: 0.8329\n",
      "Epoch 1364/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8240 - acc: 0.8230 - val_loss: 0.7859 - val_acc: 0.8248\n",
      "Epoch 1365/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8339 - acc: 0.8113 - val_loss: 0.7882 - val_acc: 0.8221\n",
      "Epoch 1366/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8185 - acc: 0.8155 - val_loss: 0.7823 - val_acc: 0.8248\n",
      "Epoch 1367/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8194 - acc: 0.8218 - val_loss: 0.7730 - val_acc: 0.8221\n",
      "Epoch 1368/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8144 - acc: 0.8167 - val_loss: 0.7775 - val_acc: 0.8221\n",
      "Epoch 1369/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8346 - acc: 0.8137 - val_loss: 0.7775 - val_acc: 0.8221\n",
      "Epoch 1370/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8219 - acc: 0.8125 - val_loss: 0.7761 - val_acc: 0.8275\n",
      "Epoch 1371/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8071 - acc: 0.8137 - val_loss: 0.7872 - val_acc: 0.8275\n",
      "Epoch 1372/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7967 - acc: 0.8188 - val_loss: 0.7896 - val_acc: 0.8302\n",
      "Epoch 1373/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8057 - acc: 0.8161 - val_loss: 0.7885 - val_acc: 0.8275\n",
      "Epoch 1374/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8232 - acc: 0.8161 - val_loss: 0.7895 - val_acc: 0.8194\n",
      "Epoch 1375/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8156 - acc: 0.8194 - val_loss: 0.7894 - val_acc: 0.8194\n",
      "Epoch 1376/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8158 - acc: 0.8152 - val_loss: 0.7896 - val_acc: 0.8275\n",
      "Epoch 1377/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8188 - acc: 0.8164 - val_loss: 0.7913 - val_acc: 0.8302\n",
      "Epoch 1378/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8060 - acc: 0.8164 - val_loss: 0.7958 - val_acc: 0.8302\n",
      "Epoch 1379/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8165 - acc: 0.8155 - val_loss: 0.7959 - val_acc: 0.8302\n",
      "Epoch 1380/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8116 - acc: 0.8143 - val_loss: 0.7927 - val_acc: 0.8248\n",
      "Epoch 1381/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8047 - acc: 0.8155 - val_loss: 0.7905 - val_acc: 0.8302\n",
      "Epoch 1382/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8178 - acc: 0.8167 - val_loss: 0.8053 - val_acc: 0.8194\n",
      "Epoch 1383/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8114 - acc: 0.8122 - val_loss: 0.8070 - val_acc: 0.8275\n",
      "Epoch 1384/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8163 - acc: 0.8194 - val_loss: 0.7958 - val_acc: 0.8248\n",
      "Epoch 1385/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8199 - acc: 0.8155 - val_loss: 0.7920 - val_acc: 0.8275\n",
      "Epoch 1386/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8201 - acc: 0.8134 - val_loss: 0.7914 - val_acc: 0.8221\n",
      "Epoch 1387/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8256 - acc: 0.8101 - val_loss: 0.8018 - val_acc: 0.8194\n",
      "Epoch 1388/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8213 - acc: 0.8131 - val_loss: 0.7962 - val_acc: 0.8194\n",
      "Epoch 1389/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8094 - acc: 0.8179 - val_loss: 0.7914 - val_acc: 0.8194\n",
      "Epoch 1390/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.8184 - acc: 0.8170 - val_loss: 0.7890 - val_acc: 0.8275\n",
      "Epoch 1391/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8219 - acc: 0.8209 - val_loss: 0.7860 - val_acc: 0.8248\n",
      "Epoch 1392/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8235 - acc: 0.8188 - val_loss: 0.7889 - val_acc: 0.8194\n",
      "Epoch 1393/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8187 - acc: 0.8140 - val_loss: 0.7852 - val_acc: 0.8221\n",
      "Epoch 1394/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8073 - acc: 0.8131 - val_loss: 0.7852 - val_acc: 0.8194\n",
      "Epoch 1395/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8030 - acc: 0.8134 - val_loss: 0.7850 - val_acc: 0.8221\n",
      "Epoch 1396/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8145 - acc: 0.8152 - val_loss: 0.7819 - val_acc: 0.8167\n",
      "Epoch 1397/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8293 - acc: 0.8122 - val_loss: 0.7759 - val_acc: 0.8221\n",
      "Epoch 1398/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8352 - acc: 0.8095 - val_loss: 0.7787 - val_acc: 0.8248\n",
      "Epoch 1399/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8175 - acc: 0.8194 - val_loss: 0.7921 - val_acc: 0.8194\n",
      "Epoch 1400/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8348 - acc: 0.8119 - val_loss: 0.7957 - val_acc: 0.8167\n",
      "Epoch 1401/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8181 - acc: 0.8146 - val_loss: 0.7929 - val_acc: 0.8194\n",
      "Epoch 1402/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8002 - acc: 0.8230 - val_loss: 0.7866 - val_acc: 0.8248\n",
      "Epoch 1403/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8238 - acc: 0.8152 - val_loss: 0.7836 - val_acc: 0.8248\n",
      "Epoch 1404/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8204 - acc: 0.8173 - val_loss: 0.7846 - val_acc: 0.8194\n",
      "Epoch 1405/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8148 - acc: 0.8125 - val_loss: 0.7779 - val_acc: 0.8221\n",
      "Epoch 1406/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7973 - acc: 0.8173 - val_loss: 0.7825 - val_acc: 0.8194\n",
      "Epoch 1407/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8193 - acc: 0.8206 - val_loss: 0.7847 - val_acc: 0.8140\n",
      "Epoch 1408/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8313 - acc: 0.8107 - val_loss: 0.7932 - val_acc: 0.8167\n",
      "Epoch 1409/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8158 - acc: 0.8179 - val_loss: 0.7864 - val_acc: 0.8221\n",
      "Epoch 1410/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8245 - acc: 0.8149 - val_loss: 0.7889 - val_acc: 0.8302\n",
      "Epoch 1411/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8207 - acc: 0.8152 - val_loss: 0.7887 - val_acc: 0.8221\n",
      "Epoch 1412/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8259 - acc: 0.8104 - val_loss: 0.7864 - val_acc: 0.8221\n",
      "Epoch 1413/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8303 - acc: 0.8149 - val_loss: 0.7879 - val_acc: 0.8194\n",
      "Epoch 1414/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8331 - acc: 0.8116 - val_loss: 0.7855 - val_acc: 0.8221\n",
      "Epoch 1415/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8176 - acc: 0.8125 - val_loss: 0.7799 - val_acc: 0.8248\n",
      "Epoch 1416/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8078 - acc: 0.8167 - val_loss: 0.7791 - val_acc: 0.8302\n",
      "Epoch 1417/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8115 - acc: 0.8170 - val_loss: 0.7778 - val_acc: 0.8302\n",
      "Epoch 1418/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8144 - acc: 0.8152 - val_loss: 0.7770 - val_acc: 0.8275\n",
      "Epoch 1419/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8085 - acc: 0.8155 - val_loss: 0.7852 - val_acc: 0.8140\n",
      "Epoch 1420/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8209 - acc: 0.8179 - val_loss: 0.7826 - val_acc: 0.8221\n",
      "Epoch 1421/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8101 - acc: 0.8137 - val_loss: 0.7792 - val_acc: 0.8302\n",
      "Epoch 1422/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8168 - acc: 0.8173 - val_loss: 0.7823 - val_acc: 0.8248\n",
      "Epoch 1423/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8141 - acc: 0.8143 - val_loss: 0.7872 - val_acc: 0.8275\n",
      "Epoch 1424/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8257 - acc: 0.8140 - val_loss: 0.7823 - val_acc: 0.8221\n",
      "Epoch 1425/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8171 - acc: 0.8140 - val_loss: 0.7810 - val_acc: 0.8248\n",
      "Epoch 1426/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8204 - acc: 0.8179 - val_loss: 0.7761 - val_acc: 0.8275\n",
      "Epoch 1427/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8120 - acc: 0.8173 - val_loss: 0.7802 - val_acc: 0.8275\n",
      "Epoch 1428/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8313 - acc: 0.8074 - val_loss: 0.7848 - val_acc: 0.8248\n",
      "Epoch 1429/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8121 - acc: 0.8173 - val_loss: 0.7872 - val_acc: 0.8248\n",
      "Epoch 1430/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8254 - acc: 0.8113 - val_loss: 0.7874 - val_acc: 0.8167\n",
      "Epoch 1431/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7981 - acc: 0.8113 - val_loss: 0.7864 - val_acc: 0.8221\n",
      "Epoch 1432/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8189 - acc: 0.8143 - val_loss: 0.7932 - val_acc: 0.8221\n",
      "Epoch 1433/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8339 - acc: 0.8092 - val_loss: 0.7905 - val_acc: 0.8194\n",
      "Epoch 1434/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8197 - acc: 0.8107 - val_loss: 0.7989 - val_acc: 0.8221\n",
      "Epoch 1435/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8279 - acc: 0.8185 - val_loss: 0.7908 - val_acc: 0.8140\n",
      "Epoch 1436/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8104 - acc: 0.8140 - val_loss: 0.7924 - val_acc: 0.8221\n",
      "Epoch 1437/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8109 - acc: 0.8140 - val_loss: 0.7899 - val_acc: 0.8167\n",
      "Epoch 1438/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7926 - acc: 0.8185 - val_loss: 0.7920 - val_acc: 0.8248\n",
      "Epoch 1439/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8137 - acc: 0.8152 - val_loss: 0.7877 - val_acc: 0.8302\n",
      "Epoch 1440/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8132 - acc: 0.8188 - val_loss: 0.7817 - val_acc: 0.8248\n",
      "Epoch 1441/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8111 - acc: 0.8155 - val_loss: 0.7896 - val_acc: 0.8248\n",
      "Epoch 1442/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8351 - acc: 0.8149 - val_loss: 0.7892 - val_acc: 0.8248\n",
      "Epoch 1443/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8248 - acc: 0.8194 - val_loss: 0.7885 - val_acc: 0.8275\n",
      "Epoch 1444/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8284 - acc: 0.8155 - val_loss: 0.7932 - val_acc: 0.8221\n",
      "Epoch 1445/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8301 - acc: 0.8104 - val_loss: 0.7907 - val_acc: 0.8221\n",
      "Epoch 1446/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8268 - acc: 0.8116 - val_loss: 0.7904 - val_acc: 0.8167\n",
      "Epoch 1447/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8163 - acc: 0.8128 - val_loss: 0.7904 - val_acc: 0.8194\n",
      "Epoch 1448/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8132 - acc: 0.8134 - val_loss: 0.7822 - val_acc: 0.8248\n",
      "Epoch 1449/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8162 - acc: 0.8143 - val_loss: 0.7859 - val_acc: 0.8221\n",
      "Epoch 1450/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8220 - acc: 0.8107 - val_loss: 0.7854 - val_acc: 0.8248\n",
      "Epoch 1451/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8329 - acc: 0.8086 - val_loss: 0.7764 - val_acc: 0.8356\n",
      "Epoch 1452/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8141 - acc: 0.8176 - val_loss: 0.7772 - val_acc: 0.8275\n",
      "Epoch 1453/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8359 - acc: 0.8056 - val_loss: 0.7780 - val_acc: 0.8275\n",
      "Epoch 1454/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8316 - acc: 0.8095 - val_loss: 0.7802 - val_acc: 0.8329\n",
      "Epoch 1455/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8224 - acc: 0.8116 - val_loss: 0.7786 - val_acc: 0.8248\n",
      "Epoch 1456/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8222 - acc: 0.8110 - val_loss: 0.7791 - val_acc: 0.8221\n",
      "Epoch 1457/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8037 - acc: 0.8107 - val_loss: 0.7798 - val_acc: 0.8248\n",
      "Epoch 1458/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8085 - acc: 0.8203 - val_loss: 0.7848 - val_acc: 0.8275\n",
      "Epoch 1459/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8157 - acc: 0.8149 - val_loss: 0.7959 - val_acc: 0.8221\n",
      "Epoch 1460/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8194 - acc: 0.8164 - val_loss: 0.7898 - val_acc: 0.8194\n",
      "Epoch 1461/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8205 - acc: 0.8113 - val_loss: 0.7813 - val_acc: 0.8221\n",
      "Epoch 1462/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8080 - acc: 0.8191 - val_loss: 0.7754 - val_acc: 0.8302\n",
      "Epoch 1463/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8146 - val_loss: 0.7748 - val_acc: 0.8248\n",
      "Epoch 1464/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7927 - acc: 0.8173 - val_loss: 0.7758 - val_acc: 0.8356\n",
      "Epoch 1465/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8140 - acc: 0.8134 - val_loss: 0.7834 - val_acc: 0.8302\n",
      "Epoch 1466/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8098 - acc: 0.8179 - val_loss: 0.7799 - val_acc: 0.8329\n",
      "Epoch 1467/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8172 - acc: 0.8167 - val_loss: 0.7824 - val_acc: 0.8248\n",
      "Epoch 1468/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8084 - acc: 0.8182 - val_loss: 0.7917 - val_acc: 0.8167\n",
      "Epoch 1469/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8145 - acc: 0.8209 - val_loss: 0.7855 - val_acc: 0.8194\n",
      "Epoch 1470/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8168 - acc: 0.8212 - val_loss: 0.7816 - val_acc: 0.8221\n",
      "Epoch 1471/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8038 - acc: 0.8128 - val_loss: 0.7766 - val_acc: 0.8329\n",
      "Epoch 1472/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8196 - acc: 0.8107 - val_loss: 0.7766 - val_acc: 0.8329\n",
      "Epoch 1473/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8116 - val_loss: 0.7719 - val_acc: 0.8383\n",
      "Epoch 1474/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8193 - acc: 0.8164 - val_loss: 0.7689 - val_acc: 0.8329\n",
      "Epoch 1475/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8013 - acc: 0.8197 - val_loss: 0.7740 - val_acc: 0.8275\n",
      "Epoch 1476/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8128 - acc: 0.8155 - val_loss: 0.7737 - val_acc: 0.8221\n",
      "Epoch 1477/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8280 - acc: 0.8158 - val_loss: 0.7698 - val_acc: 0.8329\n",
      "Epoch 1478/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8153 - acc: 0.8188 - val_loss: 0.7724 - val_acc: 0.8383\n",
      "Epoch 1479/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8199 - acc: 0.8152 - val_loss: 0.7718 - val_acc: 0.8356\n",
      "Epoch 1480/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8124 - acc: 0.8167 - val_loss: 0.7688 - val_acc: 0.8302\n",
      "Epoch 1481/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8156 - acc: 0.8128 - val_loss: 0.7720 - val_acc: 0.8275\n",
      "Epoch 1482/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7965 - acc: 0.8173 - val_loss: 0.7763 - val_acc: 0.8248\n",
      "Epoch 1483/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8260 - acc: 0.8098 - val_loss: 0.7759 - val_acc: 0.8221\n",
      "Epoch 1484/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8130 - acc: 0.8125 - val_loss: 0.7742 - val_acc: 0.8221\n",
      "Epoch 1485/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7945 - acc: 0.8161 - val_loss: 0.7709 - val_acc: 0.8275\n",
      "Epoch 1486/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8147 - acc: 0.8161 - val_loss: 0.7759 - val_acc: 0.8302\n",
      "Epoch 1487/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8188 - acc: 0.8182 - val_loss: 0.7785 - val_acc: 0.8302\n",
      "Epoch 1488/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8148 - acc: 0.8179 - val_loss: 0.7768 - val_acc: 0.8302\n",
      "Epoch 1489/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8242 - acc: 0.8110 - val_loss: 0.7783 - val_acc: 0.8275\n",
      "Epoch 1490/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8067 - acc: 0.8125 - val_loss: 0.7801 - val_acc: 0.8275\n",
      "Epoch 1491/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8270 - acc: 0.8116 - val_loss: 0.7813 - val_acc: 0.8140\n",
      "Epoch 1492/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8301 - acc: 0.8146 - val_loss: 0.7806 - val_acc: 0.8221\n",
      "Epoch 1493/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8250 - acc: 0.8134 - val_loss: 0.7763 - val_acc: 0.8248\n",
      "Epoch 1494/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8245 - acc: 0.8107 - val_loss: 0.7772 - val_acc: 0.8248\n",
      "Epoch 1495/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8307 - acc: 0.8155 - val_loss: 0.7814 - val_acc: 0.8248\n",
      "Epoch 1496/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8124 - acc: 0.8116 - val_loss: 0.7817 - val_acc: 0.8248\n",
      "Epoch 1497/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8038 - acc: 0.8236 - val_loss: 0.7790 - val_acc: 0.8194\n",
      "Epoch 1498/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8195 - acc: 0.8161 - val_loss: 0.7743 - val_acc: 0.8275\n",
      "Epoch 1499/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8041 - acc: 0.8128 - val_loss: 0.7708 - val_acc: 0.8329\n",
      "Epoch 1500/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8355 - acc: 0.8167 - val_loss: 0.7759 - val_acc: 0.8248\n",
      "Epoch 1501/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8094 - acc: 0.8137 - val_loss: 0.7758 - val_acc: 0.8248\n",
      "Epoch 1502/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8135 - acc: 0.8134 - val_loss: 0.7715 - val_acc: 0.8221\n",
      "Epoch 1503/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8122 - acc: 0.8125 - val_loss: 0.7696 - val_acc: 0.8221\n",
      "Epoch 1504/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8244 - acc: 0.8098 - val_loss: 0.7672 - val_acc: 0.8275\n",
      "Epoch 1505/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8249 - acc: 0.8056 - val_loss: 0.7679 - val_acc: 0.8275\n",
      "Epoch 1506/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8194 - acc: 0.8176 - val_loss: 0.7764 - val_acc: 0.8329\n",
      "Epoch 1507/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8027 - acc: 0.8170 - val_loss: 0.7804 - val_acc: 0.8248\n",
      "Epoch 1508/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8274 - acc: 0.8116 - val_loss: 0.7816 - val_acc: 0.8248\n",
      "Epoch 1509/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8086 - acc: 0.8134 - val_loss: 0.7944 - val_acc: 0.8248\n",
      "Epoch 1510/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8061 - acc: 0.8191 - val_loss: 0.8008 - val_acc: 0.8221\n",
      "Epoch 1511/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8316 - acc: 0.8155 - val_loss: 0.7914 - val_acc: 0.8167\n",
      "Epoch 1512/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8147 - acc: 0.8188 - val_loss: 0.7835 - val_acc: 0.8194\n",
      "Epoch 1513/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8175 - acc: 0.8167 - val_loss: 0.7720 - val_acc: 0.8221\n",
      "Epoch 1514/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8142 - acc: 0.8149 - val_loss: 0.7740 - val_acc: 0.8221\n",
      "Epoch 1515/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8205 - acc: 0.8113 - val_loss: 0.7761 - val_acc: 0.8194\n",
      "Epoch 1516/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8109 - acc: 0.8131 - val_loss: 0.7781 - val_acc: 0.8275\n",
      "Epoch 1517/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7755 - acc: 0.8203 - val_loss: 0.7825 - val_acc: 0.8248\n",
      "Epoch 1518/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8207 - acc: 0.8122 - val_loss: 0.7845 - val_acc: 0.8275\n",
      "Epoch 1519/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8340 - acc: 0.8128 - val_loss: 0.7831 - val_acc: 0.8356\n",
      "Epoch 1520/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8103 - acc: 0.8125 - val_loss: 0.7834 - val_acc: 0.8275\n",
      "Epoch 1521/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8137 - acc: 0.8146 - val_loss: 0.7889 - val_acc: 0.8194\n",
      "Epoch 1522/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8192 - acc: 0.8137 - val_loss: 0.7861 - val_acc: 0.8194\n",
      "Epoch 1523/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8060 - acc: 0.8164 - val_loss: 0.7860 - val_acc: 0.8194\n",
      "Epoch 1524/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8188 - acc: 0.8188 - val_loss: 0.7864 - val_acc: 0.8194\n",
      "Epoch 1525/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8140 - acc: 0.8182 - val_loss: 0.7893 - val_acc: 0.8275\n",
      "Epoch 1526/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8300 - acc: 0.8110 - val_loss: 0.7842 - val_acc: 0.8248\n",
      "Epoch 1527/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8291 - acc: 0.8116 - val_loss: 0.7858 - val_acc: 0.8275\n",
      "Epoch 1528/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8110 - acc: 0.8104 - val_loss: 0.7835 - val_acc: 0.8275\n",
      "Epoch 1529/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8331 - acc: 0.8173 - val_loss: 0.7873 - val_acc: 0.8248\n",
      "Epoch 1530/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8183 - acc: 0.8137 - val_loss: 0.7923 - val_acc: 0.8248\n",
      "Epoch 1531/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8083 - acc: 0.8092 - val_loss: 0.7894 - val_acc: 0.8275\n",
      "Epoch 1532/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8347 - acc: 0.8152 - val_loss: 0.7961 - val_acc: 0.8275\n",
      "Epoch 1533/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8242 - acc: 0.8170 - val_loss: 0.7888 - val_acc: 0.8275\n",
      "Epoch 1534/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8044 - acc: 0.8134 - val_loss: 0.7889 - val_acc: 0.8248\n",
      "Epoch 1535/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8079 - acc: 0.8083 - val_loss: 0.7854 - val_acc: 0.8194\n",
      "Epoch 1536/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8248 - acc: 0.8104 - val_loss: 0.7847 - val_acc: 0.8248\n",
      "Epoch 1537/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8251 - acc: 0.8137 - val_loss: 0.7841 - val_acc: 0.8302\n",
      "Epoch 1538/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8218 - acc: 0.8158 - val_loss: 0.7855 - val_acc: 0.8275\n",
      "Epoch 1539/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7952 - acc: 0.8173 - val_loss: 0.7915 - val_acc: 0.8194\n",
      "Epoch 1540/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8178 - acc: 0.8173 - val_loss: 0.7881 - val_acc: 0.8167\n",
      "Epoch 1541/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8186 - acc: 0.8164 - val_loss: 0.7820 - val_acc: 0.8275\n",
      "Epoch 1542/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8156 - acc: 0.8134 - val_loss: 0.7802 - val_acc: 0.8329\n",
      "Epoch 1543/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8156 - acc: 0.8131 - val_loss: 0.7807 - val_acc: 0.8275\n",
      "Epoch 1544/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8080 - acc: 0.8203 - val_loss: 0.7857 - val_acc: 0.8248\n",
      "Epoch 1545/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8019 - acc: 0.8197 - val_loss: 0.7777 - val_acc: 0.8248\n",
      "Epoch 1546/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8240 - acc: 0.8128 - val_loss: 0.7770 - val_acc: 0.8248\n",
      "Epoch 1547/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8158 - acc: 0.8107 - val_loss: 0.7807 - val_acc: 0.8194\n",
      "Epoch 1548/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8168 - acc: 0.8122 - val_loss: 0.7803 - val_acc: 0.8248\n",
      "Epoch 1549/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8199 - acc: 0.8185 - val_loss: 0.7799 - val_acc: 0.8194\n",
      "Epoch 1550/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8181 - acc: 0.8131 - val_loss: 0.7820 - val_acc: 0.8221\n",
      "Epoch 1551/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8186 - acc: 0.8179 - val_loss: 0.7853 - val_acc: 0.8248\n",
      "Epoch 1552/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8006 - acc: 0.8119 - val_loss: 0.7794 - val_acc: 0.8275\n",
      "Epoch 1553/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8064 - acc: 0.8170 - val_loss: 0.7760 - val_acc: 0.8248\n",
      "Epoch 1554/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8054 - acc: 0.8137 - val_loss: 0.7784 - val_acc: 0.8248\n",
      "Epoch 1555/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8076 - acc: 0.8134 - val_loss: 0.7787 - val_acc: 0.8275\n",
      "Epoch 1556/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7981 - acc: 0.8155 - val_loss: 0.7844 - val_acc: 0.8194\n",
      "Epoch 1557/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8050 - acc: 0.8149 - val_loss: 0.7845 - val_acc: 0.8167\n",
      "Epoch 1558/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8190 - acc: 0.8101 - val_loss: 0.7773 - val_acc: 0.8248\n",
      "Epoch 1559/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8105 - acc: 0.8212 - val_loss: 0.7782 - val_acc: 0.8275\n",
      "Epoch 1560/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8002 - acc: 0.8167 - val_loss: 0.7827 - val_acc: 0.8248\n",
      "Epoch 1561/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8217 - acc: 0.8146 - val_loss: 0.7790 - val_acc: 0.8221\n",
      "Epoch 1562/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8138 - acc: 0.8155 - val_loss: 0.7768 - val_acc: 0.8221\n",
      "Epoch 1563/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8106 - acc: 0.8104 - val_loss: 0.7717 - val_acc: 0.8248\n",
      "Epoch 1564/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7986 - acc: 0.8194 - val_loss: 0.7697 - val_acc: 0.8221\n",
      "Epoch 1565/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8270 - acc: 0.8098 - val_loss: 0.7684 - val_acc: 0.8275\n",
      "Epoch 1566/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8148 - acc: 0.8158 - val_loss: 0.7771 - val_acc: 0.8221\n",
      "Epoch 1567/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8300 - acc: 0.8104 - val_loss: 0.7732 - val_acc: 0.8248\n",
      "Epoch 1568/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8231 - acc: 0.8125 - val_loss: 0.7674 - val_acc: 0.8302\n",
      "Epoch 1569/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8159 - acc: 0.8125 - val_loss: 0.7676 - val_acc: 0.8302\n",
      "Epoch 1570/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8195 - acc: 0.8101 - val_loss: 0.7718 - val_acc: 0.8194\n",
      "Epoch 1571/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8138 - acc: 0.8167 - val_loss: 0.7729 - val_acc: 0.8221\n",
      "Epoch 1572/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8062 - acc: 0.8131 - val_loss: 0.7769 - val_acc: 0.8248\n",
      "Epoch 1573/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8193 - acc: 0.8128 - val_loss: 0.7697 - val_acc: 0.8275\n",
      "Epoch 1574/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8192 - acc: 0.8203 - val_loss: 0.7670 - val_acc: 0.8302\n",
      "Epoch 1575/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8067 - acc: 0.8170 - val_loss: 0.7782 - val_acc: 0.8275\n",
      "Epoch 1576/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8303 - acc: 0.8146 - val_loss: 0.7748 - val_acc: 0.8194\n",
      "Epoch 1577/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8218 - acc: 0.8155 - val_loss: 0.7783 - val_acc: 0.8167\n",
      "Epoch 1578/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7941 - acc: 0.8206 - val_loss: 0.7774 - val_acc: 0.8194\n",
      "Epoch 1579/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8052 - acc: 0.8170 - val_loss: 0.7764 - val_acc: 0.8221\n",
      "Epoch 1580/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8239 - acc: 0.8137 - val_loss: 0.7757 - val_acc: 0.8275\n",
      "Epoch 1581/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8073 - acc: 0.8209 - val_loss: 0.7805 - val_acc: 0.8275\n",
      "Epoch 1582/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8026 - acc: 0.8200 - val_loss: 0.7848 - val_acc: 0.8275\n",
      "Epoch 1583/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8119 - acc: 0.8164 - val_loss: 0.7828 - val_acc: 0.8248\n",
      "Epoch 1584/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8254 - acc: 0.8125 - val_loss: 0.7854 - val_acc: 0.8221\n",
      "Epoch 1585/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8294 - acc: 0.8089 - val_loss: 0.7775 - val_acc: 0.8221\n",
      "Epoch 1586/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8092 - acc: 0.8035 - val_loss: 0.7735 - val_acc: 0.8302\n",
      "Epoch 1587/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8280 - acc: 0.8140 - val_loss: 0.7810 - val_acc: 0.8275\n",
      "Epoch 1588/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8120 - acc: 0.8140 - val_loss: 0.7860 - val_acc: 0.8221\n",
      "Epoch 1589/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8105 - acc: 0.8116 - val_loss: 0.7782 - val_acc: 0.8275\n",
      "Epoch 1590/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8134 - acc: 0.8158 - val_loss: 0.7875 - val_acc: 0.8275\n",
      "Epoch 1591/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8066 - acc: 0.8116 - val_loss: 0.7867 - val_acc: 0.8275\n",
      "Epoch 1592/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8157 - acc: 0.8092 - val_loss: 0.7835 - val_acc: 0.8248\n",
      "Epoch 1593/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8209 - val_loss: 0.7908 - val_acc: 0.8275\n",
      "Epoch 1594/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8103 - acc: 0.8140 - val_loss: 0.7909 - val_acc: 0.8221\n",
      "Epoch 1595/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8127 - acc: 0.8188 - val_loss: 0.7887 - val_acc: 0.8248\n",
      "Epoch 1596/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8177 - acc: 0.8155 - val_loss: 0.7822 - val_acc: 0.8275\n",
      "Epoch 1597/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8230 - acc: 0.8143 - val_loss: 0.7763 - val_acc: 0.8302\n",
      "Epoch 1598/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8250 - acc: 0.8104 - val_loss: 0.7750 - val_acc: 0.8275\n",
      "Epoch 1599/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8037 - acc: 0.8194 - val_loss: 0.7850 - val_acc: 0.8194\n",
      "Epoch 1600/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8088 - acc: 0.8161 - val_loss: 0.7807 - val_acc: 0.8248\n",
      "Epoch 1601/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7936 - acc: 0.8239 - val_loss: 0.7852 - val_acc: 0.8248\n",
      "Epoch 1602/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8133 - acc: 0.8128 - val_loss: 0.7970 - val_acc: 0.8167\n",
      "Epoch 1603/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8174 - acc: 0.8101 - val_loss: 0.7960 - val_acc: 0.8221\n",
      "Epoch 1604/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8077 - acc: 0.8206 - val_loss: 0.7886 - val_acc: 0.8248\n",
      "Epoch 1605/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8036 - acc: 0.8134 - val_loss: 0.7832 - val_acc: 0.8248\n",
      "Epoch 1606/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8156 - acc: 0.8158 - val_loss: 0.7877 - val_acc: 0.8275\n",
      "Epoch 1607/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8126 - acc: 0.8143 - val_loss: 0.7929 - val_acc: 0.8221\n",
      "Epoch 1608/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8062 - acc: 0.8149 - val_loss: 0.7991 - val_acc: 0.8167\n",
      "Epoch 1609/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8083 - acc: 0.8068 - val_loss: 0.7985 - val_acc: 0.8086\n",
      "Epoch 1610/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8242 - acc: 0.8113 - val_loss: 0.7874 - val_acc: 0.8221\n",
      "Epoch 1611/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8222 - acc: 0.8071 - val_loss: 0.7890 - val_acc: 0.8221\n",
      "Epoch 1612/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8119 - acc: 0.8092 - val_loss: 0.7912 - val_acc: 0.8248\n",
      "Epoch 1613/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8157 - acc: 0.8116 - val_loss: 0.7929 - val_acc: 0.8167\n",
      "Epoch 1614/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8203 - acc: 0.8113 - val_loss: 0.7905 - val_acc: 0.8221\n",
      "Epoch 1615/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8192 - acc: 0.8152 - val_loss: 0.7909 - val_acc: 0.8221\n",
      "Epoch 1616/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8141 - acc: 0.8131 - val_loss: 0.7863 - val_acc: 0.8248\n",
      "Epoch 1617/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8212 - acc: 0.8188 - val_loss: 0.7891 - val_acc: 0.8167\n",
      "Epoch 1618/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8017 - acc: 0.8137 - val_loss: 0.7929 - val_acc: 0.8221\n",
      "Epoch 1619/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7931 - acc: 0.8188 - val_loss: 0.7853 - val_acc: 0.8248\n",
      "Epoch 1620/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8044 - acc: 0.8155 - val_loss: 0.7879 - val_acc: 0.8194\n",
      "Epoch 1621/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7969 - acc: 0.8185 - val_loss: 0.7799 - val_acc: 0.8221\n",
      "Epoch 1622/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8071 - acc: 0.8122 - val_loss: 0.7780 - val_acc: 0.8221\n",
      "Epoch 1623/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7987 - acc: 0.8197 - val_loss: 0.7782 - val_acc: 0.8221\n",
      "Epoch 1624/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8094 - acc: 0.8170 - val_loss: 0.7773 - val_acc: 0.8248\n",
      "Epoch 1625/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8203 - val_loss: 0.7688 - val_acc: 0.8275\n",
      "Epoch 1626/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8113 - acc: 0.8152 - val_loss: 0.7679 - val_acc: 0.8248\n",
      "Epoch 1627/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8240 - acc: 0.8152 - val_loss: 0.7751 - val_acc: 0.8167\n",
      "Epoch 1628/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8074 - val_loss: 0.7773 - val_acc: 0.8167\n",
      "Epoch 1629/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8131 - val_loss: 0.7737 - val_acc: 0.8275\n",
      "Epoch 1630/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8192 - acc: 0.8158 - val_loss: 0.7763 - val_acc: 0.8302\n",
      "Epoch 1631/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8067 - acc: 0.8089 - val_loss: 0.7858 - val_acc: 0.8248\n",
      "Epoch 1632/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7894 - acc: 0.8248 - val_loss: 0.7927 - val_acc: 0.8302\n",
      "Epoch 1633/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8233 - acc: 0.8041 - val_loss: 0.7928 - val_acc: 0.8194\n",
      "Epoch 1634/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8260 - acc: 0.8131 - val_loss: 0.7941 - val_acc: 0.8167\n",
      "Epoch 1635/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7941 - acc: 0.8164 - val_loss: 0.7960 - val_acc: 0.8356\n",
      "Epoch 1636/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8046 - acc: 0.8131 - val_loss: 0.7849 - val_acc: 0.8329\n",
      "Epoch 1637/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8151 - acc: 0.8116 - val_loss: 0.7873 - val_acc: 0.8302\n",
      "Epoch 1638/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8097 - acc: 0.8140 - val_loss: 0.7907 - val_acc: 0.8248\n",
      "Epoch 1639/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8023 - acc: 0.8185 - val_loss: 0.7951 - val_acc: 0.8167\n",
      "Epoch 1640/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8226 - acc: 0.8146 - val_loss: 0.7876 - val_acc: 0.8248\n",
      "Epoch 1641/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7905 - acc: 0.8158 - val_loss: 0.7855 - val_acc: 0.8275\n",
      "Epoch 1642/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7936 - acc: 0.8152 - val_loss: 0.7846 - val_acc: 0.8275\n",
      "Epoch 1643/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8013 - acc: 0.8143 - val_loss: 0.7860 - val_acc: 0.8275\n",
      "Epoch 1644/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8168 - acc: 0.8110 - val_loss: 0.7861 - val_acc: 0.8275\n",
      "Epoch 1645/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8126 - acc: 0.8191 - val_loss: 0.7936 - val_acc: 0.8221\n",
      "Epoch 1646/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8234 - acc: 0.8176 - val_loss: 0.7889 - val_acc: 0.8302\n",
      "Epoch 1647/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8252 - acc: 0.8110 - val_loss: 0.7860 - val_acc: 0.8248\n",
      "Epoch 1648/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8132 - acc: 0.8158 - val_loss: 0.7798 - val_acc: 0.8194\n",
      "Epoch 1649/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8288 - acc: 0.8113 - val_loss: 0.7717 - val_acc: 0.8275\n",
      "Epoch 1650/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8185 - acc: 0.8197 - val_loss: 0.7620 - val_acc: 0.8302\n",
      "Epoch 1651/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8078 - acc: 0.8155 - val_loss: 0.7579 - val_acc: 0.8248\n",
      "Epoch 1652/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8174 - acc: 0.8113 - val_loss: 0.7708 - val_acc: 0.8248\n",
      "Epoch 1653/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7941 - acc: 0.8182 - val_loss: 0.7753 - val_acc: 0.8275\n",
      "Epoch 1654/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8038 - acc: 0.8146 - val_loss: 0.7695 - val_acc: 0.8329\n",
      "Epoch 1655/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8102 - acc: 0.8158 - val_loss: 0.7737 - val_acc: 0.8302\n",
      "Epoch 1656/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8231 - acc: 0.8128 - val_loss: 0.7886 - val_acc: 0.8248\n",
      "Epoch 1657/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7975 - acc: 0.8158 - val_loss: 0.7924 - val_acc: 0.8167\n",
      "Epoch 1658/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8216 - acc: 0.8137 - val_loss: 0.7983 - val_acc: 0.8167\n",
      "Epoch 1659/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8009 - acc: 0.8095 - val_loss: 0.7947 - val_acc: 0.8221\n",
      "Epoch 1660/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8187 - acc: 0.8068 - val_loss: 0.7906 - val_acc: 0.8221\n",
      "Epoch 1661/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8080 - acc: 0.8215 - val_loss: 0.7740 - val_acc: 0.8275\n",
      "Epoch 1662/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7986 - acc: 0.8185 - val_loss: 0.7683 - val_acc: 0.8275\n",
      "Epoch 1663/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7977 - acc: 0.8170 - val_loss: 0.7744 - val_acc: 0.8302\n",
      "Epoch 1664/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7977 - acc: 0.8176 - val_loss: 0.7741 - val_acc: 0.8275\n",
      "Epoch 1665/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8063 - acc: 0.8134 - val_loss: 0.7771 - val_acc: 0.8194\n",
      "Epoch 1666/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7993 - acc: 0.8110 - val_loss: 0.7769 - val_acc: 0.8221\n",
      "Epoch 1667/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7950 - acc: 0.8146 - val_loss: 0.7833 - val_acc: 0.8221\n",
      "Epoch 1668/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8065 - acc: 0.8101 - val_loss: 0.7823 - val_acc: 0.8248\n",
      "Epoch 1669/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8012 - acc: 0.8134 - val_loss: 0.7794 - val_acc: 0.8248\n",
      "Epoch 1670/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8016 - acc: 0.8179 - val_loss: 0.7797 - val_acc: 0.8275\n",
      "Epoch 1671/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8242 - acc: 0.8083 - val_loss: 0.7899 - val_acc: 0.8248\n",
      "Epoch 1672/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8084 - acc: 0.8110 - val_loss: 0.7895 - val_acc: 0.8248\n",
      "Epoch 1673/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8196 - acc: 0.8137 - val_loss: 0.7722 - val_acc: 0.8275\n",
      "Epoch 1674/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8084 - acc: 0.8137 - val_loss: 0.7668 - val_acc: 0.8302\n",
      "Epoch 1675/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8097 - acc: 0.8152 - val_loss: 0.7674 - val_acc: 0.8302\n",
      "Epoch 1676/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7980 - acc: 0.8170 - val_loss: 0.7761 - val_acc: 0.8302\n",
      "Epoch 1677/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8024 - acc: 0.8143 - val_loss: 0.7779 - val_acc: 0.8302\n",
      "Epoch 1678/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8132 - acc: 0.8140 - val_loss: 0.7807 - val_acc: 0.8302\n",
      "Epoch 1679/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7963 - acc: 0.8245 - val_loss: 0.7817 - val_acc: 0.8329\n",
      "Epoch 1680/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8107 - acc: 0.8164 - val_loss: 0.7764 - val_acc: 0.8329\n",
      "Epoch 1681/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7999 - acc: 0.8197 - val_loss: 0.7744 - val_acc: 0.8275\n",
      "Epoch 1682/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8211 - acc: 0.8110 - val_loss: 0.7777 - val_acc: 0.8221\n",
      "Epoch 1683/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8126 - acc: 0.8119 - val_loss: 0.7790 - val_acc: 0.8248\n",
      "Epoch 1684/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8065 - acc: 0.8164 - val_loss: 0.7913 - val_acc: 0.8140\n",
      "Epoch 1685/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7999 - acc: 0.8185 - val_loss: 0.7916 - val_acc: 0.8221\n",
      "Epoch 1686/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8206 - acc: 0.8173 - val_loss: 0.7882 - val_acc: 0.8194\n",
      "Epoch 1687/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8250 - acc: 0.8182 - val_loss: 0.7810 - val_acc: 0.8248\n",
      "Epoch 1688/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8104 - acc: 0.8119 - val_loss: 0.7810 - val_acc: 0.8275\n",
      "Epoch 1689/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7998 - acc: 0.8149 - val_loss: 0.7807 - val_acc: 0.8329\n",
      "Epoch 1690/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7845 - acc: 0.8194 - val_loss: 0.7780 - val_acc: 0.8383\n",
      "Epoch 1691/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8163 - acc: 0.8158 - val_loss: 0.7831 - val_acc: 0.8302\n",
      "Epoch 1692/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8160 - acc: 0.8194 - val_loss: 0.7812 - val_acc: 0.8302\n",
      "Epoch 1693/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8079 - acc: 0.8134 - val_loss: 0.7827 - val_acc: 0.8275\n",
      "Epoch 1694/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8173 - acc: 0.8182 - val_loss: 0.7820 - val_acc: 0.8329\n",
      "Epoch 1695/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8125 - acc: 0.8191 - val_loss: 0.7827 - val_acc: 0.8248\n",
      "Epoch 1696/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8167 - acc: 0.8185 - val_loss: 0.7844 - val_acc: 0.8275\n",
      "Epoch 1697/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8133 - acc: 0.8158 - val_loss: 0.7801 - val_acc: 0.8248\n",
      "Epoch 1698/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8143 - acc: 0.8173 - val_loss: 0.7775 - val_acc: 0.8275\n",
      "Epoch 1699/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8114 - acc: 0.8155 - val_loss: 0.7747 - val_acc: 0.8302\n",
      "Epoch 1700/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8116 - acc: 0.8098 - val_loss: 0.7766 - val_acc: 0.8275\n",
      "Epoch 1701/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8197 - acc: 0.8131 - val_loss: 0.7778 - val_acc: 0.8356\n",
      "Epoch 1702/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8103 - acc: 0.8125 - val_loss: 0.7774 - val_acc: 0.8302\n",
      "Epoch 1703/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8048 - acc: 0.8176 - val_loss: 0.7770 - val_acc: 0.8275\n",
      "Epoch 1704/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8160 - acc: 0.8164 - val_loss: 0.7797 - val_acc: 0.8248\n",
      "Epoch 1705/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8291 - acc: 0.8095 - val_loss: 0.7816 - val_acc: 0.8302\n",
      "Epoch 1706/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8378 - acc: 0.8125 - val_loss: 0.7881 - val_acc: 0.8275\n",
      "Epoch 1707/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8043 - acc: 0.8221 - val_loss: 0.7877 - val_acc: 0.8140\n",
      "Epoch 1708/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8104 - acc: 0.8155 - val_loss: 0.7842 - val_acc: 0.8248\n",
      "Epoch 1709/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8035 - acc: 0.8188 - val_loss: 0.7879 - val_acc: 0.8329\n",
      "Epoch 1710/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8057 - acc: 0.8149 - val_loss: 0.7896 - val_acc: 0.8302\n",
      "Epoch 1711/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8213 - acc: 0.8161 - val_loss: 0.7828 - val_acc: 0.8329\n",
      "Epoch 1712/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8177 - acc: 0.8119 - val_loss: 0.7745 - val_acc: 0.8221\n",
      "Epoch 1713/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8023 - acc: 0.8203 - val_loss: 0.7728 - val_acc: 0.8248\n",
      "Epoch 1714/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8108 - acc: 0.8152 - val_loss: 0.7757 - val_acc: 0.8275\n",
      "Epoch 1715/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8157 - acc: 0.8155 - val_loss: 0.7706 - val_acc: 0.8248\n",
      "Epoch 1716/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8062 - acc: 0.8161 - val_loss: 0.7645 - val_acc: 0.8167\n",
      "Epoch 1717/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8188 - acc: 0.8182 - val_loss: 0.7656 - val_acc: 0.8248\n",
      "Epoch 1718/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8150 - acc: 0.8062 - val_loss: 0.7732 - val_acc: 0.8275\n",
      "Epoch 1719/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7963 - acc: 0.8182 - val_loss: 0.7732 - val_acc: 0.8275\n",
      "Epoch 1720/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8036 - acc: 0.8164 - val_loss: 0.7769 - val_acc: 0.8221\n",
      "Epoch 1721/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8114 - acc: 0.8155 - val_loss: 0.7761 - val_acc: 0.8275\n",
      "Epoch 1722/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8074 - acc: 0.8164 - val_loss: 0.7764 - val_acc: 0.8302\n",
      "Epoch 1723/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8144 - acc: 0.8143 - val_loss: 0.7795 - val_acc: 0.8221\n",
      "Epoch 1724/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8112 - acc: 0.8143 - val_loss: 0.7836 - val_acc: 0.8221\n",
      "Epoch 1725/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8255 - acc: 0.8107 - val_loss: 0.7815 - val_acc: 0.8329\n",
      "Epoch 1726/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8265 - acc: 0.8119 - val_loss: 0.7737 - val_acc: 0.8356\n",
      "Epoch 1727/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8159 - acc: 0.8170 - val_loss: 0.7775 - val_acc: 0.8248\n",
      "Epoch 1728/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8139 - acc: 0.8179 - val_loss: 0.7722 - val_acc: 0.8221\n",
      "Epoch 1729/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8086 - acc: 0.8155 - val_loss: 0.7655 - val_acc: 0.8275\n",
      "Epoch 1730/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8096 - acc: 0.8185 - val_loss: 0.7645 - val_acc: 0.8302\n",
      "Epoch 1731/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8121 - acc: 0.8104 - val_loss: 0.7710 - val_acc: 0.8329\n",
      "Epoch 1732/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8010 - acc: 0.8176 - val_loss: 0.7730 - val_acc: 0.8302\n",
      "Epoch 1733/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8141 - acc: 0.8143 - val_loss: 0.7797 - val_acc: 0.8275\n",
      "Epoch 1734/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8166 - acc: 0.8128 - val_loss: 0.7796 - val_acc: 0.8248\n",
      "Epoch 1735/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8057 - acc: 0.8119 - val_loss: 0.7794 - val_acc: 0.8275\n",
      "Epoch 1736/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7972 - acc: 0.8149 - val_loss: 0.7738 - val_acc: 0.8302\n",
      "Epoch 1737/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8084 - acc: 0.8152 - val_loss: 0.7773 - val_acc: 0.8248\n",
      "Epoch 1738/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8086 - acc: 0.8104 - val_loss: 0.7733 - val_acc: 0.8302\n",
      "Epoch 1739/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8118 - acc: 0.8152 - val_loss: 0.7703 - val_acc: 0.8302\n",
      "Epoch 1740/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8024 - acc: 0.8140 - val_loss: 0.7762 - val_acc: 0.8275\n",
      "Epoch 1741/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7985 - acc: 0.8128 - val_loss: 0.7819 - val_acc: 0.8302\n",
      "Epoch 1742/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8157 - acc: 0.8125 - val_loss: 0.7793 - val_acc: 0.8302\n",
      "Epoch 1743/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8163 - acc: 0.8194 - val_loss: 0.7773 - val_acc: 0.8329\n",
      "Epoch 1744/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8201 - acc: 0.8122 - val_loss: 0.7804 - val_acc: 0.8302\n",
      "Epoch 1745/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8157 - acc: 0.8119 - val_loss: 0.7855 - val_acc: 0.8302\n",
      "Epoch 1746/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7991 - acc: 0.8179 - val_loss: 0.7869 - val_acc: 0.8302\n",
      "Epoch 1747/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8071 - acc: 0.8137 - val_loss: 0.7811 - val_acc: 0.8221\n",
      "Epoch 1748/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7953 - acc: 0.8239 - val_loss: 0.7773 - val_acc: 0.8221\n",
      "Epoch 1749/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8040 - acc: 0.8110 - val_loss: 0.7799 - val_acc: 0.8248\n",
      "Epoch 1750/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8178 - acc: 0.8089 - val_loss: 0.7749 - val_acc: 0.8221\n",
      "Epoch 1751/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7996 - acc: 0.8152 - val_loss: 0.7700 - val_acc: 0.8221\n",
      "Epoch 1752/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8022 - acc: 0.8170 - val_loss: 0.7708 - val_acc: 0.8221\n",
      "Epoch 1753/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8110 - acc: 0.8170 - val_loss: 0.7799 - val_acc: 0.8275\n",
      "Epoch 1754/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8017 - acc: 0.8155 - val_loss: 0.7868 - val_acc: 0.8194\n",
      "Epoch 1755/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8144 - acc: 0.8119 - val_loss: 0.7866 - val_acc: 0.8140\n",
      "Epoch 1756/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7951 - acc: 0.8134 - val_loss: 0.7882 - val_acc: 0.8194\n",
      "Epoch 1757/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7970 - acc: 0.8173 - val_loss: 0.7830 - val_acc: 0.8248\n",
      "Epoch 1758/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8161 - acc: 0.8122 - val_loss: 0.7805 - val_acc: 0.8221\n",
      "Epoch 1759/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8200 - val_loss: 0.7757 - val_acc: 0.8275\n",
      "Epoch 1760/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8051 - acc: 0.8092 - val_loss: 0.7786 - val_acc: 0.8275\n",
      "Epoch 1761/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8063 - acc: 0.8161 - val_loss: 0.7798 - val_acc: 0.8248\n",
      "Epoch 1762/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8126 - acc: 0.8134 - val_loss: 0.7760 - val_acc: 0.8275\n",
      "Epoch 1763/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8250 - acc: 0.8173 - val_loss: 0.7766 - val_acc: 0.8302\n",
      "Epoch 1764/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8215 - acc: 0.8104 - val_loss: 0.7810 - val_acc: 0.8275\n",
      "Epoch 1765/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8087 - acc: 0.8152 - val_loss: 0.7889 - val_acc: 0.8275\n",
      "Epoch 1766/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8068 - acc: 0.8059 - val_loss: 0.7903 - val_acc: 0.8275\n",
      "Epoch 1767/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8082 - acc: 0.8104 - val_loss: 0.7871 - val_acc: 0.8221\n",
      "Epoch 1768/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8147 - acc: 0.8170 - val_loss: 0.7860 - val_acc: 0.8248\n",
      "Epoch 1769/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7939 - acc: 0.8179 - val_loss: 0.7808 - val_acc: 0.8221\n",
      "Epoch 1770/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7955 - acc: 0.8194 - val_loss: 0.7834 - val_acc: 0.8275\n",
      "Epoch 1771/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7910 - acc: 0.8173 - val_loss: 0.7881 - val_acc: 0.8275\n",
      "Epoch 1772/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8128 - acc: 0.8152 - val_loss: 0.7863 - val_acc: 0.8275\n",
      "Epoch 1773/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8065 - val_loss: 0.7840 - val_acc: 0.8140\n",
      "Epoch 1774/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8080 - val_loss: 0.7884 - val_acc: 0.8194\n",
      "Epoch 1775/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8031 - acc: 0.8191 - val_loss: 0.7852 - val_acc: 0.8248\n",
      "Epoch 1776/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8152 - val_loss: 0.7875 - val_acc: 0.8221\n",
      "Epoch 1777/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7904 - acc: 0.8161 - val_loss: 0.7895 - val_acc: 0.8248\n",
      "Epoch 1778/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8127 - acc: 0.8149 - val_loss: 0.7854 - val_acc: 0.8329\n",
      "Epoch 1779/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7999 - acc: 0.8092 - val_loss: 0.7795 - val_acc: 0.8275\n",
      "Epoch 1780/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8079 - acc: 0.8161 - val_loss: 0.7835 - val_acc: 0.8221\n",
      "Epoch 1781/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8248 - acc: 0.8128 - val_loss: 0.7902 - val_acc: 0.8302\n",
      "Epoch 1782/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8000 - acc: 0.8122 - val_loss: 0.7917 - val_acc: 0.8302\n",
      "Epoch 1783/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7943 - acc: 0.8191 - val_loss: 0.7971 - val_acc: 0.8194\n",
      "Epoch 1784/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8157 - acc: 0.8131 - val_loss: 0.7955 - val_acc: 0.8194\n",
      "Epoch 1785/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8073 - acc: 0.8206 - val_loss: 0.7817 - val_acc: 0.8329\n",
      "Epoch 1786/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7926 - acc: 0.8230 - val_loss: 0.7757 - val_acc: 0.8329\n",
      "Epoch 1787/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8005 - acc: 0.8137 - val_loss: 0.7779 - val_acc: 0.8302\n",
      "Epoch 1788/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7861 - acc: 0.8164 - val_loss: 0.7748 - val_acc: 0.8329\n",
      "Epoch 1789/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8156 - acc: 0.8167 - val_loss: 0.7774 - val_acc: 0.8329\n",
      "Epoch 1790/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8195 - acc: 0.8149 - val_loss: 0.7803 - val_acc: 0.8302\n",
      "Epoch 1791/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8063 - acc: 0.8188 - val_loss: 0.7833 - val_acc: 0.8248\n",
      "Epoch 1792/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8124 - acc: 0.8092 - val_loss: 0.7855 - val_acc: 0.8194\n",
      "Epoch 1793/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8143 - acc: 0.8149 - val_loss: 0.7871 - val_acc: 0.8194\n",
      "Epoch 1794/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8107 - acc: 0.8131 - val_loss: 0.7841 - val_acc: 0.8167\n",
      "Epoch 1795/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8170 - acc: 0.8080 - val_loss: 0.7824 - val_acc: 0.8221\n",
      "Epoch 1796/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7992 - acc: 0.8197 - val_loss: 0.7770 - val_acc: 0.8302\n",
      "Epoch 1797/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8223 - acc: 0.8158 - val_loss: 0.7768 - val_acc: 0.8302\n",
      "Epoch 1798/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8063 - acc: 0.8158 - val_loss: 0.7804 - val_acc: 0.8275\n",
      "Epoch 1799/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8080 - acc: 0.8110 - val_loss: 0.7793 - val_acc: 0.8221\n",
      "Epoch 1800/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8018 - acc: 0.8173 - val_loss: 0.7780 - val_acc: 0.8248\n",
      "Epoch 1801/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8016 - acc: 0.8119 - val_loss: 0.7815 - val_acc: 0.8248\n",
      "Epoch 1802/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8184 - acc: 0.8167 - val_loss: 0.7799 - val_acc: 0.8221\n",
      "Epoch 1803/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8096 - acc: 0.8122 - val_loss: 0.7759 - val_acc: 0.8275\n",
      "Epoch 1804/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8138 - acc: 0.8119 - val_loss: 0.7840 - val_acc: 0.8302\n",
      "Epoch 1805/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8121 - acc: 0.8137 - val_loss: 0.7804 - val_acc: 0.8194\n",
      "Epoch 1806/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8140 - acc: 0.8143 - val_loss: 0.7795 - val_acc: 0.8275\n",
      "Epoch 1807/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8212 - acc: 0.8185 - val_loss: 0.7839 - val_acc: 0.8275\n",
      "Epoch 1808/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8148 - acc: 0.8155 - val_loss: 0.7864 - val_acc: 0.8275\n",
      "Epoch 1809/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8188 - acc: 0.8161 - val_loss: 0.7828 - val_acc: 0.8275\n",
      "Epoch 1810/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8074 - acc: 0.8164 - val_loss: 0.7751 - val_acc: 0.8275\n",
      "Epoch 1811/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7949 - acc: 0.8113 - val_loss: 0.7735 - val_acc: 0.8248\n",
      "Epoch 1812/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8091 - acc: 0.8113 - val_loss: 0.7662 - val_acc: 0.8275\n",
      "Epoch 1813/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8087 - acc: 0.8125 - val_loss: 0.7668 - val_acc: 0.8194\n",
      "Epoch 1814/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7916 - acc: 0.8218 - val_loss: 0.7651 - val_acc: 0.8248\n",
      "Epoch 1815/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8094 - acc: 0.8131 - val_loss: 0.7755 - val_acc: 0.8221\n",
      "Epoch 1816/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8089 - acc: 0.8107 - val_loss: 0.7799 - val_acc: 0.8221\n",
      "Epoch 1817/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8127 - acc: 0.8173 - val_loss: 0.7761 - val_acc: 0.8221\n",
      "Epoch 1818/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7982 - acc: 0.8143 - val_loss: 0.7729 - val_acc: 0.8275\n",
      "Epoch 1819/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8065 - acc: 0.8113 - val_loss: 0.7774 - val_acc: 0.8248\n",
      "Epoch 1820/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8206 - acc: 0.8167 - val_loss: 0.7916 - val_acc: 0.8194\n",
      "Epoch 1821/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8162 - acc: 0.8113 - val_loss: 0.7990 - val_acc: 0.8167\n",
      "Epoch 1822/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8045 - acc: 0.8143 - val_loss: 0.7921 - val_acc: 0.8194\n",
      "Epoch 1823/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7898 - acc: 0.8173 - val_loss: 0.7868 - val_acc: 0.8194\n",
      "Epoch 1824/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8090 - acc: 0.8194 - val_loss: 0.7928 - val_acc: 0.8221\n",
      "Epoch 1825/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8097 - acc: 0.8176 - val_loss: 0.7943 - val_acc: 0.8248\n",
      "Epoch 1826/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8083 - acc: 0.8119 - val_loss: 0.7934 - val_acc: 0.8167\n",
      "Epoch 1827/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8142 - acc: 0.8158 - val_loss: 0.7870 - val_acc: 0.8194\n",
      "Epoch 1828/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8096 - acc: 0.8176 - val_loss: 0.7880 - val_acc: 0.8221\n",
      "Epoch 1829/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7989 - acc: 0.8161 - val_loss: 0.7832 - val_acc: 0.8221\n",
      "Epoch 1830/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8039 - acc: 0.8119 - val_loss: 0.7822 - val_acc: 0.8248\n",
      "Epoch 1831/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8084 - acc: 0.8131 - val_loss: 0.7805 - val_acc: 0.8248\n",
      "Epoch 1832/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7897 - acc: 0.8167 - val_loss: 0.7833 - val_acc: 0.8275\n",
      "Epoch 1833/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8155 - val_loss: 0.7868 - val_acc: 0.8275\n",
      "Epoch 1834/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8124 - acc: 0.8140 - val_loss: 0.7919 - val_acc: 0.8275\n",
      "Epoch 1835/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7882 - acc: 0.8170 - val_loss: 0.7906 - val_acc: 0.8275\n",
      "Epoch 1836/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7964 - acc: 0.8119 - val_loss: 0.7901 - val_acc: 0.8302\n",
      "Epoch 1837/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8057 - acc: 0.8119 - val_loss: 0.7893 - val_acc: 0.8194\n",
      "Epoch 1838/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7896 - acc: 0.8170 - val_loss: 0.7871 - val_acc: 0.8167\n",
      "Epoch 1839/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8073 - acc: 0.8107 - val_loss: 0.7945 - val_acc: 0.8167\n",
      "Epoch 1840/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7990 - acc: 0.8158 - val_loss: 0.7931 - val_acc: 0.8194\n",
      "Epoch 1841/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8150 - acc: 0.8176 - val_loss: 0.7888 - val_acc: 0.8221\n",
      "Epoch 1842/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7993 - acc: 0.8116 - val_loss: 0.7816 - val_acc: 0.8302\n",
      "Epoch 1843/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8121 - acc: 0.8146 - val_loss: 0.7907 - val_acc: 0.8140\n",
      "Epoch 1844/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8100 - acc: 0.8092 - val_loss: 0.7962 - val_acc: 0.8167\n",
      "Epoch 1845/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8102 - acc: 0.8146 - val_loss: 0.7999 - val_acc: 0.8248\n",
      "Epoch 1846/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8154 - acc: 0.8137 - val_loss: 0.7929 - val_acc: 0.8221\n",
      "Epoch 1847/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8101 - acc: 0.8104 - val_loss: 0.7842 - val_acc: 0.8275\n",
      "Epoch 1848/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8306 - acc: 0.8149 - val_loss: 0.7743 - val_acc: 0.8302\n",
      "Epoch 1849/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8080 - acc: 0.8167 - val_loss: 0.7671 - val_acc: 0.8275\n",
      "Epoch 1850/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8088 - acc: 0.8188 - val_loss: 0.7680 - val_acc: 0.8248\n",
      "Epoch 1851/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7836 - acc: 0.8182 - val_loss: 0.7691 - val_acc: 0.8221\n",
      "Epoch 1852/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7928 - acc: 0.8170 - val_loss: 0.7749 - val_acc: 0.8275\n",
      "Epoch 1853/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8194 - val_loss: 0.7778 - val_acc: 0.8275\n",
      "Epoch 1854/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8137 - val_loss: 0.7712 - val_acc: 0.8302\n",
      "Epoch 1855/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8049 - acc: 0.8110 - val_loss: 0.7652 - val_acc: 0.8275\n",
      "Epoch 1856/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8105 - acc: 0.8116 - val_loss: 0.7702 - val_acc: 0.8275\n",
      "Epoch 1857/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8065 - acc: 0.8161 - val_loss: 0.7802 - val_acc: 0.8167\n",
      "Epoch 1858/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7924 - acc: 0.8173 - val_loss: 0.7808 - val_acc: 0.8194\n",
      "Epoch 1859/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8089 - acc: 0.8155 - val_loss: 0.7727 - val_acc: 0.8302\n",
      "Epoch 1860/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8186 - acc: 0.8176 - val_loss: 0.7717 - val_acc: 0.8302\n",
      "Epoch 1861/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8047 - acc: 0.8122 - val_loss: 0.7675 - val_acc: 0.8329\n",
      "Epoch 1862/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8085 - acc: 0.8134 - val_loss: 0.7704 - val_acc: 0.8302\n",
      "Epoch 1863/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8279 - acc: 0.8047 - val_loss: 0.7747 - val_acc: 0.8302\n",
      "Epoch 1864/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8174 - acc: 0.8086 - val_loss: 0.7754 - val_acc: 0.8248\n",
      "Epoch 1865/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8019 - acc: 0.8167 - val_loss: 0.7782 - val_acc: 0.8221\n",
      "Epoch 1866/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7976 - acc: 0.8170 - val_loss: 0.7794 - val_acc: 0.8221\n",
      "Epoch 1867/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7974 - acc: 0.8179 - val_loss: 0.7868 - val_acc: 0.8248\n",
      "Epoch 1868/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8052 - acc: 0.8170 - val_loss: 0.7900 - val_acc: 0.8248\n",
      "Epoch 1869/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8081 - acc: 0.8143 - val_loss: 0.7855 - val_acc: 0.8194\n",
      "Epoch 1870/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8076 - acc: 0.8134 - val_loss: 0.7883 - val_acc: 0.8275\n",
      "Epoch 1871/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8062 - acc: 0.8167 - val_loss: 0.7866 - val_acc: 0.8221\n",
      "Epoch 1872/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8101 - acc: 0.8182 - val_loss: 0.7848 - val_acc: 0.8221\n",
      "Epoch 1873/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8133 - acc: 0.8107 - val_loss: 0.7844 - val_acc: 0.8275\n",
      "Epoch 1874/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8186 - acc: 0.8137 - val_loss: 0.7884 - val_acc: 0.8221\n",
      "Epoch 1875/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8085 - acc: 0.8179 - val_loss: 0.7849 - val_acc: 0.8248\n",
      "Epoch 1876/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8248 - acc: 0.8107 - val_loss: 0.7894 - val_acc: 0.8248\n",
      "Epoch 1877/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8338 - acc: 0.8152 - val_loss: 0.7879 - val_acc: 0.8194\n",
      "Epoch 1878/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8003 - acc: 0.8089 - val_loss: 0.7821 - val_acc: 0.8194\n",
      "Epoch 1879/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8115 - acc: 0.8098 - val_loss: 0.7872 - val_acc: 0.8248\n",
      "Epoch 1880/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8170 - val_loss: 0.7872 - val_acc: 0.8302\n",
      "Epoch 1881/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8034 - acc: 0.8152 - val_loss: 0.7883 - val_acc: 0.8248\n",
      "Epoch 1882/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8134 - acc: 0.8137 - val_loss: 0.7928 - val_acc: 0.8248\n",
      "Epoch 1883/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8161 - acc: 0.8128 - val_loss: 0.7881 - val_acc: 0.8194\n",
      "Epoch 1884/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8249 - acc: 0.8149 - val_loss: 0.7814 - val_acc: 0.8221\n",
      "Epoch 1885/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7977 - acc: 0.8158 - val_loss: 0.7797 - val_acc: 0.8221\n",
      "Epoch 1886/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8201 - acc: 0.8116 - val_loss: 0.7847 - val_acc: 0.8194\n",
      "Epoch 1887/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7944 - acc: 0.8173 - val_loss: 0.7790 - val_acc: 0.8302\n",
      "Epoch 1888/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8115 - acc: 0.8101 - val_loss: 0.7800 - val_acc: 0.8275\n",
      "Epoch 1889/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8092 - acc: 0.8113 - val_loss: 0.7799 - val_acc: 0.8302\n",
      "Epoch 1890/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8138 - acc: 0.8128 - val_loss: 0.7819 - val_acc: 0.8275\n",
      "Epoch 1891/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8227 - acc: 0.8164 - val_loss: 0.7821 - val_acc: 0.8221\n",
      "Epoch 1892/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8154 - acc: 0.8128 - val_loss: 0.7764 - val_acc: 0.8248\n",
      "Epoch 1893/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8147 - acc: 0.8176 - val_loss: 0.7738 - val_acc: 0.8248\n",
      "Epoch 1894/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8070 - acc: 0.8146 - val_loss: 0.7759 - val_acc: 0.8221\n",
      "Epoch 1895/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8043 - acc: 0.8050 - val_loss: 0.7828 - val_acc: 0.8302\n",
      "Epoch 1896/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7971 - acc: 0.8158 - val_loss: 0.7984 - val_acc: 0.8167\n",
      "Epoch 1897/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8049 - acc: 0.8140 - val_loss: 0.7994 - val_acc: 0.8275\n",
      "Epoch 1898/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8040 - acc: 0.8128 - val_loss: 0.7901 - val_acc: 0.8302\n",
      "Epoch 1899/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8035 - acc: 0.8155 - val_loss: 0.7903 - val_acc: 0.8275\n",
      "Epoch 1900/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8030 - acc: 0.8113 - val_loss: 0.7985 - val_acc: 0.8275\n",
      "Epoch 1901/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7965 - acc: 0.8155 - val_loss: 0.8030 - val_acc: 0.8221\n",
      "Epoch 1902/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7864 - acc: 0.8179 - val_loss: 0.8049 - val_acc: 0.8221\n",
      "Epoch 1903/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8096 - acc: 0.8104 - val_loss: 0.7966 - val_acc: 0.8275\n",
      "Epoch 1904/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8027 - acc: 0.8176 - val_loss: 0.7964 - val_acc: 0.8248\n",
      "Epoch 1905/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7987 - acc: 0.8158 - val_loss: 0.7939 - val_acc: 0.8221\n",
      "Epoch 1906/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8158 - acc: 0.8092 - val_loss: 0.7876 - val_acc: 0.8221\n",
      "Epoch 1907/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8089 - acc: 0.8152 - val_loss: 0.7896 - val_acc: 0.8221\n",
      "Epoch 1908/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8038 - acc: 0.8161 - val_loss: 0.7940 - val_acc: 0.8275\n",
      "Epoch 1909/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8062 - acc: 0.8176 - val_loss: 0.7860 - val_acc: 0.8329\n",
      "Epoch 1910/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8122 - acc: 0.8116 - val_loss: 0.7780 - val_acc: 0.8356\n",
      "Epoch 1911/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8023 - acc: 0.8146 - val_loss: 0.7873 - val_acc: 0.8302\n",
      "Epoch 1912/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8049 - acc: 0.8116 - val_loss: 0.7951 - val_acc: 0.8248\n",
      "Epoch 1913/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8105 - acc: 0.8080 - val_loss: 0.7925 - val_acc: 0.8248\n",
      "Epoch 1914/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8113 - acc: 0.8185 - val_loss: 0.7875 - val_acc: 0.8302\n",
      "Epoch 1915/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8016 - acc: 0.8191 - val_loss: 0.7839 - val_acc: 0.8356\n",
      "Epoch 1916/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7898 - acc: 0.8182 - val_loss: 0.7854 - val_acc: 0.8329\n",
      "Epoch 1917/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8146 - acc: 0.8095 - val_loss: 0.7850 - val_acc: 0.8221\n",
      "Epoch 1918/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7938 - acc: 0.8164 - val_loss: 0.7818 - val_acc: 0.8221\n",
      "Epoch 1919/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7953 - acc: 0.8194 - val_loss: 0.7790 - val_acc: 0.8275\n",
      "Epoch 1920/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8019 - acc: 0.8113 - val_loss: 0.7876 - val_acc: 0.8275\n",
      "Epoch 1921/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8212 - acc: 0.8086 - val_loss: 0.7831 - val_acc: 0.8275\n",
      "Epoch 1922/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8047 - acc: 0.8107 - val_loss: 0.7828 - val_acc: 0.8302\n",
      "Epoch 1923/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8030 - acc: 0.8143 - val_loss: 0.7859 - val_acc: 0.8248\n",
      "Epoch 1924/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8031 - acc: 0.8146 - val_loss: 0.7802 - val_acc: 0.8248\n",
      "Epoch 1925/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8086 - acc: 0.8071 - val_loss: 0.7772 - val_acc: 0.8302\n",
      "Epoch 1926/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8288 - acc: 0.8095 - val_loss: 0.7788 - val_acc: 0.8302\n",
      "Epoch 1927/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8119 - val_loss: 0.7891 - val_acc: 0.8248\n",
      "Epoch 1928/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8230 - acc: 0.8158 - val_loss: 0.7878 - val_acc: 0.8248\n",
      "Epoch 1929/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8004 - acc: 0.8134 - val_loss: 0.7893 - val_acc: 0.8248\n",
      "Epoch 1930/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8082 - acc: 0.8110 - val_loss: 0.7836 - val_acc: 0.8275\n",
      "Epoch 1931/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8134 - acc: 0.8119 - val_loss: 0.7936 - val_acc: 0.8248\n",
      "Epoch 1932/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7990 - acc: 0.8128 - val_loss: 0.7988 - val_acc: 0.8221\n",
      "Epoch 1933/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8138 - acc: 0.8125 - val_loss: 0.7986 - val_acc: 0.8194\n",
      "Epoch 1934/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8153 - acc: 0.8098 - val_loss: 0.7943 - val_acc: 0.8248\n",
      "Epoch 1935/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8117 - acc: 0.8125 - val_loss: 0.7927 - val_acc: 0.8275\n",
      "Epoch 1936/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8099 - acc: 0.8119 - val_loss: 0.7844 - val_acc: 0.8275\n",
      "Epoch 1937/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8191 - val_loss: 0.7811 - val_acc: 0.8248\n",
      "Epoch 1938/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8016 - acc: 0.8122 - val_loss: 0.7884 - val_acc: 0.8221\n",
      "Epoch 1939/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8114 - acc: 0.8149 - val_loss: 0.7934 - val_acc: 0.8248\n",
      "Epoch 1940/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8082 - acc: 0.8140 - val_loss: 0.7973 - val_acc: 0.8221\n",
      "Epoch 1941/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8185 - acc: 0.8158 - val_loss: 0.7909 - val_acc: 0.8221\n",
      "Epoch 1942/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7966 - acc: 0.8119 - val_loss: 0.7980 - val_acc: 0.8248\n",
      "Epoch 1943/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7942 - acc: 0.8134 - val_loss: 0.7969 - val_acc: 0.8275\n",
      "Epoch 1944/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8107 - acc: 0.8104 - val_loss: 0.7922 - val_acc: 0.8302\n",
      "Epoch 1945/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8212 - val_loss: 0.7887 - val_acc: 0.8275\n",
      "Epoch 1946/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8287 - acc: 0.8125 - val_loss: 0.7942 - val_acc: 0.8194\n",
      "Epoch 1947/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8315 - acc: 0.8143 - val_loss: 0.7952 - val_acc: 0.8275\n",
      "Epoch 1948/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8128 - acc: 0.8092 - val_loss: 0.7928 - val_acc: 0.8275\n",
      "Epoch 1949/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8058 - acc: 0.8080 - val_loss: 0.7931 - val_acc: 0.8248\n",
      "Epoch 1950/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7985 - acc: 0.8155 - val_loss: 0.7917 - val_acc: 0.8221\n",
      "Epoch 1951/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8013 - acc: 0.8128 - val_loss: 0.7882 - val_acc: 0.8248\n",
      "Epoch 1952/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8079 - acc: 0.8164 - val_loss: 0.7853 - val_acc: 0.8194\n",
      "Epoch 1953/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8222 - acc: 0.8119 - val_loss: 0.7743 - val_acc: 0.8221\n",
      "Epoch 1954/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8052 - acc: 0.8125 - val_loss: 0.7753 - val_acc: 0.8194\n",
      "Epoch 1955/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8199 - acc: 0.8095 - val_loss: 0.7789 - val_acc: 0.8194\n",
      "Epoch 1956/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8164 - acc: 0.8098 - val_loss: 0.7888 - val_acc: 0.8140\n",
      "Epoch 1957/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8026 - acc: 0.8158 - val_loss: 0.7950 - val_acc: 0.8167\n",
      "Epoch 1958/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8060 - acc: 0.8152 - val_loss: 0.7968 - val_acc: 0.8221\n",
      "Epoch 1959/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8069 - acc: 0.8038 - val_loss: 0.7888 - val_acc: 0.8248\n",
      "Epoch 1960/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7899 - acc: 0.8176 - val_loss: 0.7786 - val_acc: 0.8275\n",
      "Epoch 1961/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8010 - acc: 0.8122 - val_loss: 0.7804 - val_acc: 0.8221\n",
      "Epoch 1962/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8033 - acc: 0.8122 - val_loss: 0.7774 - val_acc: 0.8248\n",
      "Epoch 1963/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8076 - acc: 0.8179 - val_loss: 0.7750 - val_acc: 0.8275\n",
      "Epoch 1964/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8092 - acc: 0.8125 - val_loss: 0.7735 - val_acc: 0.8221\n",
      "Epoch 1965/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8042 - acc: 0.8209 - val_loss: 0.7738 - val_acc: 0.8248\n",
      "Epoch 1966/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8115 - acc: 0.8152 - val_loss: 0.7748 - val_acc: 0.8275\n",
      "Epoch 1967/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7911 - acc: 0.8137 - val_loss: 0.7803 - val_acc: 0.8302\n",
      "Epoch 1968/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8059 - acc: 0.8173 - val_loss: 0.7882 - val_acc: 0.8221\n",
      "Epoch 1969/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7907 - acc: 0.8170 - val_loss: 0.7920 - val_acc: 0.8248\n",
      "Epoch 1970/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8070 - acc: 0.8131 - val_loss: 0.7943 - val_acc: 0.8248\n",
      "Epoch 1971/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8148 - acc: 0.8074 - val_loss: 0.7992 - val_acc: 0.8248\n",
      "Epoch 1972/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8069 - acc: 0.8152 - val_loss: 0.7911 - val_acc: 0.8167\n",
      "Epoch 1973/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8013 - acc: 0.8182 - val_loss: 0.7795 - val_acc: 0.8275\n",
      "Epoch 1974/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7961 - acc: 0.8125 - val_loss: 0.7772 - val_acc: 0.8275\n",
      "Epoch 1975/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8122 - acc: 0.8134 - val_loss: 0.7722 - val_acc: 0.8356\n",
      "Epoch 1976/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8014 - acc: 0.8149 - val_loss: 0.7728 - val_acc: 0.8302\n",
      "Epoch 1977/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7847 - acc: 0.8188 - val_loss: 0.7757 - val_acc: 0.8302\n",
      "Epoch 1978/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8036 - acc: 0.8137 - val_loss: 0.7805 - val_acc: 0.8275\n",
      "Epoch 1979/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7949 - acc: 0.8116 - val_loss: 0.7822 - val_acc: 0.8248\n",
      "Epoch 1980/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8051 - acc: 0.8125 - val_loss: 0.7805 - val_acc: 0.8302\n",
      "Epoch 1981/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7938 - acc: 0.8086 - val_loss: 0.7850 - val_acc: 0.8275\n",
      "Epoch 1982/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8077 - acc: 0.8134 - val_loss: 0.7899 - val_acc: 0.8248\n",
      "Epoch 1983/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8209 - val_loss: 0.7879 - val_acc: 0.8248\n",
      "Epoch 1984/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8072 - acc: 0.8125 - val_loss: 0.7931 - val_acc: 0.8248\n",
      "Epoch 1985/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8002 - acc: 0.8140 - val_loss: 0.7941 - val_acc: 0.8248\n",
      "Epoch 1986/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7956 - acc: 0.8155 - val_loss: 0.7916 - val_acc: 0.8248\n",
      "Epoch 1987/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8046 - acc: 0.8095 - val_loss: 0.7929 - val_acc: 0.8302\n",
      "Epoch 1988/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8149 - acc: 0.8182 - val_loss: 0.7904 - val_acc: 0.8275\n",
      "Epoch 1989/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8176 - val_loss: 0.7957 - val_acc: 0.8221\n",
      "Epoch 1990/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7961 - acc: 0.8131 - val_loss: 0.7918 - val_acc: 0.8248\n",
      "Epoch 1991/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8086 - acc: 0.8161 - val_loss: 0.7892 - val_acc: 0.8275\n",
      "Epoch 1992/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7959 - acc: 0.8149 - val_loss: 0.7913 - val_acc: 0.8302\n",
      "Epoch 1993/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8102 - acc: 0.8146 - val_loss: 0.7860 - val_acc: 0.8302\n",
      "Epoch 1994/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8197 - acc: 0.8194 - val_loss: 0.7810 - val_acc: 0.8302\n",
      "Epoch 1995/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8149 - val_loss: 0.7826 - val_acc: 0.8302\n",
      "Epoch 1996/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7897 - acc: 0.8191 - val_loss: 0.7875 - val_acc: 0.8248\n",
      "Epoch 1997/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8085 - acc: 0.8083 - val_loss: 0.7860 - val_acc: 0.8275\n",
      "Epoch 1998/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8226 - acc: 0.8104 - val_loss: 0.7838 - val_acc: 0.8275\n",
      "Epoch 1999/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8179 - acc: 0.8149 - val_loss: 0.7852 - val_acc: 0.8302\n",
      "Epoch 2000/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7901 - acc: 0.8188 - val_loss: 0.7813 - val_acc: 0.8329\n",
      "Epoch 2001/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8128 - acc: 0.8158 - val_loss: 0.7816 - val_acc: 0.8275\n",
      "Epoch 2002/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8143 - acc: 0.8167 - val_loss: 0.7820 - val_acc: 0.8275\n",
      "Epoch 2003/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7973 - acc: 0.8167 - val_loss: 0.7837 - val_acc: 0.8275\n",
      "Epoch 2004/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7888 - acc: 0.8164 - val_loss: 0.7844 - val_acc: 0.8275\n",
      "Epoch 2005/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8075 - acc: 0.8242 - val_loss: 0.7823 - val_acc: 0.8275\n",
      "Epoch 2006/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8043 - acc: 0.8170 - val_loss: 0.7852 - val_acc: 0.8248\n",
      "Epoch 2007/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8169 - acc: 0.8161 - val_loss: 0.7835 - val_acc: 0.8302\n",
      "Epoch 2008/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7897 - acc: 0.8089 - val_loss: 0.7887 - val_acc: 0.8302\n",
      "Epoch 2009/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8064 - acc: 0.8188 - val_loss: 0.7958 - val_acc: 0.8221\n",
      "Epoch 2010/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8081 - acc: 0.8173 - val_loss: 0.7948 - val_acc: 0.8302\n",
      "Epoch 2011/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8029 - acc: 0.8143 - val_loss: 0.7939 - val_acc: 0.8248\n",
      "Epoch 2012/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8089 - acc: 0.8176 - val_loss: 0.7916 - val_acc: 0.8248\n",
      "Epoch 2013/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8117 - acc: 0.8134 - val_loss: 0.7953 - val_acc: 0.8194\n",
      "Epoch 2014/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8013 - acc: 0.8143 - val_loss: 0.7899 - val_acc: 0.8221\n",
      "Epoch 2015/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8012 - acc: 0.8158 - val_loss: 0.7961 - val_acc: 0.8167\n",
      "Epoch 2016/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8193 - acc: 0.8041 - val_loss: 0.7913 - val_acc: 0.8275\n",
      "Epoch 2017/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7860 - acc: 0.8152 - val_loss: 0.7868 - val_acc: 0.8248\n",
      "Epoch 2018/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8125 - acc: 0.8167 - val_loss: 0.7873 - val_acc: 0.8275\n",
      "Epoch 2019/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8086 - acc: 0.8065 - val_loss: 0.7799 - val_acc: 0.8302\n",
      "Epoch 2020/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8001 - acc: 0.8215 - val_loss: 0.7688 - val_acc: 0.8302\n",
      "Epoch 2021/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8095 - acc: 0.8128 - val_loss: 0.7719 - val_acc: 0.8248\n",
      "Epoch 2022/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7921 - acc: 0.8203 - val_loss: 0.7753 - val_acc: 0.8194\n",
      "Epoch 2023/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8070 - acc: 0.8161 - val_loss: 0.7901 - val_acc: 0.8194\n",
      "Epoch 2024/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8104 - acc: 0.8158 - val_loss: 0.7925 - val_acc: 0.8167\n",
      "Epoch 2025/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8084 - acc: 0.8176 - val_loss: 0.7822 - val_acc: 0.8194\n",
      "Epoch 2026/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7973 - acc: 0.8164 - val_loss: 0.7852 - val_acc: 0.8221\n",
      "Epoch 2027/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8148 - acc: 0.8143 - val_loss: 0.7808 - val_acc: 0.8221\n",
      "Epoch 2028/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8018 - acc: 0.8140 - val_loss: 0.7869 - val_acc: 0.8221\n",
      "Epoch 2029/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8180 - acc: 0.8179 - val_loss: 0.7869 - val_acc: 0.8248\n",
      "Epoch 2030/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7917 - acc: 0.8113 - val_loss: 0.7904 - val_acc: 0.8221\n",
      "Epoch 2031/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8088 - acc: 0.8125 - val_loss: 0.7930 - val_acc: 0.8194\n",
      "Epoch 2032/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8235 - acc: 0.8125 - val_loss: 0.7897 - val_acc: 0.8194\n",
      "Epoch 2033/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8145 - acc: 0.8161 - val_loss: 0.7855 - val_acc: 0.8194\n",
      "Epoch 2034/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8104 - acc: 0.8185 - val_loss: 0.7865 - val_acc: 0.8275\n",
      "Epoch 2035/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8078 - acc: 0.8173 - val_loss: 0.7833 - val_acc: 0.8248\n",
      "Epoch 2036/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7941 - acc: 0.8128 - val_loss: 0.7806 - val_acc: 0.8221\n",
      "Epoch 2037/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7966 - acc: 0.8173 - val_loss: 0.7769 - val_acc: 0.8248\n",
      "Epoch 2038/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8105 - acc: 0.8095 - val_loss: 0.7797 - val_acc: 0.8248\n",
      "Epoch 2039/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8170 - acc: 0.8095 - val_loss: 0.7808 - val_acc: 0.8194\n",
      "Epoch 2040/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8013 - acc: 0.8173 - val_loss: 0.7817 - val_acc: 0.8221\n",
      "Epoch 2041/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8181 - acc: 0.8092 - val_loss: 0.7758 - val_acc: 0.8221\n",
      "Epoch 2042/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8206 - acc: 0.8176 - val_loss: 0.7763 - val_acc: 0.8221\n",
      "Epoch 2043/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7855 - acc: 0.8203 - val_loss: 0.7824 - val_acc: 0.8329\n",
      "Epoch 2044/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8104 - acc: 0.8149 - val_loss: 0.7952 - val_acc: 0.8221\n",
      "Epoch 2045/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8243 - acc: 0.8050 - val_loss: 0.7904 - val_acc: 0.8275\n",
      "Epoch 2046/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8105 - acc: 0.8146 - val_loss: 0.7861 - val_acc: 0.8275\n",
      "Epoch 2047/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8108 - acc: 0.8173 - val_loss: 0.7816 - val_acc: 0.8329\n",
      "Epoch 2048/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8061 - acc: 0.8146 - val_loss: 0.7821 - val_acc: 0.8275\n",
      "Epoch 2049/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7955 - acc: 0.8113 - val_loss: 0.7851 - val_acc: 0.8221\n",
      "Epoch 2050/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7936 - acc: 0.8128 - val_loss: 0.7837 - val_acc: 0.8194\n",
      "Epoch 2051/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8001 - acc: 0.8134 - val_loss: 0.7784 - val_acc: 0.8248\n",
      "Epoch 2052/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8181 - acc: 0.8119 - val_loss: 0.7696 - val_acc: 0.8248\n",
      "Epoch 2053/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8094 - acc: 0.8164 - val_loss: 0.7765 - val_acc: 0.8221\n",
      "Epoch 2054/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8052 - acc: 0.8143 - val_loss: 0.7781 - val_acc: 0.8248\n",
      "Epoch 2055/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8029 - acc: 0.8152 - val_loss: 0.7750 - val_acc: 0.8221\n",
      "Epoch 2056/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8200 - acc: 0.8062 - val_loss: 0.7712 - val_acc: 0.8275\n",
      "Epoch 2057/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8157 - acc: 0.8140 - val_loss: 0.7653 - val_acc: 0.8302\n",
      "Epoch 2058/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7817 - acc: 0.8164 - val_loss: 0.7635 - val_acc: 0.8221\n",
      "Epoch 2059/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8056 - acc: 0.8125 - val_loss: 0.7638 - val_acc: 0.8275\n",
      "Epoch 2060/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8015 - acc: 0.8161 - val_loss: 0.7657 - val_acc: 0.8275\n",
      "Epoch 2061/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8020 - acc: 0.8185 - val_loss: 0.7658 - val_acc: 0.8329\n",
      "Epoch 2062/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8182 - acc: 0.8125 - val_loss: 0.7731 - val_acc: 0.8248\n",
      "Epoch 2063/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8061 - acc: 0.8125 - val_loss: 0.7752 - val_acc: 0.8248\n",
      "Epoch 2064/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8126 - acc: 0.8077 - val_loss: 0.7784 - val_acc: 0.8302\n",
      "Epoch 2065/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8094 - acc: 0.8167 - val_loss: 0.7737 - val_acc: 0.8329\n",
      "Epoch 2066/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7940 - acc: 0.8170 - val_loss: 0.7681 - val_acc: 0.8221\n",
      "Epoch 2067/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8150 - acc: 0.8062 - val_loss: 0.7680 - val_acc: 0.8221\n",
      "Epoch 2068/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8083 - acc: 0.8128 - val_loss: 0.7705 - val_acc: 0.8194\n",
      "Epoch 2069/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8131 - val_loss: 0.7712 - val_acc: 0.8248\n",
      "Epoch 2070/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8047 - acc: 0.8179 - val_loss: 0.7695 - val_acc: 0.8248\n",
      "Epoch 2071/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7958 - acc: 0.8149 - val_loss: 0.7717 - val_acc: 0.8302\n",
      "Epoch 2072/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8073 - acc: 0.8215 - val_loss: 0.7740 - val_acc: 0.8275\n",
      "Epoch 2073/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7975 - acc: 0.8179 - val_loss: 0.7781 - val_acc: 0.8248\n",
      "Epoch 2074/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8048 - acc: 0.8128 - val_loss: 0.7847 - val_acc: 0.8167\n",
      "Epoch 2075/5000\n",
      "3339/3339 [==============================] - 0s 10us/step - loss: 0.7963 - acc: 0.8167 - val_loss: 0.7848 - val_acc: 0.8248\n",
      "Epoch 2076/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8161 - val_loss: 0.7750 - val_acc: 0.8248\n",
      "Epoch 2077/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8080 - acc: 0.8116 - val_loss: 0.7686 - val_acc: 0.8302\n",
      "Epoch 2078/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7968 - acc: 0.8212 - val_loss: 0.7687 - val_acc: 0.8329\n",
      "Epoch 2079/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7899 - acc: 0.8122 - val_loss: 0.7700 - val_acc: 0.8329\n",
      "Epoch 2080/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8045 - acc: 0.8086 - val_loss: 0.7762 - val_acc: 0.8275\n",
      "Epoch 2081/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8015 - acc: 0.8119 - val_loss: 0.7811 - val_acc: 0.8329\n",
      "Epoch 2082/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7993 - acc: 0.8146 - val_loss: 0.7811 - val_acc: 0.8221\n",
      "Epoch 2083/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8172 - acc: 0.8176 - val_loss: 0.7787 - val_acc: 0.8248\n",
      "Epoch 2084/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8073 - acc: 0.8149 - val_loss: 0.7762 - val_acc: 0.8248\n",
      "Epoch 2085/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.8007 - acc: 0.8221 - val_loss: 0.7750 - val_acc: 0.8302\n",
      "Epoch 2086/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8006 - acc: 0.8173 - val_loss: 0.7768 - val_acc: 0.8302\n",
      "Epoch 2087/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8111 - acc: 0.8155 - val_loss: 0.7787 - val_acc: 0.8248\n",
      "Epoch 2088/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8228 - acc: 0.8128 - val_loss: 0.7781 - val_acc: 0.8221\n",
      "Epoch 2089/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8084 - acc: 0.8143 - val_loss: 0.7711 - val_acc: 0.8248\n",
      "Epoch 2090/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8063 - acc: 0.8176 - val_loss: 0.7678 - val_acc: 0.8329\n",
      "Epoch 2091/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8164 - acc: 0.8128 - val_loss: 0.7790 - val_acc: 0.8194\n",
      "Epoch 2092/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8070 - acc: 0.8146 - val_loss: 0.7771 - val_acc: 0.8275\n",
      "Epoch 2093/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8066 - acc: 0.8044 - val_loss: 0.7730 - val_acc: 0.8275\n",
      "Epoch 2094/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7917 - acc: 0.8164 - val_loss: 0.7688 - val_acc: 0.8302\n",
      "Epoch 2095/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8103 - acc: 0.8122 - val_loss: 0.7827 - val_acc: 0.8248\n",
      "Epoch 2096/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8128 - val_loss: 0.7858 - val_acc: 0.8221\n",
      "Epoch 2097/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7859 - acc: 0.8176 - val_loss: 0.7829 - val_acc: 0.8194\n",
      "Epoch 2098/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8126 - acc: 0.8134 - val_loss: 0.7727 - val_acc: 0.8248\n",
      "Epoch 2099/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7958 - acc: 0.8200 - val_loss: 0.7694 - val_acc: 0.8329\n",
      "Epoch 2100/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8100 - acc: 0.8134 - val_loss: 0.7734 - val_acc: 0.8275\n",
      "Epoch 2101/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8013 - acc: 0.8110 - val_loss: 0.7691 - val_acc: 0.8302\n",
      "Epoch 2102/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8148 - acc: 0.8191 - val_loss: 0.7708 - val_acc: 0.8329\n",
      "Epoch 2103/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8035 - acc: 0.8146 - val_loss: 0.7782 - val_acc: 0.8194\n",
      "Epoch 2104/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7891 - acc: 0.8116 - val_loss: 0.7732 - val_acc: 0.8275\n",
      "Epoch 2105/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7989 - acc: 0.8212 - val_loss: 0.7796 - val_acc: 0.8248\n",
      "Epoch 2106/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7974 - acc: 0.8140 - val_loss: 0.7800 - val_acc: 0.8275\n",
      "Epoch 2107/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8207 - acc: 0.8167 - val_loss: 0.7786 - val_acc: 0.8221\n",
      "Epoch 2108/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8023 - acc: 0.8143 - val_loss: 0.7740 - val_acc: 0.8302\n",
      "Epoch 2109/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7926 - acc: 0.8158 - val_loss: 0.7704 - val_acc: 0.8329\n",
      "Epoch 2110/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8178 - acc: 0.8173 - val_loss: 0.7613 - val_acc: 0.8329\n",
      "Epoch 2111/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7984 - acc: 0.8125 - val_loss: 0.7608 - val_acc: 0.8302\n",
      "Epoch 2112/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8124 - acc: 0.8152 - val_loss: 0.7677 - val_acc: 0.8329\n",
      "Epoch 2113/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8041 - acc: 0.8107 - val_loss: 0.7750 - val_acc: 0.8248\n",
      "Epoch 2114/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8153 - acc: 0.8119 - val_loss: 0.7816 - val_acc: 0.8275\n",
      "Epoch 2115/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7959 - acc: 0.8134 - val_loss: 0.7842 - val_acc: 0.8275\n",
      "Epoch 2116/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7939 - acc: 0.8176 - val_loss: 0.7778 - val_acc: 0.8275\n",
      "Epoch 2117/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8030 - acc: 0.8131 - val_loss: 0.7758 - val_acc: 0.8275\n",
      "Epoch 2118/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7972 - acc: 0.8197 - val_loss: 0.7802 - val_acc: 0.8221\n",
      "Epoch 2119/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7883 - acc: 0.8200 - val_loss: 0.7785 - val_acc: 0.8275\n",
      "Epoch 2120/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8057 - acc: 0.8140 - val_loss: 0.7819 - val_acc: 0.8248\n",
      "Epoch 2121/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8007 - acc: 0.8161 - val_loss: 0.7702 - val_acc: 0.8302\n",
      "Epoch 2122/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8007 - acc: 0.8134 - val_loss: 0.7669 - val_acc: 0.8302\n",
      "Epoch 2123/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7959 - acc: 0.8164 - val_loss: 0.7686 - val_acc: 0.8302\n",
      "Epoch 2124/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8152 - val_loss: 0.7661 - val_acc: 0.8275\n",
      "Epoch 2125/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7873 - acc: 0.8167 - val_loss: 0.7676 - val_acc: 0.8221\n",
      "Epoch 2126/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7966 - acc: 0.8122 - val_loss: 0.7730 - val_acc: 0.8329\n",
      "Epoch 2127/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8239 - acc: 0.8140 - val_loss: 0.7741 - val_acc: 0.8302\n",
      "Epoch 2128/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8045 - acc: 0.8128 - val_loss: 0.7751 - val_acc: 0.8356\n",
      "Epoch 2129/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8078 - acc: 0.8131 - val_loss: 0.7771 - val_acc: 0.8356\n",
      "Epoch 2130/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7815 - acc: 0.8149 - val_loss: 0.7865 - val_acc: 0.8221\n",
      "Epoch 2131/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8007 - acc: 0.8128 - val_loss: 0.7842 - val_acc: 0.8221\n",
      "Epoch 2132/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8015 - acc: 0.8140 - val_loss: 0.7824 - val_acc: 0.8194\n",
      "Epoch 2133/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8075 - acc: 0.8143 - val_loss: 0.7797 - val_acc: 0.8248\n",
      "Epoch 2134/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8182 - val_loss: 0.7826 - val_acc: 0.8248\n",
      "Epoch 2135/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8203 - val_loss: 0.7792 - val_acc: 0.8221\n",
      "Epoch 2136/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7964 - acc: 0.8167 - val_loss: 0.7825 - val_acc: 0.8248\n",
      "Epoch 2137/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7997 - acc: 0.8158 - val_loss: 0.7894 - val_acc: 0.8275\n",
      "Epoch 2138/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8119 - acc: 0.8158 - val_loss: 0.7926 - val_acc: 0.8248\n",
      "Epoch 2139/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8134 - acc: 0.8173 - val_loss: 0.7961 - val_acc: 0.8302\n",
      "Epoch 2140/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7959 - acc: 0.8110 - val_loss: 0.7944 - val_acc: 0.8275\n",
      "Epoch 2141/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8041 - acc: 0.8161 - val_loss: 0.7962 - val_acc: 0.8248\n",
      "Epoch 2142/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8010 - acc: 0.8188 - val_loss: 0.7877 - val_acc: 0.8275\n",
      "Epoch 2143/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8034 - acc: 0.8176 - val_loss: 0.7819 - val_acc: 0.8248\n",
      "Epoch 2144/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7904 - acc: 0.8128 - val_loss: 0.7794 - val_acc: 0.8221\n",
      "Epoch 2145/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7985 - acc: 0.8155 - val_loss: 0.7799 - val_acc: 0.8275\n",
      "Epoch 2146/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7964 - acc: 0.8161 - val_loss: 0.7801 - val_acc: 0.8221\n",
      "Epoch 2147/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8185 - val_loss: 0.7828 - val_acc: 0.8248\n",
      "Epoch 2148/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8131 - val_loss: 0.7869 - val_acc: 0.8248\n",
      "Epoch 2149/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7937 - acc: 0.8176 - val_loss: 0.7839 - val_acc: 0.8275\n",
      "Epoch 2150/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8137 - acc: 0.8200 - val_loss: 0.7804 - val_acc: 0.8248\n",
      "Epoch 2151/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8039 - acc: 0.8149 - val_loss: 0.7809 - val_acc: 0.8275\n",
      "Epoch 2152/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8160 - acc: 0.8119 - val_loss: 0.7852 - val_acc: 0.8275\n",
      "Epoch 2153/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8120 - acc: 0.8122 - val_loss: 0.7906 - val_acc: 0.8248\n",
      "Epoch 2154/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8078 - acc: 0.8158 - val_loss: 0.7907 - val_acc: 0.8248\n",
      "Epoch 2155/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8106 - acc: 0.8122 - val_loss: 0.7920 - val_acc: 0.8275\n",
      "Epoch 2156/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8027 - acc: 0.8143 - val_loss: 0.7912 - val_acc: 0.8275\n",
      "Epoch 2157/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8036 - acc: 0.8110 - val_loss: 0.7893 - val_acc: 0.8248\n",
      "Epoch 2158/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7997 - acc: 0.8143 - val_loss: 0.7931 - val_acc: 0.8221\n",
      "Epoch 2159/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7955 - acc: 0.8206 - val_loss: 0.7926 - val_acc: 0.8248\n",
      "Epoch 2160/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8226 - acc: 0.8056 - val_loss: 0.7978 - val_acc: 0.8248\n",
      "Epoch 2161/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8205 - acc: 0.8116 - val_loss: 0.7963 - val_acc: 0.8221\n",
      "Epoch 2162/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7992 - acc: 0.8149 - val_loss: 0.7958 - val_acc: 0.8221\n",
      "Epoch 2163/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7854 - acc: 0.8206 - val_loss: 0.7936 - val_acc: 0.8221\n",
      "Epoch 2164/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7896 - acc: 0.8188 - val_loss: 0.7927 - val_acc: 0.8248\n",
      "Epoch 2165/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8114 - acc: 0.8164 - val_loss: 0.7859 - val_acc: 0.8275\n",
      "Epoch 2166/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8131 - acc: 0.8116 - val_loss: 0.7797 - val_acc: 0.8302\n",
      "Epoch 2167/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8109 - acc: 0.8155 - val_loss: 0.7770 - val_acc: 0.8302\n",
      "Epoch 2168/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8004 - acc: 0.8131 - val_loss: 0.7703 - val_acc: 0.8275\n",
      "Epoch 2169/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7869 - acc: 0.8137 - val_loss: 0.7733 - val_acc: 0.8221\n",
      "Epoch 2170/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7809 - acc: 0.8182 - val_loss: 0.7726 - val_acc: 0.8221\n",
      "Epoch 2171/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8025 - acc: 0.8092 - val_loss: 0.7807 - val_acc: 0.8194\n",
      "Epoch 2172/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8339 - acc: 0.8086 - val_loss: 0.7863 - val_acc: 0.8194\n",
      "Epoch 2173/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8006 - acc: 0.8143 - val_loss: 0.7942 - val_acc: 0.8248\n",
      "Epoch 2174/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7901 - acc: 0.8164 - val_loss: 0.7990 - val_acc: 0.8140\n",
      "Epoch 2175/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7903 - acc: 0.8173 - val_loss: 0.7889 - val_acc: 0.8194\n",
      "Epoch 2176/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7958 - acc: 0.8158 - val_loss: 0.7796 - val_acc: 0.8248\n",
      "Epoch 2177/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8188 - val_loss: 0.7769 - val_acc: 0.8221\n",
      "Epoch 2178/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8000 - acc: 0.8137 - val_loss: 0.7782 - val_acc: 0.8221\n",
      "Epoch 2179/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8201 - acc: 0.8146 - val_loss: 0.7841 - val_acc: 0.8194\n",
      "Epoch 2180/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8002 - acc: 0.8116 - val_loss: 0.7912 - val_acc: 0.8167\n",
      "Epoch 2181/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8146 - val_loss: 0.7894 - val_acc: 0.8221\n",
      "Epoch 2182/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7972 - acc: 0.8161 - val_loss: 0.7890 - val_acc: 0.8167\n",
      "Epoch 2183/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8054 - acc: 0.8071 - val_loss: 0.7875 - val_acc: 0.8221\n",
      "Epoch 2184/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8213 - acc: 0.8125 - val_loss: 0.7792 - val_acc: 0.8329\n",
      "Epoch 2185/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7910 - acc: 0.8179 - val_loss: 0.7806 - val_acc: 0.8302\n",
      "Epoch 2186/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8134 - val_loss: 0.7788 - val_acc: 0.8329\n",
      "Epoch 2187/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8036 - acc: 0.8161 - val_loss: 0.7818 - val_acc: 0.8302\n",
      "Epoch 2188/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8082 - acc: 0.8116 - val_loss: 0.7835 - val_acc: 0.8329\n",
      "Epoch 2189/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8037 - acc: 0.8116 - val_loss: 0.7862 - val_acc: 0.8329\n",
      "Epoch 2190/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7976 - acc: 0.8134 - val_loss: 0.7838 - val_acc: 0.8302\n",
      "Epoch 2191/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8080 - acc: 0.8167 - val_loss: 0.7785 - val_acc: 0.8248\n",
      "Epoch 2192/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8054 - acc: 0.8131 - val_loss: 0.7698 - val_acc: 0.8275\n",
      "Epoch 2193/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7933 - acc: 0.8158 - val_loss: 0.7730 - val_acc: 0.8221\n",
      "Epoch 2194/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8191 - val_loss: 0.7792 - val_acc: 0.8275\n",
      "Epoch 2195/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8032 - acc: 0.8179 - val_loss: 0.7891 - val_acc: 0.8194\n",
      "Epoch 2196/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7954 - acc: 0.8185 - val_loss: 0.7873 - val_acc: 0.8221\n",
      "Epoch 2197/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8309 - acc: 0.8080 - val_loss: 0.7885 - val_acc: 0.8221\n",
      "Epoch 2198/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7951 - acc: 0.8146 - val_loss: 0.7858 - val_acc: 0.8275\n",
      "Epoch 2199/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8021 - acc: 0.8191 - val_loss: 0.7882 - val_acc: 0.8275\n",
      "Epoch 2200/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8137 - val_loss: 0.7894 - val_acc: 0.8221\n",
      "Epoch 2201/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7872 - acc: 0.8140 - val_loss: 0.7919 - val_acc: 0.8221\n",
      "Epoch 2202/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8058 - acc: 0.8143 - val_loss: 0.8020 - val_acc: 0.8194\n",
      "Epoch 2203/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8055 - acc: 0.8152 - val_loss: 0.8039 - val_acc: 0.8221\n",
      "Epoch 2204/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8131 - acc: 0.8074 - val_loss: 0.7977 - val_acc: 0.8221\n",
      "Epoch 2205/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7963 - acc: 0.8140 - val_loss: 0.7914 - val_acc: 0.8221\n",
      "Epoch 2206/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8059 - acc: 0.8200 - val_loss: 0.7805 - val_acc: 0.8275\n",
      "Epoch 2207/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7987 - acc: 0.8164 - val_loss: 0.7834 - val_acc: 0.8221\n",
      "Epoch 2208/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7993 - acc: 0.8182 - val_loss: 0.7850 - val_acc: 0.8221\n",
      "Epoch 2209/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8239 - acc: 0.8068 - val_loss: 0.7857 - val_acc: 0.8221\n",
      "Epoch 2210/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8266 - acc: 0.8092 - val_loss: 0.7836 - val_acc: 0.8275\n",
      "Epoch 2211/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8018 - acc: 0.8125 - val_loss: 0.7837 - val_acc: 0.8302\n",
      "Epoch 2212/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7980 - acc: 0.8170 - val_loss: 0.7762 - val_acc: 0.8248\n",
      "Epoch 2213/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7854 - acc: 0.8200 - val_loss: 0.7765 - val_acc: 0.8302\n",
      "Epoch 2214/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8005 - acc: 0.8107 - val_loss: 0.7711 - val_acc: 0.8329\n",
      "Epoch 2215/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8101 - val_loss: 0.7724 - val_acc: 0.8329\n",
      "Epoch 2216/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7996 - acc: 0.8131 - val_loss: 0.7789 - val_acc: 0.8248\n",
      "Epoch 2217/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8175 - acc: 0.8095 - val_loss: 0.7804 - val_acc: 0.8248\n",
      "Epoch 2218/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8243 - acc: 0.8128 - val_loss: 0.7799 - val_acc: 0.8248\n",
      "Epoch 2219/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7985 - acc: 0.8161 - val_loss: 0.7771 - val_acc: 0.8248\n",
      "Epoch 2220/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8090 - acc: 0.8122 - val_loss: 0.7740 - val_acc: 0.8221\n",
      "Epoch 2221/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7941 - acc: 0.8170 - val_loss: 0.7787 - val_acc: 0.8221\n",
      "Epoch 2222/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8040 - acc: 0.8149 - val_loss: 0.7799 - val_acc: 0.8140\n",
      "Epoch 2223/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7972 - acc: 0.8242 - val_loss: 0.7844 - val_acc: 0.8167\n",
      "Epoch 2224/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8041 - acc: 0.8107 - val_loss: 0.7892 - val_acc: 0.8140\n",
      "Epoch 2225/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7830 - acc: 0.8194 - val_loss: 0.7841 - val_acc: 0.8194\n",
      "Epoch 2226/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7989 - acc: 0.8161 - val_loss: 0.7712 - val_acc: 0.8302\n",
      "Epoch 2227/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7831 - acc: 0.8143 - val_loss: 0.7687 - val_acc: 0.8275\n",
      "Epoch 2228/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8119 - acc: 0.8116 - val_loss: 0.7735 - val_acc: 0.8248\n",
      "Epoch 2229/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8131 - acc: 0.8125 - val_loss: 0.7699 - val_acc: 0.8248\n",
      "Epoch 2230/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8183 - acc: 0.8164 - val_loss: 0.7698 - val_acc: 0.8221\n",
      "Epoch 2231/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8056 - acc: 0.8176 - val_loss: 0.7789 - val_acc: 0.8140\n",
      "Epoch 2232/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7904 - acc: 0.8128 - val_loss: 0.7709 - val_acc: 0.8167\n",
      "Epoch 2233/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8206 - val_loss: 0.7645 - val_acc: 0.8275\n",
      "Epoch 2234/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8149 - val_loss: 0.7662 - val_acc: 0.8275\n",
      "Epoch 2235/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8040 - acc: 0.8119 - val_loss: 0.7728 - val_acc: 0.8221\n",
      "Epoch 2236/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7858 - acc: 0.8143 - val_loss: 0.7729 - val_acc: 0.8221\n",
      "Epoch 2237/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8065 - acc: 0.8161 - val_loss: 0.7732 - val_acc: 0.8302\n",
      "Epoch 2238/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7850 - acc: 0.8119 - val_loss: 0.7652 - val_acc: 0.8302\n",
      "Epoch 2239/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8006 - acc: 0.8173 - val_loss: 0.7642 - val_acc: 0.8221\n",
      "Epoch 2240/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7946 - acc: 0.8137 - val_loss: 0.7665 - val_acc: 0.8302\n",
      "Epoch 2241/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7939 - acc: 0.8107 - val_loss: 0.7700 - val_acc: 0.8302\n",
      "Epoch 2242/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7875 - acc: 0.8182 - val_loss: 0.7573 - val_acc: 0.8302\n",
      "Epoch 2243/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7960 - acc: 0.8161 - val_loss: 0.7543 - val_acc: 0.8383\n",
      "Epoch 2244/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8184 - acc: 0.8089 - val_loss: 0.7615 - val_acc: 0.8275\n",
      "Epoch 2245/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8243 - acc: 0.8152 - val_loss: 0.7575 - val_acc: 0.8275\n",
      "Epoch 2246/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7921 - acc: 0.8104 - val_loss: 0.7571 - val_acc: 0.8302\n",
      "Epoch 2247/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8028 - acc: 0.8191 - val_loss: 0.7652 - val_acc: 0.8275\n",
      "Epoch 2248/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8101 - acc: 0.8140 - val_loss: 0.7706 - val_acc: 0.8221\n",
      "Epoch 2249/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7980 - acc: 0.8170 - val_loss: 0.7653 - val_acc: 0.8248\n",
      "Epoch 2250/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8111 - acc: 0.8155 - val_loss: 0.7572 - val_acc: 0.8356\n",
      "Epoch 2251/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8173 - val_loss: 0.7647 - val_acc: 0.8383\n",
      "Epoch 2252/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7923 - acc: 0.8191 - val_loss: 0.7707 - val_acc: 0.8302\n",
      "Epoch 2253/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7967 - acc: 0.8161 - val_loss: 0.7760 - val_acc: 0.8248\n",
      "Epoch 2254/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7985 - acc: 0.8146 - val_loss: 0.7755 - val_acc: 0.8194\n",
      "Epoch 2255/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7979 - acc: 0.8137 - val_loss: 0.7728 - val_acc: 0.8248\n",
      "Epoch 2256/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7984 - acc: 0.8149 - val_loss: 0.7764 - val_acc: 0.8248\n",
      "Epoch 2257/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8120 - acc: 0.8158 - val_loss: 0.7805 - val_acc: 0.8248\n",
      "Epoch 2258/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8038 - acc: 0.8197 - val_loss: 0.7812 - val_acc: 0.8248\n",
      "Epoch 2259/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8037 - acc: 0.8128 - val_loss: 0.7794 - val_acc: 0.8248\n",
      "Epoch 2260/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7899 - acc: 0.8146 - val_loss: 0.7871 - val_acc: 0.8194\n",
      "Epoch 2261/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7994 - acc: 0.8134 - val_loss: 0.7829 - val_acc: 0.8221\n",
      "Epoch 2262/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7808 - acc: 0.8179 - val_loss: 0.7877 - val_acc: 0.8248\n",
      "Epoch 2263/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7870 - acc: 0.8167 - val_loss: 0.7902 - val_acc: 0.8194\n",
      "Epoch 2264/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8122 - acc: 0.8101 - val_loss: 0.7861 - val_acc: 0.8194\n",
      "Epoch 2265/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8105 - acc: 0.8110 - val_loss: 0.7774 - val_acc: 0.8248\n",
      "Epoch 2266/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8092 - acc: 0.8164 - val_loss: 0.7715 - val_acc: 0.8356\n",
      "Epoch 2267/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8088 - acc: 0.8104 - val_loss: 0.7613 - val_acc: 0.8329\n",
      "Epoch 2268/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7971 - acc: 0.8185 - val_loss: 0.7704 - val_acc: 0.8275\n",
      "Epoch 2269/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7825 - acc: 0.8221 - val_loss: 0.7834 - val_acc: 0.8194\n",
      "Epoch 2270/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8292 - acc: 0.8119 - val_loss: 0.7888 - val_acc: 0.8140\n",
      "Epoch 2271/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8122 - val_loss: 0.7895 - val_acc: 0.8248\n",
      "Epoch 2272/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8143 - acc: 0.8125 - val_loss: 0.7969 - val_acc: 0.8140\n",
      "Epoch 2273/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8158 - acc: 0.8113 - val_loss: 0.7919 - val_acc: 0.8248\n",
      "Epoch 2274/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7887 - acc: 0.8149 - val_loss: 0.7848 - val_acc: 0.8275\n",
      "Epoch 2275/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7847 - acc: 0.8200 - val_loss: 0.7817 - val_acc: 0.8302\n",
      "Epoch 2276/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7829 - acc: 0.8161 - val_loss: 0.7858 - val_acc: 0.8275\n",
      "Epoch 2277/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7981 - acc: 0.8206 - val_loss: 0.8001 - val_acc: 0.8221\n",
      "Epoch 2278/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8034 - acc: 0.8116 - val_loss: 0.7998 - val_acc: 0.8302\n",
      "Epoch 2279/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8064 - acc: 0.8203 - val_loss: 0.8034 - val_acc: 0.8275\n",
      "Epoch 2280/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8137 - acc: 0.8161 - val_loss: 0.8019 - val_acc: 0.8194\n",
      "Epoch 2281/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7850 - acc: 0.8164 - val_loss: 0.7988 - val_acc: 0.8275\n",
      "Epoch 2282/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8060 - acc: 0.8149 - val_loss: 0.7949 - val_acc: 0.8221\n",
      "Epoch 2283/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8195 - acc: 0.8125 - val_loss: 0.7931 - val_acc: 0.8248\n",
      "Epoch 2284/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8034 - acc: 0.8125 - val_loss: 0.7960 - val_acc: 0.8194\n",
      "Epoch 2285/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7900 - acc: 0.8149 - val_loss: 0.8033 - val_acc: 0.8167\n",
      "Epoch 2286/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8126 - acc: 0.8101 - val_loss: 0.8045 - val_acc: 0.8167\n",
      "Epoch 2287/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8123 - acc: 0.8080 - val_loss: 0.8005 - val_acc: 0.8194\n",
      "Epoch 2288/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8137 - acc: 0.8164 - val_loss: 0.7916 - val_acc: 0.8275\n",
      "Epoch 2289/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8066 - acc: 0.8095 - val_loss: 0.7927 - val_acc: 0.8248\n",
      "Epoch 2290/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7982 - acc: 0.8191 - val_loss: 0.7906 - val_acc: 0.8221\n",
      "Epoch 2291/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7969 - acc: 0.8146 - val_loss: 0.7872 - val_acc: 0.8221\n",
      "Epoch 2292/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7877 - acc: 0.8197 - val_loss: 0.7805 - val_acc: 0.8221\n",
      "Epoch 2293/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8043 - acc: 0.8092 - val_loss: 0.7677 - val_acc: 0.8302\n",
      "Epoch 2294/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7840 - acc: 0.8131 - val_loss: 0.7645 - val_acc: 0.8329\n",
      "Epoch 2295/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8108 - acc: 0.8128 - val_loss: 0.7709 - val_acc: 0.8302\n",
      "Epoch 2296/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8047 - acc: 0.8173 - val_loss: 0.7826 - val_acc: 0.8221\n",
      "Epoch 2297/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8149 - val_loss: 0.7849 - val_acc: 0.8221\n",
      "Epoch 2298/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8031 - acc: 0.8140 - val_loss: 0.7775 - val_acc: 0.8221\n",
      "Epoch 2299/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8230 - val_loss: 0.7719 - val_acc: 0.8275\n",
      "Epoch 2300/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7877 - acc: 0.8095 - val_loss: 0.7737 - val_acc: 0.8248\n",
      "Epoch 2301/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7914 - acc: 0.8188 - val_loss: 0.7847 - val_acc: 0.8275\n",
      "Epoch 2302/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.7904 - acc: 0.8155 - val_loss: 0.7926 - val_acc: 0.8140\n",
      "Epoch 2303/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8146 - val_loss: 0.7838 - val_acc: 0.8221\n",
      "Epoch 2304/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7889 - acc: 0.8191 - val_loss: 0.7818 - val_acc: 0.8221\n",
      "Epoch 2305/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8043 - acc: 0.8185 - val_loss: 0.7821 - val_acc: 0.8194\n",
      "Epoch 2306/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7961 - acc: 0.8203 - val_loss: 0.7757 - val_acc: 0.8329\n",
      "Epoch 2307/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8065 - acc: 0.8107 - val_loss: 0.7704 - val_acc: 0.8329\n",
      "Epoch 2308/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8137 - val_loss: 0.7668 - val_acc: 0.8275\n",
      "Epoch 2309/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8165 - acc: 0.8128 - val_loss: 0.7699 - val_acc: 0.8275\n",
      "Epoch 2310/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8188 - val_loss: 0.7787 - val_acc: 0.8248\n",
      "Epoch 2311/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7955 - acc: 0.8116 - val_loss: 0.7858 - val_acc: 0.8194\n",
      "Epoch 2312/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7993 - acc: 0.8101 - val_loss: 0.7909 - val_acc: 0.8194\n",
      "Epoch 2313/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8001 - acc: 0.8128 - val_loss: 0.7890 - val_acc: 0.8221\n",
      "Epoch 2314/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7988 - acc: 0.8182 - val_loss: 0.7875 - val_acc: 0.8221\n",
      "Epoch 2315/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8009 - acc: 0.8170 - val_loss: 0.7837 - val_acc: 0.8302\n",
      "Epoch 2316/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8051 - acc: 0.8125 - val_loss: 0.7830 - val_acc: 0.8275\n",
      "Epoch 2317/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8002 - acc: 0.8119 - val_loss: 0.7838 - val_acc: 0.8248\n",
      "Epoch 2318/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7985 - acc: 0.8218 - val_loss: 0.7821 - val_acc: 0.8275\n",
      "Epoch 2319/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7937 - acc: 0.8128 - val_loss: 0.7803 - val_acc: 0.8275\n",
      "Epoch 2320/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8087 - acc: 0.8122 - val_loss: 0.7853 - val_acc: 0.8194\n",
      "Epoch 2321/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8116 - acc: 0.8092 - val_loss: 0.7941 - val_acc: 0.8167\n",
      "Epoch 2322/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8013 - acc: 0.8167 - val_loss: 0.7937 - val_acc: 0.8194\n",
      "Epoch 2323/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8009 - acc: 0.8116 - val_loss: 0.7883 - val_acc: 0.8221\n",
      "Epoch 2324/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7996 - acc: 0.8155 - val_loss: 0.7839 - val_acc: 0.8275\n",
      "Epoch 2325/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8138 - acc: 0.8122 - val_loss: 0.7885 - val_acc: 0.8248\n",
      "Epoch 2326/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7910 - acc: 0.8170 - val_loss: 0.7984 - val_acc: 0.8167\n",
      "Epoch 2327/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7980 - acc: 0.8113 - val_loss: 0.8026 - val_acc: 0.8194\n",
      "Epoch 2328/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8182 - acc: 0.8107 - val_loss: 0.8001 - val_acc: 0.8221\n",
      "Epoch 2329/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8118 - acc: 0.8182 - val_loss: 0.7948 - val_acc: 0.8221\n",
      "Epoch 2330/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8116 - acc: 0.8152 - val_loss: 0.7890 - val_acc: 0.8221\n",
      "Epoch 2331/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8058 - acc: 0.8167 - val_loss: 0.7847 - val_acc: 0.8248\n",
      "Epoch 2332/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7913 - acc: 0.8179 - val_loss: 0.7822 - val_acc: 0.8221\n",
      "Epoch 2333/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8040 - acc: 0.8161 - val_loss: 0.7755 - val_acc: 0.8302\n",
      "Epoch 2334/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7964 - acc: 0.8188 - val_loss: 0.7790 - val_acc: 0.8248\n",
      "Epoch 2335/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7795 - acc: 0.8143 - val_loss: 0.7914 - val_acc: 0.8167\n",
      "Epoch 2336/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8082 - acc: 0.8077 - val_loss: 0.7884 - val_acc: 0.8248\n",
      "Epoch 2337/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8103 - acc: 0.8182 - val_loss: 0.7756 - val_acc: 0.8221\n",
      "Epoch 2338/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7829 - acc: 0.8170 - val_loss: 0.7768 - val_acc: 0.8221\n",
      "Epoch 2339/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7963 - acc: 0.8173 - val_loss: 0.7727 - val_acc: 0.8275\n",
      "Epoch 2340/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7869 - acc: 0.8149 - val_loss: 0.7674 - val_acc: 0.8221\n",
      "Epoch 2341/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7873 - acc: 0.8140 - val_loss: 0.7685 - val_acc: 0.8275\n",
      "Epoch 2342/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8138 - acc: 0.8080 - val_loss: 0.7697 - val_acc: 0.8302\n",
      "Epoch 2343/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7911 - acc: 0.8179 - val_loss: 0.7763 - val_acc: 0.8248\n",
      "Epoch 2344/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7976 - acc: 0.8194 - val_loss: 0.7794 - val_acc: 0.8275\n",
      "Epoch 2345/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8000 - acc: 0.8128 - val_loss: 0.7807 - val_acc: 0.8275\n",
      "Epoch 2346/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8148 - acc: 0.8119 - val_loss: 0.7785 - val_acc: 0.8302\n",
      "Epoch 2347/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8151 - acc: 0.8137 - val_loss: 0.7737 - val_acc: 0.8248\n",
      "Epoch 2348/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7946 - acc: 0.8152 - val_loss: 0.7714 - val_acc: 0.8248\n",
      "Epoch 2349/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7997 - acc: 0.8095 - val_loss: 0.7721 - val_acc: 0.8248\n",
      "Epoch 2350/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8174 - acc: 0.8143 - val_loss: 0.7849 - val_acc: 0.8167\n",
      "Epoch 2351/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7985 - acc: 0.8113 - val_loss: 0.7813 - val_acc: 0.8194\n",
      "Epoch 2352/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7980 - acc: 0.8152 - val_loss: 0.7726 - val_acc: 0.8275\n",
      "Epoch 2353/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8023 - acc: 0.8149 - val_loss: 0.7670 - val_acc: 0.8302\n",
      "Epoch 2354/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8003 - acc: 0.8197 - val_loss: 0.7699 - val_acc: 0.8302\n",
      "Epoch 2355/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7900 - acc: 0.8194 - val_loss: 0.7823 - val_acc: 0.8221\n",
      "Epoch 2356/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8251 - acc: 0.8092 - val_loss: 0.7768 - val_acc: 0.8167\n",
      "Epoch 2357/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8116 - acc: 0.8092 - val_loss: 0.7778 - val_acc: 0.8248\n",
      "Epoch 2358/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8111 - acc: 0.8074 - val_loss: 0.7796 - val_acc: 0.8248\n",
      "Epoch 2359/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8061 - acc: 0.8116 - val_loss: 0.7863 - val_acc: 0.8248\n",
      "Epoch 2360/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8076 - acc: 0.8089 - val_loss: 0.7903 - val_acc: 0.8194\n",
      "Epoch 2361/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7988 - acc: 0.8140 - val_loss: 0.7915 - val_acc: 0.8221\n",
      "Epoch 2362/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7986 - acc: 0.8134 - val_loss: 0.7890 - val_acc: 0.8194\n",
      "Epoch 2363/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7871 - acc: 0.8122 - val_loss: 0.7849 - val_acc: 0.8221\n",
      "Epoch 2364/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8057 - acc: 0.8155 - val_loss: 0.7809 - val_acc: 0.8275\n",
      "Epoch 2365/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7836 - acc: 0.8170 - val_loss: 0.7742 - val_acc: 0.8275\n",
      "Epoch 2366/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8180 - acc: 0.8158 - val_loss: 0.7726 - val_acc: 0.8248\n",
      "Epoch 2367/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8157 - acc: 0.8140 - val_loss: 0.7745 - val_acc: 0.8248\n",
      "Epoch 2368/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8044 - acc: 0.8221 - val_loss: 0.7791 - val_acc: 0.8221\n",
      "Epoch 2369/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8128 - acc: 0.8128 - val_loss: 0.7860 - val_acc: 0.8221\n",
      "Epoch 2370/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8018 - acc: 0.8209 - val_loss: 0.7799 - val_acc: 0.8248\n",
      "Epoch 2371/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8070 - acc: 0.8110 - val_loss: 0.7791 - val_acc: 0.8275\n",
      "Epoch 2372/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7993 - acc: 0.8188 - val_loss: 0.7815 - val_acc: 0.8275\n",
      "Epoch 2373/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7971 - acc: 0.8185 - val_loss: 0.7844 - val_acc: 0.8302\n",
      "Epoch 2374/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7780 - acc: 0.8188 - val_loss: 0.7899 - val_acc: 0.8275\n",
      "Epoch 2375/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8023 - acc: 0.8122 - val_loss: 0.7897 - val_acc: 0.8248\n",
      "Epoch 2376/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7834 - acc: 0.8191 - val_loss: 0.7862 - val_acc: 0.8302\n",
      "Epoch 2377/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8121 - acc: 0.8140 - val_loss: 0.7856 - val_acc: 0.8248\n",
      "Epoch 2378/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7995 - acc: 0.8131 - val_loss: 0.7844 - val_acc: 0.8248\n",
      "Epoch 2379/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7929 - acc: 0.8113 - val_loss: 0.7835 - val_acc: 0.8248\n",
      "Epoch 2380/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7949 - acc: 0.8134 - val_loss: 0.7905 - val_acc: 0.8248\n",
      "Epoch 2381/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7876 - acc: 0.8200 - val_loss: 0.7889 - val_acc: 0.8275\n",
      "Epoch 2382/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7985 - acc: 0.8143 - val_loss: 0.7911 - val_acc: 0.8275\n",
      "Epoch 2383/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8081 - acc: 0.8197 - val_loss: 0.7876 - val_acc: 0.8221\n",
      "Epoch 2384/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8066 - acc: 0.8155 - val_loss: 0.7860 - val_acc: 0.8221\n",
      "Epoch 2385/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8158 - val_loss: 0.7943 - val_acc: 0.8248\n",
      "Epoch 2386/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8102 - acc: 0.8089 - val_loss: 0.7939 - val_acc: 0.8275\n",
      "Epoch 2387/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7979 - acc: 0.8182 - val_loss: 0.7941 - val_acc: 0.8302\n",
      "Epoch 2388/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7919 - acc: 0.8110 - val_loss: 0.7934 - val_acc: 0.8221\n",
      "Epoch 2389/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8170 - val_loss: 0.7944 - val_acc: 0.8302\n",
      "Epoch 2390/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8161 - val_loss: 0.7919 - val_acc: 0.8248\n",
      "Epoch 2391/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8001 - acc: 0.8158 - val_loss: 0.7946 - val_acc: 0.8248\n",
      "Epoch 2392/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7985 - acc: 0.8194 - val_loss: 0.7825 - val_acc: 0.8275\n",
      "Epoch 2393/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7987 - acc: 0.8107 - val_loss: 0.7752 - val_acc: 0.8329\n",
      "Epoch 2394/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8064 - acc: 0.8170 - val_loss: 0.7789 - val_acc: 0.8329\n",
      "Epoch 2395/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7974 - acc: 0.8194 - val_loss: 0.7826 - val_acc: 0.8329\n",
      "Epoch 2396/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7993 - acc: 0.8194 - val_loss: 0.7863 - val_acc: 0.8275\n",
      "Epoch 2397/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7698 - acc: 0.8134 - val_loss: 0.7843 - val_acc: 0.8275\n",
      "Epoch 2398/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7917 - acc: 0.8143 - val_loss: 0.7784 - val_acc: 0.8356\n",
      "Epoch 2399/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8033 - acc: 0.8131 - val_loss: 0.7775 - val_acc: 0.8329\n",
      "Epoch 2400/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8022 - acc: 0.8179 - val_loss: 0.7789 - val_acc: 0.8302\n",
      "Epoch 2401/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7905 - acc: 0.8119 - val_loss: 0.7855 - val_acc: 0.8248\n",
      "Epoch 2402/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8005 - acc: 0.8176 - val_loss: 0.7888 - val_acc: 0.8221\n",
      "Epoch 2403/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7903 - acc: 0.8146 - val_loss: 0.7881 - val_acc: 0.8302\n",
      "Epoch 2404/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8021 - acc: 0.8125 - val_loss: 0.7911 - val_acc: 0.8275\n",
      "Epoch 2405/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8002 - acc: 0.8134 - val_loss: 0.7944 - val_acc: 0.8221\n",
      "Epoch 2406/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8063 - acc: 0.8137 - val_loss: 0.7931 - val_acc: 0.8248\n",
      "Epoch 2407/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7863 - acc: 0.8173 - val_loss: 0.7860 - val_acc: 0.8275\n",
      "Epoch 2408/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8001 - acc: 0.8128 - val_loss: 0.7850 - val_acc: 0.8275\n",
      "Epoch 2409/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8118 - acc: 0.8131 - val_loss: 0.7869 - val_acc: 0.8275\n",
      "Epoch 2410/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7806 - acc: 0.8140 - val_loss: 0.7825 - val_acc: 0.8275\n",
      "Epoch 2411/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8025 - acc: 0.8122 - val_loss: 0.7834 - val_acc: 0.8329\n",
      "Epoch 2412/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7894 - acc: 0.8164 - val_loss: 0.7856 - val_acc: 0.8356\n",
      "Epoch 2413/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7891 - acc: 0.8185 - val_loss: 0.7916 - val_acc: 0.8302\n",
      "Epoch 2414/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8094 - acc: 0.8122 - val_loss: 0.7929 - val_acc: 0.8275\n",
      "Epoch 2415/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8127 - acc: 0.8143 - val_loss: 0.7832 - val_acc: 0.8275\n",
      "Epoch 2416/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7972 - acc: 0.8158 - val_loss: 0.7762 - val_acc: 0.8356\n",
      "Epoch 2417/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7912 - acc: 0.8203 - val_loss: 0.7760 - val_acc: 0.8356\n",
      "Epoch 2418/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8193 - acc: 0.8122 - val_loss: 0.7836 - val_acc: 0.8383\n",
      "Epoch 2419/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7916 - acc: 0.8143 - val_loss: 0.7885 - val_acc: 0.8302\n",
      "Epoch 2420/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8013 - acc: 0.8146 - val_loss: 0.7870 - val_acc: 0.8248\n",
      "Epoch 2421/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8022 - acc: 0.8116 - val_loss: 0.7837 - val_acc: 0.8221\n",
      "Epoch 2422/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8082 - acc: 0.8110 - val_loss: 0.7872 - val_acc: 0.8248\n",
      "Epoch 2423/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7711 - acc: 0.8182 - val_loss: 0.7874 - val_acc: 0.8248\n",
      "Epoch 2424/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7991 - acc: 0.8110 - val_loss: 0.7879 - val_acc: 0.8275\n",
      "Epoch 2425/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7837 - acc: 0.8176 - val_loss: 0.7921 - val_acc: 0.8275\n",
      "Epoch 2426/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7831 - acc: 0.8164 - val_loss: 0.7893 - val_acc: 0.8275\n",
      "Epoch 2427/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8075 - acc: 0.8128 - val_loss: 0.7915 - val_acc: 0.8275\n",
      "Epoch 2428/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8124 - acc: 0.8155 - val_loss: 0.7934 - val_acc: 0.8275\n",
      "Epoch 2429/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8033 - acc: 0.8095 - val_loss: 0.7955 - val_acc: 0.8275\n",
      "Epoch 2430/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7946 - acc: 0.8173 - val_loss: 0.7984 - val_acc: 0.8248\n",
      "Epoch 2431/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8156 - acc: 0.8161 - val_loss: 0.7984 - val_acc: 0.8248\n",
      "Epoch 2432/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7855 - acc: 0.8152 - val_loss: 0.7923 - val_acc: 0.8194\n",
      "Epoch 2433/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7965 - acc: 0.8158 - val_loss: 0.7932 - val_acc: 0.8221\n",
      "Epoch 2434/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8037 - acc: 0.8098 - val_loss: 0.7957 - val_acc: 0.8221\n",
      "Epoch 2435/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8042 - acc: 0.8161 - val_loss: 0.7853 - val_acc: 0.8275\n",
      "Epoch 2436/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7908 - acc: 0.8224 - val_loss: 0.7822 - val_acc: 0.8248\n",
      "Epoch 2437/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7999 - acc: 0.8155 - val_loss: 0.7837 - val_acc: 0.8275\n",
      "Epoch 2438/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7862 - acc: 0.8173 - val_loss: 0.7848 - val_acc: 0.8248\n",
      "Epoch 2439/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8145 - acc: 0.8086 - val_loss: 0.7890 - val_acc: 0.8221\n",
      "Epoch 2440/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8040 - acc: 0.8170 - val_loss: 0.7827 - val_acc: 0.8248\n",
      "Epoch 2441/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8060 - acc: 0.8110 - val_loss: 0.7757 - val_acc: 0.8302\n",
      "Epoch 2442/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7844 - acc: 0.8218 - val_loss: 0.7728 - val_acc: 0.8329\n",
      "Epoch 2443/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8163 - acc: 0.8182 - val_loss: 0.7781 - val_acc: 0.8275\n",
      "Epoch 2444/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8078 - acc: 0.8149 - val_loss: 0.7808 - val_acc: 0.8248\n",
      "Epoch 2445/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7889 - acc: 0.8146 - val_loss: 0.7781 - val_acc: 0.8275\n",
      "Epoch 2446/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8020 - acc: 0.8119 - val_loss: 0.7832 - val_acc: 0.8221\n",
      "Epoch 2447/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7972 - acc: 0.8149 - val_loss: 0.7855 - val_acc: 0.8221\n",
      "Epoch 2448/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7915 - acc: 0.8173 - val_loss: 0.7885 - val_acc: 0.8194\n",
      "Epoch 2449/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8087 - acc: 0.8131 - val_loss: 0.7916 - val_acc: 0.8167\n",
      "Epoch 2450/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7969 - acc: 0.8179 - val_loss: 0.7968 - val_acc: 0.8167\n",
      "Epoch 2451/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8025 - acc: 0.8170 - val_loss: 0.7863 - val_acc: 0.8329\n",
      "Epoch 2452/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7992 - acc: 0.8158 - val_loss: 0.7920 - val_acc: 0.8275\n",
      "Epoch 2453/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7941 - acc: 0.8176 - val_loss: 0.7956 - val_acc: 0.8221\n",
      "Epoch 2454/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8187 - acc: 0.8074 - val_loss: 0.7974 - val_acc: 0.8167\n",
      "Epoch 2455/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7966 - acc: 0.8200 - val_loss: 0.7925 - val_acc: 0.8248\n",
      "Epoch 2456/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7941 - acc: 0.8164 - val_loss: 0.7874 - val_acc: 0.8248\n",
      "Epoch 2457/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7912 - acc: 0.8170 - val_loss: 0.7884 - val_acc: 0.8248\n",
      "Epoch 2458/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8201 - acc: 0.8095 - val_loss: 0.7893 - val_acc: 0.8302\n",
      "Epoch 2459/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8070 - acc: 0.8185 - val_loss: 0.7947 - val_acc: 0.8248\n",
      "Epoch 2460/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8306 - acc: 0.8116 - val_loss: 0.8010 - val_acc: 0.8194\n",
      "Epoch 2461/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8023 - acc: 0.8137 - val_loss: 0.7861 - val_acc: 0.8275\n",
      "Epoch 2462/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8029 - acc: 0.8089 - val_loss: 0.7776 - val_acc: 0.8329\n",
      "Epoch 2463/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7898 - acc: 0.8152 - val_loss: 0.7794 - val_acc: 0.8248\n",
      "Epoch 2464/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8075 - acc: 0.8173 - val_loss: 0.7883 - val_acc: 0.8248\n",
      "Epoch 2465/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8044 - acc: 0.8107 - val_loss: 0.7840 - val_acc: 0.8302\n",
      "Epoch 2466/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8035 - acc: 0.8131 - val_loss: 0.7782 - val_acc: 0.8275\n",
      "Epoch 2467/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7864 - acc: 0.8161 - val_loss: 0.7833 - val_acc: 0.8302\n",
      "Epoch 2468/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8014 - acc: 0.8119 - val_loss: 0.7830 - val_acc: 0.8302\n",
      "Epoch 2469/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8023 - acc: 0.8107 - val_loss: 0.7727 - val_acc: 0.8275\n",
      "Epoch 2470/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7996 - acc: 0.8080 - val_loss: 0.7672 - val_acc: 0.8302\n",
      "Epoch 2471/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7924 - acc: 0.8137 - val_loss: 0.7770 - val_acc: 0.8356\n",
      "Epoch 2472/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7931 - acc: 0.8161 - val_loss: 0.7827 - val_acc: 0.8302\n",
      "Epoch 2473/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8086 - acc: 0.8140 - val_loss: 0.7848 - val_acc: 0.8275\n",
      "Epoch 2474/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7811 - acc: 0.8233 - val_loss: 0.7931 - val_acc: 0.8275\n",
      "Epoch 2475/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7863 - acc: 0.8197 - val_loss: 0.7845 - val_acc: 0.8248\n",
      "Epoch 2476/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8059 - acc: 0.8125 - val_loss: 0.7748 - val_acc: 0.8248\n",
      "Epoch 2477/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7979 - acc: 0.8152 - val_loss: 0.7675 - val_acc: 0.8275\n",
      "Epoch 2478/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7893 - acc: 0.8134 - val_loss: 0.7695 - val_acc: 0.8302\n",
      "Epoch 2479/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8044 - acc: 0.8116 - val_loss: 0.7731 - val_acc: 0.8329\n",
      "Epoch 2480/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8036 - acc: 0.8116 - val_loss: 0.7839 - val_acc: 0.8302\n",
      "Epoch 2481/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8010 - acc: 0.8146 - val_loss: 0.7850 - val_acc: 0.8302\n",
      "Epoch 2482/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7992 - acc: 0.8134 - val_loss: 0.7938 - val_acc: 0.8275\n",
      "Epoch 2483/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8091 - acc: 0.8146 - val_loss: 0.7969 - val_acc: 0.8275\n",
      "Epoch 2484/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8208 - acc: 0.8116 - val_loss: 0.7916 - val_acc: 0.8302\n",
      "Epoch 2485/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8048 - acc: 0.8134 - val_loss: 0.7839 - val_acc: 0.8302\n",
      "Epoch 2486/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8027 - acc: 0.8131 - val_loss: 0.7778 - val_acc: 0.8248\n",
      "Epoch 2487/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7908 - acc: 0.8173 - val_loss: 0.7793 - val_acc: 0.8221\n",
      "Epoch 2488/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8021 - acc: 0.8095 - val_loss: 0.7839 - val_acc: 0.8248\n",
      "Epoch 2489/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8019 - acc: 0.8158 - val_loss: 0.7872 - val_acc: 0.8167\n",
      "Epoch 2490/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8190 - acc: 0.8125 - val_loss: 0.7846 - val_acc: 0.8248\n",
      "Epoch 2491/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8019 - acc: 0.8179 - val_loss: 0.7935 - val_acc: 0.8221\n",
      "Epoch 2492/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7988 - acc: 0.8194 - val_loss: 0.8091 - val_acc: 0.8167\n",
      "Epoch 2493/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7922 - acc: 0.8137 - val_loss: 0.8080 - val_acc: 0.8194\n",
      "Epoch 2494/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8031 - acc: 0.8173 - val_loss: 0.7962 - val_acc: 0.8275\n",
      "Epoch 2495/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7767 - acc: 0.8131 - val_loss: 0.7849 - val_acc: 0.8302\n",
      "Epoch 2496/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7995 - acc: 0.8185 - val_loss: 0.7854 - val_acc: 0.8329\n",
      "Epoch 2497/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8090 - acc: 0.8113 - val_loss: 0.7871 - val_acc: 0.8275\n",
      "Epoch 2498/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7895 - acc: 0.8185 - val_loss: 0.7861 - val_acc: 0.8194\n",
      "Epoch 2499/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7960 - acc: 0.8197 - val_loss: 0.7836 - val_acc: 0.8248\n",
      "Epoch 2500/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7994 - acc: 0.8122 - val_loss: 0.7759 - val_acc: 0.8275\n",
      "Epoch 2501/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7946 - acc: 0.8170 - val_loss: 0.7677 - val_acc: 0.8275\n",
      "Epoch 2502/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7992 - acc: 0.8212 - val_loss: 0.7675 - val_acc: 0.8302\n",
      "Epoch 2503/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8005 - acc: 0.8122 - val_loss: 0.7722 - val_acc: 0.8329\n",
      "Epoch 2504/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8019 - acc: 0.8149 - val_loss: 0.7757 - val_acc: 0.8248\n",
      "Epoch 2505/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8161 - val_loss: 0.7756 - val_acc: 0.8248\n",
      "Epoch 2506/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8067 - acc: 0.8101 - val_loss: 0.7656 - val_acc: 0.8248\n",
      "Epoch 2507/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7986 - acc: 0.8134 - val_loss: 0.7698 - val_acc: 0.8275\n",
      "Epoch 2508/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8022 - acc: 0.8179 - val_loss: 0.7775 - val_acc: 0.8194\n",
      "Epoch 2509/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7922 - acc: 0.8137 - val_loss: 0.7856 - val_acc: 0.8167\n",
      "Epoch 2510/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7988 - acc: 0.8170 - val_loss: 0.7858 - val_acc: 0.8194\n",
      "Epoch 2511/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8152 - val_loss: 0.7815 - val_acc: 0.8248\n",
      "Epoch 2512/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7830 - acc: 0.8182 - val_loss: 0.7812 - val_acc: 0.8302\n",
      "Epoch 2513/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7942 - acc: 0.8131 - val_loss: 0.7816 - val_acc: 0.8302\n",
      "Epoch 2514/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.8134 - acc: 0.8143 - val_loss: 0.7856 - val_acc: 0.8221\n",
      "Epoch 2515/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8095 - val_loss: 0.7811 - val_acc: 0.8275\n",
      "Epoch 2516/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8098 - acc: 0.8152 - val_loss: 0.7751 - val_acc: 0.8194\n",
      "Epoch 2517/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8143 - acc: 0.8110 - val_loss: 0.7814 - val_acc: 0.8221\n",
      "Epoch 2518/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8071 - acc: 0.8107 - val_loss: 0.7823 - val_acc: 0.8167\n",
      "Epoch 2519/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7864 - acc: 0.8086 - val_loss: 0.7772 - val_acc: 0.8275\n",
      "Epoch 2520/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7968 - acc: 0.8218 - val_loss: 0.7755 - val_acc: 0.8194\n",
      "Epoch 2521/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8119 - val_loss: 0.7772 - val_acc: 0.8221\n",
      "Epoch 2522/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8344 - acc: 0.8113 - val_loss: 0.7716 - val_acc: 0.8194\n",
      "Epoch 2523/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8164 - acc: 0.8125 - val_loss: 0.7738 - val_acc: 0.8140\n",
      "Epoch 2524/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7768 - acc: 0.8194 - val_loss: 0.7736 - val_acc: 0.8194\n",
      "Epoch 2525/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8158 - val_loss: 0.7773 - val_acc: 0.8221\n",
      "Epoch 2526/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8082 - acc: 0.8137 - val_loss: 0.7877 - val_acc: 0.8248\n",
      "Epoch 2527/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7928 - acc: 0.8164 - val_loss: 0.7846 - val_acc: 0.8248\n",
      "Epoch 2528/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8152 - val_loss: 0.7763 - val_acc: 0.8302\n",
      "Epoch 2529/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7953 - acc: 0.8092 - val_loss: 0.7729 - val_acc: 0.8302\n",
      "Epoch 2530/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7864 - acc: 0.8173 - val_loss: 0.7718 - val_acc: 0.8302\n",
      "Epoch 2531/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8030 - acc: 0.8140 - val_loss: 0.7667 - val_acc: 0.8302\n",
      "Epoch 2532/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7840 - acc: 0.8128 - val_loss: 0.7632 - val_acc: 0.8329\n",
      "Epoch 2533/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8071 - acc: 0.8164 - val_loss: 0.7641 - val_acc: 0.8248\n",
      "Epoch 2534/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7805 - acc: 0.8152 - val_loss: 0.7687 - val_acc: 0.8221\n",
      "Epoch 2535/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8093 - acc: 0.8173 - val_loss: 0.7666 - val_acc: 0.8248\n",
      "Epoch 2536/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8000 - acc: 0.8182 - val_loss: 0.7660 - val_acc: 0.8275\n",
      "Epoch 2537/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7987 - acc: 0.8227 - val_loss: 0.7662 - val_acc: 0.8275\n",
      "Epoch 2538/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7895 - acc: 0.8167 - val_loss: 0.7739 - val_acc: 0.8275\n",
      "Epoch 2539/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8029 - acc: 0.8116 - val_loss: 0.7851 - val_acc: 0.8248\n",
      "Epoch 2540/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8132 - acc: 0.8089 - val_loss: 0.7836 - val_acc: 0.8329\n",
      "Epoch 2541/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7792 - acc: 0.8134 - val_loss: 0.7842 - val_acc: 0.8302\n",
      "Epoch 2542/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8012 - acc: 0.8188 - val_loss: 0.7792 - val_acc: 0.8329\n",
      "Epoch 2543/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8151 - acc: 0.8128 - val_loss: 0.7820 - val_acc: 0.8275\n",
      "Epoch 2544/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7958 - acc: 0.8182 - val_loss: 0.7833 - val_acc: 0.8275\n",
      "Epoch 2545/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7924 - acc: 0.8089 - val_loss: 0.7824 - val_acc: 0.8275\n",
      "Epoch 2546/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8041 - acc: 0.8161 - val_loss: 0.7760 - val_acc: 0.8275\n",
      "Epoch 2547/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7974 - acc: 0.8146 - val_loss: 0.7724 - val_acc: 0.8275\n",
      "Epoch 2548/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7994 - acc: 0.8179 - val_loss: 0.7732 - val_acc: 0.8248\n",
      "Epoch 2549/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7945 - acc: 0.8146 - val_loss: 0.7712 - val_acc: 0.8248\n",
      "Epoch 2550/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7958 - acc: 0.8203 - val_loss: 0.7747 - val_acc: 0.8221\n",
      "Epoch 2551/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8036 - acc: 0.8155 - val_loss: 0.7834 - val_acc: 0.8248\n",
      "Epoch 2552/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7913 - acc: 0.8215 - val_loss: 0.7884 - val_acc: 0.8221\n",
      "Epoch 2553/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8021 - acc: 0.8092 - val_loss: 0.7870 - val_acc: 0.8248\n",
      "Epoch 2554/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8099 - acc: 0.8128 - val_loss: 0.7842 - val_acc: 0.8248\n",
      "Epoch 2555/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8091 - acc: 0.8083 - val_loss: 0.7840 - val_acc: 0.8275\n",
      "Epoch 2556/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8093 - acc: 0.8137 - val_loss: 0.7874 - val_acc: 0.8302\n",
      "Epoch 2557/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7932 - acc: 0.8140 - val_loss: 0.7890 - val_acc: 0.8302\n",
      "Epoch 2558/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7903 - acc: 0.8134 - val_loss: 0.7797 - val_acc: 0.8248\n",
      "Epoch 2559/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7945 - acc: 0.8155 - val_loss: 0.7757 - val_acc: 0.8221\n",
      "Epoch 2560/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8114 - acc: 0.8152 - val_loss: 0.7749 - val_acc: 0.8221\n",
      "Epoch 2561/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8023 - acc: 0.8122 - val_loss: 0.7744 - val_acc: 0.8248\n",
      "Epoch 2562/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7740 - acc: 0.8134 - val_loss: 0.7709 - val_acc: 0.8329\n",
      "Epoch 2563/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8124 - acc: 0.8164 - val_loss: 0.7754 - val_acc: 0.8275\n",
      "Epoch 2564/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7875 - acc: 0.8125 - val_loss: 0.7809 - val_acc: 0.8248\n",
      "Epoch 2565/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8173 - val_loss: 0.7879 - val_acc: 0.8221\n",
      "Epoch 2566/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8081 - acc: 0.8161 - val_loss: 0.7857 - val_acc: 0.8194\n",
      "Epoch 2567/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8029 - acc: 0.8122 - val_loss: 0.7853 - val_acc: 0.8275\n",
      "Epoch 2568/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7949 - acc: 0.8137 - val_loss: 0.7874 - val_acc: 0.8275\n",
      "Epoch 2569/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8026 - acc: 0.8143 - val_loss: 0.7883 - val_acc: 0.8275\n",
      "Epoch 2570/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8085 - acc: 0.8110 - val_loss: 0.7878 - val_acc: 0.8302\n",
      "Epoch 2571/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7933 - acc: 0.8200 - val_loss: 0.7934 - val_acc: 0.8275\n",
      "Epoch 2572/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7816 - acc: 0.8173 - val_loss: 0.7971 - val_acc: 0.8248\n",
      "Epoch 2573/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8045 - acc: 0.8164 - val_loss: 0.7948 - val_acc: 0.8275\n",
      "Epoch 2574/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8079 - acc: 0.8161 - val_loss: 0.7886 - val_acc: 0.8194\n",
      "Epoch 2575/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8197 - acc: 0.8104 - val_loss: 0.7737 - val_acc: 0.8248\n",
      "Epoch 2576/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7971 - acc: 0.8098 - val_loss: 0.7753 - val_acc: 0.8248\n",
      "Epoch 2577/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7964 - acc: 0.8149 - val_loss: 0.7836 - val_acc: 0.8302\n",
      "Epoch 2578/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8035 - acc: 0.8116 - val_loss: 0.7861 - val_acc: 0.8302\n",
      "Epoch 2579/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8022 - acc: 0.8092 - val_loss: 0.7910 - val_acc: 0.8248\n",
      "Epoch 2580/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7982 - acc: 0.8191 - val_loss: 0.7893 - val_acc: 0.8194\n",
      "Epoch 2581/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7762 - acc: 0.8170 - val_loss: 0.7928 - val_acc: 0.8194\n",
      "Epoch 2582/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7876 - acc: 0.8215 - val_loss: 0.7942 - val_acc: 0.8194\n",
      "Epoch 2583/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8060 - acc: 0.8167 - val_loss: 0.7919 - val_acc: 0.8221\n",
      "Epoch 2584/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7951 - acc: 0.8119 - val_loss: 0.7942 - val_acc: 0.8302\n",
      "Epoch 2585/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8036 - acc: 0.8113 - val_loss: 0.7952 - val_acc: 0.8275\n",
      "Epoch 2586/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7944 - acc: 0.8152 - val_loss: 0.8014 - val_acc: 0.8194\n",
      "Epoch 2587/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8074 - acc: 0.8089 - val_loss: 0.8047 - val_acc: 0.8248\n",
      "Epoch 2588/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7868 - acc: 0.8143 - val_loss: 0.7953 - val_acc: 0.8302\n",
      "Epoch 2589/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7897 - acc: 0.8185 - val_loss: 0.7966 - val_acc: 0.8329\n",
      "Epoch 2590/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7849 - acc: 0.8140 - val_loss: 0.8010 - val_acc: 0.8248\n",
      "Epoch 2591/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7859 - acc: 0.8152 - val_loss: 0.7962 - val_acc: 0.8248\n",
      "Epoch 2592/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7872 - acc: 0.8116 - val_loss: 0.7919 - val_acc: 0.8248\n",
      "Epoch 2593/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8013 - acc: 0.8137 - val_loss: 0.7995 - val_acc: 0.8194\n",
      "Epoch 2594/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8078 - acc: 0.8110 - val_loss: 0.8060 - val_acc: 0.8167\n",
      "Epoch 2595/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7969 - acc: 0.8146 - val_loss: 0.8031 - val_acc: 0.8167\n",
      "Epoch 2596/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8044 - acc: 0.8170 - val_loss: 0.7936 - val_acc: 0.8194\n",
      "Epoch 2597/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7897 - acc: 0.8164 - val_loss: 0.7869 - val_acc: 0.8329\n",
      "Epoch 2598/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7920 - acc: 0.8164 - val_loss: 0.7931 - val_acc: 0.8221\n",
      "Epoch 2599/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8090 - acc: 0.8146 - val_loss: 0.7947 - val_acc: 0.8194\n",
      "Epoch 2600/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8131 - val_loss: 0.7934 - val_acc: 0.8167\n",
      "Epoch 2601/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7881 - acc: 0.8104 - val_loss: 0.7849 - val_acc: 0.8275\n",
      "Epoch 2602/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7856 - acc: 0.8179 - val_loss: 0.7846 - val_acc: 0.8302\n",
      "Epoch 2603/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8117 - acc: 0.8134 - val_loss: 0.7893 - val_acc: 0.8248\n",
      "Epoch 2604/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7926 - acc: 0.8134 - val_loss: 0.7895 - val_acc: 0.8275\n",
      "Epoch 2605/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7961 - acc: 0.8128 - val_loss: 0.7899 - val_acc: 0.8194\n",
      "Epoch 2606/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8087 - acc: 0.8188 - val_loss: 0.7910 - val_acc: 0.8221\n",
      "Epoch 2607/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8031 - acc: 0.8161 - val_loss: 0.7950 - val_acc: 0.8221\n",
      "Epoch 2608/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8107 - val_loss: 0.7928 - val_acc: 0.8194\n",
      "Epoch 2609/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7975 - acc: 0.8140 - val_loss: 0.7894 - val_acc: 0.8194\n",
      "Epoch 2610/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8075 - acc: 0.8188 - val_loss: 0.7849 - val_acc: 0.8275\n",
      "Epoch 2611/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8060 - acc: 0.8083 - val_loss: 0.7816 - val_acc: 0.8221\n",
      "Epoch 2612/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7931 - acc: 0.8206 - val_loss: 0.7897 - val_acc: 0.8194\n",
      "Epoch 2613/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7975 - acc: 0.8146 - val_loss: 0.7919 - val_acc: 0.8194\n",
      "Epoch 2614/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8209 - acc: 0.8098 - val_loss: 0.7904 - val_acc: 0.8221\n",
      "Epoch 2615/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7909 - acc: 0.8131 - val_loss: 0.7830 - val_acc: 0.8248\n",
      "Epoch 2616/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7693 - acc: 0.8185 - val_loss: 0.7818 - val_acc: 0.8167\n",
      "Epoch 2617/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8134 - val_loss: 0.7813 - val_acc: 0.8221\n",
      "Epoch 2618/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8062 - acc: 0.8104 - val_loss: 0.7860 - val_acc: 0.8275\n",
      "Epoch 2619/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7852 - acc: 0.8209 - val_loss: 0.7934 - val_acc: 0.8248\n",
      "Epoch 2620/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7969 - acc: 0.8146 - val_loss: 0.7925 - val_acc: 0.8248\n",
      "Epoch 2621/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8022 - acc: 0.8152 - val_loss: 0.7951 - val_acc: 0.8221\n",
      "Epoch 2622/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8149 - val_loss: 0.7925 - val_acc: 0.8221\n",
      "Epoch 2623/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7981 - acc: 0.8170 - val_loss: 0.7865 - val_acc: 0.8275\n",
      "Epoch 2624/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8042 - acc: 0.8149 - val_loss: 0.7857 - val_acc: 0.8248\n",
      "Epoch 2625/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8293 - acc: 0.8086 - val_loss: 0.7815 - val_acc: 0.8275\n",
      "Epoch 2626/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7993 - acc: 0.8170 - val_loss: 0.7813 - val_acc: 0.8194\n",
      "Epoch 2627/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8012 - acc: 0.8152 - val_loss: 0.7805 - val_acc: 0.8194\n",
      "Epoch 2628/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7810 - acc: 0.8176 - val_loss: 0.7791 - val_acc: 0.8275\n",
      "Epoch 2629/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8050 - acc: 0.8107 - val_loss: 0.7831 - val_acc: 0.8248\n",
      "Epoch 2630/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8125 - val_loss: 0.7917 - val_acc: 0.8248\n",
      "Epoch 2631/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8037 - acc: 0.8170 - val_loss: 0.7910 - val_acc: 0.8248\n",
      "Epoch 2632/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8188 - val_loss: 0.7830 - val_acc: 0.8302\n",
      "Epoch 2633/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7854 - acc: 0.8083 - val_loss: 0.7773 - val_acc: 0.8329\n",
      "Epoch 2634/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7992 - acc: 0.8101 - val_loss: 0.7755 - val_acc: 0.8383\n",
      "Epoch 2635/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8143 - val_loss: 0.7809 - val_acc: 0.8329\n",
      "Epoch 2636/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8108 - acc: 0.8143 - val_loss: 0.7851 - val_acc: 0.8248\n",
      "Epoch 2637/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7960 - acc: 0.8143 - val_loss: 0.7854 - val_acc: 0.8221\n",
      "Epoch 2638/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8134 - acc: 0.8092 - val_loss: 0.7907 - val_acc: 0.8167\n",
      "Epoch 2639/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8050 - acc: 0.8131 - val_loss: 0.7884 - val_acc: 0.8275\n",
      "Epoch 2640/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7979 - acc: 0.8119 - val_loss: 0.7864 - val_acc: 0.8302\n",
      "Epoch 2641/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7835 - acc: 0.8137 - val_loss: 0.7904 - val_acc: 0.8221\n",
      "Epoch 2642/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7938 - acc: 0.8101 - val_loss: 0.7958 - val_acc: 0.8221\n",
      "Epoch 2643/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7796 - acc: 0.8206 - val_loss: 0.7953 - val_acc: 0.8275\n",
      "Epoch 2644/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7940 - acc: 0.8167 - val_loss: 0.7876 - val_acc: 0.8248\n",
      "Epoch 2645/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7959 - acc: 0.8203 - val_loss: 0.7845 - val_acc: 0.8275\n",
      "Epoch 2646/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8013 - acc: 0.8101 - val_loss: 0.7882 - val_acc: 0.8329\n",
      "Epoch 2647/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8069 - acc: 0.8152 - val_loss: 0.7963 - val_acc: 0.8248\n",
      "Epoch 2648/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8040 - acc: 0.8185 - val_loss: 0.7996 - val_acc: 0.8248\n",
      "Epoch 2649/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7997 - acc: 0.8152 - val_loss: 0.8009 - val_acc: 0.8302\n",
      "Epoch 2650/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8056 - acc: 0.8119 - val_loss: 0.7917 - val_acc: 0.8356\n",
      "Epoch 2651/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7814 - acc: 0.8149 - val_loss: 0.7840 - val_acc: 0.8329\n",
      "Epoch 2652/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8006 - acc: 0.8164 - val_loss: 0.7837 - val_acc: 0.8275\n",
      "Epoch 2653/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7951 - acc: 0.8170 - val_loss: 0.7844 - val_acc: 0.8329\n",
      "Epoch 2654/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7972 - acc: 0.8143 - val_loss: 0.7866 - val_acc: 0.8248\n",
      "Epoch 2655/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7886 - acc: 0.8182 - val_loss: 0.7849 - val_acc: 0.8194\n",
      "Epoch 2656/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7958 - acc: 0.8161 - val_loss: 0.7704 - val_acc: 0.8329\n",
      "Epoch 2657/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8131 - val_loss: 0.7662 - val_acc: 0.8329\n",
      "Epoch 2658/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7960 - acc: 0.8086 - val_loss: 0.7758 - val_acc: 0.8275\n",
      "Epoch 2659/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7933 - acc: 0.8107 - val_loss: 0.7807 - val_acc: 0.8275\n",
      "Epoch 2660/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7991 - acc: 0.8107 - val_loss: 0.7764 - val_acc: 0.8248\n",
      "Epoch 2661/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7987 - acc: 0.8161 - val_loss: 0.7731 - val_acc: 0.8275\n",
      "Epoch 2662/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7839 - acc: 0.8179 - val_loss: 0.7825 - val_acc: 0.8275\n",
      "Epoch 2663/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8131 - acc: 0.8113 - val_loss: 0.7942 - val_acc: 0.8275\n",
      "Epoch 2664/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.8050 - acc: 0.8158 - val_loss: 0.7922 - val_acc: 0.8248\n",
      "Epoch 2665/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7997 - acc: 0.8143 - val_loss: 0.7830 - val_acc: 0.8248\n",
      "Epoch 2666/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7975 - acc: 0.8161 - val_loss: 0.7758 - val_acc: 0.8302\n",
      "Epoch 2667/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7975 - acc: 0.8161 - val_loss: 0.7744 - val_acc: 0.8302\n",
      "Epoch 2668/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7921 - acc: 0.8158 - val_loss: 0.7785 - val_acc: 0.8302\n",
      "Epoch 2669/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7884 - acc: 0.8215 - val_loss: 0.7830 - val_acc: 0.8275\n",
      "Epoch 2670/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8093 - acc: 0.8170 - val_loss: 0.7850 - val_acc: 0.8302\n",
      "Epoch 2671/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7927 - acc: 0.8167 - val_loss: 0.7892 - val_acc: 0.8329\n",
      "Epoch 2672/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7736 - acc: 0.8164 - val_loss: 0.7958 - val_acc: 0.8302\n",
      "Epoch 2673/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7852 - acc: 0.8164 - val_loss: 0.7947 - val_acc: 0.8302\n",
      "Epoch 2674/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7963 - acc: 0.8074 - val_loss: 0.7919 - val_acc: 0.8275\n",
      "Epoch 2675/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8059 - acc: 0.8107 - val_loss: 0.7940 - val_acc: 0.8194\n",
      "Epoch 2676/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7980 - acc: 0.8104 - val_loss: 0.7981 - val_acc: 0.8194\n",
      "Epoch 2677/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7986 - acc: 0.8122 - val_loss: 0.7874 - val_acc: 0.8221\n",
      "Epoch 2678/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8050 - acc: 0.8185 - val_loss: 0.7806 - val_acc: 0.8221\n",
      "Epoch 2679/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7993 - acc: 0.8125 - val_loss: 0.7803 - val_acc: 0.8167\n",
      "Epoch 2680/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8029 - acc: 0.8200 - val_loss: 0.7758 - val_acc: 0.8194\n",
      "Epoch 2681/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7940 - acc: 0.8164 - val_loss: 0.7774 - val_acc: 0.8167\n",
      "Epoch 2682/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7883 - acc: 0.8173 - val_loss: 0.7741 - val_acc: 0.8275\n",
      "Epoch 2683/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8109 - acc: 0.8101 - val_loss: 0.7755 - val_acc: 0.8221\n",
      "Epoch 2684/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8009 - acc: 0.8164 - val_loss: 0.7816 - val_acc: 0.8248\n",
      "Epoch 2685/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8011 - acc: 0.8119 - val_loss: 0.7845 - val_acc: 0.8140\n",
      "Epoch 2686/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7922 - acc: 0.8149 - val_loss: 0.7824 - val_acc: 0.8221\n",
      "Epoch 2687/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7843 - acc: 0.8176 - val_loss: 0.7783 - val_acc: 0.8248\n",
      "Epoch 2688/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8054 - acc: 0.8185 - val_loss: 0.7835 - val_acc: 0.8275\n",
      "Epoch 2689/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7926 - acc: 0.8128 - val_loss: 0.7917 - val_acc: 0.8275\n",
      "Epoch 2690/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8100 - acc: 0.8167 - val_loss: 0.7928 - val_acc: 0.8221\n",
      "Epoch 2691/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7992 - acc: 0.8089 - val_loss: 0.7898 - val_acc: 0.8221\n",
      "Epoch 2692/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8063 - acc: 0.8131 - val_loss: 0.7835 - val_acc: 0.8329\n",
      "Epoch 2693/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7939 - acc: 0.8146 - val_loss: 0.7740 - val_acc: 0.8329\n",
      "Epoch 2694/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7896 - acc: 0.8167 - val_loss: 0.7766 - val_acc: 0.8302\n",
      "Epoch 2695/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8143 - val_loss: 0.7814 - val_acc: 0.8302\n",
      "Epoch 2696/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8155 - val_loss: 0.7790 - val_acc: 0.8383\n",
      "Epoch 2697/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8182 - val_loss: 0.7863 - val_acc: 0.8275\n",
      "Epoch 2698/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7878 - acc: 0.8194 - val_loss: 0.7917 - val_acc: 0.8194\n",
      "Epoch 2699/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7936 - acc: 0.8197 - val_loss: 0.7956 - val_acc: 0.8221\n",
      "Epoch 2700/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8164 - acc: 0.8056 - val_loss: 0.7915 - val_acc: 0.8248\n",
      "Epoch 2701/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8158 - val_loss: 0.7893 - val_acc: 0.8140\n",
      "Epoch 2702/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7997 - acc: 0.8161 - val_loss: 0.7907 - val_acc: 0.8221\n",
      "Epoch 2703/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8026 - acc: 0.8104 - val_loss: 0.7892 - val_acc: 0.8248\n",
      "Epoch 2704/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7879 - acc: 0.8137 - val_loss: 0.7945 - val_acc: 0.8275\n",
      "Epoch 2705/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8032 - acc: 0.8116 - val_loss: 0.8018 - val_acc: 0.8248\n",
      "Epoch 2706/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7856 - acc: 0.8167 - val_loss: 0.7987 - val_acc: 0.8275\n",
      "Epoch 2707/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7844 - acc: 0.8158 - val_loss: 0.7972 - val_acc: 0.8329\n",
      "Epoch 2708/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8026 - acc: 0.8167 - val_loss: 0.8006 - val_acc: 0.8356\n",
      "Epoch 2709/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7920 - acc: 0.8188 - val_loss: 0.8021 - val_acc: 0.8302\n",
      "Epoch 2710/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8016 - acc: 0.8158 - val_loss: 0.7975 - val_acc: 0.8221\n",
      "Epoch 2711/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7912 - acc: 0.8170 - val_loss: 0.7974 - val_acc: 0.8221\n",
      "Epoch 2712/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7982 - acc: 0.8191 - val_loss: 0.7934 - val_acc: 0.8248\n",
      "Epoch 2713/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8039 - acc: 0.8167 - val_loss: 0.7947 - val_acc: 0.8248\n",
      "Epoch 2714/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7924 - acc: 0.8143 - val_loss: 0.7889 - val_acc: 0.8329\n",
      "Epoch 2715/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8113 - acc: 0.8137 - val_loss: 0.7817 - val_acc: 0.8356\n",
      "Epoch 2716/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8022 - acc: 0.8131 - val_loss: 0.7747 - val_acc: 0.8383\n",
      "Epoch 2717/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8072 - acc: 0.8101 - val_loss: 0.7795 - val_acc: 0.8275\n",
      "Epoch 2718/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8075 - acc: 0.8146 - val_loss: 0.7874 - val_acc: 0.8275\n",
      "Epoch 2719/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7954 - acc: 0.8098 - val_loss: 0.7940 - val_acc: 0.8302\n",
      "Epoch 2720/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7887 - acc: 0.8176 - val_loss: 0.7931 - val_acc: 0.8248\n",
      "Epoch 2721/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7925 - acc: 0.8188 - val_loss: 0.7843 - val_acc: 0.8275\n",
      "Epoch 2722/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8140 - val_loss: 0.7819 - val_acc: 0.8302\n",
      "Epoch 2723/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8149 - val_loss: 0.7884 - val_acc: 0.8275\n",
      "Epoch 2724/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7942 - acc: 0.8116 - val_loss: 0.7915 - val_acc: 0.8356\n",
      "Epoch 2725/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7883 - acc: 0.8158 - val_loss: 0.7936 - val_acc: 0.8302\n",
      "Epoch 2726/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7996 - acc: 0.8170 - val_loss: 0.7965 - val_acc: 0.8302\n",
      "Epoch 2727/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8085 - acc: 0.8095 - val_loss: 0.7952 - val_acc: 0.8248\n",
      "Epoch 2728/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8045 - acc: 0.8149 - val_loss: 0.7971 - val_acc: 0.8194\n",
      "Epoch 2729/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8016 - acc: 0.8161 - val_loss: 0.7913 - val_acc: 0.8167\n",
      "Epoch 2730/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8051 - acc: 0.8101 - val_loss: 0.7756 - val_acc: 0.8302\n",
      "Epoch 2731/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8182 - val_loss: 0.7727 - val_acc: 0.8302\n",
      "Epoch 2732/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7975 - acc: 0.8131 - val_loss: 0.7772 - val_acc: 0.8329\n",
      "Epoch 2733/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7877 - acc: 0.8194 - val_loss: 0.7824 - val_acc: 0.8329\n",
      "Epoch 2734/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7827 - acc: 0.8128 - val_loss: 0.7770 - val_acc: 0.8329\n",
      "Epoch 2735/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7844 - acc: 0.8134 - val_loss: 0.7775 - val_acc: 0.8329\n",
      "Epoch 2736/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7993 - acc: 0.8140 - val_loss: 0.7765 - val_acc: 0.8302\n",
      "Epoch 2737/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7938 - acc: 0.8173 - val_loss: 0.7777 - val_acc: 0.8383\n",
      "Epoch 2738/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8140 - acc: 0.8161 - val_loss: 0.7772 - val_acc: 0.8329\n",
      "Epoch 2739/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8041 - acc: 0.8107 - val_loss: 0.7794 - val_acc: 0.8275\n",
      "Epoch 2740/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7947 - acc: 0.8122 - val_loss: 0.7854 - val_acc: 0.8275\n",
      "Epoch 2741/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8169 - acc: 0.8107 - val_loss: 0.7854 - val_acc: 0.8275\n",
      "Epoch 2742/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8026 - acc: 0.8149 - val_loss: 0.7781 - val_acc: 0.8248\n",
      "Epoch 2743/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8004 - acc: 0.8131 - val_loss: 0.7782 - val_acc: 0.8221\n",
      "Epoch 2744/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7993 - acc: 0.8179 - val_loss: 0.7827 - val_acc: 0.8167\n",
      "Epoch 2745/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8161 - val_loss: 0.7862 - val_acc: 0.8167\n",
      "Epoch 2746/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8150 - acc: 0.8089 - val_loss: 0.7864 - val_acc: 0.8221\n",
      "Epoch 2747/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7954 - acc: 0.8167 - val_loss: 0.7803 - val_acc: 0.8275\n",
      "Epoch 2748/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8044 - acc: 0.8161 - val_loss: 0.7791 - val_acc: 0.8302\n",
      "Epoch 2749/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8177 - acc: 0.8104 - val_loss: 0.7770 - val_acc: 0.8221\n",
      "Epoch 2750/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7958 - acc: 0.8191 - val_loss: 0.7732 - val_acc: 0.8275\n",
      "Epoch 2751/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8158 - val_loss: 0.7754 - val_acc: 0.8275\n",
      "Epoch 2752/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8093 - acc: 0.8158 - val_loss: 0.7816 - val_acc: 0.8275\n",
      "Epoch 2753/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8042 - acc: 0.8113 - val_loss: 0.7877 - val_acc: 0.8248\n",
      "Epoch 2754/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7931 - acc: 0.8179 - val_loss: 0.7892 - val_acc: 0.8194\n",
      "Epoch 2755/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8019 - acc: 0.8206 - val_loss: 0.7865 - val_acc: 0.8248\n",
      "Epoch 2756/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8057 - acc: 0.8059 - val_loss: 0.7849 - val_acc: 0.8221\n",
      "Epoch 2757/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8078 - acc: 0.8143 - val_loss: 0.7833 - val_acc: 0.8194\n",
      "Epoch 2758/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8092 - acc: 0.8137 - val_loss: 0.7890 - val_acc: 0.8167\n",
      "Epoch 2759/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7976 - acc: 0.8119 - val_loss: 0.7903 - val_acc: 0.8167\n",
      "Epoch 2760/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8031 - acc: 0.8176 - val_loss: 0.7933 - val_acc: 0.8302\n",
      "Epoch 2761/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7952 - acc: 0.8080 - val_loss: 0.7909 - val_acc: 0.8356\n",
      "Epoch 2762/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7975 - acc: 0.8086 - val_loss: 0.7896 - val_acc: 0.8302\n",
      "Epoch 2763/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8085 - acc: 0.8143 - val_loss: 0.7896 - val_acc: 0.8221\n",
      "Epoch 2764/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8170 - val_loss: 0.7942 - val_acc: 0.8248\n",
      "Epoch 2765/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7972 - acc: 0.8122 - val_loss: 0.8045 - val_acc: 0.8221\n",
      "Epoch 2766/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7881 - acc: 0.8158 - val_loss: 0.8096 - val_acc: 0.8194\n",
      "Epoch 2767/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7950 - acc: 0.8113 - val_loss: 0.8072 - val_acc: 0.8113\n",
      "Epoch 2768/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8125 - val_loss: 0.8030 - val_acc: 0.8167\n",
      "Epoch 2769/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8024 - acc: 0.8167 - val_loss: 0.7927 - val_acc: 0.8194\n",
      "Epoch 2770/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8010 - acc: 0.8113 - val_loss: 0.7870 - val_acc: 0.8221\n",
      "Epoch 2771/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7918 - acc: 0.8161 - val_loss: 0.7874 - val_acc: 0.8221\n",
      "Epoch 2772/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8161 - val_loss: 0.7878 - val_acc: 0.8275\n",
      "Epoch 2773/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7968 - acc: 0.8215 - val_loss: 0.7976 - val_acc: 0.8248\n",
      "Epoch 2774/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7942 - acc: 0.8119 - val_loss: 0.8019 - val_acc: 0.8221\n",
      "Epoch 2775/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8010 - acc: 0.8101 - val_loss: 0.7913 - val_acc: 0.8221\n",
      "Epoch 2776/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7934 - acc: 0.8131 - val_loss: 0.7821 - val_acc: 0.8275\n",
      "Epoch 2777/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7941 - acc: 0.8155 - val_loss: 0.7768 - val_acc: 0.8329\n",
      "Epoch 2778/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7788 - acc: 0.8155 - val_loss: 0.7801 - val_acc: 0.8302\n",
      "Epoch 2779/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7779 - acc: 0.8164 - val_loss: 0.7880 - val_acc: 0.8275\n",
      "Epoch 2780/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7853 - acc: 0.8167 - val_loss: 0.7839 - val_acc: 0.8248\n",
      "Epoch 2781/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7939 - acc: 0.8095 - val_loss: 0.7851 - val_acc: 0.8167\n",
      "Epoch 2782/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8100 - acc: 0.8113 - val_loss: 0.7910 - val_acc: 0.8194\n",
      "Epoch 2783/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7888 - acc: 0.8131 - val_loss: 0.7859 - val_acc: 0.8248\n",
      "Epoch 2784/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8042 - acc: 0.8140 - val_loss: 0.7821 - val_acc: 0.8275\n",
      "Epoch 2785/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7897 - acc: 0.8170 - val_loss: 0.7825 - val_acc: 0.8302\n",
      "Epoch 2786/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7877 - acc: 0.8137 - val_loss: 0.7865 - val_acc: 0.8248\n",
      "Epoch 2787/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8113 - acc: 0.8047 - val_loss: 0.7948 - val_acc: 0.8248\n",
      "Epoch 2788/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7851 - acc: 0.8137 - val_loss: 0.7871 - val_acc: 0.8275\n",
      "Epoch 2789/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7882 - acc: 0.8194 - val_loss: 0.7827 - val_acc: 0.8329\n",
      "Epoch 2790/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7920 - acc: 0.8107 - val_loss: 0.7819 - val_acc: 0.8329\n",
      "Epoch 2791/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7988 - acc: 0.8155 - val_loss: 0.7893 - val_acc: 0.8302\n",
      "Epoch 2792/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7940 - acc: 0.8176 - val_loss: 0.8013 - val_acc: 0.8275\n",
      "Epoch 2793/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7980 - acc: 0.8194 - val_loss: 0.8048 - val_acc: 0.8248\n",
      "Epoch 2794/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7976 - acc: 0.8170 - val_loss: 0.8010 - val_acc: 0.8302\n",
      "Epoch 2795/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8039 - acc: 0.8146 - val_loss: 0.7908 - val_acc: 0.8302\n",
      "Epoch 2796/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7933 - acc: 0.8200 - val_loss: 0.7838 - val_acc: 0.8302\n",
      "Epoch 2797/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8097 - acc: 0.8167 - val_loss: 0.7859 - val_acc: 0.8275\n",
      "Epoch 2798/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8075 - acc: 0.8134 - val_loss: 0.7837 - val_acc: 0.8248\n",
      "Epoch 2799/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7980 - acc: 0.8170 - val_loss: 0.7821 - val_acc: 0.8275\n",
      "Epoch 2800/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8158 - val_loss: 0.7831 - val_acc: 0.8221\n",
      "Epoch 2801/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7962 - acc: 0.8158 - val_loss: 0.7852 - val_acc: 0.8302\n",
      "Epoch 2802/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7803 - acc: 0.8197 - val_loss: 0.7994 - val_acc: 0.8221\n",
      "Epoch 2803/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7804 - acc: 0.8152 - val_loss: 0.7991 - val_acc: 0.8275\n",
      "Epoch 2804/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8146 - val_loss: 0.7876 - val_acc: 0.8275\n",
      "Epoch 2805/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8119 - val_loss: 0.7806 - val_acc: 0.8356\n",
      "Epoch 2806/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7984 - acc: 0.8152 - val_loss: 0.7815 - val_acc: 0.8329\n",
      "Epoch 2807/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7980 - acc: 0.8131 - val_loss: 0.7878 - val_acc: 0.8302\n",
      "Epoch 2808/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7959 - acc: 0.8110 - val_loss: 0.7970 - val_acc: 0.8275\n",
      "Epoch 2809/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7874 - acc: 0.8122 - val_loss: 0.7944 - val_acc: 0.8248\n",
      "Epoch 2810/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8045 - acc: 0.8041 - val_loss: 0.7874 - val_acc: 0.8248\n",
      "Epoch 2811/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8052 - acc: 0.8140 - val_loss: 0.7881 - val_acc: 0.8221\n",
      "Epoch 2812/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8131 - val_loss: 0.7954 - val_acc: 0.8221\n",
      "Epoch 2813/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8176 - val_loss: 0.7927 - val_acc: 0.8248\n",
      "Epoch 2814/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8006 - acc: 0.8152 - val_loss: 0.7840 - val_acc: 0.8275\n",
      "Epoch 2815/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7975 - acc: 0.8188 - val_loss: 0.7761 - val_acc: 0.8329\n",
      "Epoch 2816/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8170 - val_loss: 0.7797 - val_acc: 0.8275\n",
      "Epoch 2817/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8006 - acc: 0.8146 - val_loss: 0.7837 - val_acc: 0.8221\n",
      "Epoch 2818/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8096 - acc: 0.8140 - val_loss: 0.7893 - val_acc: 0.8221\n",
      "Epoch 2819/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7963 - acc: 0.8122 - val_loss: 0.7908 - val_acc: 0.8248\n",
      "Epoch 2820/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7867 - acc: 0.8131 - val_loss: 0.7933 - val_acc: 0.8194\n",
      "Epoch 2821/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7877 - acc: 0.8164 - val_loss: 0.7938 - val_acc: 0.8221\n",
      "Epoch 2822/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7788 - acc: 0.8155 - val_loss: 0.7974 - val_acc: 0.8221\n",
      "Epoch 2823/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7920 - acc: 0.8128 - val_loss: 0.7951 - val_acc: 0.8248\n",
      "Epoch 2824/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7921 - acc: 0.8170 - val_loss: 0.7953 - val_acc: 0.8248\n",
      "Epoch 2825/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7902 - acc: 0.8131 - val_loss: 0.7961 - val_acc: 0.8248\n",
      "Epoch 2826/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7961 - acc: 0.8131 - val_loss: 0.7961 - val_acc: 0.8221\n",
      "Epoch 2827/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7922 - acc: 0.8146 - val_loss: 0.7935 - val_acc: 0.8302\n",
      "Epoch 2828/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8182 - val_loss: 0.7932 - val_acc: 0.8221\n",
      "Epoch 2829/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7896 - acc: 0.8161 - val_loss: 0.7925 - val_acc: 0.8221\n",
      "Epoch 2830/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8024 - acc: 0.8179 - val_loss: 0.7942 - val_acc: 0.8167\n",
      "Epoch 2831/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8199 - acc: 0.8074 - val_loss: 0.8023 - val_acc: 0.8167\n",
      "Epoch 2832/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8036 - acc: 0.8230 - val_loss: 0.7966 - val_acc: 0.8221\n",
      "Epoch 2833/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7842 - acc: 0.8170 - val_loss: 0.7997 - val_acc: 0.8221\n",
      "Epoch 2834/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8065 - acc: 0.8134 - val_loss: 0.8126 - val_acc: 0.8140\n",
      "Epoch 2835/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7906 - acc: 0.8146 - val_loss: 0.8138 - val_acc: 0.8221\n",
      "Epoch 2836/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8169 - acc: 0.8146 - val_loss: 0.8041 - val_acc: 0.8275\n",
      "Epoch 2837/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8062 - acc: 0.8089 - val_loss: 0.7963 - val_acc: 0.8275\n",
      "Epoch 2838/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8151 - acc: 0.8122 - val_loss: 0.7939 - val_acc: 0.8302\n",
      "Epoch 2839/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7844 - acc: 0.8239 - val_loss: 0.7891 - val_acc: 0.8302\n",
      "Epoch 2840/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7894 - acc: 0.8128 - val_loss: 0.7869 - val_acc: 0.8248\n",
      "Epoch 2841/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7992 - acc: 0.8122 - val_loss: 0.7921 - val_acc: 0.8275\n",
      "Epoch 2842/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7920 - acc: 0.8134 - val_loss: 0.8022 - val_acc: 0.8221\n",
      "Epoch 2843/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7950 - acc: 0.8173 - val_loss: 0.8079 - val_acc: 0.8221\n",
      "Epoch 2844/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7863 - acc: 0.8143 - val_loss: 0.8047 - val_acc: 0.8221\n",
      "Epoch 2845/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7899 - acc: 0.8143 - val_loss: 0.8004 - val_acc: 0.8248\n",
      "Epoch 2846/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7838 - acc: 0.8203 - val_loss: 0.7963 - val_acc: 0.8275\n",
      "Epoch 2847/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7831 - acc: 0.8158 - val_loss: 0.8040 - val_acc: 0.8221\n",
      "Epoch 2848/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7784 - acc: 0.8164 - val_loss: 0.8036 - val_acc: 0.8221\n",
      "Epoch 2849/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8173 - val_loss: 0.7973 - val_acc: 0.8302\n",
      "Epoch 2850/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7833 - acc: 0.8173 - val_loss: 0.7977 - val_acc: 0.8194\n",
      "Epoch 2851/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7938 - acc: 0.8074 - val_loss: 0.7979 - val_acc: 0.8194\n",
      "Epoch 2852/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7795 - acc: 0.8146 - val_loss: 0.7963 - val_acc: 0.8194\n",
      "Epoch 2853/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8067 - acc: 0.8125 - val_loss: 0.7899 - val_acc: 0.8275\n",
      "Epoch 2854/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7893 - acc: 0.8149 - val_loss: 0.7816 - val_acc: 0.8275\n",
      "Epoch 2855/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7963 - acc: 0.8155 - val_loss: 0.7788 - val_acc: 0.8302\n",
      "Epoch 2856/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8150 - acc: 0.8107 - val_loss: 0.7824 - val_acc: 0.8248\n",
      "Epoch 2857/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8115 - acc: 0.8119 - val_loss: 0.7825 - val_acc: 0.8248\n",
      "Epoch 2858/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7914 - acc: 0.8185 - val_loss: 0.7829 - val_acc: 0.8221\n",
      "Epoch 2859/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8047 - acc: 0.8143 - val_loss: 0.7801 - val_acc: 0.8329\n",
      "Epoch 2860/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7944 - acc: 0.8140 - val_loss: 0.7811 - val_acc: 0.8329\n",
      "Epoch 2861/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8155 - acc: 0.8101 - val_loss: 0.7864 - val_acc: 0.8248\n",
      "Epoch 2862/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7877 - acc: 0.8173 - val_loss: 0.7880 - val_acc: 0.8221\n",
      "Epoch 2863/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7964 - acc: 0.8212 - val_loss: 0.7915 - val_acc: 0.8194\n",
      "Epoch 2864/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7985 - acc: 0.8041 - val_loss: 0.7823 - val_acc: 0.8275\n",
      "Epoch 2865/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7958 - acc: 0.8104 - val_loss: 0.7835 - val_acc: 0.8248\n",
      "Epoch 2866/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7821 - acc: 0.8167 - val_loss: 0.7864 - val_acc: 0.8194\n",
      "Epoch 2867/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8136 - acc: 0.8143 - val_loss: 0.7812 - val_acc: 0.8221\n",
      "Epoch 2868/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7866 - acc: 0.8194 - val_loss: 0.7754 - val_acc: 0.8275\n",
      "Epoch 2869/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7924 - acc: 0.8176 - val_loss: 0.7746 - val_acc: 0.8275\n",
      "Epoch 2870/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7975 - acc: 0.8155 - val_loss: 0.7678 - val_acc: 0.8302\n",
      "Epoch 2871/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7845 - acc: 0.8188 - val_loss: 0.7700 - val_acc: 0.8275\n",
      "Epoch 2872/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8155 - val_loss: 0.7766 - val_acc: 0.8275\n",
      "Epoch 2873/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7876 - acc: 0.8185 - val_loss: 0.7868 - val_acc: 0.8248\n",
      "Epoch 2874/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7960 - acc: 0.8017 - val_loss: 0.7903 - val_acc: 0.8248\n",
      "Epoch 2875/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7843 - acc: 0.8182 - val_loss: 0.7850 - val_acc: 0.8221\n",
      "Epoch 2876/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7774 - acc: 0.8164 - val_loss: 0.7855 - val_acc: 0.8248\n",
      "Epoch 2877/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8086 - acc: 0.8161 - val_loss: 0.7847 - val_acc: 0.8221\n",
      "Epoch 2878/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8032 - acc: 0.8119 - val_loss: 0.7792 - val_acc: 0.8194\n",
      "Epoch 2879/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7954 - acc: 0.8188 - val_loss: 0.7803 - val_acc: 0.8275\n",
      "Epoch 2880/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7719 - acc: 0.8197 - val_loss: 0.7865 - val_acc: 0.8221\n",
      "Epoch 2881/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7910 - acc: 0.8122 - val_loss: 0.7889 - val_acc: 0.8167\n",
      "Epoch 2882/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8034 - acc: 0.8146 - val_loss: 0.7908 - val_acc: 0.8194\n",
      "Epoch 2883/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8146 - acc: 0.8149 - val_loss: 0.7981 - val_acc: 0.8221\n",
      "Epoch 2884/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7895 - acc: 0.8119 - val_loss: 0.7992 - val_acc: 0.8248\n",
      "Epoch 2885/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8137 - acc: 0.8149 - val_loss: 0.7938 - val_acc: 0.8221\n",
      "Epoch 2886/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8060 - acc: 0.8179 - val_loss: 0.7907 - val_acc: 0.8248\n",
      "Epoch 2887/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8125 - acc: 0.8191 - val_loss: 0.7962 - val_acc: 0.8248\n",
      "Epoch 2888/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8101 - val_loss: 0.7924 - val_acc: 0.8275\n",
      "Epoch 2889/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7959 - acc: 0.8155 - val_loss: 0.7866 - val_acc: 0.8302\n",
      "Epoch 2890/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7992 - acc: 0.8137 - val_loss: 0.7812 - val_acc: 0.8221\n",
      "Epoch 2891/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7783 - acc: 0.8179 - val_loss: 0.7827 - val_acc: 0.8248\n",
      "Epoch 2892/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8081 - acc: 0.8158 - val_loss: 0.7811 - val_acc: 0.8248\n",
      "Epoch 2893/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7920 - acc: 0.8209 - val_loss: 0.7864 - val_acc: 0.8221\n",
      "Epoch 2894/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8011 - acc: 0.8068 - val_loss: 0.7951 - val_acc: 0.8194\n",
      "Epoch 2895/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8045 - acc: 0.8047 - val_loss: 0.7872 - val_acc: 0.8140\n",
      "Epoch 2896/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8131 - val_loss: 0.7770 - val_acc: 0.8248\n",
      "Epoch 2897/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7960 - acc: 0.8185 - val_loss: 0.7740 - val_acc: 0.8275\n",
      "Epoch 2898/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8064 - acc: 0.8116 - val_loss: 0.7775 - val_acc: 0.8302\n",
      "Epoch 2899/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8128 - val_loss: 0.7845 - val_acc: 0.8329\n",
      "Epoch 2900/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7954 - acc: 0.8149 - val_loss: 0.7904 - val_acc: 0.8194\n",
      "Epoch 2901/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7739 - acc: 0.8110 - val_loss: 0.7954 - val_acc: 0.8140\n",
      "Epoch 2902/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8049 - acc: 0.8137 - val_loss: 0.7972 - val_acc: 0.8140\n",
      "Epoch 2903/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8019 - acc: 0.8176 - val_loss: 0.7920 - val_acc: 0.8194\n",
      "Epoch 2904/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7883 - acc: 0.8209 - val_loss: 0.7978 - val_acc: 0.8248\n",
      "Epoch 2905/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7991 - acc: 0.8146 - val_loss: 0.8060 - val_acc: 0.8194\n",
      "Epoch 2906/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7964 - acc: 0.8119 - val_loss: 0.8062 - val_acc: 0.8221\n",
      "Epoch 2907/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8040 - acc: 0.8158 - val_loss: 0.8022 - val_acc: 0.8275\n",
      "Epoch 2908/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7964 - acc: 0.8149 - val_loss: 0.8015 - val_acc: 0.8194\n",
      "Epoch 2909/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8125 - val_loss: 0.8027 - val_acc: 0.8167\n",
      "Epoch 2910/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8225 - acc: 0.8149 - val_loss: 0.7979 - val_acc: 0.8140\n",
      "Epoch 2911/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7988 - acc: 0.8119 - val_loss: 0.7933 - val_acc: 0.8248\n",
      "Epoch 2912/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7790 - acc: 0.8191 - val_loss: 0.7917 - val_acc: 0.8248\n",
      "Epoch 2913/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7968 - acc: 0.8164 - val_loss: 0.7940 - val_acc: 0.8248\n",
      "Epoch 2914/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7890 - acc: 0.8104 - val_loss: 0.7983 - val_acc: 0.8194\n",
      "Epoch 2915/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7800 - acc: 0.8191 - val_loss: 0.7928 - val_acc: 0.8167\n",
      "Epoch 2916/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7739 - acc: 0.8146 - val_loss: 0.7870 - val_acc: 0.8194\n",
      "Epoch 2917/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7882 - acc: 0.8173 - val_loss: 0.7913 - val_acc: 0.8221\n",
      "Epoch 2918/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7741 - acc: 0.8170 - val_loss: 0.7912 - val_acc: 0.8275\n",
      "Epoch 2919/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7928 - acc: 0.8092 - val_loss: 0.7865 - val_acc: 0.8248\n",
      "Epoch 2920/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7763 - acc: 0.8188 - val_loss: 0.7899 - val_acc: 0.8221\n",
      "Epoch 2921/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7889 - acc: 0.8140 - val_loss: 0.7957 - val_acc: 0.8248\n",
      "Epoch 2922/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7956 - acc: 0.8104 - val_loss: 0.7892 - val_acc: 0.8194\n",
      "Epoch 2923/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7795 - acc: 0.8167 - val_loss: 0.7875 - val_acc: 0.8221\n",
      "Epoch 2924/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8007 - acc: 0.8125 - val_loss: 0.7841 - val_acc: 0.8275\n",
      "Epoch 2925/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8063 - acc: 0.8125 - val_loss: 0.7896 - val_acc: 0.8248\n",
      "Epoch 2926/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7976 - acc: 0.8146 - val_loss: 0.7855 - val_acc: 0.8275\n",
      "Epoch 2927/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7997 - acc: 0.8179 - val_loss: 0.7756 - val_acc: 0.8248\n",
      "Epoch 2928/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7969 - acc: 0.8089 - val_loss: 0.7764 - val_acc: 0.8221\n",
      "Epoch 2929/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8122 - val_loss: 0.7754 - val_acc: 0.8248\n",
      "Epoch 2930/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8013 - acc: 0.8170 - val_loss: 0.7767 - val_acc: 0.8275\n",
      "Epoch 2931/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7783 - acc: 0.8197 - val_loss: 0.7820 - val_acc: 0.8194\n",
      "Epoch 2932/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7918 - acc: 0.8200 - val_loss: 0.7868 - val_acc: 0.8221\n",
      "Epoch 2933/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8058 - acc: 0.8110 - val_loss: 0.7879 - val_acc: 0.8221\n",
      "Epoch 2934/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8087 - acc: 0.8173 - val_loss: 0.7840 - val_acc: 0.8221\n",
      "Epoch 2935/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7911 - acc: 0.8125 - val_loss: 0.7742 - val_acc: 0.8275\n",
      "Epoch 2936/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7916 - acc: 0.8146 - val_loss: 0.7720 - val_acc: 0.8248\n",
      "Epoch 2937/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7854 - acc: 0.8197 - val_loss: 0.7812 - val_acc: 0.8221\n",
      "Epoch 2938/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7982 - acc: 0.8089 - val_loss: 0.7888 - val_acc: 0.8248\n",
      "Epoch 2939/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7799 - acc: 0.8131 - val_loss: 0.7854 - val_acc: 0.8302\n",
      "Epoch 2940/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7842 - acc: 0.8218 - val_loss: 0.7805 - val_acc: 0.8329\n",
      "Epoch 2941/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7795 - acc: 0.8188 - val_loss: 0.7764 - val_acc: 0.8356\n",
      "Epoch 2942/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7905 - acc: 0.8092 - val_loss: 0.7779 - val_acc: 0.8302\n",
      "Epoch 2943/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7890 - acc: 0.8197 - val_loss: 0.7807 - val_acc: 0.8302\n",
      "Epoch 2944/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7885 - acc: 0.8083 - val_loss: 0.7770 - val_acc: 0.8275\n",
      "Epoch 2945/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7933 - acc: 0.8134 - val_loss: 0.7763 - val_acc: 0.8302\n",
      "Epoch 2946/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7793 - acc: 0.8224 - val_loss: 0.7829 - val_acc: 0.8275\n",
      "Epoch 2947/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7852 - acc: 0.8143 - val_loss: 0.7837 - val_acc: 0.8302\n",
      "Epoch 2948/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7919 - acc: 0.8182 - val_loss: 0.7854 - val_acc: 0.8275\n",
      "Epoch 2949/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8002 - acc: 0.8179 - val_loss: 0.7869 - val_acc: 0.8275\n",
      "Epoch 2950/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7986 - acc: 0.8146 - val_loss: 0.7897 - val_acc: 0.8194\n",
      "Epoch 2951/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7678 - acc: 0.8170 - val_loss: 0.7839 - val_acc: 0.8221\n",
      "Epoch 2952/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7964 - acc: 0.8179 - val_loss: 0.7782 - val_acc: 0.8221\n",
      "Epoch 2953/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8051 - acc: 0.8122 - val_loss: 0.7771 - val_acc: 0.8302\n",
      "Epoch 2954/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8104 - val_loss: 0.7862 - val_acc: 0.8248\n",
      "Epoch 2955/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7909 - acc: 0.8131 - val_loss: 0.7979 - val_acc: 0.8194\n",
      "Epoch 2956/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8006 - acc: 0.8068 - val_loss: 0.8036 - val_acc: 0.8194\n",
      "Epoch 2957/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8024 - acc: 0.8104 - val_loss: 0.7976 - val_acc: 0.8248\n",
      "Epoch 2958/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7812 - acc: 0.8161 - val_loss: 0.7884 - val_acc: 0.8248\n",
      "Epoch 2959/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7851 - acc: 0.8188 - val_loss: 0.7889 - val_acc: 0.8248\n",
      "Epoch 2960/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7976 - acc: 0.8152 - val_loss: 0.7870 - val_acc: 0.8194\n",
      "Epoch 2961/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7917 - acc: 0.8161 - val_loss: 0.7836 - val_acc: 0.8167\n",
      "Epoch 2962/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8209 - val_loss: 0.7888 - val_acc: 0.8221\n",
      "Epoch 2963/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8120 - acc: 0.8104 - val_loss: 0.7927 - val_acc: 0.8275\n",
      "Epoch 2964/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7890 - acc: 0.8128 - val_loss: 0.7911 - val_acc: 0.8275\n",
      "Epoch 2965/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7766 - acc: 0.8176 - val_loss: 0.7899 - val_acc: 0.8302\n",
      "Epoch 2966/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8171 - acc: 0.8167 - val_loss: 0.7913 - val_acc: 0.8302\n",
      "Epoch 2967/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7955 - acc: 0.8155 - val_loss: 0.7951 - val_acc: 0.8248\n",
      "Epoch 2968/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8158 - val_loss: 0.7920 - val_acc: 0.8275\n",
      "Epoch 2969/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7886 - acc: 0.8170 - val_loss: 0.7896 - val_acc: 0.8275\n",
      "Epoch 2970/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8036 - acc: 0.8149 - val_loss: 0.7908 - val_acc: 0.8221\n",
      "Epoch 2971/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7760 - acc: 0.8128 - val_loss: 0.7991 - val_acc: 0.8248\n",
      "Epoch 2972/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7991 - acc: 0.8131 - val_loss: 0.7953 - val_acc: 0.8221\n",
      "Epoch 2973/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7987 - acc: 0.8158 - val_loss: 0.7934 - val_acc: 0.8248\n",
      "Epoch 2974/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7912 - acc: 0.8155 - val_loss: 0.7884 - val_acc: 0.8248\n",
      "Epoch 2975/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7857 - acc: 0.8125 - val_loss: 0.7793 - val_acc: 0.8302\n",
      "Epoch 2976/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7913 - acc: 0.8137 - val_loss: 0.7796 - val_acc: 0.8275\n",
      "Epoch 2977/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8140 - val_loss: 0.7852 - val_acc: 0.8221\n",
      "Epoch 2978/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8064 - acc: 0.8098 - val_loss: 0.7896 - val_acc: 0.8221\n",
      "Epoch 2979/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8006 - acc: 0.8164 - val_loss: 0.7887 - val_acc: 0.8248\n",
      "Epoch 2980/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7975 - acc: 0.8107 - val_loss: 0.7865 - val_acc: 0.8248\n",
      "Epoch 2981/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8197 - val_loss: 0.7856 - val_acc: 0.8248\n",
      "Epoch 2982/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8053 - acc: 0.8140 - val_loss: 0.7888 - val_acc: 0.8248\n",
      "Epoch 2983/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7877 - acc: 0.8134 - val_loss: 0.7808 - val_acc: 0.8248\n",
      "Epoch 2984/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8010 - acc: 0.8167 - val_loss: 0.7683 - val_acc: 0.8275\n",
      "Epoch 2985/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8084 - acc: 0.8086 - val_loss: 0.7726 - val_acc: 0.8302\n",
      "Epoch 2986/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7905 - acc: 0.8110 - val_loss: 0.7858 - val_acc: 0.8302\n",
      "Epoch 2987/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8134 - val_loss: 0.7883 - val_acc: 0.8275\n",
      "Epoch 2988/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7921 - acc: 0.8110 - val_loss: 0.7862 - val_acc: 0.8275\n",
      "Epoch 2989/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7856 - acc: 0.8218 - val_loss: 0.7872 - val_acc: 0.8302\n",
      "Epoch 2990/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8032 - acc: 0.8173 - val_loss: 0.7919 - val_acc: 0.8275\n",
      "Epoch 2991/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8188 - val_loss: 0.7870 - val_acc: 0.8248\n",
      "Epoch 2992/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8016 - acc: 0.8143 - val_loss: 0.7853 - val_acc: 0.8302\n",
      "Epoch 2993/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7924 - acc: 0.8164 - val_loss: 0.7884 - val_acc: 0.8302\n",
      "Epoch 2994/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7944 - acc: 0.8152 - val_loss: 0.7856 - val_acc: 0.8248\n",
      "Epoch 2995/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7846 - acc: 0.8176 - val_loss: 0.7844 - val_acc: 0.8248\n",
      "Epoch 2996/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8030 - acc: 0.8131 - val_loss: 0.7838 - val_acc: 0.8221\n",
      "Epoch 2997/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8053 - acc: 0.8110 - val_loss: 0.7861 - val_acc: 0.8248\n",
      "Epoch 2998/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8013 - acc: 0.8206 - val_loss: 0.7919 - val_acc: 0.8194\n",
      "Epoch 2999/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7801 - acc: 0.8185 - val_loss: 0.7913 - val_acc: 0.8248\n",
      "Epoch 3000/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7953 - acc: 0.8194 - val_loss: 0.7871 - val_acc: 0.8275\n",
      "Epoch 3001/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7994 - acc: 0.8095 - val_loss: 0.7875 - val_acc: 0.8275\n",
      "Epoch 3002/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7889 - acc: 0.8149 - val_loss: 0.7856 - val_acc: 0.8248\n",
      "Epoch 3003/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8140 - val_loss: 0.7852 - val_acc: 0.8302\n",
      "Epoch 3004/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7998 - acc: 0.8119 - val_loss: 0.7872 - val_acc: 0.8275\n",
      "Epoch 3005/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8043 - acc: 0.8101 - val_loss: 0.7866 - val_acc: 0.8275\n",
      "Epoch 3006/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8143 - acc: 0.8113 - val_loss: 0.7889 - val_acc: 0.8248\n",
      "Epoch 3007/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7841 - acc: 0.8131 - val_loss: 0.7929 - val_acc: 0.8248\n",
      "Epoch 3008/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8000 - acc: 0.8110 - val_loss: 0.7962 - val_acc: 0.8221\n",
      "Epoch 3009/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7957 - acc: 0.8137 - val_loss: 0.7870 - val_acc: 0.8248\n",
      "Epoch 3010/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8122 - val_loss: 0.7823 - val_acc: 0.8302\n",
      "Epoch 3011/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8183 - acc: 0.8104 - val_loss: 0.7789 - val_acc: 0.8329\n",
      "Epoch 3012/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7931 - acc: 0.8218 - val_loss: 0.7816 - val_acc: 0.8221\n",
      "Epoch 3013/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8029 - acc: 0.8158 - val_loss: 0.7896 - val_acc: 0.8140\n",
      "Epoch 3014/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7958 - acc: 0.8182 - val_loss: 0.7946 - val_acc: 0.8194\n",
      "Epoch 3015/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7878 - acc: 0.8125 - val_loss: 0.7985 - val_acc: 0.8194\n",
      "Epoch 3016/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8007 - acc: 0.8146 - val_loss: 0.7969 - val_acc: 0.8221\n",
      "Epoch 3017/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7813 - acc: 0.8197 - val_loss: 0.7976 - val_acc: 0.8248\n",
      "Epoch 3018/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7959 - acc: 0.8188 - val_loss: 0.7957 - val_acc: 0.8221\n",
      "Epoch 3019/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8144 - acc: 0.8191 - val_loss: 0.7948 - val_acc: 0.8248\n",
      "Epoch 3020/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7991 - acc: 0.8128 - val_loss: 0.7922 - val_acc: 0.8221\n",
      "Epoch 3021/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8062 - acc: 0.8110 - val_loss: 0.7922 - val_acc: 0.8221\n",
      "Epoch 3022/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7885 - acc: 0.8200 - val_loss: 0.7940 - val_acc: 0.8221\n",
      "Epoch 3023/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7749 - acc: 0.8155 - val_loss: 0.7891 - val_acc: 0.8275\n",
      "Epoch 3024/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7921 - acc: 0.8116 - val_loss: 0.7845 - val_acc: 0.8329\n",
      "Epoch 3025/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7889 - acc: 0.8152 - val_loss: 0.7843 - val_acc: 0.8275\n",
      "Epoch 3026/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8047 - acc: 0.8092 - val_loss: 0.7826 - val_acc: 0.8275\n",
      "Epoch 3027/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7964 - acc: 0.8158 - val_loss: 0.7808 - val_acc: 0.8248\n",
      "Epoch 3028/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7973 - acc: 0.8104 - val_loss: 0.7801 - val_acc: 0.8248\n",
      "Epoch 3029/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7977 - acc: 0.8116 - val_loss: 0.7786 - val_acc: 0.8329\n",
      "Epoch 3030/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7928 - acc: 0.8182 - val_loss: 0.7690 - val_acc: 0.8302\n",
      "Epoch 3031/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7875 - acc: 0.8110 - val_loss: 0.7696 - val_acc: 0.8275\n",
      "Epoch 3032/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7782 - acc: 0.8128 - val_loss: 0.7747 - val_acc: 0.8221\n",
      "Epoch 3033/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7942 - acc: 0.8182 - val_loss: 0.7782 - val_acc: 0.8194\n",
      "Epoch 3034/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8158 - val_loss: 0.7804 - val_acc: 0.8248\n",
      "Epoch 3035/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8046 - acc: 0.8164 - val_loss: 0.7771 - val_acc: 0.8275\n",
      "Epoch 3036/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7819 - acc: 0.8140 - val_loss: 0.7777 - val_acc: 0.8275\n",
      "Epoch 3037/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7886 - acc: 0.8161 - val_loss: 0.7736 - val_acc: 0.8302\n",
      "Epoch 3038/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7920 - acc: 0.8131 - val_loss: 0.7685 - val_acc: 0.8275\n",
      "Epoch 3039/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7843 - acc: 0.8167 - val_loss: 0.7678 - val_acc: 0.8302\n",
      "Epoch 3040/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7754 - acc: 0.8158 - val_loss: 0.7684 - val_acc: 0.8302\n",
      "Epoch 3041/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8065 - acc: 0.8161 - val_loss: 0.7774 - val_acc: 0.8329\n",
      "Epoch 3042/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7956 - acc: 0.8158 - val_loss: 0.7781 - val_acc: 0.8302\n",
      "Epoch 3043/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7853 - acc: 0.8209 - val_loss: 0.7831 - val_acc: 0.8248\n",
      "Epoch 3044/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7888 - acc: 0.8188 - val_loss: 0.7842 - val_acc: 0.8248\n",
      "Epoch 3045/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7976 - acc: 0.8131 - val_loss: 0.7814 - val_acc: 0.8302\n",
      "Epoch 3046/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7896 - acc: 0.8176 - val_loss: 0.7803 - val_acc: 0.8221\n",
      "Epoch 3047/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7910 - acc: 0.8125 - val_loss: 0.7817 - val_acc: 0.8221\n",
      "Epoch 3048/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8038 - acc: 0.8095 - val_loss: 0.7898 - val_acc: 0.8194\n",
      "Epoch 3049/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8089 - val_loss: 0.7928 - val_acc: 0.8275\n",
      "Epoch 3050/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7984 - acc: 0.8191 - val_loss: 0.7889 - val_acc: 0.8329\n",
      "Epoch 3051/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8149 - val_loss: 0.7973 - val_acc: 0.8329\n",
      "Epoch 3052/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7917 - acc: 0.8170 - val_loss: 0.7982 - val_acc: 0.8275\n",
      "Epoch 3053/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7894 - acc: 0.8086 - val_loss: 0.7972 - val_acc: 0.8221\n",
      "Epoch 3054/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7825 - acc: 0.8158 - val_loss: 0.7936 - val_acc: 0.8167\n",
      "Epoch 3055/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8139 - acc: 0.8053 - val_loss: 0.7838 - val_acc: 0.8275\n",
      "Epoch 3056/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8096 - acc: 0.8116 - val_loss: 0.7880 - val_acc: 0.8275\n",
      "Epoch 3057/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7916 - acc: 0.8140 - val_loss: 0.7967 - val_acc: 0.8248\n",
      "Epoch 3058/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8051 - acc: 0.8083 - val_loss: 0.7970 - val_acc: 0.8248\n",
      "Epoch 3059/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7783 - acc: 0.8140 - val_loss: 0.7875 - val_acc: 0.8248\n",
      "Epoch 3060/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8029 - acc: 0.8164 - val_loss: 0.7851 - val_acc: 0.8275\n",
      "Epoch 3061/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7877 - acc: 0.8101 - val_loss: 0.7922 - val_acc: 0.8194\n",
      "Epoch 3062/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8039 - acc: 0.8113 - val_loss: 0.7981 - val_acc: 0.8221\n",
      "Epoch 3063/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7937 - acc: 0.8182 - val_loss: 0.7929 - val_acc: 0.8221\n",
      "Epoch 3064/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7985 - acc: 0.8140 - val_loss: 0.7911 - val_acc: 0.8194\n",
      "Epoch 3065/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7933 - acc: 0.8110 - val_loss: 0.7918 - val_acc: 0.8248\n",
      "Epoch 3066/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7954 - acc: 0.8161 - val_loss: 0.7909 - val_acc: 0.8194\n",
      "Epoch 3067/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8128 - val_loss: 0.7846 - val_acc: 0.8194\n",
      "Epoch 3068/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8182 - val_loss: 0.7798 - val_acc: 0.8248\n",
      "Epoch 3069/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8048 - acc: 0.8173 - val_loss: 0.7835 - val_acc: 0.8275\n",
      "Epoch 3070/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7810 - acc: 0.8137 - val_loss: 0.7900 - val_acc: 0.8302\n",
      "Epoch 3071/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7804 - acc: 0.8194 - val_loss: 0.7998 - val_acc: 0.8248\n",
      "Epoch 3072/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7969 - acc: 0.8131 - val_loss: 0.7965 - val_acc: 0.8221\n",
      "Epoch 3073/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8019 - acc: 0.8158 - val_loss: 0.7882 - val_acc: 0.8275\n",
      "Epoch 3074/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7963 - acc: 0.8131 - val_loss: 0.7837 - val_acc: 0.8275\n",
      "Epoch 3075/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7727 - acc: 0.8209 - val_loss: 0.7856 - val_acc: 0.8275\n",
      "Epoch 3076/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7923 - acc: 0.8149 - val_loss: 0.7890 - val_acc: 0.8248\n",
      "Epoch 3077/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8002 - acc: 0.8092 - val_loss: 0.7867 - val_acc: 0.8221\n",
      "Epoch 3078/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7956 - acc: 0.8224 - val_loss: 0.7807 - val_acc: 0.8248\n",
      "Epoch 3079/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8203 - acc: 0.8170 - val_loss: 0.7794 - val_acc: 0.8248\n",
      "Epoch 3080/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7893 - acc: 0.8197 - val_loss: 0.7842 - val_acc: 0.8221\n",
      "Epoch 3081/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7954 - acc: 0.8185 - val_loss: 0.7837 - val_acc: 0.8221\n",
      "Epoch 3082/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8185 - val_loss: 0.7839 - val_acc: 0.8221\n",
      "Epoch 3083/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7931 - acc: 0.8146 - val_loss: 0.7821 - val_acc: 0.8248\n",
      "Epoch 3084/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7928 - acc: 0.8182 - val_loss: 0.7830 - val_acc: 0.8248\n",
      "Epoch 3085/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8136 - acc: 0.8200 - val_loss: 0.7851 - val_acc: 0.8329\n",
      "Epoch 3086/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8044 - val_loss: 0.7781 - val_acc: 0.8302\n",
      "Epoch 3087/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7782 - acc: 0.8143 - val_loss: 0.7714 - val_acc: 0.8275\n",
      "Epoch 3088/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7825 - acc: 0.8152 - val_loss: 0.7738 - val_acc: 0.8221\n",
      "Epoch 3089/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7955 - acc: 0.8152 - val_loss: 0.7806 - val_acc: 0.8221\n",
      "Epoch 3090/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8200 - val_loss: 0.7874 - val_acc: 0.8221\n",
      "Epoch 3091/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7817 - acc: 0.8185 - val_loss: 0.7814 - val_acc: 0.8248\n",
      "Epoch 3092/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7985 - acc: 0.8092 - val_loss: 0.7704 - val_acc: 0.8302\n",
      "Epoch 3093/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7844 - acc: 0.8197 - val_loss: 0.7752 - val_acc: 0.8302\n",
      "Epoch 3094/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7982 - acc: 0.8194 - val_loss: 0.7831 - val_acc: 0.8221\n",
      "Epoch 3095/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8024 - acc: 0.8167 - val_loss: 0.7885 - val_acc: 0.8248\n",
      "Epoch 3096/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7863 - acc: 0.8182 - val_loss: 0.7910 - val_acc: 0.8221\n",
      "Epoch 3097/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7858 - acc: 0.8167 - val_loss: 0.7932 - val_acc: 0.8248\n",
      "Epoch 3098/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7967 - acc: 0.8119 - val_loss: 0.7949 - val_acc: 0.8248\n",
      "Epoch 3099/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7767 - acc: 0.8125 - val_loss: 0.7912 - val_acc: 0.8248\n",
      "Epoch 3100/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8024 - acc: 0.8149 - val_loss: 0.7874 - val_acc: 0.8221\n",
      "Epoch 3101/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7860 - acc: 0.8173 - val_loss: 0.7862 - val_acc: 0.8221\n",
      "Epoch 3102/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7944 - acc: 0.8191 - val_loss: 0.7823 - val_acc: 0.8221\n",
      "Epoch 3103/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7834 - acc: 0.8167 - val_loss: 0.7759 - val_acc: 0.8221\n",
      "Epoch 3104/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8176 - val_loss: 0.7753 - val_acc: 0.8275\n",
      "Epoch 3105/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8202 - acc: 0.8179 - val_loss: 0.7811 - val_acc: 0.8221\n",
      "Epoch 3106/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7937 - acc: 0.8170 - val_loss: 0.7844 - val_acc: 0.8221\n",
      "Epoch 3107/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8080 - acc: 0.8119 - val_loss: 0.7782 - val_acc: 0.8275\n",
      "Epoch 3108/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7977 - acc: 0.8128 - val_loss: 0.7829 - val_acc: 0.8221\n",
      "Epoch 3109/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7988 - acc: 0.8128 - val_loss: 0.7854 - val_acc: 0.8221\n",
      "Epoch 3110/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8007 - acc: 0.8125 - val_loss: 0.7906 - val_acc: 0.8194\n",
      "Epoch 3111/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8057 - acc: 0.8104 - val_loss: 0.7939 - val_acc: 0.8140\n",
      "Epoch 3112/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8140 - val_loss: 0.7900 - val_acc: 0.8221\n",
      "Epoch 3113/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7961 - acc: 0.8167 - val_loss: 0.7914 - val_acc: 0.8221\n",
      "Epoch 3114/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7985 - acc: 0.8116 - val_loss: 0.7904 - val_acc: 0.8221\n",
      "Epoch 3115/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7862 - acc: 0.8179 - val_loss: 0.7852 - val_acc: 0.8248\n",
      "Epoch 3116/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7897 - acc: 0.8062 - val_loss: 0.7836 - val_acc: 0.8248\n",
      "Epoch 3117/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8176 - acc: 0.8149 - val_loss: 0.7736 - val_acc: 0.8356\n",
      "Epoch 3118/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7980 - acc: 0.8167 - val_loss: 0.7769 - val_acc: 0.8248\n",
      "Epoch 3119/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7794 - acc: 0.8170 - val_loss: 0.7853 - val_acc: 0.8194\n",
      "Epoch 3120/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7752 - acc: 0.8134 - val_loss: 0.7876 - val_acc: 0.8221\n",
      "Epoch 3121/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7940 - acc: 0.8137 - val_loss: 0.7877 - val_acc: 0.8221\n",
      "Epoch 3122/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8146 - val_loss: 0.7854 - val_acc: 0.8275\n",
      "Epoch 3123/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7798 - acc: 0.8173 - val_loss: 0.7870 - val_acc: 0.8248\n",
      "Epoch 3124/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7861 - acc: 0.8122 - val_loss: 0.7884 - val_acc: 0.8275\n",
      "Epoch 3125/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8128 - acc: 0.8107 - val_loss: 0.7889 - val_acc: 0.8248\n",
      "Epoch 3126/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7942 - acc: 0.8137 - val_loss: 0.7938 - val_acc: 0.8248\n",
      "Epoch 3127/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7996 - acc: 0.8101 - val_loss: 0.7999 - val_acc: 0.8167\n",
      "Epoch 3128/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7734 - acc: 0.8209 - val_loss: 0.7994 - val_acc: 0.8221\n",
      "Epoch 3129/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7757 - acc: 0.8182 - val_loss: 0.7982 - val_acc: 0.8248\n",
      "Epoch 3130/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8021 - acc: 0.8113 - val_loss: 0.7988 - val_acc: 0.8302\n",
      "Epoch 3131/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7961 - acc: 0.8110 - val_loss: 0.7961 - val_acc: 0.8275\n",
      "Epoch 3132/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8232 - acc: 0.8107 - val_loss: 0.7924 - val_acc: 0.8302\n",
      "Epoch 3133/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7900 - acc: 0.8128 - val_loss: 0.7845 - val_acc: 0.8329\n",
      "Epoch 3134/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7954 - acc: 0.8107 - val_loss: 0.7814 - val_acc: 0.8275\n",
      "Epoch 3135/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8009 - acc: 0.8215 - val_loss: 0.7800 - val_acc: 0.8302\n",
      "Epoch 3136/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7964 - acc: 0.8161 - val_loss: 0.7885 - val_acc: 0.8248\n",
      "Epoch 3137/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8140 - acc: 0.8101 - val_loss: 0.7964 - val_acc: 0.8248\n",
      "Epoch 3138/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8046 - acc: 0.8116 - val_loss: 0.7934 - val_acc: 0.8221\n",
      "Epoch 3139/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8119 - acc: 0.8134 - val_loss: 0.7890 - val_acc: 0.8221\n",
      "Epoch 3140/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7808 - acc: 0.8230 - val_loss: 0.7855 - val_acc: 0.8248\n",
      "Epoch 3141/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8179 - val_loss: 0.7874 - val_acc: 0.8221\n",
      "Epoch 3142/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8143 - acc: 0.8071 - val_loss: 0.7792 - val_acc: 0.8194\n",
      "Epoch 3143/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7786 - acc: 0.8224 - val_loss: 0.7778 - val_acc: 0.8221\n",
      "Epoch 3144/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7866 - acc: 0.8122 - val_loss: 0.7825 - val_acc: 0.8275\n",
      "Epoch 3145/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7910 - acc: 0.8173 - val_loss: 0.7890 - val_acc: 0.8221\n",
      "Epoch 3146/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7935 - acc: 0.8158 - val_loss: 0.7915 - val_acc: 0.8194\n",
      "Epoch 3147/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7991 - acc: 0.8071 - val_loss: 0.7851 - val_acc: 0.8248\n",
      "Epoch 3148/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7812 - acc: 0.8170 - val_loss: 0.7795 - val_acc: 0.8302\n",
      "Epoch 3149/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.8027 - acc: 0.8158 - val_loss: 0.7805 - val_acc: 0.8248\n",
      "Epoch 3150/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7880 - acc: 0.8104 - val_loss: 0.7804 - val_acc: 0.8221\n",
      "Epoch 3151/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7790 - acc: 0.8146 - val_loss: 0.7804 - val_acc: 0.8221\n",
      "Epoch 3152/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8070 - acc: 0.8146 - val_loss: 0.7815 - val_acc: 0.8221\n",
      "Epoch 3153/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8110 - acc: 0.8113 - val_loss: 0.7837 - val_acc: 0.8194\n",
      "Epoch 3154/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7867 - acc: 0.8152 - val_loss: 0.7731 - val_acc: 0.8221\n",
      "Epoch 3155/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7972 - acc: 0.8158 - val_loss: 0.7654 - val_acc: 0.8302\n",
      "Epoch 3156/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.7820 - acc: 0.8137 - val_loss: 0.7670 - val_acc: 0.8302\n",
      "Epoch 3157/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7859 - acc: 0.8182 - val_loss: 0.7787 - val_acc: 0.8302\n",
      "Epoch 3158/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8000 - acc: 0.8128 - val_loss: 0.7913 - val_acc: 0.8221\n",
      "Epoch 3159/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7936 - acc: 0.8152 - val_loss: 0.7889 - val_acc: 0.8275\n",
      "Epoch 3160/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7920 - acc: 0.8161 - val_loss: 0.7856 - val_acc: 0.8275\n",
      "Epoch 3161/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7882 - acc: 0.8176 - val_loss: 0.7802 - val_acc: 0.8302\n",
      "Epoch 3162/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7851 - acc: 0.8143 - val_loss: 0.7823 - val_acc: 0.8248\n",
      "Epoch 3163/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7997 - acc: 0.8161 - val_loss: 0.7874 - val_acc: 0.8275\n",
      "Epoch 3164/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7986 - acc: 0.8122 - val_loss: 0.7861 - val_acc: 0.8221\n",
      "Epoch 3165/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7909 - acc: 0.8155 - val_loss: 0.7850 - val_acc: 0.8167\n",
      "Epoch 3166/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8035 - acc: 0.8110 - val_loss: 0.7858 - val_acc: 0.8221\n",
      "Epoch 3167/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8170 - val_loss: 0.7876 - val_acc: 0.8248\n",
      "Epoch 3168/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7860 - acc: 0.8188 - val_loss: 0.7939 - val_acc: 0.8194\n",
      "Epoch 3169/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7945 - acc: 0.8155 - val_loss: 0.7936 - val_acc: 0.8194\n",
      "Epoch 3170/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8122 - val_loss: 0.7888 - val_acc: 0.8221\n",
      "Epoch 3171/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7804 - acc: 0.8161 - val_loss: 0.7823 - val_acc: 0.8194\n",
      "Epoch 3172/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8068 - acc: 0.8188 - val_loss: 0.7825 - val_acc: 0.8221\n",
      "Epoch 3173/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7907 - acc: 0.8176 - val_loss: 0.7853 - val_acc: 0.8248\n",
      "Epoch 3174/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7806 - acc: 0.8152 - val_loss: 0.7909 - val_acc: 0.8194\n",
      "Epoch 3175/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7955 - acc: 0.8188 - val_loss: 0.7933 - val_acc: 0.8221\n",
      "Epoch 3176/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7726 - acc: 0.8194 - val_loss: 0.7915 - val_acc: 0.8167\n",
      "Epoch 3177/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7911 - acc: 0.8101 - val_loss: 0.7913 - val_acc: 0.8221\n",
      "Epoch 3178/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8152 - val_loss: 0.7882 - val_acc: 0.8194\n",
      "Epoch 3179/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8083 - val_loss: 0.7900 - val_acc: 0.8167\n",
      "Epoch 3180/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7865 - acc: 0.8245 - val_loss: 0.8028 - val_acc: 0.8194\n",
      "Epoch 3181/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8009 - acc: 0.8122 - val_loss: 0.8092 - val_acc: 0.8221\n",
      "Epoch 3182/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8039 - acc: 0.8185 - val_loss: 0.8026 - val_acc: 0.8275\n",
      "Epoch 3183/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7916 - acc: 0.8140 - val_loss: 0.7996 - val_acc: 0.8275\n",
      "Epoch 3184/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7872 - acc: 0.8119 - val_loss: 0.7969 - val_acc: 0.8248\n",
      "Epoch 3185/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7972 - acc: 0.8137 - val_loss: 0.8015 - val_acc: 0.8194\n",
      "Epoch 3186/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7750 - acc: 0.8170 - val_loss: 0.7992 - val_acc: 0.8221\n",
      "Epoch 3187/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7995 - acc: 0.8116 - val_loss: 0.7945 - val_acc: 0.8248\n",
      "Epoch 3188/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7997 - acc: 0.8149 - val_loss: 0.7887 - val_acc: 0.8248\n",
      "Epoch 3189/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8014 - acc: 0.8143 - val_loss: 0.7850 - val_acc: 0.8329\n",
      "Epoch 3190/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7817 - acc: 0.8116 - val_loss: 0.7846 - val_acc: 0.8275\n",
      "Epoch 3191/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7735 - acc: 0.8158 - val_loss: 0.7897 - val_acc: 0.8275\n",
      "Epoch 3192/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8131 - val_loss: 0.7946 - val_acc: 0.8275\n",
      "Epoch 3193/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7739 - acc: 0.8149 - val_loss: 0.7994 - val_acc: 0.8221\n",
      "Epoch 3194/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7889 - acc: 0.8083 - val_loss: 0.7988 - val_acc: 0.8275\n",
      "Epoch 3195/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8071 - acc: 0.8110 - val_loss: 0.7980 - val_acc: 0.8248\n",
      "Epoch 3196/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7931 - acc: 0.8116 - val_loss: 0.7997 - val_acc: 0.8221\n",
      "Epoch 3197/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7908 - acc: 0.8155 - val_loss: 0.8012 - val_acc: 0.8167\n",
      "Epoch 3198/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7909 - acc: 0.8125 - val_loss: 0.7933 - val_acc: 0.8194\n",
      "Epoch 3199/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7954 - acc: 0.8122 - val_loss: 0.7853 - val_acc: 0.8275\n",
      "Epoch 3200/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8080 - acc: 0.8143 - val_loss: 0.7871 - val_acc: 0.8221\n",
      "Epoch 3201/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7959 - acc: 0.8119 - val_loss: 0.7989 - val_acc: 0.8221\n",
      "Epoch 3202/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7926 - acc: 0.8134 - val_loss: 0.8056 - val_acc: 0.8194\n",
      "Epoch 3203/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7969 - acc: 0.8182 - val_loss: 0.7842 - val_acc: 0.8302\n",
      "Epoch 3204/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7996 - acc: 0.8212 - val_loss: 0.7800 - val_acc: 0.8329\n",
      "Epoch 3205/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8091 - acc: 0.8089 - val_loss: 0.7883 - val_acc: 0.8302\n",
      "Epoch 3206/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8005 - acc: 0.8062 - val_loss: 0.7993 - val_acc: 0.8221\n",
      "Epoch 3207/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7837 - acc: 0.8149 - val_loss: 0.7943 - val_acc: 0.8248\n",
      "Epoch 3208/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7901 - acc: 0.8140 - val_loss: 0.7919 - val_acc: 0.8275\n",
      "Epoch 3209/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8125 - val_loss: 0.7912 - val_acc: 0.8275\n",
      "Epoch 3210/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7805 - acc: 0.8152 - val_loss: 0.7895 - val_acc: 0.8302\n",
      "Epoch 3211/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8028 - acc: 0.8068 - val_loss: 0.7834 - val_acc: 0.8302\n",
      "Epoch 3212/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7607 - acc: 0.8188 - val_loss: 0.7788 - val_acc: 0.8356\n",
      "Epoch 3213/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8093 - acc: 0.8155 - val_loss: 0.7809 - val_acc: 0.8302\n",
      "Epoch 3214/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7905 - acc: 0.8131 - val_loss: 0.7835 - val_acc: 0.8248\n",
      "Epoch 3215/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7864 - acc: 0.8164 - val_loss: 0.7768 - val_acc: 0.8275\n",
      "Epoch 3216/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7984 - acc: 0.8122 - val_loss: 0.7769 - val_acc: 0.8302\n",
      "Epoch 3217/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7962 - acc: 0.8179 - val_loss: 0.7794 - val_acc: 0.8275\n",
      "Epoch 3218/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7944 - acc: 0.8101 - val_loss: 0.7756 - val_acc: 0.8302\n",
      "Epoch 3219/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7828 - acc: 0.8191 - val_loss: 0.7756 - val_acc: 0.8329\n",
      "Epoch 3220/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8008 - acc: 0.8092 - val_loss: 0.7753 - val_acc: 0.8329\n",
      "Epoch 3221/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7996 - acc: 0.8188 - val_loss: 0.7733 - val_acc: 0.8329\n",
      "Epoch 3222/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7889 - acc: 0.8182 - val_loss: 0.7747 - val_acc: 0.8329\n",
      "Epoch 3223/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7862 - acc: 0.8191 - val_loss: 0.7769 - val_acc: 0.8302\n",
      "Epoch 3224/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7813 - acc: 0.8155 - val_loss: 0.7807 - val_acc: 0.8356\n",
      "Epoch 3225/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8143 - val_loss: 0.7862 - val_acc: 0.8248\n",
      "Epoch 3226/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7963 - acc: 0.8137 - val_loss: 0.7874 - val_acc: 0.8275\n",
      "Epoch 3227/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8144 - acc: 0.8143 - val_loss: 0.7860 - val_acc: 0.8302\n",
      "Epoch 3228/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7857 - acc: 0.8215 - val_loss: 0.7874 - val_acc: 0.8221\n",
      "Epoch 3229/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7815 - acc: 0.8179 - val_loss: 0.7854 - val_acc: 0.8275\n",
      "Epoch 3230/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8039 - acc: 0.8128 - val_loss: 0.7803 - val_acc: 0.8248\n",
      "Epoch 3231/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8004 - acc: 0.8182 - val_loss: 0.7687 - val_acc: 0.8167\n",
      "Epoch 3232/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7745 - acc: 0.8134 - val_loss: 0.7688 - val_acc: 0.8248\n",
      "Epoch 3233/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7868 - acc: 0.8143 - val_loss: 0.7698 - val_acc: 0.8329\n",
      "Epoch 3234/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8025 - acc: 0.8062 - val_loss: 0.7797 - val_acc: 0.8329\n",
      "Epoch 3235/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8002 - acc: 0.8089 - val_loss: 0.7920 - val_acc: 0.8248\n",
      "Epoch 3236/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7958 - acc: 0.8149 - val_loss: 0.7933 - val_acc: 0.8248\n",
      "Epoch 3237/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7991 - acc: 0.8122 - val_loss: 0.7904 - val_acc: 0.8221\n",
      "Epoch 3238/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8131 - val_loss: 0.7853 - val_acc: 0.8302\n",
      "Epoch 3239/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7845 - acc: 0.8131 - val_loss: 0.7713 - val_acc: 0.8329\n",
      "Epoch 3240/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8009 - acc: 0.8128 - val_loss: 0.7700 - val_acc: 0.8275\n",
      "Epoch 3241/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7941 - acc: 0.8194 - val_loss: 0.7755 - val_acc: 0.8248\n",
      "Epoch 3242/5000\n",
      "3339/3339 [==============================] - 0s 10us/step - loss: 0.7863 - acc: 0.8179 - val_loss: 0.7838 - val_acc: 0.8167\n",
      "Epoch 3243/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8152 - val_loss: 0.7878 - val_acc: 0.8194\n",
      "Epoch 3244/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7996 - acc: 0.8167 - val_loss: 0.7885 - val_acc: 0.8194\n",
      "Epoch 3245/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8003 - acc: 0.8176 - val_loss: 0.7832 - val_acc: 0.8329\n",
      "Epoch 3246/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7717 - acc: 0.8176 - val_loss: 0.7808 - val_acc: 0.8275\n",
      "Epoch 3247/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7796 - acc: 0.8107 - val_loss: 0.7794 - val_acc: 0.8275\n",
      "Epoch 3248/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7883 - acc: 0.8206 - val_loss: 0.7802 - val_acc: 0.8248\n",
      "Epoch 3249/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8104 - val_loss: 0.7783 - val_acc: 0.8248\n",
      "Epoch 3250/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7834 - acc: 0.8146 - val_loss: 0.7756 - val_acc: 0.8329\n",
      "Epoch 3251/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7898 - acc: 0.8092 - val_loss: 0.7724 - val_acc: 0.8329\n",
      "Epoch 3252/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7828 - acc: 0.8155 - val_loss: 0.7757 - val_acc: 0.8275\n",
      "Epoch 3253/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8140 - val_loss: 0.7836 - val_acc: 0.8167\n",
      "Epoch 3254/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7786 - acc: 0.8134 - val_loss: 0.7888 - val_acc: 0.8194\n",
      "Epoch 3255/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7863 - acc: 0.8194 - val_loss: 0.7945 - val_acc: 0.8221\n",
      "Epoch 3256/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8032 - acc: 0.8137 - val_loss: 0.7911 - val_acc: 0.8221\n",
      "Epoch 3257/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8096 - acc: 0.8104 - val_loss: 0.7848 - val_acc: 0.8248\n",
      "Epoch 3258/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7866 - acc: 0.8179 - val_loss: 0.7763 - val_acc: 0.8302\n",
      "Epoch 3259/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8161 - val_loss: 0.7755 - val_acc: 0.8329\n",
      "Epoch 3260/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7888 - acc: 0.8146 - val_loss: 0.7768 - val_acc: 0.8302\n",
      "Epoch 3261/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7911 - acc: 0.8143 - val_loss: 0.7764 - val_acc: 0.8302\n",
      "Epoch 3262/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7793 - acc: 0.8173 - val_loss: 0.7811 - val_acc: 0.8275\n",
      "Epoch 3263/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8030 - acc: 0.8134 - val_loss: 0.7865 - val_acc: 0.8248\n",
      "Epoch 3264/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7840 - acc: 0.8161 - val_loss: 0.7899 - val_acc: 0.8221\n",
      "Epoch 3265/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7819 - acc: 0.8164 - val_loss: 0.7859 - val_acc: 0.8248\n",
      "Epoch 3266/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8000 - acc: 0.8140 - val_loss: 0.7876 - val_acc: 0.8275\n",
      "Epoch 3267/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7806 - acc: 0.8173 - val_loss: 0.7875 - val_acc: 0.8329\n",
      "Epoch 3268/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7798 - acc: 0.8239 - val_loss: 0.7944 - val_acc: 0.8248\n",
      "Epoch 3269/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7767 - acc: 0.8152 - val_loss: 0.8003 - val_acc: 0.8194\n",
      "Epoch 3270/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7816 - acc: 0.8173 - val_loss: 0.7988 - val_acc: 0.8221\n",
      "Epoch 3271/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7793 - acc: 0.8191 - val_loss: 0.7980 - val_acc: 0.8194\n",
      "Epoch 3272/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7966 - acc: 0.8170 - val_loss: 0.7976 - val_acc: 0.8275\n",
      "Epoch 3273/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7979 - acc: 0.8149 - val_loss: 0.7889 - val_acc: 0.8221\n",
      "Epoch 3274/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7970 - acc: 0.8152 - val_loss: 0.7810 - val_acc: 0.8221\n",
      "Epoch 3275/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8102 - acc: 0.8173 - val_loss: 0.7785 - val_acc: 0.8248\n",
      "Epoch 3276/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7863 - acc: 0.8143 - val_loss: 0.7754 - val_acc: 0.8302\n",
      "Epoch 3277/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7939 - acc: 0.8173 - val_loss: 0.7762 - val_acc: 0.8275\n",
      "Epoch 3278/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7965 - acc: 0.8143 - val_loss: 0.7824 - val_acc: 0.8275\n",
      "Epoch 3279/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7828 - acc: 0.8152 - val_loss: 0.7823 - val_acc: 0.8275\n",
      "Epoch 3280/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7900 - acc: 0.8143 - val_loss: 0.7774 - val_acc: 0.8248\n",
      "Epoch 3281/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7883 - acc: 0.8185 - val_loss: 0.7822 - val_acc: 0.8194\n",
      "Epoch 3282/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7972 - acc: 0.8161 - val_loss: 0.7797 - val_acc: 0.8248\n",
      "Epoch 3283/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7770 - acc: 0.8083 - val_loss: 0.7764 - val_acc: 0.8329\n",
      "Epoch 3284/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8059 - acc: 0.8125 - val_loss: 0.7753 - val_acc: 0.8302\n",
      "Epoch 3285/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7856 - acc: 0.8119 - val_loss: 0.7753 - val_acc: 0.8248\n",
      "Epoch 3286/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7979 - acc: 0.8116 - val_loss: 0.7753 - val_acc: 0.8302\n",
      "Epoch 3287/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7914 - acc: 0.8158 - val_loss: 0.7723 - val_acc: 0.8248\n",
      "Epoch 3288/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7806 - acc: 0.8197 - val_loss: 0.7730 - val_acc: 0.8248\n",
      "Epoch 3289/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7847 - acc: 0.8116 - val_loss: 0.7788 - val_acc: 0.8248\n",
      "Epoch 3290/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7900 - acc: 0.8143 - val_loss: 0.7880 - val_acc: 0.8221\n",
      "Epoch 3291/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7981 - acc: 0.8110 - val_loss: 0.7878 - val_acc: 0.8194\n",
      "Epoch 3292/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8016 - acc: 0.8161 - val_loss: 0.7823 - val_acc: 0.8221\n",
      "Epoch 3293/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7839 - acc: 0.8134 - val_loss: 0.7813 - val_acc: 0.8275\n",
      "Epoch 3294/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7919 - acc: 0.8161 - val_loss: 0.7853 - val_acc: 0.8275\n",
      "Epoch 3295/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7777 - acc: 0.8146 - val_loss: 0.7854 - val_acc: 0.8248\n",
      "Epoch 3296/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7704 - acc: 0.8164 - val_loss: 0.7882 - val_acc: 0.8167\n",
      "Epoch 3297/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7764 - acc: 0.8221 - val_loss: 0.7924 - val_acc: 0.8194\n",
      "Epoch 3298/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7987 - acc: 0.8134 - val_loss: 0.7889 - val_acc: 0.8194\n",
      "Epoch 3299/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7857 - acc: 0.8176 - val_loss: 0.7803 - val_acc: 0.8275\n",
      "Epoch 3300/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8114 - acc: 0.8134 - val_loss: 0.7724 - val_acc: 0.8302\n",
      "Epoch 3301/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7901 - acc: 0.8125 - val_loss: 0.7712 - val_acc: 0.8302\n",
      "Epoch 3302/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7842 - acc: 0.8146 - val_loss: 0.7725 - val_acc: 0.8248\n",
      "Epoch 3303/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7866 - acc: 0.8173 - val_loss: 0.7688 - val_acc: 0.8329\n",
      "Epoch 3304/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7936 - acc: 0.8131 - val_loss: 0.7704 - val_acc: 0.8356\n",
      "Epoch 3305/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7935 - acc: 0.8122 - val_loss: 0.7814 - val_acc: 0.8329\n",
      "Epoch 3306/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8041 - acc: 0.8101 - val_loss: 0.7848 - val_acc: 0.8356\n",
      "Epoch 3307/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7827 - acc: 0.8164 - val_loss: 0.7890 - val_acc: 0.8302\n",
      "Epoch 3308/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7957 - acc: 0.8146 - val_loss: 0.7861 - val_acc: 0.8275\n",
      "Epoch 3309/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7946 - acc: 0.8140 - val_loss: 0.7850 - val_acc: 0.8329\n",
      "Epoch 3310/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8046 - acc: 0.8080 - val_loss: 0.7841 - val_acc: 0.8275\n",
      "Epoch 3311/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7842 - acc: 0.8215 - val_loss: 0.7826 - val_acc: 0.8275\n",
      "Epoch 3312/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8007 - acc: 0.8206 - val_loss: 0.7819 - val_acc: 0.8275\n",
      "Epoch 3313/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7921 - acc: 0.8161 - val_loss: 0.7809 - val_acc: 0.8302\n",
      "Epoch 3314/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7906 - acc: 0.8095 - val_loss: 0.7817 - val_acc: 0.8275\n",
      "Epoch 3315/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8108 - acc: 0.8161 - val_loss: 0.7794 - val_acc: 0.8302\n",
      "Epoch 3316/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7787 - acc: 0.8155 - val_loss: 0.7837 - val_acc: 0.8194\n",
      "Epoch 3317/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8003 - acc: 0.8110 - val_loss: 0.7862 - val_acc: 0.8194\n",
      "Epoch 3318/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7850 - acc: 0.8167 - val_loss: 0.7909 - val_acc: 0.8275\n",
      "Epoch 3319/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7937 - acc: 0.8176 - val_loss: 0.7944 - val_acc: 0.8248\n",
      "Epoch 3320/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7661 - acc: 0.8230 - val_loss: 0.7948 - val_acc: 0.8275\n",
      "Epoch 3321/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7827 - acc: 0.8179 - val_loss: 0.7892 - val_acc: 0.8356\n",
      "Epoch 3322/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8074 - val_loss: 0.7902 - val_acc: 0.8302\n",
      "Epoch 3323/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7796 - acc: 0.8170 - val_loss: 0.7937 - val_acc: 0.8248\n",
      "Epoch 3324/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7911 - acc: 0.8104 - val_loss: 0.7939 - val_acc: 0.8275\n",
      "Epoch 3325/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7964 - acc: 0.8161 - val_loss: 0.7920 - val_acc: 0.8275\n",
      "Epoch 3326/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7999 - acc: 0.8065 - val_loss: 0.7859 - val_acc: 0.8248\n",
      "Epoch 3327/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8200 - val_loss: 0.7760 - val_acc: 0.8302\n",
      "Epoch 3328/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8176 - val_loss: 0.7738 - val_acc: 0.8275\n",
      "Epoch 3329/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7973 - acc: 0.8176 - val_loss: 0.7802 - val_acc: 0.8248\n",
      "Epoch 3330/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7855 - acc: 0.8176 - val_loss: 0.7944 - val_acc: 0.8275\n",
      "Epoch 3331/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7906 - acc: 0.8170 - val_loss: 0.7985 - val_acc: 0.8302\n",
      "Epoch 3332/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7866 - acc: 0.8173 - val_loss: 0.7952 - val_acc: 0.8194\n",
      "Epoch 3333/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7841 - acc: 0.8176 - val_loss: 0.7863 - val_acc: 0.8248\n",
      "Epoch 3334/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7797 - acc: 0.8152 - val_loss: 0.7802 - val_acc: 0.8275\n",
      "Epoch 3335/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7842 - acc: 0.8197 - val_loss: 0.7738 - val_acc: 0.8302\n",
      "Epoch 3336/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7979 - acc: 0.8095 - val_loss: 0.7857 - val_acc: 0.8221\n",
      "Epoch 3337/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8128 - acc: 0.8095 - val_loss: 0.7931 - val_acc: 0.8167\n",
      "Epoch 3338/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7895 - acc: 0.8152 - val_loss: 0.7966 - val_acc: 0.8194\n",
      "Epoch 3339/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7931 - acc: 0.8098 - val_loss: 0.7950 - val_acc: 0.8194\n",
      "Epoch 3340/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7890 - acc: 0.8119 - val_loss: 0.7864 - val_acc: 0.8194\n",
      "Epoch 3341/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7835 - acc: 0.8203 - val_loss: 0.7813 - val_acc: 0.8329\n",
      "Epoch 3342/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8090 - acc: 0.8146 - val_loss: 0.7798 - val_acc: 0.8275\n",
      "Epoch 3343/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7764 - acc: 0.8200 - val_loss: 0.7819 - val_acc: 0.8221\n",
      "Epoch 3344/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7943 - acc: 0.8155 - val_loss: 0.7826 - val_acc: 0.8302\n",
      "Epoch 3345/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7804 - acc: 0.8200 - val_loss: 0.7819 - val_acc: 0.8248\n",
      "Epoch 3346/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7850 - acc: 0.8128 - val_loss: 0.7749 - val_acc: 0.8248\n",
      "Epoch 3347/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8055 - acc: 0.8152 - val_loss: 0.7753 - val_acc: 0.8329\n",
      "Epoch 3348/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8043 - acc: 0.8143 - val_loss: 0.7828 - val_acc: 0.8302\n",
      "Epoch 3349/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8146 - val_loss: 0.7888 - val_acc: 0.8302\n",
      "Epoch 3350/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7858 - acc: 0.8134 - val_loss: 0.7887 - val_acc: 0.8248\n",
      "Epoch 3351/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7853 - acc: 0.8176 - val_loss: 0.7815 - val_acc: 0.8248\n",
      "Epoch 3352/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8119 - val_loss: 0.7808 - val_acc: 0.8275\n",
      "Epoch 3353/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7875 - acc: 0.8131 - val_loss: 0.7851 - val_acc: 0.8302\n",
      "Epoch 3354/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7884 - acc: 0.8122 - val_loss: 0.7863 - val_acc: 0.8302\n",
      "Epoch 3355/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7769 - acc: 0.8194 - val_loss: 0.7933 - val_acc: 0.8221\n",
      "Epoch 3356/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8018 - acc: 0.8077 - val_loss: 0.7940 - val_acc: 0.8275\n",
      "Epoch 3357/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8005 - acc: 0.8149 - val_loss: 0.7918 - val_acc: 0.8275\n",
      "Epoch 3358/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7984 - acc: 0.8116 - val_loss: 0.7883 - val_acc: 0.8221\n",
      "Epoch 3359/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8074 - acc: 0.8155 - val_loss: 0.7794 - val_acc: 0.8302\n",
      "Epoch 3360/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7918 - acc: 0.8143 - val_loss: 0.7767 - val_acc: 0.8329\n",
      "Epoch 3361/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8206 - acc: 0.8137 - val_loss: 0.7778 - val_acc: 0.8302\n",
      "Epoch 3362/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7950 - acc: 0.8176 - val_loss: 0.7803 - val_acc: 0.8248\n",
      "Epoch 3363/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7855 - acc: 0.8191 - val_loss: 0.7884 - val_acc: 0.8248\n",
      "Epoch 3364/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7936 - acc: 0.8194 - val_loss: 0.7892 - val_acc: 0.8302\n",
      "Epoch 3365/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8152 - val_loss: 0.7792 - val_acc: 0.8329\n",
      "Epoch 3366/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7764 - acc: 0.8194 - val_loss: 0.7799 - val_acc: 0.8221\n",
      "Epoch 3367/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7929 - acc: 0.8215 - val_loss: 0.7847 - val_acc: 0.8221\n",
      "Epoch 3368/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7818 - acc: 0.8200 - val_loss: 0.7789 - val_acc: 0.8356\n",
      "Epoch 3369/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8054 - acc: 0.8143 - val_loss: 0.7794 - val_acc: 0.8356\n",
      "Epoch 3370/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7725 - acc: 0.8161 - val_loss: 0.7829 - val_acc: 0.8356\n",
      "Epoch 3371/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7888 - acc: 0.8107 - val_loss: 0.7849 - val_acc: 0.8302\n",
      "Epoch 3372/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8133 - acc: 0.8155 - val_loss: 0.7742 - val_acc: 0.8302\n",
      "Epoch 3373/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8020 - acc: 0.8137 - val_loss: 0.7734 - val_acc: 0.8275\n",
      "Epoch 3374/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7849 - acc: 0.8149 - val_loss: 0.7761 - val_acc: 0.8248\n",
      "Epoch 3375/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7737 - acc: 0.8185 - val_loss: 0.7760 - val_acc: 0.8302\n",
      "Epoch 3376/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7995 - acc: 0.8116 - val_loss: 0.7750 - val_acc: 0.8302\n",
      "Epoch 3377/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7876 - acc: 0.8086 - val_loss: 0.7776 - val_acc: 0.8275\n",
      "Epoch 3378/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7811 - acc: 0.8116 - val_loss: 0.7865 - val_acc: 0.8248\n",
      "Epoch 3379/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7984 - acc: 0.8158 - val_loss: 0.7913 - val_acc: 0.8248\n",
      "Epoch 3380/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7811 - acc: 0.8206 - val_loss: 0.7943 - val_acc: 0.8248\n",
      "Epoch 3381/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8032 - acc: 0.8146 - val_loss: 0.7933 - val_acc: 0.8194\n",
      "Epoch 3382/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7886 - acc: 0.8143 - val_loss: 0.7872 - val_acc: 0.8248\n",
      "Epoch 3383/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7928 - acc: 0.8170 - val_loss: 0.7884 - val_acc: 0.8221\n",
      "Epoch 3384/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7889 - acc: 0.8164 - val_loss: 0.7895 - val_acc: 0.8248\n",
      "Epoch 3385/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7805 - acc: 0.8152 - val_loss: 0.7909 - val_acc: 0.8248\n",
      "Epoch 3386/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7891 - acc: 0.8173 - val_loss: 0.7856 - val_acc: 0.8248\n",
      "Epoch 3387/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8199 - acc: 0.8122 - val_loss: 0.7858 - val_acc: 0.8221\n",
      "Epoch 3388/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8104 - val_loss: 0.7895 - val_acc: 0.8194\n",
      "Epoch 3389/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7993 - acc: 0.8158 - val_loss: 0.7912 - val_acc: 0.8194\n",
      "Epoch 3390/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7867 - acc: 0.8167 - val_loss: 0.7962 - val_acc: 0.8167\n",
      "Epoch 3391/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8009 - acc: 0.8107 - val_loss: 0.7949 - val_acc: 0.8248\n",
      "Epoch 3392/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8006 - acc: 0.8179 - val_loss: 0.7990 - val_acc: 0.8167\n",
      "Epoch 3393/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7968 - acc: 0.8122 - val_loss: 0.7951 - val_acc: 0.8248\n",
      "Epoch 3394/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8224 - val_loss: 0.7958 - val_acc: 0.8221\n",
      "Epoch 3395/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7890 - acc: 0.8113 - val_loss: 0.8082 - val_acc: 0.8194\n",
      "Epoch 3396/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8116 - val_loss: 0.8155 - val_acc: 0.8167\n",
      "Epoch 3397/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7887 - acc: 0.8143 - val_loss: 0.8112 - val_acc: 0.8194\n",
      "Epoch 3398/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7984 - acc: 0.8140 - val_loss: 0.8031 - val_acc: 0.8248\n",
      "Epoch 3399/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7950 - acc: 0.8155 - val_loss: 0.7992 - val_acc: 0.8194\n",
      "Epoch 3400/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8083 - val_loss: 0.7988 - val_acc: 0.8302\n",
      "Epoch 3401/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7874 - acc: 0.8152 - val_loss: 0.7949 - val_acc: 0.8275\n",
      "Epoch 3402/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7918 - acc: 0.8167 - val_loss: 0.7926 - val_acc: 0.8275\n",
      "Epoch 3403/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7808 - acc: 0.8188 - val_loss: 0.7913 - val_acc: 0.8302\n",
      "Epoch 3404/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7842 - acc: 0.8170 - val_loss: 0.7922 - val_acc: 0.8248\n",
      "Epoch 3405/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7818 - acc: 0.8158 - val_loss: 0.7804 - val_acc: 0.8356\n",
      "Epoch 3406/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7919 - acc: 0.8170 - val_loss: 0.7698 - val_acc: 0.8329\n",
      "Epoch 3407/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7873 - acc: 0.8125 - val_loss: 0.7743 - val_acc: 0.8248\n",
      "Epoch 3408/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7868 - acc: 0.8200 - val_loss: 0.7825 - val_acc: 0.8248\n",
      "Epoch 3409/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7741 - acc: 0.8155 - val_loss: 0.7830 - val_acc: 0.8356\n",
      "Epoch 3410/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7874 - acc: 0.8176 - val_loss: 0.7917 - val_acc: 0.8329\n",
      "Epoch 3411/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7890 - acc: 0.8161 - val_loss: 0.7993 - val_acc: 0.8221\n",
      "Epoch 3412/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8151 - acc: 0.8125 - val_loss: 0.7987 - val_acc: 0.8275\n",
      "Epoch 3413/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7925 - acc: 0.8167 - val_loss: 0.8012 - val_acc: 0.8221\n",
      "Epoch 3414/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7868 - acc: 0.8137 - val_loss: 0.8013 - val_acc: 0.8221\n",
      "Epoch 3415/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7903 - acc: 0.8161 - val_loss: 0.7970 - val_acc: 0.8275\n",
      "Epoch 3416/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8025 - acc: 0.8134 - val_loss: 0.7848 - val_acc: 0.8302\n",
      "Epoch 3417/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7912 - acc: 0.8146 - val_loss: 0.7797 - val_acc: 0.8275\n",
      "Epoch 3418/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7939 - acc: 0.8125 - val_loss: 0.7830 - val_acc: 0.8275\n",
      "Epoch 3419/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7851 - acc: 0.8107 - val_loss: 0.7930 - val_acc: 0.8275\n",
      "Epoch 3420/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8032 - acc: 0.8161 - val_loss: 0.7959 - val_acc: 0.8140\n",
      "Epoch 3421/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8158 - val_loss: 0.7975 - val_acc: 0.8167\n",
      "Epoch 3422/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8025 - acc: 0.8143 - val_loss: 0.7876 - val_acc: 0.8194\n",
      "Epoch 3423/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7922 - acc: 0.8188 - val_loss: 0.7780 - val_acc: 0.8302\n",
      "Epoch 3424/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7936 - acc: 0.8113 - val_loss: 0.7771 - val_acc: 0.8302\n",
      "Epoch 3425/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8143 - val_loss: 0.7747 - val_acc: 0.8248\n",
      "Epoch 3426/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8020 - acc: 0.8119 - val_loss: 0.7778 - val_acc: 0.8194\n",
      "Epoch 3427/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7930 - acc: 0.8122 - val_loss: 0.7818 - val_acc: 0.8167\n",
      "Epoch 3428/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8092 - acc: 0.8116 - val_loss: 0.7752 - val_acc: 0.8248\n",
      "Epoch 3429/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7930 - acc: 0.8164 - val_loss: 0.7688 - val_acc: 0.8275\n",
      "Epoch 3430/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7999 - acc: 0.8107 - val_loss: 0.7665 - val_acc: 0.8329\n",
      "Epoch 3431/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8095 - val_loss: 0.7672 - val_acc: 0.8248\n",
      "Epoch 3432/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7978 - acc: 0.8179 - val_loss: 0.7745 - val_acc: 0.8248\n",
      "Epoch 3433/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8128 - acc: 0.8077 - val_loss: 0.7773 - val_acc: 0.8248\n",
      "Epoch 3434/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8167 - val_loss: 0.7803 - val_acc: 0.8221\n",
      "Epoch 3435/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7854 - acc: 0.8179 - val_loss: 0.7813 - val_acc: 0.8167\n",
      "Epoch 3436/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8089 - val_loss: 0.7844 - val_acc: 0.8194\n",
      "Epoch 3437/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7775 - acc: 0.8146 - val_loss: 0.7850 - val_acc: 0.8248\n",
      "Epoch 3438/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8164 - val_loss: 0.7922 - val_acc: 0.8140\n",
      "Epoch 3439/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7774 - acc: 0.8134 - val_loss: 0.7954 - val_acc: 0.8194\n",
      "Epoch 3440/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7757 - acc: 0.8191 - val_loss: 0.7982 - val_acc: 0.8221\n",
      "Epoch 3441/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7845 - acc: 0.8170 - val_loss: 0.7957 - val_acc: 0.8248\n",
      "Epoch 3442/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7941 - acc: 0.8140 - val_loss: 0.7828 - val_acc: 0.8221\n",
      "Epoch 3443/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7833 - acc: 0.8065 - val_loss: 0.7717 - val_acc: 0.8302\n",
      "Epoch 3444/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8098 - val_loss: 0.7655 - val_acc: 0.8329\n",
      "Epoch 3445/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7901 - acc: 0.8194 - val_loss: 0.7663 - val_acc: 0.8302\n",
      "Epoch 3446/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8085 - acc: 0.8185 - val_loss: 0.7739 - val_acc: 0.8248\n",
      "Epoch 3447/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7971 - acc: 0.8170 - val_loss: 0.7787 - val_acc: 0.8194\n",
      "Epoch 3448/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7945 - acc: 0.8152 - val_loss: 0.7785 - val_acc: 0.8140\n",
      "Epoch 3449/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7960 - acc: 0.8122 - val_loss: 0.7804 - val_acc: 0.8194\n",
      "Epoch 3450/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7717 - acc: 0.8230 - val_loss: 0.7872 - val_acc: 0.8248\n",
      "Epoch 3451/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8137 - val_loss: 0.7864 - val_acc: 0.8248\n",
      "Epoch 3452/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7764 - acc: 0.8125 - val_loss: 0.7797 - val_acc: 0.8302\n",
      "Epoch 3453/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7939 - acc: 0.8170 - val_loss: 0.7778 - val_acc: 0.8275\n",
      "Epoch 3454/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7716 - acc: 0.8200 - val_loss: 0.7808 - val_acc: 0.8248\n",
      "Epoch 3455/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7846 - acc: 0.8203 - val_loss: 0.7866 - val_acc: 0.8275\n",
      "Epoch 3456/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7765 - acc: 0.8218 - val_loss: 0.7826 - val_acc: 0.8275\n",
      "Epoch 3457/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8089 - val_loss: 0.7828 - val_acc: 0.8275\n",
      "Epoch 3458/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7800 - acc: 0.8239 - val_loss: 0.7825 - val_acc: 0.8275\n",
      "Epoch 3459/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7787 - acc: 0.8146 - val_loss: 0.7814 - val_acc: 0.8302\n",
      "Epoch 3460/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7931 - acc: 0.8068 - val_loss: 0.7800 - val_acc: 0.8302\n",
      "Epoch 3461/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8016 - acc: 0.8095 - val_loss: 0.7835 - val_acc: 0.8302\n",
      "Epoch 3462/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8068 - acc: 0.8122 - val_loss: 0.7846 - val_acc: 0.8275\n",
      "Epoch 3463/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8066 - acc: 0.8104 - val_loss: 0.7818 - val_acc: 0.8275\n",
      "Epoch 3464/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7974 - acc: 0.8140 - val_loss: 0.7796 - val_acc: 0.8248\n",
      "Epoch 3465/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8044 - acc: 0.8143 - val_loss: 0.7812 - val_acc: 0.8221\n",
      "Epoch 3466/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7804 - acc: 0.8182 - val_loss: 0.7790 - val_acc: 0.8194\n",
      "Epoch 3467/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8038 - acc: 0.8122 - val_loss: 0.7756 - val_acc: 0.8248\n",
      "Epoch 3468/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7815 - acc: 0.8152 - val_loss: 0.7768 - val_acc: 0.8329\n",
      "Epoch 3469/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8097 - acc: 0.8131 - val_loss: 0.7818 - val_acc: 0.8275\n",
      "Epoch 3470/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8113 - acc: 0.8122 - val_loss: 0.7748 - val_acc: 0.8302\n",
      "Epoch 3471/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7805 - acc: 0.8095 - val_loss: 0.7685 - val_acc: 0.8275\n",
      "Epoch 3472/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7772 - acc: 0.8137 - val_loss: 0.7721 - val_acc: 0.8248\n",
      "Epoch 3473/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8112 - acc: 0.8134 - val_loss: 0.7740 - val_acc: 0.8194\n",
      "Epoch 3474/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8146 - val_loss: 0.7739 - val_acc: 0.8248\n",
      "Epoch 3475/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7886 - acc: 0.8164 - val_loss: 0.7760 - val_acc: 0.8302\n",
      "Epoch 3476/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7945 - acc: 0.8131 - val_loss: 0.7820 - val_acc: 0.8275\n",
      "Epoch 3477/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8026 - acc: 0.8116 - val_loss: 0.7896 - val_acc: 0.8194\n",
      "Epoch 3478/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7793 - acc: 0.8188 - val_loss: 0.7871 - val_acc: 0.8248\n",
      "Epoch 3479/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7788 - acc: 0.8203 - val_loss: 0.7868 - val_acc: 0.8221\n",
      "Epoch 3480/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7909 - acc: 0.8095 - val_loss: 0.7911 - val_acc: 0.8221\n",
      "Epoch 3481/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7938 - acc: 0.8083 - val_loss: 0.7834 - val_acc: 0.8248\n",
      "Epoch 3482/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7834 - acc: 0.8113 - val_loss: 0.7760 - val_acc: 0.8248\n",
      "Epoch 3483/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7869 - acc: 0.8212 - val_loss: 0.7758 - val_acc: 0.8302\n",
      "Epoch 3484/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7854 - acc: 0.8134 - val_loss: 0.7758 - val_acc: 0.8302\n",
      "Epoch 3485/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8016 - acc: 0.8134 - val_loss: 0.7743 - val_acc: 0.8302\n",
      "Epoch 3486/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7720 - acc: 0.8221 - val_loss: 0.7775 - val_acc: 0.8248\n",
      "Epoch 3487/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7780 - acc: 0.8188 - val_loss: 0.7793 - val_acc: 0.8194\n",
      "Epoch 3488/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7752 - acc: 0.8170 - val_loss: 0.7790 - val_acc: 0.8248\n",
      "Epoch 3489/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7768 - acc: 0.8203 - val_loss: 0.7829 - val_acc: 0.8194\n",
      "Epoch 3490/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7817 - acc: 0.8209 - val_loss: 0.7869 - val_acc: 0.8194\n",
      "Epoch 3491/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7974 - acc: 0.8125 - val_loss: 0.7862 - val_acc: 0.8221\n",
      "Epoch 3492/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7778 - acc: 0.8182 - val_loss: 0.7763 - val_acc: 0.8221\n",
      "Epoch 3493/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7797 - acc: 0.8179 - val_loss: 0.7730 - val_acc: 0.8248\n",
      "Epoch 3494/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7784 - acc: 0.8155 - val_loss: 0.7709 - val_acc: 0.8248\n",
      "Epoch 3495/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7804 - acc: 0.8173 - val_loss: 0.7729 - val_acc: 0.8275\n",
      "Epoch 3496/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7930 - acc: 0.8134 - val_loss: 0.7733 - val_acc: 0.8248\n",
      "Epoch 3497/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7654 - acc: 0.8158 - val_loss: 0.7760 - val_acc: 0.8275\n",
      "Epoch 3498/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7820 - acc: 0.8113 - val_loss: 0.7760 - val_acc: 0.8248\n",
      "Epoch 3499/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7829 - acc: 0.8182 - val_loss: 0.7774 - val_acc: 0.8329\n",
      "Epoch 3500/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7943 - acc: 0.8152 - val_loss: 0.7818 - val_acc: 0.8302\n",
      "Epoch 3501/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8134 - val_loss: 0.7862 - val_acc: 0.8248\n",
      "Epoch 3502/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8094 - acc: 0.8131 - val_loss: 0.7934 - val_acc: 0.8248\n",
      "Epoch 3503/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7962 - acc: 0.8164 - val_loss: 0.7935 - val_acc: 0.8248\n",
      "Epoch 3504/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7821 - acc: 0.8134 - val_loss: 0.7906 - val_acc: 0.8275\n",
      "Epoch 3505/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7646 - acc: 0.8134 - val_loss: 0.7859 - val_acc: 0.8248\n",
      "Epoch 3506/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8170 - val_loss: 0.7904 - val_acc: 0.8248\n",
      "Epoch 3507/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7819 - acc: 0.8185 - val_loss: 0.7887 - val_acc: 0.8275\n",
      "Epoch 3508/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7856 - acc: 0.8110 - val_loss: 0.7816 - val_acc: 0.8248\n",
      "Epoch 3509/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8068 - acc: 0.8071 - val_loss: 0.7811 - val_acc: 0.8221\n",
      "Epoch 3510/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7763 - acc: 0.8197 - val_loss: 0.7745 - val_acc: 0.8221\n",
      "Epoch 3511/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7806 - acc: 0.8125 - val_loss: 0.7692 - val_acc: 0.8275\n",
      "Epoch 3512/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7855 - acc: 0.8203 - val_loss: 0.7702 - val_acc: 0.8221\n",
      "Epoch 3513/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7971 - acc: 0.8143 - val_loss: 0.7730 - val_acc: 0.8248\n",
      "Epoch 3514/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8089 - acc: 0.8113 - val_loss: 0.7746 - val_acc: 0.8275\n",
      "Epoch 3515/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7958 - acc: 0.8209 - val_loss: 0.7761 - val_acc: 0.8275\n",
      "Epoch 3516/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7757 - acc: 0.8146 - val_loss: 0.7831 - val_acc: 0.8221\n",
      "Epoch 3517/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7874 - acc: 0.8134 - val_loss: 0.7896 - val_acc: 0.8221\n",
      "Epoch 3518/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7954 - acc: 0.8110 - val_loss: 0.7912 - val_acc: 0.8248\n",
      "Epoch 3519/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7776 - acc: 0.8185 - val_loss: 0.7880 - val_acc: 0.8302\n",
      "Epoch 3520/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7916 - acc: 0.8149 - val_loss: 0.7938 - val_acc: 0.8248\n",
      "Epoch 3521/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7954 - acc: 0.8158 - val_loss: 0.7953 - val_acc: 0.8248\n",
      "Epoch 3522/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7814 - acc: 0.8179 - val_loss: 0.7949 - val_acc: 0.8275\n",
      "Epoch 3523/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8025 - acc: 0.8206 - val_loss: 0.7955 - val_acc: 0.8275\n",
      "Epoch 3524/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8008 - acc: 0.8134 - val_loss: 0.7991 - val_acc: 0.8329\n",
      "Epoch 3525/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7896 - acc: 0.8152 - val_loss: 0.8022 - val_acc: 0.8302\n",
      "Epoch 3526/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7773 - acc: 0.8143 - val_loss: 0.7985 - val_acc: 0.8248\n",
      "Epoch 3527/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8167 - val_loss: 0.7963 - val_acc: 0.8221\n",
      "Epoch 3528/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7936 - acc: 0.8119 - val_loss: 0.7943 - val_acc: 0.8248\n",
      "Epoch 3529/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8154 - acc: 0.8143 - val_loss: 0.7882 - val_acc: 0.8248\n",
      "Epoch 3530/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7977 - acc: 0.8134 - val_loss: 0.7865 - val_acc: 0.8248\n",
      "Epoch 3531/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7858 - acc: 0.8134 - val_loss: 0.7869 - val_acc: 0.8221\n",
      "Epoch 3532/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8057 - acc: 0.8140 - val_loss: 0.7847 - val_acc: 0.8221\n",
      "Epoch 3533/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7890 - acc: 0.8173 - val_loss: 0.7783 - val_acc: 0.8221\n",
      "Epoch 3534/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7965 - acc: 0.8140 - val_loss: 0.7699 - val_acc: 0.8248\n",
      "Epoch 3535/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7852 - acc: 0.8167 - val_loss: 0.7695 - val_acc: 0.8275\n",
      "Epoch 3536/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7987 - acc: 0.8122 - val_loss: 0.7783 - val_acc: 0.8248\n",
      "Epoch 3537/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7951 - acc: 0.8134 - val_loss: 0.7827 - val_acc: 0.8248\n",
      "Epoch 3538/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8143 - val_loss: 0.7874 - val_acc: 0.8221\n",
      "Epoch 3539/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7912 - acc: 0.8137 - val_loss: 0.7903 - val_acc: 0.8248\n",
      "Epoch 3540/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8185 - val_loss: 0.7951 - val_acc: 0.8194\n",
      "Epoch 3541/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8131 - val_loss: 0.7981 - val_acc: 0.8221\n",
      "Epoch 3542/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8000 - acc: 0.8083 - val_loss: 0.7918 - val_acc: 0.8275\n",
      "Epoch 3543/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8146 - val_loss: 0.7942 - val_acc: 0.8275\n",
      "Epoch 3544/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7937 - acc: 0.8140 - val_loss: 0.7962 - val_acc: 0.8221\n",
      "Epoch 3545/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7821 - acc: 0.8179 - val_loss: 0.7961 - val_acc: 0.8140\n",
      "Epoch 3546/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7727 - acc: 0.8161 - val_loss: 0.7970 - val_acc: 0.8194\n",
      "Epoch 3547/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7995 - acc: 0.8185 - val_loss: 0.8027 - val_acc: 0.8248\n",
      "Epoch 3548/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7970 - acc: 0.8128 - val_loss: 0.7975 - val_acc: 0.8302\n",
      "Epoch 3549/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7833 - acc: 0.8092 - val_loss: 0.7901 - val_acc: 0.8383\n",
      "Epoch 3550/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8167 - val_loss: 0.7869 - val_acc: 0.8383\n",
      "Epoch 3551/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8057 - acc: 0.8188 - val_loss: 0.7929 - val_acc: 0.8356\n",
      "Epoch 3552/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7676 - acc: 0.8182 - val_loss: 0.7991 - val_acc: 0.8302\n",
      "Epoch 3553/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7994 - acc: 0.8119 - val_loss: 0.7958 - val_acc: 0.8221\n",
      "Epoch 3554/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8073 - acc: 0.8155 - val_loss: 0.7863 - val_acc: 0.8302\n",
      "Epoch 3555/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7950 - acc: 0.8125 - val_loss: 0.7828 - val_acc: 0.8221\n",
      "Epoch 3556/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7808 - acc: 0.8137 - val_loss: 0.7816 - val_acc: 0.8248\n",
      "Epoch 3557/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7917 - acc: 0.8092 - val_loss: 0.7750 - val_acc: 0.8248\n",
      "Epoch 3558/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7914 - acc: 0.8089 - val_loss: 0.7748 - val_acc: 0.8275\n",
      "Epoch 3559/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7871 - acc: 0.8188 - val_loss: 0.7775 - val_acc: 0.8275\n",
      "Epoch 3560/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7995 - acc: 0.8134 - val_loss: 0.7848 - val_acc: 0.8275\n",
      "Epoch 3561/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7872 - acc: 0.8110 - val_loss: 0.7909 - val_acc: 0.8248\n",
      "Epoch 3562/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8007 - acc: 0.8155 - val_loss: 0.7911 - val_acc: 0.8167\n",
      "Epoch 3563/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7977 - acc: 0.8146 - val_loss: 0.7861 - val_acc: 0.8140\n",
      "Epoch 3564/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7933 - acc: 0.8167 - val_loss: 0.7805 - val_acc: 0.8140\n",
      "Epoch 3565/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7724 - acc: 0.8233 - val_loss: 0.7744 - val_acc: 0.8194\n",
      "Epoch 3566/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8101 - acc: 0.8149 - val_loss: 0.7707 - val_acc: 0.8221\n",
      "Epoch 3567/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7868 - acc: 0.8218 - val_loss: 0.7795 - val_acc: 0.8275\n",
      "Epoch 3568/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7890 - acc: 0.8194 - val_loss: 0.7911 - val_acc: 0.8275\n",
      "Epoch 3569/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7959 - acc: 0.8098 - val_loss: 0.7930 - val_acc: 0.8221\n",
      "Epoch 3570/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7990 - acc: 0.8113 - val_loss: 0.7927 - val_acc: 0.8167\n",
      "Epoch 3571/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7820 - acc: 0.8119 - val_loss: 0.7998 - val_acc: 0.8167\n",
      "Epoch 3572/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7837 - acc: 0.8155 - val_loss: 0.8007 - val_acc: 0.8194\n",
      "Epoch 3573/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7855 - acc: 0.8131 - val_loss: 0.7950 - val_acc: 0.8221\n",
      "Epoch 3574/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7961 - acc: 0.8098 - val_loss: 0.7921 - val_acc: 0.8221\n",
      "Epoch 3575/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7844 - acc: 0.8104 - val_loss: 0.7853 - val_acc: 0.8221\n",
      "Epoch 3576/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7928 - acc: 0.8167 - val_loss: 0.7845 - val_acc: 0.8167\n",
      "Epoch 3577/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7803 - acc: 0.8170 - val_loss: 0.7794 - val_acc: 0.8167\n",
      "Epoch 3578/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8037 - acc: 0.8131 - val_loss: 0.7782 - val_acc: 0.8248\n",
      "Epoch 3579/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7776 - acc: 0.8182 - val_loss: 0.7814 - val_acc: 0.8275\n",
      "Epoch 3580/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8128 - val_loss: 0.7817 - val_acc: 0.8275\n",
      "Epoch 3581/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7827 - acc: 0.8200 - val_loss: 0.7797 - val_acc: 0.8194\n",
      "Epoch 3582/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7998 - acc: 0.8146 - val_loss: 0.7774 - val_acc: 0.8275\n",
      "Epoch 3583/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7896 - acc: 0.8125 - val_loss: 0.7764 - val_acc: 0.8329\n",
      "Epoch 3584/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7911 - acc: 0.8155 - val_loss: 0.7790 - val_acc: 0.8302\n",
      "Epoch 3585/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8026 - acc: 0.8182 - val_loss: 0.7794 - val_acc: 0.8302\n",
      "Epoch 3586/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7740 - acc: 0.8164 - val_loss: 0.7819 - val_acc: 0.8248\n",
      "Epoch 3587/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7991 - acc: 0.8107 - val_loss: 0.7852 - val_acc: 0.8275\n",
      "Epoch 3588/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7905 - acc: 0.8185 - val_loss: 0.7935 - val_acc: 0.8194\n",
      "Epoch 3589/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7770 - acc: 0.8155 - val_loss: 0.7856 - val_acc: 0.8194\n",
      "Epoch 3590/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7863 - acc: 0.8197 - val_loss: 0.7837 - val_acc: 0.8248\n",
      "Epoch 3591/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7913 - acc: 0.8143 - val_loss: 0.7773 - val_acc: 0.8275\n",
      "Epoch 3592/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8164 - val_loss: 0.7757 - val_acc: 0.8302\n",
      "Epoch 3593/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7898 - acc: 0.8125 - val_loss: 0.7807 - val_acc: 0.8248\n",
      "Epoch 3594/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7941 - acc: 0.8197 - val_loss: 0.7870 - val_acc: 0.8248\n",
      "Epoch 3595/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8155 - val_loss: 0.7877 - val_acc: 0.8275\n",
      "Epoch 3596/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7713 - acc: 0.8143 - val_loss: 0.7871 - val_acc: 0.8248\n",
      "Epoch 3597/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7973 - acc: 0.8149 - val_loss: 0.7883 - val_acc: 0.8194\n",
      "Epoch 3598/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7835 - acc: 0.8152 - val_loss: 0.7844 - val_acc: 0.8275\n",
      "Epoch 3599/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7720 - acc: 0.8131 - val_loss: 0.7824 - val_acc: 0.8275\n",
      "Epoch 3600/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7957 - acc: 0.8143 - val_loss: 0.7888 - val_acc: 0.8248\n",
      "Epoch 3601/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7848 - acc: 0.8125 - val_loss: 0.7963 - val_acc: 0.8221\n",
      "Epoch 3602/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7914 - acc: 0.8158 - val_loss: 0.7880 - val_acc: 0.8221\n",
      "Epoch 3603/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7829 - acc: 0.8098 - val_loss: 0.7790 - val_acc: 0.8248\n",
      "Epoch 3604/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7886 - acc: 0.8113 - val_loss: 0.7737 - val_acc: 0.8302\n",
      "Epoch 3605/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7834 - acc: 0.8170 - val_loss: 0.7762 - val_acc: 0.8248\n",
      "Epoch 3606/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7836 - acc: 0.8101 - val_loss: 0.7770 - val_acc: 0.8275\n",
      "Epoch 3607/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7981 - acc: 0.8116 - val_loss: 0.7818 - val_acc: 0.8194\n",
      "Epoch 3608/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7957 - acc: 0.8113 - val_loss: 0.7885 - val_acc: 0.8167\n",
      "Epoch 3609/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7943 - acc: 0.8152 - val_loss: 0.7918 - val_acc: 0.8275\n",
      "Epoch 3610/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7780 - acc: 0.8128 - val_loss: 0.7946 - val_acc: 0.8329\n",
      "Epoch 3611/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7780 - acc: 0.8167 - val_loss: 0.7913 - val_acc: 0.8302\n",
      "Epoch 3612/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8002 - acc: 0.8149 - val_loss: 0.7831 - val_acc: 0.8302\n",
      "Epoch 3613/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7899 - acc: 0.8152 - val_loss: 0.7726 - val_acc: 0.8329\n",
      "Epoch 3614/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8140 - val_loss: 0.7765 - val_acc: 0.8302\n",
      "Epoch 3615/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7928 - acc: 0.8161 - val_loss: 0.7880 - val_acc: 0.8302\n",
      "Epoch 3616/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7880 - acc: 0.8191 - val_loss: 0.7949 - val_acc: 0.8302\n",
      "Epoch 3617/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7999 - acc: 0.8131 - val_loss: 0.7941 - val_acc: 0.8356\n",
      "Epoch 3618/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8014 - acc: 0.8086 - val_loss: 0.7952 - val_acc: 0.8194\n",
      "Epoch 3619/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7776 - acc: 0.8197 - val_loss: 0.7978 - val_acc: 0.8113\n",
      "Epoch 3620/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7973 - acc: 0.8146 - val_loss: 0.7874 - val_acc: 0.8167\n",
      "Epoch 3621/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7988 - acc: 0.8095 - val_loss: 0.7814 - val_acc: 0.8194\n",
      "Epoch 3622/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8052 - acc: 0.8110 - val_loss: 0.7786 - val_acc: 0.8248\n",
      "Epoch 3623/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8173 - val_loss: 0.7849 - val_acc: 0.8275\n",
      "Epoch 3624/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7781 - acc: 0.8191 - val_loss: 0.7940 - val_acc: 0.8194\n",
      "Epoch 3625/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7843 - acc: 0.8182 - val_loss: 0.7995 - val_acc: 0.8167\n",
      "Epoch 3626/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7874 - acc: 0.8128 - val_loss: 0.7952 - val_acc: 0.8167\n",
      "Epoch 3627/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7853 - acc: 0.8227 - val_loss: 0.7851 - val_acc: 0.8194\n",
      "Epoch 3628/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8176 - val_loss: 0.7841 - val_acc: 0.8221\n",
      "Epoch 3629/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7971 - acc: 0.8173 - val_loss: 0.7917 - val_acc: 0.8248\n",
      "Epoch 3630/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7855 - acc: 0.8167 - val_loss: 0.7873 - val_acc: 0.8221\n",
      "Epoch 3631/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7797 - acc: 0.8194 - val_loss: 0.7795 - val_acc: 0.8194\n",
      "Epoch 3632/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7911 - acc: 0.8143 - val_loss: 0.7842 - val_acc: 0.8194\n",
      "Epoch 3633/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7881 - acc: 0.8152 - val_loss: 0.7934 - val_acc: 0.8194\n",
      "Epoch 3634/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7709 - acc: 0.8230 - val_loss: 0.7983 - val_acc: 0.8167\n",
      "Epoch 3635/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8167 - val_loss: 0.7978 - val_acc: 0.8194\n",
      "Epoch 3636/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8131 - val_loss: 0.7945 - val_acc: 0.8248\n",
      "Epoch 3637/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7890 - acc: 0.8104 - val_loss: 0.7908 - val_acc: 0.8275\n",
      "Epoch 3638/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7945 - acc: 0.8191 - val_loss: 0.7938 - val_acc: 0.8221\n",
      "Epoch 3639/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8068 - acc: 0.8173 - val_loss: 0.7985 - val_acc: 0.8275\n",
      "Epoch 3640/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8080 - val_loss: 0.8038 - val_acc: 0.8221\n",
      "Epoch 3641/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7892 - acc: 0.8140 - val_loss: 0.8051 - val_acc: 0.8275\n",
      "Epoch 3642/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7944 - acc: 0.8095 - val_loss: 0.8042 - val_acc: 0.8221\n",
      "Epoch 3643/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8001 - acc: 0.8161 - val_loss: 0.8012 - val_acc: 0.8221\n",
      "Epoch 3644/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7910 - acc: 0.8143 - val_loss: 0.7994 - val_acc: 0.8248\n",
      "Epoch 3645/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7989 - acc: 0.8149 - val_loss: 0.8006 - val_acc: 0.8221\n",
      "Epoch 3646/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7791 - acc: 0.8167 - val_loss: 0.7994 - val_acc: 0.8248\n",
      "Epoch 3647/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7861 - acc: 0.8239 - val_loss: 0.7903 - val_acc: 0.8248\n",
      "Epoch 3648/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8061 - acc: 0.8110 - val_loss: 0.7791 - val_acc: 0.8356\n",
      "Epoch 3649/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7888 - acc: 0.8155 - val_loss: 0.7792 - val_acc: 0.8248\n",
      "Epoch 3650/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7805 - acc: 0.8158 - val_loss: 0.7784 - val_acc: 0.8275\n",
      "Epoch 3651/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8116 - val_loss: 0.7810 - val_acc: 0.8275\n",
      "Epoch 3652/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8025 - acc: 0.8122 - val_loss: 0.7868 - val_acc: 0.8275\n",
      "Epoch 3653/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7924 - acc: 0.8170 - val_loss: 0.7882 - val_acc: 0.8275\n",
      "Epoch 3654/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8007 - acc: 0.8149 - val_loss: 0.7871 - val_acc: 0.8302\n",
      "Epoch 3655/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7717 - acc: 0.8152 - val_loss: 0.7862 - val_acc: 0.8248\n",
      "Epoch 3656/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8143 - val_loss: 0.7774 - val_acc: 0.8248\n",
      "Epoch 3657/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7983 - acc: 0.8134 - val_loss: 0.7738 - val_acc: 0.8248\n",
      "Epoch 3658/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7798 - acc: 0.8113 - val_loss: 0.7792 - val_acc: 0.8248\n",
      "Epoch 3659/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7790 - acc: 0.8164 - val_loss: 0.7875 - val_acc: 0.8167\n",
      "Epoch 3660/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8200 - val_loss: 0.7978 - val_acc: 0.8194\n",
      "Epoch 3661/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7861 - acc: 0.8125 - val_loss: 0.8021 - val_acc: 0.8221\n",
      "Epoch 3662/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7890 - acc: 0.8164 - val_loss: 0.7982 - val_acc: 0.8275\n",
      "Epoch 3663/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7911 - acc: 0.8113 - val_loss: 0.7991 - val_acc: 0.8248\n",
      "Epoch 3664/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7924 - acc: 0.8134 - val_loss: 0.7957 - val_acc: 0.8194\n",
      "Epoch 3665/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8176 - val_loss: 0.7978 - val_acc: 0.8221\n",
      "Epoch 3666/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8189 - acc: 0.8107 - val_loss: 0.7965 - val_acc: 0.8275\n",
      "Epoch 3667/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8022 - acc: 0.8101 - val_loss: 0.7954 - val_acc: 0.8329\n",
      "Epoch 3668/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7713 - acc: 0.8221 - val_loss: 0.8026 - val_acc: 0.8248\n",
      "Epoch 3669/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8010 - acc: 0.8173 - val_loss: 0.8036 - val_acc: 0.8221\n",
      "Epoch 3670/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8177 - acc: 0.8140 - val_loss: 0.8016 - val_acc: 0.8221\n",
      "Epoch 3671/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8128 - val_loss: 0.7949 - val_acc: 0.8248\n",
      "Epoch 3672/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8025 - acc: 0.8104 - val_loss: 0.7880 - val_acc: 0.8248\n",
      "Epoch 3673/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7888 - acc: 0.8125 - val_loss: 0.7859 - val_acc: 0.8248\n",
      "Epoch 3674/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7929 - acc: 0.8146 - val_loss: 0.7907 - val_acc: 0.8221\n",
      "Epoch 3675/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7888 - acc: 0.8161 - val_loss: 0.7946 - val_acc: 0.8275\n",
      "Epoch 3676/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8191 - val_loss: 0.7918 - val_acc: 0.8302\n",
      "Epoch 3677/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7937 - acc: 0.8098 - val_loss: 0.7932 - val_acc: 0.8275\n",
      "Epoch 3678/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8149 - val_loss: 0.8013 - val_acc: 0.8248\n",
      "Epoch 3679/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8005 - acc: 0.8152 - val_loss: 0.8053 - val_acc: 0.8221\n",
      "Epoch 3680/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8185 - val_loss: 0.8068 - val_acc: 0.8275\n",
      "Epoch 3681/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8041 - acc: 0.8110 - val_loss: 0.8092 - val_acc: 0.8248\n",
      "Epoch 3682/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7916 - acc: 0.8212 - val_loss: 0.8051 - val_acc: 0.8248\n",
      "Epoch 3683/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7953 - acc: 0.8200 - val_loss: 0.7958 - val_acc: 0.8194\n",
      "Epoch 3684/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7727 - acc: 0.8155 - val_loss: 0.7905 - val_acc: 0.8302\n",
      "Epoch 3685/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7989 - acc: 0.8128 - val_loss: 0.7891 - val_acc: 0.8275\n",
      "Epoch 3686/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7974 - acc: 0.8131 - val_loss: 0.7836 - val_acc: 0.8356\n",
      "Epoch 3687/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7957 - acc: 0.8155 - val_loss: 0.7820 - val_acc: 0.8275\n",
      "Epoch 3688/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7666 - acc: 0.8185 - val_loss: 0.7922 - val_acc: 0.8248\n",
      "Epoch 3689/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7818 - acc: 0.8188 - val_loss: 0.8016 - val_acc: 0.8248\n",
      "Epoch 3690/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7971 - acc: 0.8137 - val_loss: 0.8038 - val_acc: 0.8221\n",
      "Epoch 3691/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8084 - acc: 0.8107 - val_loss: 0.8052 - val_acc: 0.8221\n",
      "Epoch 3692/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8036 - acc: 0.8116 - val_loss: 0.8098 - val_acc: 0.8275\n",
      "Epoch 3693/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8012 - acc: 0.8074 - val_loss: 0.8105 - val_acc: 0.8248\n",
      "Epoch 3694/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8070 - acc: 0.8050 - val_loss: 0.8095 - val_acc: 0.8248\n",
      "Epoch 3695/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8033 - acc: 0.8110 - val_loss: 0.8047 - val_acc: 0.8221\n",
      "Epoch 3696/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7947 - acc: 0.8191 - val_loss: 0.7990 - val_acc: 0.8275\n",
      "Epoch 3697/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7899 - acc: 0.8146 - val_loss: 0.7906 - val_acc: 0.8248\n",
      "Epoch 3698/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7987 - acc: 0.8128 - val_loss: 0.7863 - val_acc: 0.8194\n",
      "Epoch 3699/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7724 - acc: 0.8200 - val_loss: 0.7884 - val_acc: 0.8221\n",
      "Epoch 3700/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8017 - acc: 0.8131 - val_loss: 0.7855 - val_acc: 0.8194\n",
      "Epoch 3701/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7922 - acc: 0.8089 - val_loss: 0.7816 - val_acc: 0.8221\n",
      "Epoch 3702/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7876 - acc: 0.8164 - val_loss: 0.7815 - val_acc: 0.8221\n",
      "Epoch 3703/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7855 - acc: 0.8191 - val_loss: 0.7875 - val_acc: 0.8221\n",
      "Epoch 3704/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7858 - acc: 0.8152 - val_loss: 0.7950 - val_acc: 0.8140\n",
      "Epoch 3705/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7895 - acc: 0.8086 - val_loss: 0.7938 - val_acc: 0.8167\n",
      "Epoch 3706/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7936 - acc: 0.8149 - val_loss: 0.7850 - val_acc: 0.8194\n",
      "Epoch 3707/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8113 - val_loss: 0.7831 - val_acc: 0.8248\n",
      "Epoch 3708/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7711 - acc: 0.8173 - val_loss: 0.7823 - val_acc: 0.8302\n",
      "Epoch 3709/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7876 - acc: 0.8083 - val_loss: 0.7808 - val_acc: 0.8302\n",
      "Epoch 3710/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7800 - acc: 0.8155 - val_loss: 0.7844 - val_acc: 0.8302\n",
      "Epoch 3711/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8131 - val_loss: 0.7834 - val_acc: 0.8302\n",
      "Epoch 3712/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7851 - acc: 0.8116 - val_loss: 0.7878 - val_acc: 0.8248\n",
      "Epoch 3713/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8106 - acc: 0.8026 - val_loss: 0.7890 - val_acc: 0.8275\n",
      "Epoch 3714/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7802 - acc: 0.8137 - val_loss: 0.7820 - val_acc: 0.8302\n",
      "Epoch 3715/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7820 - acc: 0.8176 - val_loss: 0.7830 - val_acc: 0.8329\n",
      "Epoch 3716/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7879 - acc: 0.8134 - val_loss: 0.7844 - val_acc: 0.8275\n",
      "Epoch 3717/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7901 - acc: 0.8149 - val_loss: 0.7829 - val_acc: 0.8302\n",
      "Epoch 3718/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7862 - acc: 0.8119 - val_loss: 0.7803 - val_acc: 0.8302\n",
      "Epoch 3719/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8188 - val_loss: 0.7793 - val_acc: 0.8302\n",
      "Epoch 3720/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7944 - acc: 0.8149 - val_loss: 0.7776 - val_acc: 0.8302\n",
      "Epoch 3721/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7991 - acc: 0.8188 - val_loss: 0.7726 - val_acc: 0.8302\n",
      "Epoch 3722/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7830 - acc: 0.8206 - val_loss: 0.7720 - val_acc: 0.8329\n",
      "Epoch 3723/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7902 - acc: 0.8149 - val_loss: 0.7796 - val_acc: 0.8302\n",
      "Epoch 3724/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7922 - acc: 0.8101 - val_loss: 0.7823 - val_acc: 0.8275\n",
      "Epoch 3725/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7916 - acc: 0.8173 - val_loss: 0.7807 - val_acc: 0.8302\n",
      "Epoch 3726/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7744 - acc: 0.8188 - val_loss: 0.7825 - val_acc: 0.8248\n",
      "Epoch 3727/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7896 - acc: 0.8128 - val_loss: 0.7915 - val_acc: 0.8248\n",
      "Epoch 3728/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8113 - val_loss: 0.7961 - val_acc: 0.8248\n",
      "Epoch 3729/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7739 - acc: 0.8116 - val_loss: 0.7943 - val_acc: 0.8248\n",
      "Epoch 3730/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8009 - acc: 0.8161 - val_loss: 0.7870 - val_acc: 0.8221\n",
      "Epoch 3731/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7850 - acc: 0.8215 - val_loss: 0.7825 - val_acc: 0.8221\n",
      "Epoch 3732/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8008 - acc: 0.8116 - val_loss: 0.7849 - val_acc: 0.8221\n",
      "Epoch 3733/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7766 - acc: 0.8248 - val_loss: 0.7862 - val_acc: 0.8275\n",
      "Epoch 3734/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8131 - val_loss: 0.7877 - val_acc: 0.8248\n",
      "Epoch 3735/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7928 - acc: 0.8053 - val_loss: 0.7894 - val_acc: 0.8221\n",
      "Epoch 3736/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7875 - acc: 0.8134 - val_loss: 0.7869 - val_acc: 0.8248\n",
      "Epoch 3737/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7647 - acc: 0.8236 - val_loss: 0.7808 - val_acc: 0.8221\n",
      "Epoch 3738/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7941 - acc: 0.8128 - val_loss: 0.7697 - val_acc: 0.8302\n",
      "Epoch 3739/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7735 - acc: 0.8218 - val_loss: 0.7670 - val_acc: 0.8248\n",
      "Epoch 3740/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8027 - acc: 0.8152 - val_loss: 0.7651 - val_acc: 0.8248\n",
      "Epoch 3741/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7806 - acc: 0.8125 - val_loss: 0.7722 - val_acc: 0.8167\n",
      "Epoch 3742/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7858 - acc: 0.8188 - val_loss: 0.7830 - val_acc: 0.8167\n",
      "Epoch 3743/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8062 - val_loss: 0.7929 - val_acc: 0.8194\n",
      "Epoch 3744/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8024 - acc: 0.8131 - val_loss: 0.7929 - val_acc: 0.8248\n",
      "Epoch 3745/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8081 - acc: 0.8146 - val_loss: 0.7822 - val_acc: 0.8302\n",
      "Epoch 3746/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7823 - acc: 0.8167 - val_loss: 0.7771 - val_acc: 0.8221\n",
      "Epoch 3747/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7888 - acc: 0.8134 - val_loss: 0.7809 - val_acc: 0.8194\n",
      "Epoch 3748/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7884 - acc: 0.8176 - val_loss: 0.7781 - val_acc: 0.8248\n",
      "Epoch 3749/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8107 - val_loss: 0.7812 - val_acc: 0.8329\n",
      "Epoch 3750/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7811 - acc: 0.8176 - val_loss: 0.7824 - val_acc: 0.8275\n",
      "Epoch 3751/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8022 - acc: 0.8119 - val_loss: 0.7800 - val_acc: 0.8275\n",
      "Epoch 3752/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7926 - acc: 0.8134 - val_loss: 0.7771 - val_acc: 0.8275\n",
      "Epoch 3753/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7889 - acc: 0.8065 - val_loss: 0.7781 - val_acc: 0.8194\n",
      "Epoch 3754/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7910 - acc: 0.8119 - val_loss: 0.7798 - val_acc: 0.8248\n",
      "Epoch 3755/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7783 - acc: 0.8161 - val_loss: 0.7699 - val_acc: 0.8248\n",
      "Epoch 3756/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7981 - acc: 0.8176 - val_loss: 0.7578 - val_acc: 0.8248\n",
      "Epoch 3757/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8013 - acc: 0.8164 - val_loss: 0.7561 - val_acc: 0.8329\n",
      "Epoch 3758/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7840 - acc: 0.8104 - val_loss: 0.7678 - val_acc: 0.8329\n",
      "Epoch 3759/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8009 - acc: 0.8143 - val_loss: 0.7825 - val_acc: 0.8248\n",
      "Epoch 3760/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7874 - acc: 0.8119 - val_loss: 0.7869 - val_acc: 0.8302\n",
      "Epoch 3761/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8067 - acc: 0.8137 - val_loss: 0.7900 - val_acc: 0.8275\n",
      "Epoch 3762/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7967 - acc: 0.8167 - val_loss: 0.7913 - val_acc: 0.8248\n",
      "Epoch 3763/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7722 - acc: 0.8164 - val_loss: 0.7931 - val_acc: 0.8275\n",
      "Epoch 3764/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8077 - val_loss: 0.7922 - val_acc: 0.8221\n",
      "Epoch 3765/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8090 - acc: 0.8239 - val_loss: 0.7834 - val_acc: 0.8248\n",
      "Epoch 3766/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7998 - acc: 0.8152 - val_loss: 0.7819 - val_acc: 0.8275\n",
      "Epoch 3767/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8107 - val_loss: 0.7874 - val_acc: 0.8275\n",
      "Epoch 3768/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7963 - acc: 0.8137 - val_loss: 0.7925 - val_acc: 0.8302\n",
      "Epoch 3769/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7952 - acc: 0.8191 - val_loss: 0.7869 - val_acc: 0.8302\n",
      "Epoch 3770/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7934 - acc: 0.8140 - val_loss: 0.7745 - val_acc: 0.8248\n",
      "Epoch 3771/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7973 - acc: 0.8191 - val_loss: 0.7701 - val_acc: 0.8275\n",
      "Epoch 3772/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7899 - acc: 0.8098 - val_loss: 0.7731 - val_acc: 0.8329\n",
      "Epoch 3773/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7686 - acc: 0.8218 - val_loss: 0.7767 - val_acc: 0.8275\n",
      "Epoch 3774/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7767 - acc: 0.8203 - val_loss: 0.7738 - val_acc: 0.8329\n",
      "Epoch 3775/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7827 - acc: 0.8107 - val_loss: 0.7701 - val_acc: 0.8275\n",
      "Epoch 3776/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8008 - acc: 0.8167 - val_loss: 0.7711 - val_acc: 0.8383\n",
      "Epoch 3777/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7852 - acc: 0.8131 - val_loss: 0.7807 - val_acc: 0.8329\n",
      "Epoch 3778/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7928 - acc: 0.8110 - val_loss: 0.7932 - val_acc: 0.8356\n",
      "Epoch 3779/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7722 - acc: 0.8185 - val_loss: 0.7938 - val_acc: 0.8275\n",
      "Epoch 3780/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7794 - acc: 0.8173 - val_loss: 0.7907 - val_acc: 0.8275\n",
      "Epoch 3781/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8028 - acc: 0.8158 - val_loss: 0.7943 - val_acc: 0.8221\n",
      "Epoch 3782/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7905 - acc: 0.8131 - val_loss: 0.7965 - val_acc: 0.8221\n",
      "Epoch 3783/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7885 - acc: 0.8146 - val_loss: 0.7925 - val_acc: 0.8221\n",
      "Epoch 3784/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7857 - acc: 0.8206 - val_loss: 0.7983 - val_acc: 0.8248\n",
      "Epoch 3785/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7686 - acc: 0.8158 - val_loss: 0.8014 - val_acc: 0.8248\n",
      "Epoch 3786/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8061 - acc: 0.8083 - val_loss: 0.7918 - val_acc: 0.8356\n",
      "Epoch 3787/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7796 - acc: 0.8185 - val_loss: 0.7826 - val_acc: 0.8383\n",
      "Epoch 3788/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7741 - acc: 0.8173 - val_loss: 0.7856 - val_acc: 0.8356\n",
      "Epoch 3789/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7904 - acc: 0.8080 - val_loss: 0.7825 - val_acc: 0.8302\n",
      "Epoch 3790/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7842 - acc: 0.8167 - val_loss: 0.7814 - val_acc: 0.8248\n",
      "Epoch 3791/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8030 - acc: 0.8110 - val_loss: 0.7832 - val_acc: 0.8275\n",
      "Epoch 3792/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8000 - acc: 0.8158 - val_loss: 0.7824 - val_acc: 0.8329\n",
      "Epoch 3793/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7900 - acc: 0.8188 - val_loss: 0.7819 - val_acc: 0.8302\n",
      "Epoch 3794/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7861 - acc: 0.8119 - val_loss: 0.7842 - val_acc: 0.8275\n",
      "Epoch 3795/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7837 - acc: 0.8188 - val_loss: 0.7966 - val_acc: 0.8248\n",
      "Epoch 3796/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7784 - acc: 0.8191 - val_loss: 0.7990 - val_acc: 0.8140\n",
      "Epoch 3797/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7871 - acc: 0.8176 - val_loss: 0.7940 - val_acc: 0.8302\n",
      "Epoch 3798/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7947 - acc: 0.8092 - val_loss: 0.7933 - val_acc: 0.8302\n",
      "Epoch 3799/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7922 - acc: 0.8176 - val_loss: 0.7968 - val_acc: 0.8329\n",
      "Epoch 3800/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7837 - acc: 0.8152 - val_loss: 0.7983 - val_acc: 0.8221\n",
      "Epoch 3801/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7779 - acc: 0.8179 - val_loss: 0.8032 - val_acc: 0.8167\n",
      "Epoch 3802/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7750 - acc: 0.8185 - val_loss: 0.7998 - val_acc: 0.8194\n",
      "Epoch 3803/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7752 - acc: 0.8161 - val_loss: 0.7897 - val_acc: 0.8221\n",
      "Epoch 3804/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7818 - acc: 0.8146 - val_loss: 0.7854 - val_acc: 0.8329\n",
      "Epoch 3805/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7777 - acc: 0.8224 - val_loss: 0.7818 - val_acc: 0.8329\n",
      "Epoch 3806/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7801 - acc: 0.8155 - val_loss: 0.7857 - val_acc: 0.8329\n",
      "Epoch 3807/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7833 - acc: 0.8098 - val_loss: 0.7877 - val_acc: 0.8248\n",
      "Epoch 3808/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8188 - val_loss: 0.7871 - val_acc: 0.8140\n",
      "Epoch 3809/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8095 - val_loss: 0.7848 - val_acc: 0.8275\n",
      "Epoch 3810/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8014 - acc: 0.8170 - val_loss: 0.7840 - val_acc: 0.8221\n",
      "Epoch 3811/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8029 - acc: 0.8116 - val_loss: 0.7889 - val_acc: 0.8248\n",
      "Epoch 3812/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7708 - acc: 0.8173 - val_loss: 0.7986 - val_acc: 0.8221\n",
      "Epoch 3813/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8006 - acc: 0.8116 - val_loss: 0.7943 - val_acc: 0.8275\n",
      "Epoch 3814/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7894 - acc: 0.8110 - val_loss: 0.7861 - val_acc: 0.8302\n",
      "Epoch 3815/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7837 - acc: 0.8167 - val_loss: 0.7875 - val_acc: 0.8140\n",
      "Epoch 3816/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7734 - acc: 0.8155 - val_loss: 0.7869 - val_acc: 0.8140\n",
      "Epoch 3817/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8083 - acc: 0.8119 - val_loss: 0.7849 - val_acc: 0.8194\n",
      "Epoch 3818/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7795 - acc: 0.8191 - val_loss: 0.7860 - val_acc: 0.8194\n",
      "Epoch 3819/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7899 - acc: 0.8095 - val_loss: 0.7905 - val_acc: 0.8248\n",
      "Epoch 3820/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8065 - acc: 0.8107 - val_loss: 0.7949 - val_acc: 0.8275\n",
      "Epoch 3821/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7961 - acc: 0.8146 - val_loss: 0.7893 - val_acc: 0.8302\n",
      "Epoch 3822/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7973 - acc: 0.8134 - val_loss: 0.7868 - val_acc: 0.8302\n",
      "Epoch 3823/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7719 - acc: 0.8218 - val_loss: 0.7876 - val_acc: 0.8329\n",
      "Epoch 3824/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7847 - acc: 0.8107 - val_loss: 0.7894 - val_acc: 0.8248\n",
      "Epoch 3825/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7858 - acc: 0.8161 - val_loss: 0.7883 - val_acc: 0.8248\n",
      "Epoch 3826/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7947 - acc: 0.8158 - val_loss: 0.7868 - val_acc: 0.8221\n",
      "Epoch 3827/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7898 - acc: 0.8134 - val_loss: 0.7882 - val_acc: 0.8248\n",
      "Epoch 3828/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7897 - acc: 0.8161 - val_loss: 0.7909 - val_acc: 0.8275\n",
      "Epoch 3829/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7842 - acc: 0.8164 - val_loss: 0.7917 - val_acc: 0.8275\n",
      "Epoch 3830/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8152 - val_loss: 0.7816 - val_acc: 0.8302\n",
      "Epoch 3831/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7818 - acc: 0.8167 - val_loss: 0.7878 - val_acc: 0.8329\n",
      "Epoch 3832/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8098 - acc: 0.8089 - val_loss: 0.7979 - val_acc: 0.8221\n",
      "Epoch 3833/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8086 - val_loss: 0.7910 - val_acc: 0.8221\n",
      "Epoch 3834/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7945 - acc: 0.8101 - val_loss: 0.7834 - val_acc: 0.8248\n",
      "Epoch 3835/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7929 - acc: 0.8233 - val_loss: 0.7859 - val_acc: 0.8248\n",
      "Epoch 3836/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7861 - acc: 0.8146 - val_loss: 0.7901 - val_acc: 0.8248\n",
      "Epoch 3837/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7945 - acc: 0.8110 - val_loss: 0.7887 - val_acc: 0.8248\n",
      "Epoch 3838/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8019 - acc: 0.8215 - val_loss: 0.7891 - val_acc: 0.8194\n",
      "Epoch 3839/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7797 - acc: 0.8161 - val_loss: 0.7919 - val_acc: 0.8194\n",
      "Epoch 3840/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8072 - acc: 0.8191 - val_loss: 0.7896 - val_acc: 0.8194\n",
      "Epoch 3841/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7696 - acc: 0.8170 - val_loss: 0.7782 - val_acc: 0.8302\n",
      "Epoch 3842/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8003 - acc: 0.8071 - val_loss: 0.7773 - val_acc: 0.8302\n",
      "Epoch 3843/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7845 - acc: 0.8104 - val_loss: 0.7784 - val_acc: 0.8302\n",
      "Epoch 3844/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8131 - val_loss: 0.7763 - val_acc: 0.8275\n",
      "Epoch 3845/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8140 - val_loss: 0.7760 - val_acc: 0.8275\n",
      "Epoch 3846/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7917 - acc: 0.8113 - val_loss: 0.7791 - val_acc: 0.8302\n",
      "Epoch 3847/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8061 - acc: 0.8122 - val_loss: 0.7805 - val_acc: 0.8248\n",
      "Epoch 3848/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7891 - acc: 0.8128 - val_loss: 0.7806 - val_acc: 0.8275\n",
      "Epoch 3849/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7865 - acc: 0.8197 - val_loss: 0.7776 - val_acc: 0.8248\n",
      "Epoch 3850/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7825 - acc: 0.8191 - val_loss: 0.7721 - val_acc: 0.8248\n",
      "Epoch 3851/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7988 - acc: 0.8137 - val_loss: 0.7704 - val_acc: 0.8302\n",
      "Epoch 3852/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7808 - acc: 0.8206 - val_loss: 0.7711 - val_acc: 0.8275\n",
      "Epoch 3853/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7846 - acc: 0.8152 - val_loss: 0.7805 - val_acc: 0.8194\n",
      "Epoch 3854/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8008 - acc: 0.8164 - val_loss: 0.7871 - val_acc: 0.8221\n",
      "Epoch 3855/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7865 - acc: 0.8146 - val_loss: 0.7843 - val_acc: 0.8248\n",
      "Epoch 3856/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7765 - acc: 0.8176 - val_loss: 0.7753 - val_acc: 0.8167\n",
      "Epoch 3857/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7854 - acc: 0.8122 - val_loss: 0.7763 - val_acc: 0.8167\n",
      "Epoch 3858/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7787 - acc: 0.8176 - val_loss: 0.7774 - val_acc: 0.8275\n",
      "Epoch 3859/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7606 - acc: 0.8149 - val_loss: 0.7770 - val_acc: 0.8302\n",
      "Epoch 3860/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7856 - acc: 0.8128 - val_loss: 0.7785 - val_acc: 0.8275\n",
      "Epoch 3861/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7943 - acc: 0.8104 - val_loss: 0.7828 - val_acc: 0.8275\n",
      "Epoch 3862/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7771 - acc: 0.8167 - val_loss: 0.7857 - val_acc: 0.8248\n",
      "Epoch 3863/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7886 - acc: 0.8080 - val_loss: 0.7821 - val_acc: 0.8248\n",
      "Epoch 3864/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7812 - acc: 0.8119 - val_loss: 0.7729 - val_acc: 0.8302\n",
      "Epoch 3865/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8086 - val_loss: 0.7752 - val_acc: 0.8329\n",
      "Epoch 3866/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7901 - acc: 0.8161 - val_loss: 0.7839 - val_acc: 0.8221\n",
      "Epoch 3867/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8008 - acc: 0.8158 - val_loss: 0.7926 - val_acc: 0.8221\n",
      "Epoch 3868/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7880 - acc: 0.8125 - val_loss: 0.7909 - val_acc: 0.8275\n",
      "Epoch 3869/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7819 - acc: 0.8149 - val_loss: 0.7925 - val_acc: 0.8302\n",
      "Epoch 3870/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7786 - acc: 0.8161 - val_loss: 0.7996 - val_acc: 0.8275\n",
      "Epoch 3871/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7897 - acc: 0.8143 - val_loss: 0.7978 - val_acc: 0.8275\n",
      "Epoch 3872/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7836 - acc: 0.8125 - val_loss: 0.7908 - val_acc: 0.8248\n",
      "Epoch 3873/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7820 - acc: 0.8191 - val_loss: 0.7888 - val_acc: 0.8221\n",
      "Epoch 3874/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7794 - acc: 0.8155 - val_loss: 0.7860 - val_acc: 0.8275\n",
      "Epoch 3875/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7881 - acc: 0.8170 - val_loss: 0.7851 - val_acc: 0.8302\n",
      "Epoch 3876/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8008 - acc: 0.8149 - val_loss: 0.7761 - val_acc: 0.8356\n",
      "Epoch 3877/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7796 - acc: 0.8146 - val_loss: 0.7763 - val_acc: 0.8221\n",
      "Epoch 3878/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7937 - acc: 0.8167 - val_loss: 0.7784 - val_acc: 0.8221\n",
      "Epoch 3879/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7818 - acc: 0.8179 - val_loss: 0.7851 - val_acc: 0.8221\n",
      "Epoch 3880/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7989 - acc: 0.8140 - val_loss: 0.7893 - val_acc: 0.8248\n",
      "Epoch 3881/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7781 - acc: 0.8140 - val_loss: 0.7949 - val_acc: 0.8248\n",
      "Epoch 3882/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8001 - acc: 0.8125 - val_loss: 0.7938 - val_acc: 0.8248\n",
      "Epoch 3883/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7799 - acc: 0.8203 - val_loss: 0.7914 - val_acc: 0.8221\n",
      "Epoch 3884/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7883 - acc: 0.8110 - val_loss: 0.7901 - val_acc: 0.8221\n",
      "Epoch 3885/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7921 - acc: 0.8164 - val_loss: 0.7884 - val_acc: 0.8221\n",
      "Epoch 3886/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8179 - acc: 0.8116 - val_loss: 0.7928 - val_acc: 0.8248\n",
      "Epoch 3887/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7863 - acc: 0.8146 - val_loss: 0.7934 - val_acc: 0.8221\n",
      "Epoch 3888/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7855 - acc: 0.8155 - val_loss: 0.7943 - val_acc: 0.8194\n",
      "Epoch 3889/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7816 - acc: 0.8152 - val_loss: 0.7819 - val_acc: 0.8167\n",
      "Epoch 3890/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7760 - acc: 0.8176 - val_loss: 0.7631 - val_acc: 0.8275\n",
      "Epoch 3891/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7857 - acc: 0.8158 - val_loss: 0.7585 - val_acc: 0.8275\n",
      "Epoch 3892/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7972 - acc: 0.8155 - val_loss: 0.7712 - val_acc: 0.8221\n",
      "Epoch 3893/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8098 - val_loss: 0.7820 - val_acc: 0.8194\n",
      "Epoch 3894/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7657 - acc: 0.8209 - val_loss: 0.7796 - val_acc: 0.8221\n",
      "Epoch 3895/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7752 - acc: 0.8164 - val_loss: 0.7751 - val_acc: 0.8194\n",
      "Epoch 3896/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8012 - acc: 0.8125 - val_loss: 0.7684 - val_acc: 0.8194\n",
      "Epoch 3897/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7521 - acc: 0.8230 - val_loss: 0.7628 - val_acc: 0.8221\n",
      "Epoch 3898/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8113 - val_loss: 0.7533 - val_acc: 0.8356\n",
      "Epoch 3899/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7870 - acc: 0.8077 - val_loss: 0.7569 - val_acc: 0.8302\n",
      "Epoch 3900/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7995 - acc: 0.8083 - val_loss: 0.7667 - val_acc: 0.8248\n",
      "Epoch 3901/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7891 - acc: 0.8125 - val_loss: 0.7740 - val_acc: 0.8248\n",
      "Epoch 3902/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7906 - acc: 0.8152 - val_loss: 0.7738 - val_acc: 0.8221\n",
      "Epoch 3903/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7820 - acc: 0.8089 - val_loss: 0.7724 - val_acc: 0.8248\n",
      "Epoch 3904/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7777 - acc: 0.8137 - val_loss: 0.7747 - val_acc: 0.8275\n",
      "Epoch 3905/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7784 - acc: 0.8179 - val_loss: 0.7750 - val_acc: 0.8221\n",
      "Epoch 3906/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7806 - acc: 0.8188 - val_loss: 0.7726 - val_acc: 0.8302\n",
      "Epoch 3907/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7854 - acc: 0.8113 - val_loss: 0.7765 - val_acc: 0.8302\n",
      "Epoch 3908/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7835 - acc: 0.8143 - val_loss: 0.7816 - val_acc: 0.8167\n",
      "Epoch 3909/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8026 - acc: 0.8104 - val_loss: 0.7753 - val_acc: 0.8275\n",
      "Epoch 3910/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8046 - acc: 0.8116 - val_loss: 0.7733 - val_acc: 0.8248\n",
      "Epoch 3911/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7807 - acc: 0.8182 - val_loss: 0.7789 - val_acc: 0.8167\n",
      "Epoch 3912/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7635 - acc: 0.8194 - val_loss: 0.7831 - val_acc: 0.8194\n",
      "Epoch 3913/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8177 - acc: 0.8113 - val_loss: 0.7775 - val_acc: 0.8221\n",
      "Epoch 3914/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7847 - acc: 0.8182 - val_loss: 0.7727 - val_acc: 0.8275\n",
      "Epoch 3915/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7843 - acc: 0.8176 - val_loss: 0.7718 - val_acc: 0.8221\n",
      "Epoch 3916/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7940 - acc: 0.8179 - val_loss: 0.7687 - val_acc: 0.8248\n",
      "Epoch 3917/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7878 - acc: 0.8173 - val_loss: 0.7664 - val_acc: 0.8248\n",
      "Epoch 3918/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7746 - acc: 0.8167 - val_loss: 0.7714 - val_acc: 0.8167\n",
      "Epoch 3919/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7732 - acc: 0.8176 - val_loss: 0.7709 - val_acc: 0.8194\n",
      "Epoch 3920/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7869 - acc: 0.8092 - val_loss: 0.7701 - val_acc: 0.8248\n",
      "Epoch 3921/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8125 - val_loss: 0.7702 - val_acc: 0.8221\n",
      "Epoch 3922/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8107 - acc: 0.8098 - val_loss: 0.7680 - val_acc: 0.8221\n",
      "Epoch 3923/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7773 - acc: 0.8155 - val_loss: 0.7675 - val_acc: 0.8275\n",
      "Epoch 3924/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8104 - val_loss: 0.7808 - val_acc: 0.8221\n",
      "Epoch 3925/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7881 - acc: 0.8167 - val_loss: 0.7883 - val_acc: 0.8248\n",
      "Epoch 3926/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7776 - acc: 0.8194 - val_loss: 0.7912 - val_acc: 0.8248\n",
      "Epoch 3927/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7760 - acc: 0.8113 - val_loss: 0.7953 - val_acc: 0.8302\n",
      "Epoch 3928/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7808 - acc: 0.8212 - val_loss: 0.7871 - val_acc: 0.8275\n",
      "Epoch 3929/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7979 - acc: 0.8137 - val_loss: 0.7808 - val_acc: 0.8302\n",
      "Epoch 3930/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7864 - acc: 0.8164 - val_loss: 0.7830 - val_acc: 0.8248\n",
      "Epoch 3931/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7870 - acc: 0.8101 - val_loss: 0.7840 - val_acc: 0.8167\n",
      "Epoch 3932/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7889 - acc: 0.8143 - val_loss: 0.7811 - val_acc: 0.8194\n",
      "Epoch 3933/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7893 - acc: 0.8164 - val_loss: 0.7802 - val_acc: 0.8221\n",
      "Epoch 3934/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8143 - val_loss: 0.7851 - val_acc: 0.8221\n",
      "Epoch 3935/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7827 - acc: 0.8143 - val_loss: 0.7851 - val_acc: 0.8194\n",
      "Epoch 3936/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8088 - acc: 0.8158 - val_loss: 0.7880 - val_acc: 0.8194\n",
      "Epoch 3937/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7792 - acc: 0.8176 - val_loss: 0.7895 - val_acc: 0.8275\n",
      "Epoch 3938/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7828 - acc: 0.8218 - val_loss: 0.7877 - val_acc: 0.8275\n",
      "Epoch 3939/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7750 - acc: 0.8116 - val_loss: 0.7844 - val_acc: 0.8248\n",
      "Epoch 3940/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7743 - acc: 0.8155 - val_loss: 0.7882 - val_acc: 0.8248\n",
      "Epoch 3941/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7797 - acc: 0.8140 - val_loss: 0.7850 - val_acc: 0.8194\n",
      "Epoch 3942/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8021 - acc: 0.8143 - val_loss: 0.7814 - val_acc: 0.8302\n",
      "Epoch 3943/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8176 - val_loss: 0.7861 - val_acc: 0.8275\n",
      "Epoch 3944/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7896 - acc: 0.8107 - val_loss: 0.7947 - val_acc: 0.8248\n",
      "Epoch 3945/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7883 - acc: 0.8086 - val_loss: 0.7932 - val_acc: 0.8248\n",
      "Epoch 3946/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7857 - acc: 0.8125 - val_loss: 0.7950 - val_acc: 0.8248\n",
      "Epoch 3947/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7720 - acc: 0.8134 - val_loss: 0.7962 - val_acc: 0.8248\n",
      "Epoch 3948/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8109 - acc: 0.8122 - val_loss: 0.7878 - val_acc: 0.8275\n",
      "Epoch 3949/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7750 - acc: 0.8128 - val_loss: 0.7880 - val_acc: 0.8248\n",
      "Epoch 3950/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7805 - acc: 0.8173 - val_loss: 0.8002 - val_acc: 0.8248\n",
      "Epoch 3951/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7955 - acc: 0.8155 - val_loss: 0.7998 - val_acc: 0.8248\n",
      "Epoch 3952/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7808 - acc: 0.8185 - val_loss: 0.7941 - val_acc: 0.8221\n",
      "Epoch 3953/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7769 - acc: 0.8155 - val_loss: 0.7944 - val_acc: 0.8194\n",
      "Epoch 3954/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8152 - val_loss: 0.7975 - val_acc: 0.8221\n",
      "Epoch 3955/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7872 - acc: 0.8143 - val_loss: 0.8001 - val_acc: 0.8194\n",
      "Epoch 3956/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8185 - val_loss: 0.8038 - val_acc: 0.8302\n",
      "Epoch 3957/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7963 - acc: 0.8137 - val_loss: 0.7996 - val_acc: 0.8275\n",
      "Epoch 3958/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8094 - acc: 0.8098 - val_loss: 0.7955 - val_acc: 0.8248\n",
      "Epoch 3959/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7875 - acc: 0.8185 - val_loss: 0.7986 - val_acc: 0.8221\n",
      "Epoch 3960/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7867 - acc: 0.8137 - val_loss: 0.8032 - val_acc: 0.8248\n",
      "Epoch 3961/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7860 - acc: 0.8173 - val_loss: 0.8013 - val_acc: 0.8194\n",
      "Epoch 3962/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8167 - val_loss: 0.7967 - val_acc: 0.8275\n",
      "Epoch 3963/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7645 - acc: 0.8197 - val_loss: 0.7900 - val_acc: 0.8275\n",
      "Epoch 3964/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7781 - acc: 0.8164 - val_loss: 0.7863 - val_acc: 0.8302\n",
      "Epoch 3965/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7803 - acc: 0.8170 - val_loss: 0.7827 - val_acc: 0.8302\n",
      "Epoch 3966/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8013 - acc: 0.8137 - val_loss: 0.7867 - val_acc: 0.8221\n",
      "Epoch 3967/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7869 - acc: 0.8173 - val_loss: 0.7846 - val_acc: 0.8248\n",
      "Epoch 3968/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7882 - acc: 0.8182 - val_loss: 0.7838 - val_acc: 0.8167\n",
      "Epoch 3969/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8059 - acc: 0.8200 - val_loss: 0.7799 - val_acc: 0.8221\n",
      "Epoch 3970/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7916 - acc: 0.8152 - val_loss: 0.7729 - val_acc: 0.8275\n",
      "Epoch 3971/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7912 - acc: 0.8125 - val_loss: 0.7742 - val_acc: 0.8302\n",
      "Epoch 3972/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7803 - acc: 0.8158 - val_loss: 0.7836 - val_acc: 0.8329\n",
      "Epoch 3973/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7783 - acc: 0.8164 - val_loss: 0.7892 - val_acc: 0.8275\n",
      "Epoch 3974/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7891 - acc: 0.8137 - val_loss: 0.7958 - val_acc: 0.8140\n",
      "Epoch 3975/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7795 - acc: 0.8149 - val_loss: 0.7998 - val_acc: 0.8248\n",
      "Epoch 3976/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7922 - acc: 0.8155 - val_loss: 0.7982 - val_acc: 0.8221\n",
      "Epoch 3977/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8146 - val_loss: 0.7981 - val_acc: 0.8248\n",
      "Epoch 3978/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8012 - acc: 0.8164 - val_loss: 0.8021 - val_acc: 0.8248\n",
      "Epoch 3979/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8023 - acc: 0.8161 - val_loss: 0.7959 - val_acc: 0.8221\n",
      "Epoch 3980/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7960 - acc: 0.8146 - val_loss: 0.7885 - val_acc: 0.8329\n",
      "Epoch 3981/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7800 - acc: 0.8128 - val_loss: 0.7877 - val_acc: 0.8329\n",
      "Epoch 3982/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7908 - acc: 0.8104 - val_loss: 0.7827 - val_acc: 0.8302\n",
      "Epoch 3983/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7884 - acc: 0.8170 - val_loss: 0.7812 - val_acc: 0.8275\n",
      "Epoch 3984/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8055 - acc: 0.8074 - val_loss: 0.7792 - val_acc: 0.8248\n",
      "Epoch 3985/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7820 - acc: 0.8155 - val_loss: 0.7828 - val_acc: 0.8275\n",
      "Epoch 3986/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7666 - acc: 0.8209 - val_loss: 0.7906 - val_acc: 0.8221\n",
      "Epoch 3987/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7854 - acc: 0.8146 - val_loss: 0.7985 - val_acc: 0.8221\n",
      "Epoch 3988/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7668 - acc: 0.8188 - val_loss: 0.7958 - val_acc: 0.8194\n",
      "Epoch 3989/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7807 - acc: 0.8167 - val_loss: 0.7900 - val_acc: 0.8248\n",
      "Epoch 3990/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7859 - acc: 0.8185 - val_loss: 0.7869 - val_acc: 0.8302\n",
      "Epoch 3991/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7818 - acc: 0.8173 - val_loss: 0.7867 - val_acc: 0.8275\n",
      "Epoch 3992/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7865 - acc: 0.8146 - val_loss: 0.7833 - val_acc: 0.8194\n",
      "Epoch 3993/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7852 - acc: 0.8152 - val_loss: 0.7778 - val_acc: 0.8221\n",
      "Epoch 3994/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7748 - acc: 0.8131 - val_loss: 0.7799 - val_acc: 0.8221\n",
      "Epoch 3995/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8002 - acc: 0.8152 - val_loss: 0.7882 - val_acc: 0.8248\n",
      "Epoch 3996/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7887 - acc: 0.8164 - val_loss: 0.7832 - val_acc: 0.8167\n",
      "Epoch 3997/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7871 - acc: 0.8137 - val_loss: 0.7725 - val_acc: 0.8302\n",
      "Epoch 3998/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7854 - acc: 0.8203 - val_loss: 0.7693 - val_acc: 0.8275\n",
      "Epoch 3999/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7810 - acc: 0.8218 - val_loss: 0.7716 - val_acc: 0.8248\n",
      "Epoch 4000/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7873 - acc: 0.8149 - val_loss: 0.7759 - val_acc: 0.8248\n",
      "Epoch 4001/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7920 - acc: 0.8161 - val_loss: 0.7826 - val_acc: 0.8221\n",
      "Epoch 4002/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7738 - acc: 0.8128 - val_loss: 0.7934 - val_acc: 0.8221\n",
      "Epoch 4003/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7537 - acc: 0.8212 - val_loss: 0.8015 - val_acc: 0.8194\n",
      "Epoch 4004/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7960 - acc: 0.8170 - val_loss: 0.7970 - val_acc: 0.8140\n",
      "Epoch 4005/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8007 - acc: 0.8143 - val_loss: 0.7862 - val_acc: 0.8275\n",
      "Epoch 4006/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7937 - acc: 0.8083 - val_loss: 0.7831 - val_acc: 0.8221\n",
      "Epoch 4007/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7917 - acc: 0.8179 - val_loss: 0.7782 - val_acc: 0.8275\n",
      "Epoch 4008/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7913 - acc: 0.8131 - val_loss: 0.7777 - val_acc: 0.8248\n",
      "Epoch 4009/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8116 - val_loss: 0.7880 - val_acc: 0.8167\n",
      "Epoch 4010/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8134 - val_loss: 0.7886 - val_acc: 0.8194\n",
      "Epoch 4011/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7922 - acc: 0.8179 - val_loss: 0.7893 - val_acc: 0.8248\n",
      "Epoch 4012/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7931 - acc: 0.8173 - val_loss: 0.7876 - val_acc: 0.8221\n",
      "Epoch 4013/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8013 - acc: 0.8185 - val_loss: 0.7792 - val_acc: 0.8194\n",
      "Epoch 4014/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8046 - acc: 0.8125 - val_loss: 0.7785 - val_acc: 0.8140\n",
      "Epoch 4015/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7825 - acc: 0.8149 - val_loss: 0.7825 - val_acc: 0.8221\n",
      "Epoch 4016/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7818 - acc: 0.8182 - val_loss: 0.7879 - val_acc: 0.8275\n",
      "Epoch 4017/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7542 - acc: 0.8221 - val_loss: 0.7834 - val_acc: 0.8302\n",
      "Epoch 4018/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7913 - acc: 0.8098 - val_loss: 0.7825 - val_acc: 0.8329\n",
      "Epoch 4019/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8081 - acc: 0.8122 - val_loss: 0.7903 - val_acc: 0.8221\n",
      "Epoch 4020/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7970 - acc: 0.8137 - val_loss: 0.7992 - val_acc: 0.8167\n",
      "Epoch 4021/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7813 - acc: 0.8119 - val_loss: 0.7884 - val_acc: 0.8221\n",
      "Epoch 4022/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7878 - acc: 0.8140 - val_loss: 0.7778 - val_acc: 0.8248\n",
      "Epoch 4023/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8119 - val_loss: 0.7825 - val_acc: 0.8221\n",
      "Epoch 4024/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7732 - acc: 0.8185 - val_loss: 0.7840 - val_acc: 0.8275\n",
      "Epoch 4025/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7786 - acc: 0.8203 - val_loss: 0.7830 - val_acc: 0.8275\n",
      "Epoch 4026/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7834 - acc: 0.8188 - val_loss: 0.7856 - val_acc: 0.8248\n",
      "Epoch 4027/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7883 - acc: 0.8140 - val_loss: 0.7884 - val_acc: 0.8248\n",
      "Epoch 4028/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7868 - acc: 0.8188 - val_loss: 0.7938 - val_acc: 0.8194\n",
      "Epoch 4029/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7738 - acc: 0.8128 - val_loss: 0.7972 - val_acc: 0.8221\n",
      "Epoch 4030/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7864 - acc: 0.8170 - val_loss: 0.7979 - val_acc: 0.8194\n",
      "Epoch 4031/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8026 - acc: 0.8152 - val_loss: 0.7885 - val_acc: 0.8275\n",
      "Epoch 4032/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7929 - acc: 0.8176 - val_loss: 0.7778 - val_acc: 0.8275\n",
      "Epoch 4033/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7980 - acc: 0.8185 - val_loss: 0.7860 - val_acc: 0.8302\n",
      "Epoch 4034/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8041 - acc: 0.8122 - val_loss: 0.7899 - val_acc: 0.8167\n",
      "Epoch 4035/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7872 - acc: 0.8155 - val_loss: 0.7857 - val_acc: 0.8167\n",
      "Epoch 4036/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7843 - acc: 0.8158 - val_loss: 0.7867 - val_acc: 0.8194\n",
      "Epoch 4037/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8005 - acc: 0.8116 - val_loss: 0.7866 - val_acc: 0.8194\n",
      "Epoch 4038/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8149 - val_loss: 0.7889 - val_acc: 0.8221\n",
      "Epoch 4039/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7858 - acc: 0.8146 - val_loss: 0.7891 - val_acc: 0.8221\n",
      "Epoch 4040/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8019 - acc: 0.8158 - val_loss: 0.7831 - val_acc: 0.8302\n",
      "Epoch 4041/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7971 - acc: 0.8155 - val_loss: 0.7789 - val_acc: 0.8356\n",
      "Epoch 4042/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7885 - acc: 0.8161 - val_loss: 0.7855 - val_acc: 0.8275\n",
      "Epoch 4043/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8158 - val_loss: 0.7942 - val_acc: 0.8248\n",
      "Epoch 4044/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7914 - acc: 0.8134 - val_loss: 0.7977 - val_acc: 0.8194\n",
      "Epoch 4045/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7868 - acc: 0.8176 - val_loss: 0.7967 - val_acc: 0.8221\n",
      "Epoch 4046/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7708 - acc: 0.8143 - val_loss: 0.7888 - val_acc: 0.8302\n",
      "Epoch 4047/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7834 - acc: 0.8167 - val_loss: 0.7815 - val_acc: 0.8302\n",
      "Epoch 4048/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8029 - acc: 0.8101 - val_loss: 0.7840 - val_acc: 0.8275\n",
      "Epoch 4049/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7838 - acc: 0.8146 - val_loss: 0.7899 - val_acc: 0.8302\n",
      "Epoch 4050/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7874 - acc: 0.8092 - val_loss: 0.7954 - val_acc: 0.8275\n",
      "Epoch 4051/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8019 - acc: 0.8128 - val_loss: 0.7951 - val_acc: 0.8302\n",
      "Epoch 4052/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7832 - acc: 0.8134 - val_loss: 0.7917 - val_acc: 0.8302\n",
      "Epoch 4053/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7805 - acc: 0.8170 - val_loss: 0.7891 - val_acc: 0.8329\n",
      "Epoch 4054/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8149 - val_loss: 0.7877 - val_acc: 0.8302\n",
      "Epoch 4055/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8167 - val_loss: 0.7860 - val_acc: 0.8302\n",
      "Epoch 4056/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8064 - acc: 0.8119 - val_loss: 0.7916 - val_acc: 0.8356\n",
      "Epoch 4057/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7987 - acc: 0.8113 - val_loss: 0.7974 - val_acc: 0.8329\n",
      "Epoch 4058/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7910 - acc: 0.8170 - val_loss: 0.8008 - val_acc: 0.8356\n",
      "Epoch 4059/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7772 - acc: 0.8116 - val_loss: 0.7988 - val_acc: 0.8302\n",
      "Epoch 4060/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7844 - acc: 0.8122 - val_loss: 0.8117 - val_acc: 0.8221\n",
      "Epoch 4061/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8161 - val_loss: 0.8089 - val_acc: 0.8221\n",
      "Epoch 4062/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8164 - val_loss: 0.7995 - val_acc: 0.8248\n",
      "Epoch 4063/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8182 - val_loss: 0.7898 - val_acc: 0.8248\n",
      "Epoch 4064/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8008 - acc: 0.8131 - val_loss: 0.7868 - val_acc: 0.8383\n",
      "Epoch 4065/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7798 - acc: 0.8170 - val_loss: 0.7865 - val_acc: 0.8356\n",
      "Epoch 4066/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7842 - acc: 0.8080 - val_loss: 0.7900 - val_acc: 0.8302\n",
      "Epoch 4067/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8149 - val_loss: 0.7922 - val_acc: 0.8302\n",
      "Epoch 4068/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7862 - acc: 0.8125 - val_loss: 0.7965 - val_acc: 0.8221\n",
      "Epoch 4069/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7977 - acc: 0.8176 - val_loss: 0.7965 - val_acc: 0.8302\n",
      "Epoch 4070/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8065 - val_loss: 0.7972 - val_acc: 0.8248\n",
      "Epoch 4071/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7639 - acc: 0.8134 - val_loss: 0.8001 - val_acc: 0.8248\n",
      "Epoch 4072/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8019 - acc: 0.8131 - val_loss: 0.8039 - val_acc: 0.8194\n",
      "Epoch 4073/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8206 - val_loss: 0.8059 - val_acc: 0.8275\n",
      "Epoch 4074/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7954 - acc: 0.8194 - val_loss: 0.7992 - val_acc: 0.8221\n",
      "Epoch 4075/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7896 - acc: 0.8179 - val_loss: 0.7871 - val_acc: 0.8221\n",
      "Epoch 4076/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7745 - acc: 0.8161 - val_loss: 0.7840 - val_acc: 0.8248\n",
      "Epoch 4077/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8128 - val_loss: 0.7889 - val_acc: 0.8329\n",
      "Epoch 4078/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7761 - acc: 0.8212 - val_loss: 0.7961 - val_acc: 0.8248\n",
      "Epoch 4079/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7713 - acc: 0.8185 - val_loss: 0.7993 - val_acc: 0.8275\n",
      "Epoch 4080/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7908 - acc: 0.8113 - val_loss: 0.8022 - val_acc: 0.8248\n",
      "Epoch 4081/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7985 - acc: 0.8137 - val_loss: 0.7948 - val_acc: 0.8194\n",
      "Epoch 4082/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7833 - acc: 0.8113 - val_loss: 0.7898 - val_acc: 0.8248\n",
      "Epoch 4083/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7970 - acc: 0.8137 - val_loss: 0.7934 - val_acc: 0.8275\n",
      "Epoch 4084/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7994 - acc: 0.8125 - val_loss: 0.8079 - val_acc: 0.8194\n",
      "Epoch 4085/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7974 - acc: 0.8170 - val_loss: 0.8075 - val_acc: 0.8221\n",
      "Epoch 4086/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7942 - acc: 0.8212 - val_loss: 0.8025 - val_acc: 0.8221\n",
      "Epoch 4087/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8224 - val_loss: 0.8033 - val_acc: 0.8221\n",
      "Epoch 4088/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7973 - acc: 0.8152 - val_loss: 0.8019 - val_acc: 0.8194\n",
      "Epoch 4089/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8170 - val_loss: 0.7992 - val_acc: 0.8248\n",
      "Epoch 4090/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7905 - acc: 0.8110 - val_loss: 0.8011 - val_acc: 0.8275\n",
      "Epoch 4091/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7848 - acc: 0.8113 - val_loss: 0.7915 - val_acc: 0.8194\n",
      "Epoch 4092/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7703 - acc: 0.8158 - val_loss: 0.7914 - val_acc: 0.8275\n",
      "Epoch 4093/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7844 - acc: 0.8140 - val_loss: 0.7938 - val_acc: 0.8221\n",
      "Epoch 4094/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7985 - acc: 0.8110 - val_loss: 0.7945 - val_acc: 0.8248\n",
      "Epoch 4095/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7730 - acc: 0.8158 - val_loss: 0.7913 - val_acc: 0.8248\n",
      "Epoch 4096/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8113 - val_loss: 0.7948 - val_acc: 0.8167\n",
      "Epoch 4097/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7832 - acc: 0.8194 - val_loss: 0.7921 - val_acc: 0.8221\n",
      "Epoch 4098/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8098 - val_loss: 0.7899 - val_acc: 0.8248\n",
      "Epoch 4099/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7798 - acc: 0.8122 - val_loss: 0.7834 - val_acc: 0.8275\n",
      "Epoch 4100/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8135 - acc: 0.8044 - val_loss: 0.7820 - val_acc: 0.8275\n",
      "Epoch 4101/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7882 - acc: 0.8131 - val_loss: 0.7834 - val_acc: 0.8302\n",
      "Epoch 4102/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7912 - acc: 0.8221 - val_loss: 0.7912 - val_acc: 0.8248\n",
      "Epoch 4103/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7907 - acc: 0.8224 - val_loss: 0.7990 - val_acc: 0.8167\n",
      "Epoch 4104/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7787 - acc: 0.8191 - val_loss: 0.8000 - val_acc: 0.8167\n",
      "Epoch 4105/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7608 - acc: 0.8212 - val_loss: 0.8014 - val_acc: 0.8221\n",
      "Epoch 4106/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7821 - acc: 0.8164 - val_loss: 0.7913 - val_acc: 0.8221\n",
      "Epoch 4107/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7947 - acc: 0.8116 - val_loss: 0.7848 - val_acc: 0.8275\n",
      "Epoch 4108/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7742 - acc: 0.8200 - val_loss: 0.7867 - val_acc: 0.8275\n",
      "Epoch 4109/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7989 - acc: 0.8104 - val_loss: 0.7818 - val_acc: 0.8221\n",
      "Epoch 4110/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7881 - acc: 0.8116 - val_loss: 0.7838 - val_acc: 0.8248\n",
      "Epoch 4111/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8020 - acc: 0.8176 - val_loss: 0.7928 - val_acc: 0.8221\n",
      "Epoch 4112/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7899 - acc: 0.8116 - val_loss: 0.7938 - val_acc: 0.8221\n",
      "Epoch 4113/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7860 - acc: 0.8155 - val_loss: 0.7924 - val_acc: 0.8248\n",
      "Epoch 4114/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7736 - acc: 0.8200 - val_loss: 0.7937 - val_acc: 0.8302\n",
      "Epoch 4115/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7906 - acc: 0.8194 - val_loss: 0.7974 - val_acc: 0.8221\n",
      "Epoch 4116/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7933 - acc: 0.8080 - val_loss: 0.7962 - val_acc: 0.8248\n",
      "Epoch 4117/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7955 - acc: 0.8173 - val_loss: 0.7898 - val_acc: 0.8275\n",
      "Epoch 4118/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8182 - val_loss: 0.7784 - val_acc: 0.8329\n",
      "Epoch 4119/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7893 - acc: 0.8122 - val_loss: 0.7780 - val_acc: 0.8356\n",
      "Epoch 4120/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7761 - acc: 0.8146 - val_loss: 0.7798 - val_acc: 0.8383\n",
      "Epoch 4121/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7851 - acc: 0.8152 - val_loss: 0.7835 - val_acc: 0.8356\n",
      "Epoch 4122/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7821 - acc: 0.8182 - val_loss: 0.7934 - val_acc: 0.8275\n",
      "Epoch 4123/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7710 - acc: 0.8188 - val_loss: 0.7897 - val_acc: 0.8221\n",
      "Epoch 4124/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7805 - acc: 0.8170 - val_loss: 0.7930 - val_acc: 0.8248\n",
      "Epoch 4125/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8188 - val_loss: 0.7994 - val_acc: 0.8221\n",
      "Epoch 4126/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7755 - acc: 0.8227 - val_loss: 0.7988 - val_acc: 0.8221\n",
      "Epoch 4127/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.8017 - acc: 0.8092 - val_loss: 0.7939 - val_acc: 0.8302\n",
      "Epoch 4128/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8194 - val_loss: 0.7943 - val_acc: 0.8275\n",
      "Epoch 4129/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7949 - acc: 0.8176 - val_loss: 0.7952 - val_acc: 0.8302\n",
      "Epoch 4130/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7870 - acc: 0.8131 - val_loss: 0.7951 - val_acc: 0.8275\n",
      "Epoch 4131/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7968 - acc: 0.8107 - val_loss: 0.7905 - val_acc: 0.8248\n",
      "Epoch 4132/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7673 - acc: 0.8179 - val_loss: 0.7838 - val_acc: 0.8302\n",
      "Epoch 4133/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7880 - acc: 0.8152 - val_loss: 0.7809 - val_acc: 0.8275\n",
      "Epoch 4134/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7741 - acc: 0.8176 - val_loss: 0.7806 - val_acc: 0.8248\n",
      "Epoch 4135/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7809 - acc: 0.8122 - val_loss: 0.7873 - val_acc: 0.8275\n",
      "Epoch 4136/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7954 - acc: 0.8101 - val_loss: 0.7909 - val_acc: 0.8302\n",
      "Epoch 4137/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7855 - acc: 0.8101 - val_loss: 0.7997 - val_acc: 0.8221\n",
      "Epoch 4138/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7966 - acc: 0.8146 - val_loss: 0.7988 - val_acc: 0.8275\n",
      "Epoch 4139/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.7765 - acc: 0.8206 - val_loss: 0.7892 - val_acc: 0.8275\n",
      "Epoch 4140/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7867 - acc: 0.8122 - val_loss: 0.7869 - val_acc: 0.8275\n",
      "Epoch 4141/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7735 - acc: 0.8248 - val_loss: 0.7815 - val_acc: 0.8275\n",
      "Epoch 4142/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7986 - acc: 0.8155 - val_loss: 0.7793 - val_acc: 0.8329\n",
      "Epoch 4143/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7796 - acc: 0.8119 - val_loss: 0.7810 - val_acc: 0.8302\n",
      "Epoch 4144/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7993 - acc: 0.8218 - val_loss: 0.7809 - val_acc: 0.8329\n",
      "Epoch 4145/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7890 - acc: 0.8137 - val_loss: 0.7864 - val_acc: 0.8275\n",
      "Epoch 4146/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7945 - acc: 0.8119 - val_loss: 0.7924 - val_acc: 0.8221\n",
      "Epoch 4147/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7712 - acc: 0.8218 - val_loss: 0.7940 - val_acc: 0.8302\n",
      "Epoch 4148/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7911 - acc: 0.8182 - val_loss: 0.7926 - val_acc: 0.8221\n",
      "Epoch 4149/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7830 - acc: 0.8179 - val_loss: 0.7983 - val_acc: 0.8194\n",
      "Epoch 4150/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7975 - acc: 0.8143 - val_loss: 0.7977 - val_acc: 0.8248\n",
      "Epoch 4151/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7968 - acc: 0.8116 - val_loss: 0.7918 - val_acc: 0.8302\n",
      "Epoch 4152/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8019 - acc: 0.8137 - val_loss: 0.7862 - val_acc: 0.8329\n",
      "Epoch 4153/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8066 - acc: 0.8029 - val_loss: 0.7882 - val_acc: 0.8329\n",
      "Epoch 4154/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8164 - val_loss: 0.7968 - val_acc: 0.8275\n",
      "Epoch 4155/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7994 - acc: 0.8143 - val_loss: 0.8004 - val_acc: 0.8248\n",
      "Epoch 4156/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7728 - acc: 0.8185 - val_loss: 0.7984 - val_acc: 0.8302\n",
      "Epoch 4157/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8212 - val_loss: 0.7956 - val_acc: 0.8302\n",
      "Epoch 4158/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7784 - acc: 0.8158 - val_loss: 0.7989 - val_acc: 0.8302\n",
      "Epoch 4159/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7930 - acc: 0.8137 - val_loss: 0.8007 - val_acc: 0.8221\n",
      "Epoch 4160/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7910 - acc: 0.8155 - val_loss: 0.7975 - val_acc: 0.8248\n",
      "Epoch 4161/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7599 - acc: 0.8116 - val_loss: 0.7919 - val_acc: 0.8275\n",
      "Epoch 4162/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7794 - acc: 0.8158 - val_loss: 0.7897 - val_acc: 0.8275\n",
      "Epoch 4163/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7784 - acc: 0.8224 - val_loss: 0.7862 - val_acc: 0.8302\n",
      "Epoch 4164/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.7660 - acc: 0.8167 - val_loss: 0.7817 - val_acc: 0.8248\n",
      "Epoch 4165/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7995 - acc: 0.8146 - val_loss: 0.7808 - val_acc: 0.8248\n",
      "Epoch 4166/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7816 - acc: 0.8137 - val_loss: 0.7821 - val_acc: 0.8221\n",
      "Epoch 4167/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8176 - val_loss: 0.7906 - val_acc: 0.8275\n",
      "Epoch 4168/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7617 - acc: 0.8212 - val_loss: 0.8023 - val_acc: 0.8248\n",
      "Epoch 4169/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7682 - acc: 0.8143 - val_loss: 0.8080 - val_acc: 0.8248\n",
      "Epoch 4170/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7820 - acc: 0.8110 - val_loss: 0.7974 - val_acc: 0.8302\n",
      "Epoch 4171/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7984 - acc: 0.8089 - val_loss: 0.7913 - val_acc: 0.8302\n",
      "Epoch 4172/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7820 - acc: 0.8101 - val_loss: 0.7942 - val_acc: 0.8248\n",
      "Epoch 4173/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7852 - acc: 0.8113 - val_loss: 0.7950 - val_acc: 0.8275\n",
      "Epoch 4174/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7785 - acc: 0.8080 - val_loss: 0.7989 - val_acc: 0.8221\n",
      "Epoch 4175/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7807 - acc: 0.8194 - val_loss: 0.8027 - val_acc: 0.8194\n",
      "Epoch 4176/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7759 - acc: 0.8191 - val_loss: 0.8078 - val_acc: 0.8194\n",
      "Epoch 4177/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7794 - acc: 0.8164 - val_loss: 0.8105 - val_acc: 0.8221\n",
      "Epoch 4178/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7814 - acc: 0.8155 - val_loss: 0.8123 - val_acc: 0.8275\n",
      "Epoch 4179/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7838 - acc: 0.8158 - val_loss: 0.8148 - val_acc: 0.8221\n",
      "Epoch 4180/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8053 - val_loss: 0.8104 - val_acc: 0.8302\n",
      "Epoch 4181/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7839 - acc: 0.8167 - val_loss: 0.8048 - val_acc: 0.8248\n",
      "Epoch 4182/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7795 - acc: 0.8182 - val_loss: 0.7975 - val_acc: 0.8248\n",
      "Epoch 4183/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.7868 - acc: 0.8125 - val_loss: 0.8012 - val_acc: 0.8302\n",
      "Epoch 4184/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8033 - acc: 0.8095 - val_loss: 0.8090 - val_acc: 0.8248\n",
      "Epoch 4185/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8119 - val_loss: 0.8156 - val_acc: 0.8221\n",
      "Epoch 4186/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8167 - val_loss: 0.8129 - val_acc: 0.8194\n",
      "Epoch 4187/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7757 - acc: 0.8155 - val_loss: 0.8071 - val_acc: 0.8248\n",
      "Epoch 4188/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8110 - acc: 0.8086 - val_loss: 0.7996 - val_acc: 0.8275\n",
      "Epoch 4189/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8131 - val_loss: 0.7926 - val_acc: 0.8167\n",
      "Epoch 4190/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7645 - acc: 0.8176 - val_loss: 0.7831 - val_acc: 0.8194\n",
      "Epoch 4191/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8230 - val_loss: 0.7787 - val_acc: 0.8275\n",
      "Epoch 4192/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7802 - acc: 0.8185 - val_loss: 0.7839 - val_acc: 0.8329\n",
      "Epoch 4193/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7806 - acc: 0.8179 - val_loss: 0.7863 - val_acc: 0.8275\n",
      "Epoch 4194/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7794 - acc: 0.8185 - val_loss: 0.7850 - val_acc: 0.8302\n",
      "Epoch 4195/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.7789 - acc: 0.8179 - val_loss: 0.7852 - val_acc: 0.8302\n",
      "Epoch 4196/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7919 - acc: 0.8065 - val_loss: 0.7836 - val_acc: 0.8302\n",
      "Epoch 4197/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8025 - acc: 0.8155 - val_loss: 0.7843 - val_acc: 0.8329\n",
      "Epoch 4198/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7728 - acc: 0.8164 - val_loss: 0.7914 - val_acc: 0.8275\n",
      "Epoch 4199/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7675 - acc: 0.8215 - val_loss: 0.7985 - val_acc: 0.8194\n",
      "Epoch 4200/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7864 - acc: 0.8173 - val_loss: 0.7963 - val_acc: 0.8194\n",
      "Epoch 4201/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7893 - acc: 0.8143 - val_loss: 0.7881 - val_acc: 0.8140\n",
      "Epoch 4202/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7706 - acc: 0.8179 - val_loss: 0.7846 - val_acc: 0.8248\n",
      "Epoch 4203/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7801 - acc: 0.8125 - val_loss: 0.7864 - val_acc: 0.8221\n",
      "Epoch 4204/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7845 - acc: 0.8161 - val_loss: 0.7883 - val_acc: 0.8194\n",
      "Epoch 4205/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7842 - acc: 0.8179 - val_loss: 0.7917 - val_acc: 0.8194\n",
      "Epoch 4206/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7693 - acc: 0.8227 - val_loss: 0.7955 - val_acc: 0.8194\n",
      "Epoch 4207/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7802 - acc: 0.8122 - val_loss: 0.7928 - val_acc: 0.8275\n",
      "Epoch 4208/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7909 - acc: 0.8119 - val_loss: 0.7894 - val_acc: 0.8302\n",
      "Epoch 4209/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7639 - acc: 0.8215 - val_loss: 0.7953 - val_acc: 0.8302\n",
      "Epoch 4210/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7804 - acc: 0.8221 - val_loss: 0.8005 - val_acc: 0.8329\n",
      "Epoch 4211/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7909 - acc: 0.8173 - val_loss: 0.7995 - val_acc: 0.8329\n",
      "Epoch 4212/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7877 - acc: 0.8164 - val_loss: 0.7990 - val_acc: 0.8248\n",
      "Epoch 4213/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7699 - acc: 0.8149 - val_loss: 0.7956 - val_acc: 0.8275\n",
      "Epoch 4214/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7880 - acc: 0.8128 - val_loss: 0.7916 - val_acc: 0.8248\n",
      "Epoch 4215/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7761 - acc: 0.8182 - val_loss: 0.7929 - val_acc: 0.8275\n",
      "Epoch 4216/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7850 - acc: 0.8155 - val_loss: 0.7926 - val_acc: 0.8221\n",
      "Epoch 4217/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7750 - acc: 0.8227 - val_loss: 0.8005 - val_acc: 0.8194\n",
      "Epoch 4218/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7827 - acc: 0.8164 - val_loss: 0.7966 - val_acc: 0.8221\n",
      "Epoch 4219/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7808 - acc: 0.8209 - val_loss: 0.7961 - val_acc: 0.8194\n",
      "Epoch 4220/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7876 - acc: 0.8149 - val_loss: 0.8036 - val_acc: 0.8221\n",
      "Epoch 4221/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7744 - acc: 0.8149 - val_loss: 0.8048 - val_acc: 0.8167\n",
      "Epoch 4222/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7832 - acc: 0.8155 - val_loss: 0.7973 - val_acc: 0.8140\n",
      "Epoch 4223/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8009 - acc: 0.8152 - val_loss: 0.7830 - val_acc: 0.8167\n",
      "Epoch 4224/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7821 - acc: 0.8203 - val_loss: 0.7773 - val_acc: 0.8167\n",
      "Epoch 4225/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7857 - acc: 0.8137 - val_loss: 0.7791 - val_acc: 0.8194\n",
      "Epoch 4226/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7905 - acc: 0.8155 - val_loss: 0.7778 - val_acc: 0.8221\n",
      "Epoch 4227/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7730 - acc: 0.8194 - val_loss: 0.7747 - val_acc: 0.8248\n",
      "Epoch 4228/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7884 - acc: 0.8071 - val_loss: 0.7792 - val_acc: 0.8167\n",
      "Epoch 4229/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8122 - val_loss: 0.7827 - val_acc: 0.8140\n",
      "Epoch 4230/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8161 - val_loss: 0.7788 - val_acc: 0.8194\n",
      "Epoch 4231/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7883 - acc: 0.8143 - val_loss: 0.7768 - val_acc: 0.8194\n",
      "Epoch 4232/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7777 - acc: 0.8116 - val_loss: 0.7872 - val_acc: 0.8221\n",
      "Epoch 4233/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7919 - acc: 0.8125 - val_loss: 0.7963 - val_acc: 0.8275\n",
      "Epoch 4234/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7987 - acc: 0.8125 - val_loss: 0.8018 - val_acc: 0.8275\n",
      "Epoch 4235/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7884 - acc: 0.8101 - val_loss: 0.8009 - val_acc: 0.8248\n",
      "Epoch 4236/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8019 - acc: 0.8173 - val_loss: 0.7974 - val_acc: 0.8221\n",
      "Epoch 4237/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7848 - acc: 0.8152 - val_loss: 0.7957 - val_acc: 0.8248\n",
      "Epoch 4238/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7749 - acc: 0.8152 - val_loss: 0.7921 - val_acc: 0.8248\n",
      "Epoch 4239/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7768 - acc: 0.8143 - val_loss: 0.7895 - val_acc: 0.8248\n",
      "Epoch 4240/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7846 - acc: 0.8086 - val_loss: 0.7910 - val_acc: 0.8248\n",
      "Epoch 4241/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7717 - acc: 0.8158 - val_loss: 0.7967 - val_acc: 0.8248\n",
      "Epoch 4242/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7940 - acc: 0.8107 - val_loss: 0.7921 - val_acc: 0.8329\n",
      "Epoch 4243/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8264 - acc: 0.8068 - val_loss: 0.7933 - val_acc: 0.8329\n",
      "Epoch 4244/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7692 - acc: 0.8176 - val_loss: 0.7905 - val_acc: 0.8275\n",
      "Epoch 4245/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7849 - acc: 0.8179 - val_loss: 0.7878 - val_acc: 0.8302\n",
      "Epoch 4246/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7752 - acc: 0.8155 - val_loss: 0.7845 - val_acc: 0.8329\n",
      "Epoch 4247/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8004 - acc: 0.8098 - val_loss: 0.7861 - val_acc: 0.8248\n",
      "Epoch 4248/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7973 - acc: 0.8086 - val_loss: 0.7895 - val_acc: 0.8275\n",
      "Epoch 4249/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8074 - acc: 0.8128 - val_loss: 0.7812 - val_acc: 0.8167\n",
      "Epoch 4250/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7725 - acc: 0.8173 - val_loss: 0.7726 - val_acc: 0.8275\n",
      "Epoch 4251/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8188 - val_loss: 0.7730 - val_acc: 0.8275\n",
      "Epoch 4252/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7752 - acc: 0.8131 - val_loss: 0.7774 - val_acc: 0.8194\n",
      "Epoch 4253/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8077 - val_loss: 0.7767 - val_acc: 0.8221\n",
      "Epoch 4254/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7916 - acc: 0.8146 - val_loss: 0.7742 - val_acc: 0.8248\n",
      "Epoch 4255/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7768 - acc: 0.8149 - val_loss: 0.7793 - val_acc: 0.8329\n",
      "Epoch 4256/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8122 - val_loss: 0.7887 - val_acc: 0.8194\n",
      "Epoch 4257/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8158 - val_loss: 0.7940 - val_acc: 0.8194\n",
      "Epoch 4258/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7863 - acc: 0.8113 - val_loss: 0.7915 - val_acc: 0.8167\n",
      "Epoch 4259/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7931 - acc: 0.8080 - val_loss: 0.7867 - val_acc: 0.8302\n",
      "Epoch 4260/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7894 - acc: 0.8134 - val_loss: 0.7861 - val_acc: 0.8275\n",
      "Epoch 4261/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7944 - acc: 0.8101 - val_loss: 0.7816 - val_acc: 0.8248\n",
      "Epoch 4262/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7926 - acc: 0.8125 - val_loss: 0.7807 - val_acc: 0.8248\n",
      "Epoch 4263/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7856 - acc: 0.8164 - val_loss: 0.7754 - val_acc: 0.8221\n",
      "Epoch 4264/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7939 - acc: 0.8149 - val_loss: 0.7750 - val_acc: 0.8302\n",
      "Epoch 4265/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7994 - acc: 0.8137 - val_loss: 0.7824 - val_acc: 0.8275\n",
      "Epoch 4266/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7932 - acc: 0.8134 - val_loss: 0.7920 - val_acc: 0.8248\n",
      "Epoch 4267/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7762 - acc: 0.8173 - val_loss: 0.7937 - val_acc: 0.8248\n",
      "Epoch 4268/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7839 - acc: 0.8167 - val_loss: 0.7912 - val_acc: 0.8248\n",
      "Epoch 4269/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7800 - acc: 0.8131 - val_loss: 0.7863 - val_acc: 0.8194\n",
      "Epoch 4270/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8140 - val_loss: 0.7804 - val_acc: 0.8248\n",
      "Epoch 4271/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7974 - acc: 0.8143 - val_loss: 0.7843 - val_acc: 0.8194\n",
      "Epoch 4272/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7996 - acc: 0.8137 - val_loss: 0.7912 - val_acc: 0.8248\n",
      "Epoch 4273/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8176 - val_loss: 0.7928 - val_acc: 0.8248\n",
      "Epoch 4274/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7913 - acc: 0.8122 - val_loss: 0.7926 - val_acc: 0.8221\n",
      "Epoch 4275/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7841 - acc: 0.8137 - val_loss: 0.7917 - val_acc: 0.8275\n",
      "Epoch 4276/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7974 - acc: 0.8167 - val_loss: 0.7841 - val_acc: 0.8275\n",
      "Epoch 4277/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7844 - acc: 0.8182 - val_loss: 0.7790 - val_acc: 0.8275\n",
      "Epoch 4278/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7789 - acc: 0.8107 - val_loss: 0.7697 - val_acc: 0.8356\n",
      "Epoch 4279/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7754 - acc: 0.8173 - val_loss: 0.7716 - val_acc: 0.8383\n",
      "Epoch 4280/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7867 - acc: 0.8143 - val_loss: 0.7780 - val_acc: 0.8329\n",
      "Epoch 4281/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8185 - val_loss: 0.7784 - val_acc: 0.8275\n",
      "Epoch 4282/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7870 - acc: 0.8182 - val_loss: 0.7821 - val_acc: 0.8248\n",
      "Epoch 4283/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8203 - val_loss: 0.7793 - val_acc: 0.8302\n",
      "Epoch 4284/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7839 - acc: 0.8140 - val_loss: 0.7744 - val_acc: 0.8302\n",
      "Epoch 4285/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7863 - acc: 0.8173 - val_loss: 0.7782 - val_acc: 0.8275\n",
      "Epoch 4286/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7894 - acc: 0.8152 - val_loss: 0.7783 - val_acc: 0.8302\n",
      "Epoch 4287/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7814 - acc: 0.8164 - val_loss: 0.7800 - val_acc: 0.8275\n",
      "Epoch 4288/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7863 - acc: 0.8167 - val_loss: 0.7798 - val_acc: 0.8275\n",
      "Epoch 4289/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7918 - acc: 0.8134 - val_loss: 0.7823 - val_acc: 0.8275\n",
      "Epoch 4290/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7956 - acc: 0.8143 - val_loss: 0.7808 - val_acc: 0.8194\n",
      "Epoch 4291/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7801 - acc: 0.8176 - val_loss: 0.7763 - val_acc: 0.8221\n",
      "Epoch 4292/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7820 - acc: 0.8143 - val_loss: 0.7749 - val_acc: 0.8221\n",
      "Epoch 4293/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7933 - acc: 0.8158 - val_loss: 0.7794 - val_acc: 0.8302\n",
      "Epoch 4294/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8173 - val_loss: 0.7832 - val_acc: 0.8329\n",
      "Epoch 4295/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8110 - val_loss: 0.7881 - val_acc: 0.8194\n",
      "Epoch 4296/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8146 - val_loss: 0.7907 - val_acc: 0.8194\n",
      "Epoch 4297/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7801 - acc: 0.8134 - val_loss: 0.7886 - val_acc: 0.8194\n",
      "Epoch 4298/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8164 - val_loss: 0.7784 - val_acc: 0.8275\n",
      "Epoch 4299/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7753 - acc: 0.8167 - val_loss: 0.7826 - val_acc: 0.8302\n",
      "Epoch 4300/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7671 - acc: 0.8197 - val_loss: 0.7879 - val_acc: 0.8329\n",
      "Epoch 4301/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7943 - acc: 0.8143 - val_loss: 0.7889 - val_acc: 0.8275\n",
      "Epoch 4302/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7737 - acc: 0.8185 - val_loss: 0.7840 - val_acc: 0.8248\n",
      "Epoch 4303/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7848 - acc: 0.8185 - val_loss: 0.7770 - val_acc: 0.8248\n",
      "Epoch 4304/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8188 - val_loss: 0.7766 - val_acc: 0.8275\n",
      "Epoch 4305/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7846 - acc: 0.8131 - val_loss: 0.7735 - val_acc: 0.8302\n",
      "Epoch 4306/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7850 - acc: 0.8206 - val_loss: 0.7714 - val_acc: 0.8329\n",
      "Epoch 4307/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7970 - acc: 0.8155 - val_loss: 0.7672 - val_acc: 0.8356\n",
      "Epoch 4308/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7916 - acc: 0.8188 - val_loss: 0.7650 - val_acc: 0.8356\n",
      "Epoch 4309/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7821 - acc: 0.8197 - val_loss: 0.7768 - val_acc: 0.8302\n",
      "Epoch 4310/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7813 - acc: 0.8140 - val_loss: 0.7859 - val_acc: 0.8275\n",
      "Epoch 4311/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7663 - acc: 0.8146 - val_loss: 0.7906 - val_acc: 0.8275\n",
      "Epoch 4312/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7805 - acc: 0.8176 - val_loss: 0.7919 - val_acc: 0.8275\n",
      "Epoch 4313/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7799 - acc: 0.8149 - val_loss: 0.7937 - val_acc: 0.8221\n",
      "Epoch 4314/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7727 - acc: 0.8173 - val_loss: 0.7887 - val_acc: 0.8302\n",
      "Epoch 4315/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7900 - acc: 0.8155 - val_loss: 0.7809 - val_acc: 0.8329\n",
      "Epoch 4316/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7975 - acc: 0.8140 - val_loss: 0.7773 - val_acc: 0.8329\n",
      "Epoch 4317/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7852 - acc: 0.8125 - val_loss: 0.7806 - val_acc: 0.8356\n",
      "Epoch 4318/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8116 - val_loss: 0.7812 - val_acc: 0.8248\n",
      "Epoch 4319/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7730 - acc: 0.8188 - val_loss: 0.7836 - val_acc: 0.8221\n",
      "Epoch 4320/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7812 - acc: 0.8188 - val_loss: 0.7850 - val_acc: 0.8248\n",
      "Epoch 4321/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8122 - val_loss: 0.7900 - val_acc: 0.8221\n",
      "Epoch 4322/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7847 - acc: 0.8185 - val_loss: 0.7971 - val_acc: 0.8248\n",
      "Epoch 4323/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7812 - acc: 0.8143 - val_loss: 0.8032 - val_acc: 0.8194\n",
      "Epoch 4324/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7813 - acc: 0.8143 - val_loss: 0.7965 - val_acc: 0.8302\n",
      "Epoch 4325/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7981 - acc: 0.8110 - val_loss: 0.7925 - val_acc: 0.8302\n",
      "Epoch 4326/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7828 - acc: 0.8191 - val_loss: 0.7853 - val_acc: 0.8302\n",
      "Epoch 4327/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7853 - acc: 0.8182 - val_loss: 0.7832 - val_acc: 0.8248\n",
      "Epoch 4328/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7744 - acc: 0.8161 - val_loss: 0.7930 - val_acc: 0.8248\n",
      "Epoch 4329/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7929 - acc: 0.8197 - val_loss: 0.7938 - val_acc: 0.8248\n",
      "Epoch 4330/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8131 - val_loss: 0.7914 - val_acc: 0.8302\n",
      "Epoch 4331/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7666 - acc: 0.8209 - val_loss: 0.7909 - val_acc: 0.8221\n",
      "Epoch 4332/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7728 - acc: 0.8200 - val_loss: 0.7893 - val_acc: 0.8329\n",
      "Epoch 4333/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7841 - acc: 0.8179 - val_loss: 0.7890 - val_acc: 0.8356\n",
      "Epoch 4334/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7808 - acc: 0.8137 - val_loss: 0.7881 - val_acc: 0.8248\n",
      "Epoch 4335/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7767 - acc: 0.8176 - val_loss: 0.7942 - val_acc: 0.8221\n",
      "Epoch 4336/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7812 - acc: 0.8170 - val_loss: 0.7993 - val_acc: 0.8194\n",
      "Epoch 4337/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8067 - acc: 0.8128 - val_loss: 0.8016 - val_acc: 0.8248\n",
      "Epoch 4338/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7837 - acc: 0.8185 - val_loss: 0.7894 - val_acc: 0.8329\n",
      "Epoch 4339/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7763 - acc: 0.8221 - val_loss: 0.7838 - val_acc: 0.8302\n",
      "Epoch 4340/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7972 - acc: 0.8077 - val_loss: 0.7875 - val_acc: 0.8329\n",
      "Epoch 4341/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7953 - acc: 0.8134 - val_loss: 0.7911 - val_acc: 0.8248\n",
      "Epoch 4342/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7756 - acc: 0.8188 - val_loss: 0.7945 - val_acc: 0.8221\n",
      "Epoch 4343/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7872 - acc: 0.8185 - val_loss: 0.7928 - val_acc: 0.8275\n",
      "Epoch 4344/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7889 - acc: 0.8173 - val_loss: 0.7924 - val_acc: 0.8248\n",
      "Epoch 4345/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7855 - acc: 0.8170 - val_loss: 0.7969 - val_acc: 0.8302\n",
      "Epoch 4346/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8095 - acc: 0.8152 - val_loss: 0.8021 - val_acc: 0.8329\n",
      "Epoch 4347/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7770 - acc: 0.8152 - val_loss: 0.8053 - val_acc: 0.8275\n",
      "Epoch 4348/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7787 - acc: 0.8164 - val_loss: 0.7996 - val_acc: 0.8221\n",
      "Epoch 4349/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7856 - acc: 0.8113 - val_loss: 0.7941 - val_acc: 0.8221\n",
      "Epoch 4350/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7880 - acc: 0.8137 - val_loss: 0.7907 - val_acc: 0.8275\n",
      "Epoch 4351/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7792 - acc: 0.8137 - val_loss: 0.7895 - val_acc: 0.8275\n",
      "Epoch 4352/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7967 - acc: 0.8125 - val_loss: 0.7890 - val_acc: 0.8194\n",
      "Epoch 4353/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7788 - acc: 0.8185 - val_loss: 0.7875 - val_acc: 0.8221\n",
      "Epoch 4354/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7787 - acc: 0.8143 - val_loss: 0.7905 - val_acc: 0.8194\n",
      "Epoch 4355/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7888 - acc: 0.8158 - val_loss: 0.7922 - val_acc: 0.8248\n",
      "Epoch 4356/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7975 - acc: 0.8104 - val_loss: 0.7869 - val_acc: 0.8248\n",
      "Epoch 4357/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8061 - acc: 0.8179 - val_loss: 0.7887 - val_acc: 0.8302\n",
      "Epoch 4358/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8024 - acc: 0.8101 - val_loss: 0.7948 - val_acc: 0.8275\n",
      "Epoch 4359/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7922 - acc: 0.8176 - val_loss: 0.7979 - val_acc: 0.8194\n",
      "Epoch 4360/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7685 - acc: 0.8200 - val_loss: 0.7972 - val_acc: 0.8221\n",
      "Epoch 4361/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8191 - val_loss: 0.7940 - val_acc: 0.8194\n",
      "Epoch 4362/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7772 - acc: 0.8182 - val_loss: 0.7925 - val_acc: 0.8194\n",
      "Epoch 4363/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7809 - acc: 0.8164 - val_loss: 0.7905 - val_acc: 0.8275\n",
      "Epoch 4364/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7889 - acc: 0.8179 - val_loss: 0.7907 - val_acc: 0.8248\n",
      "Epoch 4365/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7763 - acc: 0.8221 - val_loss: 0.7881 - val_acc: 0.8221\n",
      "Epoch 4366/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7868 - acc: 0.8146 - val_loss: 0.7874 - val_acc: 0.8248\n",
      "Epoch 4367/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8122 - val_loss: 0.7869 - val_acc: 0.8221\n",
      "Epoch 4368/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8161 - val_loss: 0.7896 - val_acc: 0.8194\n",
      "Epoch 4369/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7839 - acc: 0.8164 - val_loss: 0.7948 - val_acc: 0.8221\n",
      "Epoch 4370/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7802 - acc: 0.8215 - val_loss: 0.7960 - val_acc: 0.8248\n",
      "Epoch 4371/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7961 - acc: 0.8212 - val_loss: 0.7948 - val_acc: 0.8248\n",
      "Epoch 4372/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7987 - acc: 0.8116 - val_loss: 0.7920 - val_acc: 0.8248\n",
      "Epoch 4373/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8007 - acc: 0.8125 - val_loss: 0.7936 - val_acc: 0.8302\n",
      "Epoch 4374/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7884 - acc: 0.8185 - val_loss: 0.7949 - val_acc: 0.8194\n",
      "Epoch 4375/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8092 - acc: 0.8104 - val_loss: 0.8018 - val_acc: 0.8194\n",
      "Epoch 4376/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7714 - acc: 0.8182 - val_loss: 0.8079 - val_acc: 0.8167\n",
      "Epoch 4377/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7904 - acc: 0.8131 - val_loss: 0.8078 - val_acc: 0.8113\n",
      "Epoch 4378/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8095 - val_loss: 0.7981 - val_acc: 0.8194\n",
      "Epoch 4379/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8134 - val_loss: 0.7859 - val_acc: 0.8248\n",
      "Epoch 4380/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7699 - acc: 0.8143 - val_loss: 0.7801 - val_acc: 0.8248\n",
      "Epoch 4381/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7779 - acc: 0.8101 - val_loss: 0.7797 - val_acc: 0.8302\n",
      "Epoch 4382/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8149 - val_loss: 0.7847 - val_acc: 0.8275\n",
      "Epoch 4383/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7816 - acc: 0.8101 - val_loss: 0.7830 - val_acc: 0.8275\n",
      "Epoch 4384/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7851 - acc: 0.8179 - val_loss: 0.7810 - val_acc: 0.8302\n",
      "Epoch 4385/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7968 - acc: 0.8131 - val_loss: 0.7849 - val_acc: 0.8302\n",
      "Epoch 4386/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7776 - acc: 0.8098 - val_loss: 0.7880 - val_acc: 0.8275\n",
      "Epoch 4387/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7809 - acc: 0.8140 - val_loss: 0.7891 - val_acc: 0.8302\n",
      "Epoch 4388/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7888 - acc: 0.8152 - val_loss: 0.7923 - val_acc: 0.8248\n",
      "Epoch 4389/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7762 - acc: 0.8176 - val_loss: 0.8021 - val_acc: 0.8194\n",
      "Epoch 4390/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7896 - acc: 0.8209 - val_loss: 0.8035 - val_acc: 0.8194\n",
      "Epoch 4391/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7894 - acc: 0.8131 - val_loss: 0.8020 - val_acc: 0.8194\n",
      "Epoch 4392/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7857 - acc: 0.8179 - val_loss: 0.7905 - val_acc: 0.8221\n",
      "Epoch 4393/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7709 - acc: 0.8167 - val_loss: 0.7790 - val_acc: 0.8302\n",
      "Epoch 4394/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8149 - val_loss: 0.7733 - val_acc: 0.8356\n",
      "Epoch 4395/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7916 - acc: 0.8209 - val_loss: 0.7746 - val_acc: 0.8302\n",
      "Epoch 4396/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7668 - acc: 0.8161 - val_loss: 0.7754 - val_acc: 0.8275\n",
      "Epoch 4397/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8010 - acc: 0.8113 - val_loss: 0.7812 - val_acc: 0.8194\n",
      "Epoch 4398/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8125 - val_loss: 0.7776 - val_acc: 0.8221\n",
      "Epoch 4399/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7773 - acc: 0.8137 - val_loss: 0.7694 - val_acc: 0.8275\n",
      "Epoch 4400/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7910 - acc: 0.8116 - val_loss: 0.7757 - val_acc: 0.8275\n",
      "Epoch 4401/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7783 - acc: 0.8182 - val_loss: 0.7827 - val_acc: 0.8167\n",
      "Epoch 4402/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8164 - val_loss: 0.7859 - val_acc: 0.8194\n",
      "Epoch 4403/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8170 - val_loss: 0.7822 - val_acc: 0.8275\n",
      "Epoch 4404/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7887 - acc: 0.8122 - val_loss: 0.7756 - val_acc: 0.8329\n",
      "Epoch 4405/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7825 - acc: 0.8086 - val_loss: 0.7797 - val_acc: 0.8275\n",
      "Epoch 4406/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7753 - acc: 0.8107 - val_loss: 0.7861 - val_acc: 0.8275\n",
      "Epoch 4407/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7844 - acc: 0.8137 - val_loss: 0.7867 - val_acc: 0.8194\n",
      "Epoch 4408/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7829 - acc: 0.8149 - val_loss: 0.7908 - val_acc: 0.8194\n",
      "Epoch 4409/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8021 - acc: 0.8086 - val_loss: 0.7907 - val_acc: 0.8302\n",
      "Epoch 4410/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7823 - acc: 0.8164 - val_loss: 0.7894 - val_acc: 0.8302\n",
      "Epoch 4411/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7862 - acc: 0.8140 - val_loss: 0.7946 - val_acc: 0.8302\n",
      "Epoch 4412/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7864 - acc: 0.8110 - val_loss: 0.7925 - val_acc: 0.8275\n",
      "Epoch 4413/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7956 - acc: 0.8122 - val_loss: 0.7963 - val_acc: 0.8248\n",
      "Epoch 4414/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7922 - acc: 0.8128 - val_loss: 0.8045 - val_acc: 0.8275\n",
      "Epoch 4415/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7908 - acc: 0.8200 - val_loss: 0.7920 - val_acc: 0.8275\n",
      "Epoch 4416/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7939 - acc: 0.8149 - val_loss: 0.7860 - val_acc: 0.8329\n",
      "Epoch 4417/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7699 - acc: 0.8176 - val_loss: 0.7916 - val_acc: 0.8275\n",
      "Epoch 4418/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7763 - acc: 0.8158 - val_loss: 0.7932 - val_acc: 0.8248\n",
      "Epoch 4419/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7917 - acc: 0.8152 - val_loss: 0.7940 - val_acc: 0.8248\n",
      "Epoch 4420/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7669 - acc: 0.8170 - val_loss: 0.8003 - val_acc: 0.8221\n",
      "Epoch 4421/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8042 - acc: 0.8173 - val_loss: 0.8016 - val_acc: 0.8194\n",
      "Epoch 4422/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8004 - acc: 0.8041 - val_loss: 0.8039 - val_acc: 0.8248\n",
      "Epoch 4423/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8104 - val_loss: 0.8066 - val_acc: 0.8221\n",
      "Epoch 4424/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8015 - acc: 0.8101 - val_loss: 0.8083 - val_acc: 0.8248\n",
      "Epoch 4425/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7825 - acc: 0.8089 - val_loss: 0.8061 - val_acc: 0.8221\n",
      "Epoch 4426/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7769 - acc: 0.8158 - val_loss: 0.8013 - val_acc: 0.8194\n",
      "Epoch 4427/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7894 - acc: 0.8155 - val_loss: 0.7999 - val_acc: 0.8248\n",
      "Epoch 4428/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7805 - acc: 0.8206 - val_loss: 0.7960 - val_acc: 0.8275\n",
      "Epoch 4429/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7785 - acc: 0.8194 - val_loss: 0.7996 - val_acc: 0.8248\n",
      "Epoch 4430/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8067 - acc: 0.8104 - val_loss: 0.7984 - val_acc: 0.8248\n",
      "Epoch 4431/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7989 - acc: 0.8158 - val_loss: 0.8002 - val_acc: 0.8194\n",
      "Epoch 4432/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7869 - acc: 0.8167 - val_loss: 0.7993 - val_acc: 0.8194\n",
      "Epoch 4433/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7908 - acc: 0.8128 - val_loss: 0.7926 - val_acc: 0.8248\n",
      "Epoch 4434/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7939 - acc: 0.8161 - val_loss: 0.7890 - val_acc: 0.8329\n",
      "Epoch 4435/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7799 - acc: 0.8143 - val_loss: 0.7839 - val_acc: 0.8356\n",
      "Epoch 4436/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7774 - acc: 0.8146 - val_loss: 0.7860 - val_acc: 0.8275\n",
      "Epoch 4437/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7701 - acc: 0.8134 - val_loss: 0.7962 - val_acc: 0.8221\n",
      "Epoch 4438/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7791 - acc: 0.8203 - val_loss: 0.7892 - val_acc: 0.8221\n",
      "Epoch 4439/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7994 - acc: 0.8158 - val_loss: 0.7838 - val_acc: 0.8302\n",
      "Epoch 4440/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8176 - val_loss: 0.7876 - val_acc: 0.8302\n",
      "Epoch 4441/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7924 - acc: 0.8122 - val_loss: 0.7913 - val_acc: 0.8302\n",
      "Epoch 4442/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7764 - acc: 0.8137 - val_loss: 0.7964 - val_acc: 0.8275\n",
      "Epoch 4443/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7953 - acc: 0.8134 - val_loss: 0.7970 - val_acc: 0.8302\n",
      "Epoch 4444/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7825 - acc: 0.8167 - val_loss: 0.8003 - val_acc: 0.8275\n",
      "Epoch 4445/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7789 - acc: 0.8209 - val_loss: 0.8006 - val_acc: 0.8248\n",
      "Epoch 4446/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7886 - acc: 0.8200 - val_loss: 0.7948 - val_acc: 0.8275\n",
      "Epoch 4447/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7770 - acc: 0.8200 - val_loss: 0.7935 - val_acc: 0.8329\n",
      "Epoch 4448/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7712 - acc: 0.8158 - val_loss: 0.7935 - val_acc: 0.8248\n",
      "Epoch 4449/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7973 - acc: 0.8188 - val_loss: 0.7953 - val_acc: 0.8221\n",
      "Epoch 4450/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7859 - acc: 0.8173 - val_loss: 0.7907 - val_acc: 0.8275\n",
      "Epoch 4451/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7694 - acc: 0.8200 - val_loss: 0.7866 - val_acc: 0.8275\n",
      "Epoch 4452/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7931 - acc: 0.8131 - val_loss: 0.7955 - val_acc: 0.8248\n",
      "Epoch 4453/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8140 - val_loss: 0.8036 - val_acc: 0.8248\n",
      "Epoch 4454/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7916 - acc: 0.8092 - val_loss: 0.8031 - val_acc: 0.8275\n",
      "Epoch 4455/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7911 - acc: 0.8164 - val_loss: 0.7961 - val_acc: 0.8275\n",
      "Epoch 4456/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7859 - acc: 0.8131 - val_loss: 0.8010 - val_acc: 0.8329\n",
      "Epoch 4457/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7731 - acc: 0.8191 - val_loss: 0.8095 - val_acc: 0.8248\n",
      "Epoch 4458/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7841 - acc: 0.8116 - val_loss: 0.8119 - val_acc: 0.8194\n",
      "Epoch 4459/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7812 - acc: 0.8152 - val_loss: 0.7954 - val_acc: 0.8248\n",
      "Epoch 4460/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7950 - acc: 0.8152 - val_loss: 0.7849 - val_acc: 0.8302\n",
      "Epoch 4461/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7927 - acc: 0.8080 - val_loss: 0.7816 - val_acc: 0.8302\n",
      "Epoch 4462/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7695 - acc: 0.8170 - val_loss: 0.7834 - val_acc: 0.8302\n",
      "Epoch 4463/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7850 - acc: 0.8146 - val_loss: 0.7857 - val_acc: 0.8356\n",
      "Epoch 4464/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8004 - acc: 0.8155 - val_loss: 0.7871 - val_acc: 0.8302\n",
      "Epoch 4465/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7814 - acc: 0.8200 - val_loss: 0.7937 - val_acc: 0.8248\n",
      "Epoch 4466/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7867 - acc: 0.8179 - val_loss: 0.7967 - val_acc: 0.8275\n",
      "Epoch 4467/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7857 - acc: 0.8185 - val_loss: 0.7985 - val_acc: 0.8275\n",
      "Epoch 4468/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7914 - acc: 0.8098 - val_loss: 0.8004 - val_acc: 0.8248\n",
      "Epoch 4469/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7756 - acc: 0.8182 - val_loss: 0.7977 - val_acc: 0.8302\n",
      "Epoch 4470/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7831 - acc: 0.8215 - val_loss: 0.7981 - val_acc: 0.8275\n",
      "Epoch 4471/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7785 - acc: 0.8179 - val_loss: 0.7945 - val_acc: 0.8275\n",
      "Epoch 4472/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7861 - acc: 0.8161 - val_loss: 0.7938 - val_acc: 0.8194\n",
      "Epoch 4473/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7806 - acc: 0.8119 - val_loss: 0.7935 - val_acc: 0.8221\n",
      "Epoch 4474/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7792 - acc: 0.8155 - val_loss: 0.7877 - val_acc: 0.8221\n",
      "Epoch 4475/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7772 - acc: 0.8137 - val_loss: 0.7797 - val_acc: 0.8302\n",
      "Epoch 4476/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7770 - acc: 0.8110 - val_loss: 0.7772 - val_acc: 0.8329\n",
      "Epoch 4477/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7878 - acc: 0.8149 - val_loss: 0.7816 - val_acc: 0.8302\n",
      "Epoch 4478/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7961 - acc: 0.8194 - val_loss: 0.7829 - val_acc: 0.8248\n",
      "Epoch 4479/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7953 - acc: 0.8167 - val_loss: 0.7804 - val_acc: 0.8248\n",
      "Epoch 4480/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7895 - acc: 0.8098 - val_loss: 0.7847 - val_acc: 0.8275\n",
      "Epoch 4481/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7720 - acc: 0.8176 - val_loss: 0.7920 - val_acc: 0.8221\n",
      "Epoch 4482/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7760 - acc: 0.8179 - val_loss: 0.7845 - val_acc: 0.8221\n",
      "Epoch 4483/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8058 - acc: 0.8110 - val_loss: 0.7717 - val_acc: 0.8275\n",
      "Epoch 4484/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7853 - acc: 0.8149 - val_loss: 0.7664 - val_acc: 0.8275\n",
      "Epoch 4485/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7850 - acc: 0.8116 - val_loss: 0.7699 - val_acc: 0.8275\n",
      "Epoch 4486/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8176 - val_loss: 0.7847 - val_acc: 0.8248\n",
      "Epoch 4487/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8131 - val_loss: 0.7927 - val_acc: 0.8221\n",
      "Epoch 4488/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7926 - acc: 0.8128 - val_loss: 0.7849 - val_acc: 0.8275\n",
      "Epoch 4489/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7891 - acc: 0.8176 - val_loss: 0.7795 - val_acc: 0.8275\n",
      "Epoch 4490/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7848 - acc: 0.8176 - val_loss: 0.7787 - val_acc: 0.8302\n",
      "Epoch 4491/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7841 - acc: 0.8155 - val_loss: 0.7807 - val_acc: 0.8248\n",
      "Epoch 4492/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7695 - acc: 0.8173 - val_loss: 0.7822 - val_acc: 0.8248\n",
      "Epoch 4493/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7953 - acc: 0.8143 - val_loss: 0.7868 - val_acc: 0.8221\n",
      "Epoch 4494/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7924 - acc: 0.8206 - val_loss: 0.7955 - val_acc: 0.8302\n",
      "Epoch 4495/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7841 - acc: 0.8212 - val_loss: 0.8002 - val_acc: 0.8302\n",
      "Epoch 4496/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7910 - acc: 0.8170 - val_loss: 0.7910 - val_acc: 0.8275\n",
      "Epoch 4497/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8155 - val_loss: 0.7924 - val_acc: 0.8248\n",
      "Epoch 4498/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7936 - acc: 0.8077 - val_loss: 0.7958 - val_acc: 0.8221\n",
      "Epoch 4499/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7908 - acc: 0.8164 - val_loss: 0.7892 - val_acc: 0.8221\n",
      "Epoch 4500/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7753 - acc: 0.8083 - val_loss: 0.7826 - val_acc: 0.8248\n",
      "Epoch 4501/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7829 - acc: 0.8179 - val_loss: 0.7784 - val_acc: 0.8221\n",
      "Epoch 4502/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7980 - acc: 0.8161 - val_loss: 0.7757 - val_acc: 0.8275\n",
      "Epoch 4503/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7796 - acc: 0.8185 - val_loss: 0.7742 - val_acc: 0.8329\n",
      "Epoch 4504/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7868 - acc: 0.8167 - val_loss: 0.7764 - val_acc: 0.8302\n",
      "Epoch 4505/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7670 - acc: 0.8185 - val_loss: 0.7819 - val_acc: 0.8329\n",
      "Epoch 4506/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7741 - acc: 0.8119 - val_loss: 0.7926 - val_acc: 0.8194\n",
      "Epoch 4507/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7847 - acc: 0.8125 - val_loss: 0.8021 - val_acc: 0.8167\n",
      "Epoch 4508/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7861 - acc: 0.8077 - val_loss: 0.7990 - val_acc: 0.8221\n",
      "Epoch 4509/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7930 - acc: 0.8155 - val_loss: 0.7890 - val_acc: 0.8329\n",
      "Epoch 4510/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7723 - acc: 0.8185 - val_loss: 0.7880 - val_acc: 0.8356\n",
      "Epoch 4511/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7858 - acc: 0.8206 - val_loss: 0.7930 - val_acc: 0.8302\n",
      "Epoch 4512/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7805 - acc: 0.8137 - val_loss: 0.7920 - val_acc: 0.8221\n",
      "Epoch 4513/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8188 - val_loss: 0.7962 - val_acc: 0.8248\n",
      "Epoch 4514/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7861 - acc: 0.8098 - val_loss: 0.8028 - val_acc: 0.8167\n",
      "Epoch 4515/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7919 - acc: 0.8176 - val_loss: 0.8033 - val_acc: 0.8221\n",
      "Epoch 4516/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8037 - acc: 0.8131 - val_loss: 0.7980 - val_acc: 0.8248\n",
      "Epoch 4517/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7632 - acc: 0.8182 - val_loss: 0.7926 - val_acc: 0.8302\n",
      "Epoch 4518/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7936 - acc: 0.8110 - val_loss: 0.7920 - val_acc: 0.8275\n",
      "Epoch 4519/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7833 - acc: 0.8119 - val_loss: 0.7871 - val_acc: 0.8302\n",
      "Epoch 4520/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7968 - acc: 0.8104 - val_loss: 0.7825 - val_acc: 0.8275\n",
      "Epoch 4521/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7960 - acc: 0.8062 - val_loss: 0.7836 - val_acc: 0.8194\n",
      "Epoch 4522/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7928 - acc: 0.8131 - val_loss: 0.7849 - val_acc: 0.8248\n",
      "Epoch 4523/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7843 - acc: 0.8155 - val_loss: 0.7866 - val_acc: 0.8221\n",
      "Epoch 4524/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7835 - acc: 0.8140 - val_loss: 0.7874 - val_acc: 0.8221\n",
      "Epoch 4525/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8046 - acc: 0.8116 - val_loss: 0.7931 - val_acc: 0.8194\n",
      "Epoch 4526/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8158 - val_loss: 0.7973 - val_acc: 0.8248\n",
      "Epoch 4527/5000\n",
      "3339/3339 [==============================] - 0s 10us/step - loss: 0.7986 - acc: 0.8143 - val_loss: 0.7946 - val_acc: 0.8221\n",
      "Epoch 4528/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8128 - val_loss: 0.7971 - val_acc: 0.8221\n",
      "Epoch 4529/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7956 - acc: 0.8077 - val_loss: 0.7969 - val_acc: 0.8194\n",
      "Epoch 4530/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8027 - acc: 0.8215 - val_loss: 0.7948 - val_acc: 0.8167\n",
      "Epoch 4531/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7840 - acc: 0.8179 - val_loss: 0.7854 - val_acc: 0.8221\n",
      "Epoch 4532/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7716 - acc: 0.8185 - val_loss: 0.7799 - val_acc: 0.8275\n",
      "Epoch 4533/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8128 - val_loss: 0.7852 - val_acc: 0.8248\n",
      "Epoch 4534/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7717 - acc: 0.8209 - val_loss: 0.7879 - val_acc: 0.8275\n",
      "Epoch 4535/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7847 - acc: 0.8161 - val_loss: 0.7797 - val_acc: 0.8275\n",
      "Epoch 4536/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7852 - acc: 0.8110 - val_loss: 0.7771 - val_acc: 0.8275\n",
      "Epoch 4537/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7981 - acc: 0.8146 - val_loss: 0.7888 - val_acc: 0.8221\n",
      "Epoch 4538/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7959 - acc: 0.8107 - val_loss: 0.7971 - val_acc: 0.8194\n",
      "Epoch 4539/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8024 - acc: 0.8119 - val_loss: 0.7918 - val_acc: 0.8221\n",
      "Epoch 4540/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7774 - acc: 0.8233 - val_loss: 0.7868 - val_acc: 0.8221\n",
      "Epoch 4541/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7833 - acc: 0.8155 - val_loss: 0.7889 - val_acc: 0.8140\n",
      "Epoch 4542/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7802 - acc: 0.8119 - val_loss: 0.7807 - val_acc: 0.8167\n",
      "Epoch 4543/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7943 - acc: 0.8146 - val_loss: 0.7789 - val_acc: 0.8275\n",
      "Epoch 4544/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7957 - acc: 0.8134 - val_loss: 0.7878 - val_acc: 0.8221\n",
      "Epoch 4545/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7833 - acc: 0.8113 - val_loss: 0.7933 - val_acc: 0.8194\n",
      "Epoch 4546/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7738 - acc: 0.8086 - val_loss: 0.7903 - val_acc: 0.8194\n",
      "Epoch 4547/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7827 - acc: 0.8161 - val_loss: 0.7861 - val_acc: 0.8194\n",
      "Epoch 4548/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7987 - acc: 0.8068 - val_loss: 0.7817 - val_acc: 0.8221\n",
      "Epoch 4549/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7977 - acc: 0.8113 - val_loss: 0.7811 - val_acc: 0.8248\n",
      "Epoch 4550/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7872 - acc: 0.8212 - val_loss: 0.7806 - val_acc: 0.8275\n",
      "Epoch 4551/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7916 - acc: 0.8173 - val_loss: 0.7846 - val_acc: 0.8248\n",
      "Epoch 4552/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8161 - val_loss: 0.7865 - val_acc: 0.8248\n",
      "Epoch 4553/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7893 - acc: 0.8191 - val_loss: 0.7800 - val_acc: 0.8275\n",
      "Epoch 4554/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7898 - acc: 0.8113 - val_loss: 0.7838 - val_acc: 0.8194\n",
      "Epoch 4555/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7944 - acc: 0.8125 - val_loss: 0.7907 - val_acc: 0.8194\n",
      "Epoch 4556/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7637 - acc: 0.8218 - val_loss: 0.7917 - val_acc: 0.8275\n",
      "Epoch 4557/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7803 - acc: 0.8158 - val_loss: 0.7924 - val_acc: 0.8248\n",
      "Epoch 4558/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7693 - acc: 0.8203 - val_loss: 0.7933 - val_acc: 0.8167\n",
      "Epoch 4559/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7899 - acc: 0.8116 - val_loss: 0.7910 - val_acc: 0.8221\n",
      "Epoch 4560/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7626 - acc: 0.8164 - val_loss: 0.7922 - val_acc: 0.8275\n",
      "Epoch 4561/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7919 - acc: 0.8155 - val_loss: 0.7961 - val_acc: 0.8329\n",
      "Epoch 4562/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7785 - acc: 0.8191 - val_loss: 0.7980 - val_acc: 0.8275\n",
      "Epoch 4563/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8149 - val_loss: 0.7991 - val_acc: 0.8221\n",
      "Epoch 4564/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7993 - acc: 0.8161 - val_loss: 0.7964 - val_acc: 0.8221\n",
      "Epoch 4565/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7866 - acc: 0.8197 - val_loss: 0.7996 - val_acc: 0.8221\n",
      "Epoch 4566/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7933 - acc: 0.8131 - val_loss: 0.7942 - val_acc: 0.8275\n",
      "Epoch 4567/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7989 - acc: 0.8155 - val_loss: 0.7934 - val_acc: 0.8248\n",
      "Epoch 4568/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7799 - acc: 0.8173 - val_loss: 0.7988 - val_acc: 0.8275\n",
      "Epoch 4569/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7861 - acc: 0.8128 - val_loss: 0.8078 - val_acc: 0.8221\n",
      "Epoch 4570/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7880 - acc: 0.8170 - val_loss: 0.8131 - val_acc: 0.8194\n",
      "Epoch 4571/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8140 - val_loss: 0.8036 - val_acc: 0.8194\n",
      "Epoch 4572/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7811 - acc: 0.8092 - val_loss: 0.7847 - val_acc: 0.8275\n",
      "Epoch 4573/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7858 - acc: 0.8161 - val_loss: 0.7702 - val_acc: 0.8356\n",
      "Epoch 4574/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7837 - acc: 0.8164 - val_loss: 0.7715 - val_acc: 0.8356\n",
      "Epoch 4575/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8007 - acc: 0.8179 - val_loss: 0.7737 - val_acc: 0.8437\n",
      "Epoch 4576/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7754 - acc: 0.8176 - val_loss: 0.7774 - val_acc: 0.8383\n",
      "Epoch 4577/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7899 - acc: 0.8149 - val_loss: 0.7798 - val_acc: 0.8248\n",
      "Epoch 4578/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7875 - acc: 0.8104 - val_loss: 0.7764 - val_acc: 0.8275\n",
      "Epoch 4579/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7821 - acc: 0.8167 - val_loss: 0.7781 - val_acc: 0.8275\n",
      "Epoch 4580/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7705 - acc: 0.8224 - val_loss: 0.7844 - val_acc: 0.8221\n",
      "Epoch 4581/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7952 - acc: 0.8143 - val_loss: 0.7860 - val_acc: 0.8248\n",
      "Epoch 4582/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7778 - acc: 0.8164 - val_loss: 0.7801 - val_acc: 0.8302\n",
      "Epoch 4583/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7669 - acc: 0.8188 - val_loss: 0.7786 - val_acc: 0.8248\n",
      "Epoch 4584/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7796 - acc: 0.8158 - val_loss: 0.7803 - val_acc: 0.8275\n",
      "Epoch 4585/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7959 - acc: 0.8140 - val_loss: 0.7906 - val_acc: 0.8248\n",
      "Epoch 4586/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7836 - acc: 0.8098 - val_loss: 0.7956 - val_acc: 0.8248\n",
      "Epoch 4587/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7908 - acc: 0.8116 - val_loss: 0.7882 - val_acc: 0.8302\n",
      "Epoch 4588/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7800 - acc: 0.8143 - val_loss: 0.7868 - val_acc: 0.8275\n",
      "Epoch 4589/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7931 - acc: 0.8182 - val_loss: 0.7856 - val_acc: 0.8248\n",
      "Epoch 4590/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8091 - acc: 0.8107 - val_loss: 0.7892 - val_acc: 0.8275\n",
      "Epoch 4591/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7817 - acc: 0.8221 - val_loss: 0.7915 - val_acc: 0.8275\n",
      "Epoch 4592/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7903 - acc: 0.8143 - val_loss: 0.7809 - val_acc: 0.8221\n",
      "Epoch 4593/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8143 - val_loss: 0.7788 - val_acc: 0.8275\n",
      "Epoch 4594/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7966 - acc: 0.8158 - val_loss: 0.7809 - val_acc: 0.8302\n",
      "Epoch 4595/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7904 - acc: 0.8167 - val_loss: 0.7883 - val_acc: 0.8275\n",
      "Epoch 4596/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7791 - acc: 0.8149 - val_loss: 0.7883 - val_acc: 0.8248\n",
      "Epoch 4597/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7869 - acc: 0.8146 - val_loss: 0.7882 - val_acc: 0.8248\n",
      "Epoch 4598/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7744 - acc: 0.8164 - val_loss: 0.7890 - val_acc: 0.8275\n",
      "Epoch 4599/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7776 - acc: 0.8164 - val_loss: 0.7860 - val_acc: 0.8302\n",
      "Epoch 4600/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7829 - acc: 0.8104 - val_loss: 0.7814 - val_acc: 0.8329\n",
      "Epoch 4601/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7807 - acc: 0.8143 - val_loss: 0.7748 - val_acc: 0.8356\n",
      "Epoch 4602/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7745 - acc: 0.8212 - val_loss: 0.7759 - val_acc: 0.8275\n",
      "Epoch 4603/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7751 - acc: 0.8116 - val_loss: 0.7872 - val_acc: 0.8194\n",
      "Epoch 4604/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7764 - acc: 0.8215 - val_loss: 0.7897 - val_acc: 0.8167\n",
      "Epoch 4605/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8010 - acc: 0.8155 - val_loss: 0.7824 - val_acc: 0.8302\n",
      "Epoch 4606/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7905 - acc: 0.8134 - val_loss: 0.7753 - val_acc: 0.8383\n",
      "Epoch 4607/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7788 - acc: 0.8113 - val_loss: 0.7773 - val_acc: 0.8356\n",
      "Epoch 4608/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8179 - val_loss: 0.7870 - val_acc: 0.8221\n",
      "Epoch 4609/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7814 - acc: 0.8167 - val_loss: 0.7825 - val_acc: 0.8248\n",
      "Epoch 4610/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7635 - acc: 0.8182 - val_loss: 0.7720 - val_acc: 0.8221\n",
      "Epoch 4611/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7955 - acc: 0.8170 - val_loss: 0.7683 - val_acc: 0.8275\n",
      "Epoch 4612/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7812 - acc: 0.8173 - val_loss: 0.7714 - val_acc: 0.8302\n",
      "Epoch 4613/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7909 - acc: 0.8149 - val_loss: 0.7768 - val_acc: 0.8329\n",
      "Epoch 4614/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7806 - acc: 0.8191 - val_loss: 0.7777 - val_acc: 0.8329\n",
      "Epoch 4615/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7999 - acc: 0.8089 - val_loss: 0.7788 - val_acc: 0.8302\n",
      "Epoch 4616/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7911 - acc: 0.8164 - val_loss: 0.7898 - val_acc: 0.8248\n",
      "Epoch 4617/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7867 - acc: 0.8158 - val_loss: 0.7983 - val_acc: 0.8221\n",
      "Epoch 4618/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7982 - acc: 0.8122 - val_loss: 0.7922 - val_acc: 0.8275\n",
      "Epoch 4619/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7817 - acc: 0.8167 - val_loss: 0.7936 - val_acc: 0.8275\n",
      "Epoch 4620/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7756 - acc: 0.8164 - val_loss: 0.7974 - val_acc: 0.8302\n",
      "Epoch 4621/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7792 - acc: 0.8194 - val_loss: 0.7958 - val_acc: 0.8275\n",
      "Epoch 4622/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8137 - val_loss: 0.7940 - val_acc: 0.8248\n",
      "Epoch 4623/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7756 - acc: 0.8140 - val_loss: 0.7941 - val_acc: 0.8248\n",
      "Epoch 4624/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7954 - acc: 0.8122 - val_loss: 0.7930 - val_acc: 0.8302\n",
      "Epoch 4625/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7722 - acc: 0.8146 - val_loss: 0.7919 - val_acc: 0.8302\n",
      "Epoch 4626/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7669 - acc: 0.8155 - val_loss: 0.7913 - val_acc: 0.8221\n",
      "Epoch 4627/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7844 - acc: 0.8197 - val_loss: 0.7912 - val_acc: 0.8275\n",
      "Epoch 4628/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7878 - acc: 0.8191 - val_loss: 0.7866 - val_acc: 0.8248\n",
      "Epoch 4629/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7799 - acc: 0.8149 - val_loss: 0.7887 - val_acc: 0.8275\n",
      "Epoch 4630/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7909 - acc: 0.8182 - val_loss: 0.7953 - val_acc: 0.8221\n",
      "Epoch 4631/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7799 - acc: 0.8128 - val_loss: 0.7919 - val_acc: 0.8275\n",
      "Epoch 4632/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7708 - acc: 0.8206 - val_loss: 0.7904 - val_acc: 0.8275\n",
      "Epoch 4633/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7861 - acc: 0.8173 - val_loss: 0.7931 - val_acc: 0.8194\n",
      "Epoch 4634/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7783 - acc: 0.8218 - val_loss: 0.7988 - val_acc: 0.8194\n",
      "Epoch 4635/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7864 - acc: 0.8194 - val_loss: 0.7993 - val_acc: 0.8275\n",
      "Epoch 4636/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7713 - acc: 0.8149 - val_loss: 0.7917 - val_acc: 0.8302\n",
      "Epoch 4637/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7800 - acc: 0.8170 - val_loss: 0.7853 - val_acc: 0.8302\n",
      "Epoch 4638/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7789 - acc: 0.8179 - val_loss: 0.7811 - val_acc: 0.8302\n",
      "Epoch 4639/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7883 - acc: 0.8152 - val_loss: 0.7790 - val_acc: 0.8302\n",
      "Epoch 4640/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7651 - acc: 0.8143 - val_loss: 0.7794 - val_acc: 0.8356\n",
      "Epoch 4641/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7849 - acc: 0.8200 - val_loss: 0.7820 - val_acc: 0.8302\n",
      "Epoch 4642/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8146 - val_loss: 0.7887 - val_acc: 0.8248\n",
      "Epoch 4643/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7740 - acc: 0.8242 - val_loss: 0.7942 - val_acc: 0.8248\n",
      "Epoch 4644/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7776 - acc: 0.8161 - val_loss: 0.7925 - val_acc: 0.8275\n",
      "Epoch 4645/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7786 - acc: 0.8179 - val_loss: 0.7902 - val_acc: 0.8221\n",
      "Epoch 4646/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8149 - val_loss: 0.7896 - val_acc: 0.8248\n",
      "Epoch 4647/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7948 - acc: 0.8125 - val_loss: 0.7866 - val_acc: 0.8221\n",
      "Epoch 4648/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7827 - acc: 0.8191 - val_loss: 0.7777 - val_acc: 0.8329\n",
      "Epoch 4649/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7883 - acc: 0.8140 - val_loss: 0.7733 - val_acc: 0.8383\n",
      "Epoch 4650/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7758 - acc: 0.8164 - val_loss: 0.7774 - val_acc: 0.8275\n",
      "Epoch 4651/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8137 - val_loss: 0.7831 - val_acc: 0.8302\n",
      "Epoch 4652/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7724 - acc: 0.8185 - val_loss: 0.7902 - val_acc: 0.8221\n",
      "Epoch 4653/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7760 - acc: 0.8200 - val_loss: 0.7921 - val_acc: 0.8221\n",
      "Epoch 4654/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7881 - acc: 0.8218 - val_loss: 0.7811 - val_acc: 0.8302\n",
      "Epoch 4655/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7858 - acc: 0.8140 - val_loss: 0.7778 - val_acc: 0.8248\n",
      "Epoch 4656/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7786 - acc: 0.8122 - val_loss: 0.7756 - val_acc: 0.8275\n",
      "Epoch 4657/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7915 - acc: 0.8158 - val_loss: 0.7736 - val_acc: 0.8302\n",
      "Epoch 4658/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7976 - acc: 0.8182 - val_loss: 0.7761 - val_acc: 0.8275\n",
      "Epoch 4659/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8116 - val_loss: 0.7817 - val_acc: 0.8248\n",
      "Epoch 4660/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7842 - acc: 0.8137 - val_loss: 0.7892 - val_acc: 0.8221\n",
      "Epoch 4661/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7989 - acc: 0.8137 - val_loss: 0.7903 - val_acc: 0.8248\n",
      "Epoch 4662/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7982 - acc: 0.8155 - val_loss: 0.7860 - val_acc: 0.8194\n",
      "Epoch 4663/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7986 - acc: 0.8176 - val_loss: 0.7844 - val_acc: 0.8194\n",
      "Epoch 4664/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7958 - acc: 0.8053 - val_loss: 0.7851 - val_acc: 0.8248\n",
      "Epoch 4665/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7968 - acc: 0.8164 - val_loss: 0.7870 - val_acc: 0.8302\n",
      "Epoch 4666/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7940 - acc: 0.8170 - val_loss: 0.7907 - val_acc: 0.8221\n",
      "Epoch 4667/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8129 - acc: 0.8095 - val_loss: 0.7948 - val_acc: 0.8221\n",
      "Epoch 4668/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7818 - acc: 0.8173 - val_loss: 0.7896 - val_acc: 0.8221\n",
      "Epoch 4669/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7906 - acc: 0.8146 - val_loss: 0.7899 - val_acc: 0.8275\n",
      "Epoch 4670/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7754 - acc: 0.8173 - val_loss: 0.7892 - val_acc: 0.8248\n",
      "Epoch 4671/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7594 - acc: 0.8197 - val_loss: 0.7876 - val_acc: 0.8248\n",
      "Epoch 4672/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7967 - acc: 0.8155 - val_loss: 0.7940 - val_acc: 0.8221\n",
      "Epoch 4673/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.7733 - acc: 0.8152 - val_loss: 0.7985 - val_acc: 0.8221\n",
      "Epoch 4674/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7752 - acc: 0.8203 - val_loss: 0.7912 - val_acc: 0.8221\n",
      "Epoch 4675/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7899 - acc: 0.8173 - val_loss: 0.7817 - val_acc: 0.8248\n",
      "Epoch 4676/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7890 - acc: 0.8137 - val_loss: 0.7875 - val_acc: 0.8194\n",
      "Epoch 4677/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8131 - val_loss: 0.7925 - val_acc: 0.8275\n",
      "Epoch 4678/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7900 - acc: 0.8185 - val_loss: 0.7892 - val_acc: 0.8248\n",
      "Epoch 4679/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7902 - acc: 0.8227 - val_loss: 0.7883 - val_acc: 0.8248\n",
      "Epoch 4680/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8114 - acc: 0.8146 - val_loss: 0.7847 - val_acc: 0.8275\n",
      "Epoch 4681/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7743 - acc: 0.8146 - val_loss: 0.7805 - val_acc: 0.8302\n",
      "Epoch 4682/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8019 - acc: 0.8143 - val_loss: 0.7718 - val_acc: 0.8329\n",
      "Epoch 4683/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7801 - acc: 0.8131 - val_loss: 0.7719 - val_acc: 0.8329\n",
      "Epoch 4684/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7931 - acc: 0.8164 - val_loss: 0.7764 - val_acc: 0.8329\n",
      "Epoch 4685/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7738 - acc: 0.8173 - val_loss: 0.7800 - val_acc: 0.8329\n",
      "Epoch 4686/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7799 - acc: 0.8191 - val_loss: 0.7851 - val_acc: 0.8275\n",
      "Epoch 4687/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7898 - acc: 0.8107 - val_loss: 0.7888 - val_acc: 0.8248\n",
      "Epoch 4688/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7817 - acc: 0.8191 - val_loss: 0.7941 - val_acc: 0.8194\n",
      "Epoch 4689/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7751 - acc: 0.8146 - val_loss: 0.7981 - val_acc: 0.8194\n",
      "Epoch 4690/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8008 - acc: 0.8137 - val_loss: 0.7940 - val_acc: 0.8194\n",
      "Epoch 4691/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7865 - acc: 0.8134 - val_loss: 0.7873 - val_acc: 0.8248\n",
      "Epoch 4692/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7694 - acc: 0.8179 - val_loss: 0.7857 - val_acc: 0.8329\n",
      "Epoch 4693/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7796 - acc: 0.8161 - val_loss: 0.7904 - val_acc: 0.8329\n",
      "Epoch 4694/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7912 - acc: 0.8203 - val_loss: 0.7926 - val_acc: 0.8329\n",
      "Epoch 4695/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7818 - acc: 0.8131 - val_loss: 0.7933 - val_acc: 0.8275\n",
      "Epoch 4696/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8010 - acc: 0.8095 - val_loss: 0.7973 - val_acc: 0.8221\n",
      "Epoch 4697/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7745 - acc: 0.8152 - val_loss: 0.7882 - val_acc: 0.8248\n",
      "Epoch 4698/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7856 - acc: 0.8143 - val_loss: 0.7806 - val_acc: 0.8329\n",
      "Epoch 4699/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7745 - acc: 0.8158 - val_loss: 0.7794 - val_acc: 0.8275\n",
      "Epoch 4700/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7779 - acc: 0.8200 - val_loss: 0.7857 - val_acc: 0.8275\n",
      "Epoch 4701/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7683 - acc: 0.8155 - val_loss: 0.7902 - val_acc: 0.8167\n",
      "Epoch 4702/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7781 - acc: 0.8176 - val_loss: 0.7957 - val_acc: 0.8275\n",
      "Epoch 4703/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7816 - acc: 0.8173 - val_loss: 0.7965 - val_acc: 0.8221\n",
      "Epoch 4704/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7900 - acc: 0.8149 - val_loss: 0.7908 - val_acc: 0.8221\n",
      "Epoch 4705/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7808 - acc: 0.8155 - val_loss: 0.7874 - val_acc: 0.8221\n",
      "Epoch 4706/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7962 - acc: 0.8176 - val_loss: 0.7818 - val_acc: 0.8167\n",
      "Epoch 4707/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7858 - acc: 0.8119 - val_loss: 0.7760 - val_acc: 0.8275\n",
      "Epoch 4708/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7673 - acc: 0.8188 - val_loss: 0.7726 - val_acc: 0.8221\n",
      "Epoch 4709/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7907 - acc: 0.8116 - val_loss: 0.7782 - val_acc: 0.8248\n",
      "Epoch 4710/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7925 - acc: 0.8164 - val_loss: 0.7805 - val_acc: 0.8248\n",
      "Epoch 4711/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7837 - acc: 0.8170 - val_loss: 0.7831 - val_acc: 0.8275\n",
      "Epoch 4712/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7719 - acc: 0.8140 - val_loss: 0.7822 - val_acc: 0.8383\n",
      "Epoch 4713/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7921 - acc: 0.8146 - val_loss: 0.7881 - val_acc: 0.8329\n",
      "Epoch 4714/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7677 - acc: 0.8164 - val_loss: 0.7936 - val_acc: 0.8302\n",
      "Epoch 4715/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7970 - acc: 0.8125 - val_loss: 0.7910 - val_acc: 0.8302\n",
      "Epoch 4716/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7817 - acc: 0.8167 - val_loss: 0.7843 - val_acc: 0.8302\n",
      "Epoch 4717/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7773 - acc: 0.8185 - val_loss: 0.7796 - val_acc: 0.8302\n",
      "Epoch 4718/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7872 - acc: 0.8155 - val_loss: 0.7789 - val_acc: 0.8248\n",
      "Epoch 4719/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7806 - acc: 0.8143 - val_loss: 0.7841 - val_acc: 0.8275\n",
      "Epoch 4720/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7642 - acc: 0.8146 - val_loss: 0.7875 - val_acc: 0.8194\n",
      "Epoch 4721/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8042 - acc: 0.8128 - val_loss: 0.7797 - val_acc: 0.8194\n",
      "Epoch 4722/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7900 - acc: 0.8191 - val_loss: 0.7769 - val_acc: 0.8248\n",
      "Epoch 4723/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7798 - acc: 0.8164 - val_loss: 0.7802 - val_acc: 0.8248\n",
      "Epoch 4724/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8143 - val_loss: 0.7811 - val_acc: 0.8275\n",
      "Epoch 4725/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7887 - acc: 0.8179 - val_loss: 0.7819 - val_acc: 0.8302\n",
      "Epoch 4726/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8158 - val_loss: 0.7819 - val_acc: 0.8248\n",
      "Epoch 4727/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7734 - acc: 0.8170 - val_loss: 0.7832 - val_acc: 0.8275\n",
      "Epoch 4728/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7787 - acc: 0.8173 - val_loss: 0.7900 - val_acc: 0.8221\n",
      "Epoch 4729/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7818 - acc: 0.8242 - val_loss: 0.7864 - val_acc: 0.8221\n",
      "Epoch 4730/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7881 - acc: 0.8098 - val_loss: 0.7799 - val_acc: 0.8275\n",
      "Epoch 4731/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7942 - acc: 0.8146 - val_loss: 0.7799 - val_acc: 0.8302\n",
      "Epoch 4732/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7765 - acc: 0.8146 - val_loss: 0.7781 - val_acc: 0.8302\n",
      "Epoch 4733/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7750 - acc: 0.8119 - val_loss: 0.7778 - val_acc: 0.8275\n",
      "Epoch 4734/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7623 - acc: 0.8188 - val_loss: 0.7773 - val_acc: 0.8167\n",
      "Epoch 4735/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7930 - acc: 0.8107 - val_loss: 0.7726 - val_acc: 0.8248\n",
      "Epoch 4736/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7677 - acc: 0.8194 - val_loss: 0.7768 - val_acc: 0.8248\n",
      "Epoch 4737/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7835 - acc: 0.8200 - val_loss: 0.7793 - val_acc: 0.8248\n",
      "Epoch 4738/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8203 - val_loss: 0.7822 - val_acc: 0.8221\n",
      "Epoch 4739/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7774 - acc: 0.8134 - val_loss: 0.7851 - val_acc: 0.8275\n",
      "Epoch 4740/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7989 - acc: 0.8155 - val_loss: 0.7819 - val_acc: 0.8329\n",
      "Epoch 4741/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8149 - val_loss: 0.7869 - val_acc: 0.8329\n",
      "Epoch 4742/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7970 - acc: 0.8107 - val_loss: 0.7910 - val_acc: 0.8302\n",
      "Epoch 4743/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7676 - acc: 0.8140 - val_loss: 0.7895 - val_acc: 0.8275\n",
      "Epoch 4744/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7965 - acc: 0.8119 - val_loss: 0.7846 - val_acc: 0.8275\n",
      "Epoch 4745/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7699 - acc: 0.8146 - val_loss: 0.7828 - val_acc: 0.8329\n",
      "Epoch 4746/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7780 - acc: 0.8107 - val_loss: 0.7866 - val_acc: 0.8302\n",
      "Epoch 4747/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7920 - acc: 0.8161 - val_loss: 0.7889 - val_acc: 0.8275\n",
      "Epoch 4748/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7862 - acc: 0.8122 - val_loss: 0.7919 - val_acc: 0.8329\n",
      "Epoch 4749/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7693 - acc: 0.8203 - val_loss: 0.7919 - val_acc: 0.8356\n",
      "Epoch 4750/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7840 - acc: 0.8194 - val_loss: 0.7876 - val_acc: 0.8329\n",
      "Epoch 4751/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7922 - acc: 0.8122 - val_loss: 0.7880 - val_acc: 0.8248\n",
      "Epoch 4752/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8062 - val_loss: 0.7809 - val_acc: 0.8356\n",
      "Epoch 4753/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7959 - acc: 0.8104 - val_loss: 0.7800 - val_acc: 0.8356\n",
      "Epoch 4754/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7976 - acc: 0.8158 - val_loss: 0.7834 - val_acc: 0.8329\n",
      "Epoch 4755/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7731 - acc: 0.8146 - val_loss: 0.7943 - val_acc: 0.8221\n",
      "Epoch 4756/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8021 - acc: 0.8125 - val_loss: 0.7894 - val_acc: 0.8302\n",
      "Epoch 4757/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7808 - acc: 0.8140 - val_loss: 0.7793 - val_acc: 0.8302\n",
      "Epoch 4758/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7784 - acc: 0.8152 - val_loss: 0.7887 - val_acc: 0.8302\n",
      "Epoch 4759/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7720 - acc: 0.8188 - val_loss: 0.7927 - val_acc: 0.8248\n",
      "Epoch 4760/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7933 - acc: 0.8152 - val_loss: 0.7933 - val_acc: 0.8221\n",
      "Epoch 4761/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8167 - val_loss: 0.7874 - val_acc: 0.8275\n",
      "Epoch 4762/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7917 - acc: 0.8068 - val_loss: 0.7828 - val_acc: 0.8464\n",
      "Epoch 4763/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8179 - val_loss: 0.7872 - val_acc: 0.8356\n",
      "Epoch 4764/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7812 - acc: 0.8221 - val_loss: 0.7951 - val_acc: 0.8275\n",
      "Epoch 4765/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7894 - acc: 0.8140 - val_loss: 0.8016 - val_acc: 0.8248\n",
      "Epoch 4766/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7970 - acc: 0.8161 - val_loss: 0.8052 - val_acc: 0.8248\n",
      "Epoch 4767/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7880 - acc: 0.8134 - val_loss: 0.8062 - val_acc: 0.8248\n",
      "Epoch 4768/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7767 - acc: 0.8212 - val_loss: 0.8026 - val_acc: 0.8248\n",
      "Epoch 4769/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8002 - acc: 0.8116 - val_loss: 0.7962 - val_acc: 0.8248\n",
      "Epoch 4770/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7813 - acc: 0.8125 - val_loss: 0.7937 - val_acc: 0.8248\n",
      "Epoch 4771/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7866 - acc: 0.8179 - val_loss: 0.7975 - val_acc: 0.8302\n",
      "Epoch 4772/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7895 - acc: 0.8080 - val_loss: 0.7986 - val_acc: 0.8221\n",
      "Epoch 4773/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8016 - acc: 0.8125 - val_loss: 0.7980 - val_acc: 0.8221\n",
      "Epoch 4774/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8062 - acc: 0.8080 - val_loss: 0.8021 - val_acc: 0.8248\n",
      "Epoch 4775/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7991 - acc: 0.8161 - val_loss: 0.7991 - val_acc: 0.8302\n",
      "Epoch 4776/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7876 - acc: 0.8188 - val_loss: 0.7965 - val_acc: 0.8302\n",
      "Epoch 4777/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7777 - acc: 0.8185 - val_loss: 0.8071 - val_acc: 0.8248\n",
      "Epoch 4778/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7871 - acc: 0.8167 - val_loss: 0.8121 - val_acc: 0.8248\n",
      "Epoch 4779/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7850 - acc: 0.8161 - val_loss: 0.8029 - val_acc: 0.8329\n",
      "Epoch 4780/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7796 - acc: 0.8185 - val_loss: 0.8004 - val_acc: 0.8275\n",
      "Epoch 4781/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7978 - acc: 0.8149 - val_loss: 0.8006 - val_acc: 0.8302\n",
      "Epoch 4782/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8158 - val_loss: 0.8009 - val_acc: 0.8248\n",
      "Epoch 4783/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7893 - acc: 0.8227 - val_loss: 0.7990 - val_acc: 0.8167\n",
      "Epoch 4784/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7774 - acc: 0.8149 - val_loss: 0.7971 - val_acc: 0.8248\n",
      "Epoch 4785/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7780 - acc: 0.8128 - val_loss: 0.7952 - val_acc: 0.8275\n",
      "Epoch 4786/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7821 - acc: 0.8212 - val_loss: 0.7903 - val_acc: 0.8275\n",
      "Epoch 4787/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7830 - acc: 0.8164 - val_loss: 0.7858 - val_acc: 0.8275\n",
      "Epoch 4788/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7790 - acc: 0.8158 - val_loss: 0.7864 - val_acc: 0.8302\n",
      "Epoch 4789/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8111 - acc: 0.8119 - val_loss: 0.7922 - val_acc: 0.8248\n",
      "Epoch 4790/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7955 - acc: 0.8110 - val_loss: 0.7913 - val_acc: 0.8248\n",
      "Epoch 4791/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7972 - acc: 0.8134 - val_loss: 0.7896 - val_acc: 0.8275\n",
      "Epoch 4792/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7755 - acc: 0.8176 - val_loss: 0.7880 - val_acc: 0.8275\n",
      "Epoch 4793/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8044 - acc: 0.8119 - val_loss: 0.7908 - val_acc: 0.8221\n",
      "Epoch 4794/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7945 - acc: 0.8176 - val_loss: 0.7932 - val_acc: 0.8167\n",
      "Epoch 4795/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7834 - acc: 0.8200 - val_loss: 0.7876 - val_acc: 0.8275\n",
      "Epoch 4796/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7833 - acc: 0.8098 - val_loss: 0.7889 - val_acc: 0.8329\n",
      "Epoch 4797/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7794 - acc: 0.8206 - val_loss: 0.7981 - val_acc: 0.8302\n",
      "Epoch 4798/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7796 - acc: 0.8182 - val_loss: 0.7994 - val_acc: 0.8302\n",
      "Epoch 4799/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7754 - acc: 0.8182 - val_loss: 0.8056 - val_acc: 0.8194\n",
      "Epoch 4800/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7865 - acc: 0.8152 - val_loss: 0.8023 - val_acc: 0.8221\n",
      "Epoch 4801/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8022 - acc: 0.8161 - val_loss: 0.7969 - val_acc: 0.8275\n",
      "Epoch 4802/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.8069 - acc: 0.8155 - val_loss: 0.7911 - val_acc: 0.8275\n",
      "Epoch 4803/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7795 - acc: 0.8092 - val_loss: 0.7868 - val_acc: 0.8329\n",
      "Epoch 4804/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7966 - acc: 0.8182 - val_loss: 0.7884 - val_acc: 0.8275\n",
      "Epoch 4805/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7961 - acc: 0.8122 - val_loss: 0.7940 - val_acc: 0.8302\n",
      "Epoch 4806/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7916 - acc: 0.8173 - val_loss: 0.7886 - val_acc: 0.8356\n",
      "Epoch 4807/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8104 - val_loss: 0.7841 - val_acc: 0.8221\n",
      "Epoch 4808/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7914 - acc: 0.8206 - val_loss: 0.7866 - val_acc: 0.8221\n",
      "Epoch 4809/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7734 - acc: 0.8140 - val_loss: 0.7826 - val_acc: 0.8194\n",
      "Epoch 4810/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7793 - acc: 0.8227 - val_loss: 0.7724 - val_acc: 0.8221\n",
      "Epoch 4811/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7861 - acc: 0.8077 - val_loss: 0.7677 - val_acc: 0.8329\n",
      "Epoch 4812/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7763 - acc: 0.8194 - val_loss: 0.7715 - val_acc: 0.8248\n",
      "Epoch 4813/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7867 - acc: 0.8113 - val_loss: 0.7742 - val_acc: 0.8248\n",
      "Epoch 4814/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7965 - acc: 0.8131 - val_loss: 0.7740 - val_acc: 0.8275\n",
      "Epoch 4815/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8176 - val_loss: 0.7756 - val_acc: 0.8275\n",
      "Epoch 4816/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7662 - acc: 0.8158 - val_loss: 0.7812 - val_acc: 0.8275\n",
      "Epoch 4817/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7776 - acc: 0.8113 - val_loss: 0.7864 - val_acc: 0.8248\n",
      "Epoch 4818/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7893 - acc: 0.8149 - val_loss: 0.7841 - val_acc: 0.8275\n",
      "Epoch 4819/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7809 - acc: 0.8200 - val_loss: 0.7905 - val_acc: 0.8221\n",
      "Epoch 4820/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7884 - acc: 0.8077 - val_loss: 0.7974 - val_acc: 0.8248\n",
      "Epoch 4821/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7815 - acc: 0.8158 - val_loss: 0.7847 - val_acc: 0.8302\n",
      "Epoch 4822/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8048 - acc: 0.8098 - val_loss: 0.7798 - val_acc: 0.8221\n",
      "Epoch 4823/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7918 - acc: 0.8176 - val_loss: 0.7824 - val_acc: 0.8248\n",
      "Epoch 4824/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8012 - acc: 0.8164 - val_loss: 0.7926 - val_acc: 0.8194\n",
      "Epoch 4825/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8013 - acc: 0.8074 - val_loss: 0.7949 - val_acc: 0.8194\n",
      "Epoch 4826/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7889 - acc: 0.8203 - val_loss: 0.7881 - val_acc: 0.8248\n",
      "Epoch 4827/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8140 - val_loss: 0.7899 - val_acc: 0.8329\n",
      "Epoch 4828/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7986 - acc: 0.8095 - val_loss: 0.8009 - val_acc: 0.8248\n",
      "Epoch 4829/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7908 - acc: 0.8155 - val_loss: 0.8076 - val_acc: 0.8221\n",
      "Epoch 4830/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8153 - acc: 0.8134 - val_loss: 0.8038 - val_acc: 0.8275\n",
      "Epoch 4831/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7848 - acc: 0.8143 - val_loss: 0.7953 - val_acc: 0.8275\n",
      "Epoch 4832/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7688 - acc: 0.8173 - val_loss: 0.7857 - val_acc: 0.8275\n",
      "Epoch 4833/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8134 - val_loss: 0.7761 - val_acc: 0.8248\n",
      "Epoch 4834/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7738 - acc: 0.8218 - val_loss: 0.7775 - val_acc: 0.8221\n",
      "Epoch 4835/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7782 - acc: 0.8182 - val_loss: 0.7800 - val_acc: 0.8221\n",
      "Epoch 4836/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7845 - acc: 0.8104 - val_loss: 0.7879 - val_acc: 0.8221\n",
      "Epoch 4837/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8069 - acc: 0.8155 - val_loss: 0.7900 - val_acc: 0.8248\n",
      "Epoch 4838/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7976 - acc: 0.8152 - val_loss: 0.7816 - val_acc: 0.8275\n",
      "Epoch 4839/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8110 - val_loss: 0.7779 - val_acc: 0.8302\n",
      "Epoch 4840/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7763 - acc: 0.8134 - val_loss: 0.7826 - val_acc: 0.8302\n",
      "Epoch 4841/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7882 - acc: 0.8197 - val_loss: 0.7854 - val_acc: 0.8302\n",
      "Epoch 4842/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7692 - acc: 0.8227 - val_loss: 0.7829 - val_acc: 0.8302\n",
      "Epoch 4843/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7849 - acc: 0.8155 - val_loss: 0.7796 - val_acc: 0.8275\n",
      "Epoch 4844/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.8131 - val_loss: 0.7721 - val_acc: 0.8356\n",
      "Epoch 4845/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7815 - acc: 0.8233 - val_loss: 0.7724 - val_acc: 0.8302\n",
      "Epoch 4846/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7876 - acc: 0.8203 - val_loss: 0.7746 - val_acc: 0.8248\n",
      "Epoch 4847/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7849 - acc: 0.8197 - val_loss: 0.7797 - val_acc: 0.8302\n",
      "Epoch 4848/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7896 - acc: 0.8158 - val_loss: 0.7853 - val_acc: 0.8302\n",
      "Epoch 4849/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7749 - acc: 0.8134 - val_loss: 0.7817 - val_acc: 0.8302\n",
      "Epoch 4850/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7759 - acc: 0.8125 - val_loss: 0.7814 - val_acc: 0.8275\n",
      "Epoch 4851/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7731 - acc: 0.8158 - val_loss: 0.7783 - val_acc: 0.8275\n",
      "Epoch 4852/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7834 - acc: 0.8113 - val_loss: 0.7810 - val_acc: 0.8275\n",
      "Epoch 4853/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7880 - acc: 0.8116 - val_loss: 0.7904 - val_acc: 0.8194\n",
      "Epoch 4854/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7964 - acc: 0.8095 - val_loss: 0.7964 - val_acc: 0.8221\n",
      "Epoch 4855/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8036 - acc: 0.8026 - val_loss: 0.7821 - val_acc: 0.8248\n",
      "Epoch 4856/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8188 - val_loss: 0.7750 - val_acc: 0.8248\n",
      "Epoch 4857/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7813 - acc: 0.8071 - val_loss: 0.7786 - val_acc: 0.8248\n",
      "Epoch 4858/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7768 - acc: 0.8143 - val_loss: 0.7846 - val_acc: 0.8275\n",
      "Epoch 4859/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7832 - acc: 0.8116 - val_loss: 0.7802 - val_acc: 0.8302\n",
      "Epoch 4860/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7863 - acc: 0.8122 - val_loss: 0.7714 - val_acc: 0.8275\n",
      "Epoch 4861/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8145 - acc: 0.8089 - val_loss: 0.7683 - val_acc: 0.8248\n",
      "Epoch 4862/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7807 - acc: 0.8194 - val_loss: 0.7728 - val_acc: 0.8275\n",
      "Epoch 4863/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7981 - acc: 0.8152 - val_loss: 0.7765 - val_acc: 0.8248\n",
      "Epoch 4864/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8140 - acc: 0.8182 - val_loss: 0.7759 - val_acc: 0.8275\n",
      "Epoch 4865/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7953 - acc: 0.8149 - val_loss: 0.7735 - val_acc: 0.8302\n",
      "Epoch 4866/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8197 - val_loss: 0.7709 - val_acc: 0.8329\n",
      "Epoch 4867/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7850 - acc: 0.8197 - val_loss: 0.7710 - val_acc: 0.8302\n",
      "Epoch 4868/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7965 - acc: 0.8110 - val_loss: 0.7741 - val_acc: 0.8302\n",
      "Epoch 4869/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7805 - acc: 0.8152 - val_loss: 0.7750 - val_acc: 0.8302\n",
      "Epoch 4870/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7934 - acc: 0.8146 - val_loss: 0.7812 - val_acc: 0.8275\n",
      "Epoch 4871/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8167 - val_loss: 0.7860 - val_acc: 0.8221\n",
      "Epoch 4872/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7690 - acc: 0.8104 - val_loss: 0.7829 - val_acc: 0.8275\n",
      "Epoch 4873/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7688 - acc: 0.8167 - val_loss: 0.7796 - val_acc: 0.8221\n",
      "Epoch 4874/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7618 - acc: 0.8167 - val_loss: 0.7805 - val_acc: 0.8248\n",
      "Epoch 4875/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7796 - acc: 0.8152 - val_loss: 0.7806 - val_acc: 0.8248\n",
      "Epoch 4876/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7678 - acc: 0.8182 - val_loss: 0.7853 - val_acc: 0.8275\n",
      "Epoch 4877/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8101 - val_loss: 0.7903 - val_acc: 0.8302\n",
      "Epoch 4878/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7732 - acc: 0.8194 - val_loss: 0.7945 - val_acc: 0.8302\n",
      "Epoch 4879/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7888 - acc: 0.8155 - val_loss: 0.7912 - val_acc: 0.8356\n",
      "Epoch 4880/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7844 - acc: 0.8218 - val_loss: 0.7952 - val_acc: 0.8248\n",
      "Epoch 4881/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7729 - acc: 0.8170 - val_loss: 0.8011 - val_acc: 0.8221\n",
      "Epoch 4882/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7748 - acc: 0.8170 - val_loss: 0.7886 - val_acc: 0.8248\n",
      "Epoch 4883/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7863 - acc: 0.8176 - val_loss: 0.7682 - val_acc: 0.8383\n",
      "Epoch 4884/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7851 - acc: 0.8146 - val_loss: 0.7703 - val_acc: 0.8275\n",
      "Epoch 4885/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7985 - acc: 0.8131 - val_loss: 0.7774 - val_acc: 0.8248\n",
      "Epoch 4886/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8206 - val_loss: 0.7771 - val_acc: 0.8221\n",
      "Epoch 4887/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7913 - acc: 0.8074 - val_loss: 0.7721 - val_acc: 0.8302\n",
      "Epoch 4888/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7834 - acc: 0.8125 - val_loss: 0.7697 - val_acc: 0.8302\n",
      "Epoch 4889/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7986 - acc: 0.8116 - val_loss: 0.7740 - val_acc: 0.8302\n",
      "Epoch 4890/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7965 - acc: 0.8212 - val_loss: 0.7817 - val_acc: 0.8275\n",
      "Epoch 4891/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7871 - acc: 0.8128 - val_loss: 0.7870 - val_acc: 0.8248\n",
      "Epoch 4892/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7848 - acc: 0.8149 - val_loss: 0.7861 - val_acc: 0.8248\n",
      "Epoch 4893/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7955 - acc: 0.8122 - val_loss: 0.7802 - val_acc: 0.8275\n",
      "Epoch 4894/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7946 - acc: 0.8143 - val_loss: 0.7796 - val_acc: 0.8194\n",
      "Epoch 4895/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7889 - acc: 0.8149 - val_loss: 0.7763 - val_acc: 0.8248\n",
      "Epoch 4896/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7869 - acc: 0.8164 - val_loss: 0.7770 - val_acc: 0.8275\n",
      "Epoch 4897/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7892 - acc: 0.8128 - val_loss: 0.7891 - val_acc: 0.8221\n",
      "Epoch 4898/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7712 - acc: 0.8206 - val_loss: 0.7996 - val_acc: 0.8167\n",
      "Epoch 4899/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7742 - acc: 0.8194 - val_loss: 0.7928 - val_acc: 0.8221\n",
      "Epoch 4900/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7887 - acc: 0.8173 - val_loss: 0.7868 - val_acc: 0.8221\n",
      "Epoch 4901/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7812 - acc: 0.8185 - val_loss: 0.7839 - val_acc: 0.8302\n",
      "Epoch 4902/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7893 - acc: 0.8185 - val_loss: 0.7865 - val_acc: 0.8302\n",
      "Epoch 4903/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7726 - acc: 0.8170 - val_loss: 0.7848 - val_acc: 0.8248\n",
      "Epoch 4904/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7917 - acc: 0.8113 - val_loss: 0.7816 - val_acc: 0.8248\n",
      "Epoch 4905/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8034 - acc: 0.8131 - val_loss: 0.7770 - val_acc: 0.8275\n",
      "Epoch 4906/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7955 - acc: 0.8125 - val_loss: 0.7783 - val_acc: 0.8248\n",
      "Epoch 4907/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8047 - acc: 0.8077 - val_loss: 0.7856 - val_acc: 0.8167\n",
      "Epoch 4908/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7784 - acc: 0.8152 - val_loss: 0.7870 - val_acc: 0.8194\n",
      "Epoch 4909/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7925 - acc: 0.8194 - val_loss: 0.7904 - val_acc: 0.8248\n",
      "Epoch 4910/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7707 - acc: 0.8227 - val_loss: 0.7967 - val_acc: 0.8248\n",
      "Epoch 4911/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7935 - acc: 0.8128 - val_loss: 0.7990 - val_acc: 0.8248\n",
      "Epoch 4912/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7735 - acc: 0.8212 - val_loss: 0.7939 - val_acc: 0.8275\n",
      "Epoch 4913/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7658 - acc: 0.8188 - val_loss: 0.7946 - val_acc: 0.8221\n",
      "Epoch 4914/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7682 - acc: 0.8197 - val_loss: 0.7957 - val_acc: 0.8194\n",
      "Epoch 4915/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7960 - acc: 0.8155 - val_loss: 0.7854 - val_acc: 0.8248\n",
      "Epoch 4916/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7856 - acc: 0.8152 - val_loss: 0.7799 - val_acc: 0.8275\n",
      "Epoch 4917/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7858 - acc: 0.8158 - val_loss: 0.7822 - val_acc: 0.8275\n",
      "Epoch 4918/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7767 - acc: 0.8131 - val_loss: 0.7894 - val_acc: 0.8248\n",
      "Epoch 4919/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8122 - val_loss: 0.7887 - val_acc: 0.8248\n",
      "Epoch 4920/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7825 - acc: 0.8197 - val_loss: 0.7819 - val_acc: 0.8356\n",
      "Epoch 4921/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7846 - acc: 0.8149 - val_loss: 0.7791 - val_acc: 0.8356\n",
      "Epoch 4922/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7943 - acc: 0.8131 - val_loss: 0.7810 - val_acc: 0.8356\n",
      "Epoch 4923/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7790 - acc: 0.8161 - val_loss: 0.7874 - val_acc: 0.8302\n",
      "Epoch 4924/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7812 - acc: 0.8143 - val_loss: 0.7909 - val_acc: 0.8221\n",
      "Epoch 4925/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8170 - val_loss: 0.7852 - val_acc: 0.8248\n",
      "Epoch 4926/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7792 - acc: 0.8191 - val_loss: 0.7884 - val_acc: 0.8275\n",
      "Epoch 4927/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7676 - acc: 0.8206 - val_loss: 0.7952 - val_acc: 0.8275\n",
      "Epoch 4928/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8092 - acc: 0.8074 - val_loss: 0.7975 - val_acc: 0.8221\n",
      "Epoch 4929/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7813 - acc: 0.8149 - val_loss: 0.7872 - val_acc: 0.8221\n",
      "Epoch 4930/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7786 - acc: 0.8176 - val_loss: 0.7800 - val_acc: 0.8329\n",
      "Epoch 4931/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7806 - acc: 0.8161 - val_loss: 0.7875 - val_acc: 0.8356\n",
      "Epoch 4932/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7865 - acc: 0.8164 - val_loss: 0.7945 - val_acc: 0.8302\n",
      "Epoch 4933/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.7690 - acc: 0.8140 - val_loss: 0.7904 - val_acc: 0.8275\n",
      "Epoch 4934/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7878 - acc: 0.8149 - val_loss: 0.7880 - val_acc: 0.8248\n",
      "Epoch 4935/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7825 - acc: 0.8167 - val_loss: 0.7840 - val_acc: 0.8275\n",
      "Epoch 4936/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7795 - acc: 0.8221 - val_loss: 0.7862 - val_acc: 0.8221\n",
      "Epoch 4937/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7704 - acc: 0.8182 - val_loss: 0.7946 - val_acc: 0.8221\n",
      "Epoch 4938/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8000 - acc: 0.8134 - val_loss: 0.8018 - val_acc: 0.8194\n",
      "Epoch 4939/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7723 - acc: 0.8173 - val_loss: 0.7950 - val_acc: 0.8248\n",
      "Epoch 4940/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7763 - acc: 0.8101 - val_loss: 0.7881 - val_acc: 0.8302\n",
      "Epoch 4941/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7857 - acc: 0.8167 - val_loss: 0.7892 - val_acc: 0.8275\n",
      "Epoch 4942/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7913 - acc: 0.8194 - val_loss: 0.7897 - val_acc: 0.8194\n",
      "Epoch 4943/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7801 - acc: 0.8212 - val_loss: 0.7932 - val_acc: 0.8194\n",
      "Epoch 4944/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7785 - acc: 0.8170 - val_loss: 0.7932 - val_acc: 0.8167\n",
      "Epoch 4945/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7916 - acc: 0.8134 - val_loss: 0.8009 - val_acc: 0.8140\n",
      "Epoch 4946/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7971 - acc: 0.8137 - val_loss: 0.8030 - val_acc: 0.8221\n",
      "Epoch 4947/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7924 - acc: 0.8119 - val_loss: 0.7943 - val_acc: 0.8275\n",
      "Epoch 4948/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7820 - acc: 0.8116 - val_loss: 0.7869 - val_acc: 0.8302\n",
      "Epoch 4949/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8041 - acc: 0.8098 - val_loss: 0.7868 - val_acc: 0.8248\n",
      "Epoch 4950/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7712 - acc: 0.8194 - val_loss: 0.7910 - val_acc: 0.8248\n",
      "Epoch 4951/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7893 - acc: 0.8140 - val_loss: 0.7884 - val_acc: 0.8275\n",
      "Epoch 4952/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8119 - val_loss: 0.7862 - val_acc: 0.8221\n",
      "Epoch 4953/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7923 - acc: 0.8158 - val_loss: 0.7920 - val_acc: 0.8248\n",
      "Epoch 4954/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8014 - acc: 0.8119 - val_loss: 0.7869 - val_acc: 0.8194\n",
      "Epoch 4955/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7991 - acc: 0.8191 - val_loss: 0.7843 - val_acc: 0.8221\n",
      "Epoch 4956/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7938 - acc: 0.8161 - val_loss: 0.7871 - val_acc: 0.8221\n",
      "Epoch 4957/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7817 - acc: 0.8227 - val_loss: 0.7816 - val_acc: 0.8248\n",
      "Epoch 4958/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7793 - acc: 0.8125 - val_loss: 0.7796 - val_acc: 0.8248\n",
      "Epoch 4959/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7781 - acc: 0.8152 - val_loss: 0.7802 - val_acc: 0.8275\n",
      "Epoch 4960/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7899 - acc: 0.8104 - val_loss: 0.7882 - val_acc: 0.8248\n",
      "Epoch 4961/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7932 - acc: 0.8116 - val_loss: 0.7944 - val_acc: 0.8194\n",
      "Epoch 4962/5000\n",
      "3339/3339 [==============================] - 0s 9us/step - loss: 0.8008 - acc: 0.8131 - val_loss: 0.7931 - val_acc: 0.8302\n",
      "Epoch 4963/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7866 - acc: 0.8158 - val_loss: 0.7907 - val_acc: 0.8248\n",
      "Epoch 4964/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7789 - acc: 0.8185 - val_loss: 0.7840 - val_acc: 0.8275\n",
      "Epoch 4965/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7964 - acc: 0.8170 - val_loss: 0.7800 - val_acc: 0.8275\n",
      "Epoch 4966/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7822 - acc: 0.8164 - val_loss: 0.7879 - val_acc: 0.8275\n",
      "Epoch 4967/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7901 - acc: 0.8149 - val_loss: 0.7953 - val_acc: 0.8221\n",
      "Epoch 4968/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7640 - acc: 0.8188 - val_loss: 0.7927 - val_acc: 0.8302\n",
      "Epoch 4969/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7869 - acc: 0.8134 - val_loss: 0.7847 - val_acc: 0.8329\n",
      "Epoch 4970/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7942 - acc: 0.8119 - val_loss: 0.7784 - val_acc: 0.8329\n",
      "Epoch 4971/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7788 - acc: 0.8152 - val_loss: 0.7843 - val_acc: 0.8221\n",
      "Epoch 4972/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7751 - acc: 0.8170 - val_loss: 0.7905 - val_acc: 0.8221\n",
      "Epoch 4973/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7709 - acc: 0.8230 - val_loss: 0.7921 - val_acc: 0.8194\n",
      "Epoch 4974/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7738 - acc: 0.8167 - val_loss: 0.7945 - val_acc: 0.8221\n",
      "Epoch 4975/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7980 - acc: 0.8140 - val_loss: 0.7918 - val_acc: 0.8275\n",
      "Epoch 4976/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7843 - acc: 0.8125 - val_loss: 0.7835 - val_acc: 0.8302\n",
      "Epoch 4977/5000\n",
      "3339/3339 [==============================] - 0s 10us/step - loss: 0.7878 - acc: 0.8197 - val_loss: 0.7766 - val_acc: 0.8302\n",
      "Epoch 4978/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7776 - acc: 0.8191 - val_loss: 0.7828 - val_acc: 0.8248\n",
      "Epoch 4979/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7850 - acc: 0.8233 - val_loss: 0.7870 - val_acc: 0.8194\n",
      "Epoch 4980/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7861 - acc: 0.8155 - val_loss: 0.7848 - val_acc: 0.8248\n",
      "Epoch 4981/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7879 - acc: 0.8122 - val_loss: 0.7856 - val_acc: 0.8194\n",
      "Epoch 4982/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7826 - acc: 0.8191 - val_loss: 0.7845 - val_acc: 0.8248\n",
      "Epoch 4983/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7702 - acc: 0.8185 - val_loss: 0.7815 - val_acc: 0.8221\n",
      "Epoch 4984/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7878 - acc: 0.8182 - val_loss: 0.7934 - val_acc: 0.8221\n",
      "Epoch 4985/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7764 - acc: 0.8191 - val_loss: 0.8021 - val_acc: 0.8221\n",
      "Epoch 4986/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.8044 - acc: 0.8173 - val_loss: 0.8018 - val_acc: 0.8248\n",
      "Epoch 4987/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7885 - acc: 0.8146 - val_loss: 0.8004 - val_acc: 0.8221\n",
      "Epoch 4988/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7837 - acc: 0.8110 - val_loss: 0.7951 - val_acc: 0.8248\n",
      "Epoch 4989/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7835 - acc: 0.8122 - val_loss: 0.7897 - val_acc: 0.8302\n",
      "Epoch 4990/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7723 - acc: 0.8173 - val_loss: 0.7887 - val_acc: 0.8248\n",
      "Epoch 4991/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7875 - acc: 0.8152 - val_loss: 0.7939 - val_acc: 0.8248\n",
      "Epoch 4992/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7853 - acc: 0.8152 - val_loss: 0.7982 - val_acc: 0.8248\n",
      "Epoch 4993/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7769 - acc: 0.8185 - val_loss: 0.7919 - val_acc: 0.8248\n",
      "Epoch 4994/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7921 - acc: 0.8119 - val_loss: 0.7805 - val_acc: 0.8275\n",
      "Epoch 4995/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7924 - acc: 0.8134 - val_loss: 0.7848 - val_acc: 0.8221\n",
      "Epoch 4996/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7895 - acc: 0.8131 - val_loss: 0.7877 - val_acc: 0.8302\n",
      "Epoch 4997/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7881 - acc: 0.8170 - val_loss: 0.7926 - val_acc: 0.8275\n",
      "Epoch 4998/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7778 - acc: 0.8179 - val_loss: 0.7951 - val_acc: 0.8248\n",
      "Epoch 4999/5000\n",
      "3339/3339 [==============================] - 0s 7us/step - loss: 0.7867 - acc: 0.8128 - val_loss: 0.7938 - val_acc: 0.8248\n",
      "Epoch 5000/5000\n",
      "3339/3339 [==============================] - 0s 8us/step - loss: 0.7919 - acc: 0.8113 - val_loss: 0.7944 - val_acc: 0.8248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1ece008a90>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model.fit(X_train,one_hot_label,validation_data=(X_valid,one_hot_label_V),epochs=5000,batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39,  0, 39, 25, 40,  9, 39,  6, 20,  0,  5, 15, 10, 13, 20, 32,  4,\n",
       "       12,  2, 35, 29, 33,  4,  1,  1, 25,  7, 33, 20, 13,  7, 25,  7, 40,\n",
       "        7, 20, 28, 29,  4,  6,  0, 37, 39,  1, 15,  8,  8, 31,  6, 28,  9,\n",
       "       19, 13, 38, 17, 30,  2,  0, 39,  9,  2, 16, 32, 19, 39, 38, 40, 10,\n",
       "       20,  8, 26, 31, 39,  4,  7, 27,  6,  9, 37, 18, 14, 19, 31,  6,  4,\n",
       "       29,  9, 28,  5,  2, 25, 16, 12, 25,  4,  1, 40, 15, 32, 39, 16,  5,\n",
       "        4, 29, 39, 35, 30, 16, 16, 33, 13, 12, 39,  8, 17, 17, 19,  2,  1,\n",
       "       15, 39, 38,  4, 29, 32, 34, 12,  4, 12, 34, 39, 21, 14, 13,  6, 33,\n",
       "       19, 15, 10, 27, 30, 32, 16, 39, 14, 34, 17,  0, 11,  4,  5, 28,  1,\n",
       "       16, 38, 13, 34, 11, 18, 38, 39, 27, 24, 22, 18, 31, 39,  6,  7, 34,\n",
       "       29, 32, 15, 10, 30,  0, 26, 10, 15,  8, 15, 27,  4, 33, 34, 24, 14,\n",
       "        1, 13, 20, 16,  9,  1, 33, 38,  6, 22,  6,  6, 26, 14, 12, 20, 25,\n",
       "       39,  8, 15, 11, 12,  7, 31, 28,  1, 20, 19, 11,  6, 14, 20, 39, 15,\n",
       "       34,  4, 20, 10, 31,  1,  9,  6,  1, 16, 40, 12, 31,  0, 21,  8, 31,\n",
       "        0, 31, 19, 37, 39, 26,  6, 12,  1, 39, 27,  1, 12, 39, 34, 30,  7,\n",
       "       16, 23, 36, 39, 16, 25, 29, 40,  9, 39, 15, 35, 33,  2,  1, 31, 23,\n",
       "       35, 18, 36,  4, 12, 14,  1, 25, 25,  1,  6,  1, 17, 39,  3, 31, 33,\n",
       "        4, 25, 37, 34, 39,  6,  7, 22,  7,  1, 14, 28, 32,  3, 39,  6,  3,\n",
       "        6, 35,  5, 38,  6, 39, 34, 16, 18, 15, 24,  1, 20, 16, 15, 19,  2,\n",
       "        1,  7, 12,  4, 40, 39, 19, 11, 17, 39, 38, 10, 12,  9,  6,  7, 16,\n",
       "       39,  7, 21, 20, 26, 19,  8, 26,  5, 25, 29, 36, 22, 18,  1, 39, 29,\n",
       "       25, 25, 19, 31, 34, 21, 14, 16,  5, 40, 39,  1, 12,  9])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = model.predict(X_valid)\n",
    "ans = np.argmax(ans,axis=1)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8274932614555256"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ans == Y_valid) / len(Y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
