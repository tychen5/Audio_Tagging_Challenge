{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical ,Sequence\n",
    "from keras import losses, models, optimizers\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.activations import relu, softmax\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "from keras.layers import Activation, LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from random_eraser import get_random_eraser\n",
    "from keras.optimizers import Adam\n",
    "from os.path import join\n",
    "import resnet\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "map_dict = pk.load(open('data/map.pkl' , 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi = pd.read_csv('data/cotrain/Y_selftrain_ens_verified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_map = {}\n",
    "\n",
    "semi_name = semi['fname'].values\n",
    "semi_label_verified = semi['label_verified'].values\n",
    "\n",
    "for idx ,d in enumerate( semi_name):\n",
    "    semi_map[d] = semi_label_verified[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "unverified_df = pd.read_csv('data/train_label.csv')\n",
    "test_df = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "unverified_df = unverified_df[unverified_df['fname'].isin(semi_name)]\n",
    "unverified_df = unverified_df.drop(columns=['manually_verified'])\n",
    "unverified_df['label_verified'] = unverified_df['fname'].map(semi_map)\n",
    "\n",
    "test_df = test_df[test_df['fname'].isin(semi_name)]\n",
    "test_df['label_verified'] = test_df['fname'].map(semi_map)\n",
    "\n",
    "unverified_idx = unverified_df.index.values\n",
    "test_idx = test_df.index.values\n",
    "\n",
    "df = pd.concat([unverified_df , test_df])\n",
    "df = df.drop(columns=['label'])\n",
    "df['trans'] = df['label_verified'].map(map_dict)\n",
    "df['onehot'] = df['trans'].apply(lambda x: to_categorical(x,num_classes=41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4823, 40, 345, 1)\n",
      "(4823, 41)\n"
     ]
    }
   ],
   "source": [
    "X_unverified = np.load('data/mfcc/X_train.npy')[unverified_idx]\n",
    "X_test = np.load('data/X_test.npy')[test_idx]\n",
    "\n",
    "X_semi = np.append(X_unverified,X_test , axis=0)\n",
    "Y_semi = np.array(df['onehot'].tolist()).reshape(-1,41)\n",
    "\n",
    "print(X_semi.shape)\n",
    "print(Y_semi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # data generator ====================================================================================\n",
    "class MixupGenerator():\n",
    "    def __init__(self, X_train, y_train, batch_size=32, alpha=0.2, shuffle=True, datagen=None):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.shuffle = shuffle\n",
    "        self.sample_num = len(X_train)\n",
    "        self.datagen = datagen\n",
    "\n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            indexes = self.__get_exploration_order()\n",
    "            itr_num = int(len(indexes) // (self.batch_size * 2))\n",
    "\n",
    "            for i in range(itr_num):\n",
    "                batch_ids = indexes[i * self.batch_size * 2:(i + 1) * self.batch_size * 2]\n",
    "                X, y = self.__data_generation(batch_ids)\n",
    "\n",
    "                yield X, y\n",
    "\n",
    "    def __get_exploration_order(self):\n",
    "        indexes = np.arange(self.sample_num)\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(indexes)\n",
    "\n",
    "        return indexes\n",
    "\n",
    "    def __data_generation(self, batch_ids):\n",
    "        _, h, w, c = self.X_train.shape\n",
    "        l = np.random.beta(self.alpha, self.alpha, self.batch_size)\n",
    "        X_l = l.reshape(self.batch_size, 1, 1, 1)\n",
    "        y_l = l.reshape(self.batch_size, 1)\n",
    "\n",
    "        X1 = self.X_train[batch_ids[:self.batch_size]]\n",
    "        X2 = self.X_train[batch_ids[self.batch_size:]]\n",
    "        X = X1 * X_l + X2 * (1 - X_l)\n",
    "\n",
    "        if self.datagen:\n",
    "            for i in range(self.batch_size):\n",
    "                X[i] = self.datagen.random_transform(X[i])\n",
    "                X[i] = self.datagen.standardize(X[i])\n",
    "\n",
    "        if isinstance(self.y_train, list):\n",
    "            y = []\n",
    "\n",
    "            for y_train_ in self.y_train:\n",
    "                y1 = y_train_[batch_ids[:self.batch_size]]\n",
    "                y2 = y_train_[batch_ids[self.batch_size:]]\n",
    "                y.append(y1 * y_l + y2 * (1 - y_l))\n",
    "        else:\n",
    "            y1 = self.y_train[batch_ids[:self.batch_size]]\n",
    "            y2 = self.y_train[batch_ids[self.batch_size:]]\n",
    "            y = y1 * y_l + y2 * (1 - y_l)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Semi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8162, 40, 345, 1)\n",
      "(8162, 41)\n",
      "(371, 40, 345, 1)\n",
      "(371, 41)\n",
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/Desktop/venv/lib/python3.5/site-packages/keras/preprocessing/image.py:506: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn'tbeen fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/63 [============================>.] - ETA: 0s - loss: 1.1907 - acc: 0.8577Epoch 00000: val_acc improved from -inf to 0.86523, saving model to model_full_resnet2_refine_co/semi_self_1_0.86523.h5\n",
      "63/63 [==============================] - 26s - loss: 1.1897 - acc: 0.8578 - val_loss: 0.7869 - val_acc: 0.8652\n",
      "Epoch 2/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1719 - acc: 0.8556Epoch 00001: val_acc improved from 0.86523 to 0.87332, saving model to model_full_resnet2_refine_co/semi_self_1_0.87332.h5\n",
      "63/63 [==============================] - 19s - loss: 1.1716 - acc: 0.8559 - val_loss: 0.7611 - val_acc: 0.8733\n",
      "Epoch 3/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1474 - acc: 0.8625Epoch 00002: val_acc improved from 0.87332 to 0.88140, saving model to model_full_resnet2_refine_co/semi_self_1_0.88140.h5\n",
      "63/63 [==============================] - 19s - loss: 1.1473 - acc: 0.8621 - val_loss: 0.7559 - val_acc: 0.8814\n",
      "Epoch 4/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1394 - acc: 0.8667Epoch 00003: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1389 - acc: 0.8673 - val_loss: 0.7714 - val_acc: 0.8787\n",
      "Epoch 5/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1381 - acc: 0.8708Epoch 00004: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.1378 - acc: 0.8709 - val_loss: 0.8263 - val_acc: 0.8760\n",
      "Epoch 6/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1345 - acc: 0.8687Epoch 00005: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.1355 - acc: 0.8686 - val_loss: 0.8560 - val_acc: 0.8571\n",
      "Epoch 7/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1378 - acc: 0.8701Epoch 00006: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1378 - acc: 0.8704 - val_loss: 0.8416 - val_acc: 0.8652\n",
      "Epoch 8/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1215 - acc: 0.8749Epoch 00007: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1221 - acc: 0.8748 - val_loss: 0.8100 - val_acc: 0.8814\n",
      "Epoch 9/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1345 - acc: 0.8715Epoch 00008: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1339 - acc: 0.8717 - val_loss: 0.8316 - val_acc: 0.8706\n",
      "Epoch 10/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1254 - acc: 0.8705Epoch 00009: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1264 - acc: 0.8695 - val_loss: 0.7772 - val_acc: 0.8679\n",
      "Epoch 11/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1179 - acc: 0.8725Epoch 00010: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1177 - acc: 0.8733 - val_loss: 0.7862 - val_acc: 0.8625\n",
      "Epoch 12/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1258 - acc: 0.8677Epoch 00011: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1261 - acc: 0.8673 - val_loss: 0.7613 - val_acc: 0.8760\n",
      "Epoch 13/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1356 - acc: 0.8671Epoch 00012: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1351 - acc: 0.8668 - val_loss: 0.8369 - val_acc: 0.8652\n",
      "Epoch 14/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1383 - acc: 0.8720Epoch 00013: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1385 - acc: 0.8717 - val_loss: 0.7889 - val_acc: 0.8760\n",
      "Epoch 15/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1266 - acc: 0.8711Epoch 00014: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1258 - acc: 0.8718 - val_loss: 0.8241 - val_acc: 0.8410\n",
      "Epoch 16/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1185 - acc: 0.8729Epoch 00015: val_acc improved from 0.88140 to 0.88410, saving model to model_full_resnet2_refine_co/semi_self_1_0.88410.h5\n",
      "63/63 [==============================] - 20s - loss: 1.1168 - acc: 0.8729 - val_loss: 0.7540 - val_acc: 0.8841\n",
      "Epoch 17/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1211 - acc: 0.8711Epoch 00016: val_acc improved from 0.88410 to 0.88679, saving model to model_full_resnet2_refine_co/semi_self_1_0.88679.h5\n",
      "63/63 [==============================] - 20s - loss: 1.1218 - acc: 0.8714 - val_loss: 0.7077 - val_acc: 0.8868\n",
      "Epoch 18/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1233 - acc: 0.8735Epoch 00017: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1226 - acc: 0.8738 - val_loss: 0.7416 - val_acc: 0.8868\n",
      "Epoch 19/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1281 - acc: 0.8773Epoch 00018: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1284 - acc: 0.8770 - val_loss: 0.7820 - val_acc: 0.8706\n",
      "Epoch 20/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1315 - acc: 0.8758Epoch 00019: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1320 - acc: 0.8760 - val_loss: 0.7819 - val_acc: 0.8598\n",
      "Epoch 21/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1162 - acc: 0.8722Epoch 00020: val_acc improved from 0.88679 to 0.89757, saving model to model_full_resnet2_refine_co/semi_self_1_0.89757.h5\n",
      "63/63 [==============================] - 19s - loss: 1.1158 - acc: 0.8720 - val_loss: 0.7304 - val_acc: 0.8976\n",
      "Epoch 22/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1190 - acc: 0.8727Epoch 00021: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1189 - acc: 0.8730 - val_loss: 0.7792 - val_acc: 0.8706\n",
      "Epoch 23/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1114 - acc: 0.8771Epoch 00022: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1102 - acc: 0.8774 - val_loss: 0.8218 - val_acc: 0.8733\n",
      "Epoch 24/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1194 - acc: 0.8761Epoch 00023: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1189 - acc: 0.8757 - val_loss: 0.7676 - val_acc: 0.8706\n",
      "Epoch 25/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1098 - acc: 0.8771Epoch 00024: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1093 - acc: 0.8770 - val_loss: 0.7988 - val_acc: 0.8868\n",
      "Epoch 26/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1167 - acc: 0.8732Epoch 00025: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1170 - acc: 0.8731 - val_loss: 0.7871 - val_acc: 0.8787\n",
      "Epoch 27/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1126 - acc: 0.8684Epoch 00026: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1125 - acc: 0.8690 - val_loss: 0.7957 - val_acc: 0.8760\n",
      "Epoch 28/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1109 - acc: 0.8679Epoch 00027: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.1111 - acc: 0.8687 - val_loss: 0.8201 - val_acc: 0.8868\n",
      "Epoch 29/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1127 - acc: 0.8727Epoch 00028: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.1130 - acc: 0.8728 - val_loss: 0.8314 - val_acc: 0.8895\n",
      "Epoch 30/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1071 - acc: 0.8782Epoch 00029: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1082 - acc: 0.8781 - val_loss: 0.8016 - val_acc: 0.8895\n",
      "Epoch 31/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1098 - acc: 0.8805Epoch 00030: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.1100 - acc: 0.8806 - val_loss: 0.8036 - val_acc: 0.8814\n",
      "Epoch 32/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1167 - acc: 0.8783Epoch 00031: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1170 - acc: 0.8786 - val_loss: 0.8400 - val_acc: 0.8760\n",
      "Epoch 33/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/63 [============================>.] - ETA: 0s - loss: 1.1228 - acc: 0.8692Epoch 00032: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1231 - acc: 0.8693 - val_loss: 0.8358 - val_acc: 0.8491\n",
      "Epoch 34/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1061 - acc: 0.8775Epoch 00033: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1076 - acc: 0.8769 - val_loss: 0.8249 - val_acc: 0.8652\n",
      "Epoch 35/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1147 - acc: 0.8674Epoch 00034: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1140 - acc: 0.8671 - val_loss: 0.8391 - val_acc: 0.8598\n",
      "Epoch 36/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1056 - acc: 0.8808Epoch 00035: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1071 - acc: 0.8803 - val_loss: 0.7889 - val_acc: 0.8868\n",
      "Epoch 37/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1101 - acc: 0.8679Epoch 00036: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.1089 - acc: 0.8690 - val_loss: 0.7828 - val_acc: 0.8868\n",
      "Epoch 38/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1086 - acc: 0.8778Epoch 00037: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 1.1085 - acc: 0.8775 - val_loss: 0.8892 - val_acc: 0.8491\n",
      "Epoch 39/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1043 - acc: 0.8758Epoch 00038: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.1034 - acc: 0.8760 - val_loss: 0.8126 - val_acc: 0.8706\n",
      "Epoch 40/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1082 - acc: 0.8732Epoch 00039: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 1.1065 - acc: 0.8735 - val_loss: 0.7793 - val_acc: 0.8679\n",
      "Epoch 41/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0983 - acc: 0.8771Epoch 00040: val_acc did not improve\n",
      "63/63 [==============================] - 22s - loss: 1.0989 - acc: 0.8770 - val_loss: 0.8111 - val_acc: 0.8760\n",
      "Epoch 42/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1041 - acc: 0.8787Epoch 00041: val_acc improved from 0.89757 to 0.90027, saving model to model_full_resnet2_refine_co/semi_self_1_0.90027.h5\n",
      "63/63 [==============================] - 20s - loss: 1.1030 - acc: 0.8793 - val_loss: 0.7385 - val_acc: 0.9003\n",
      "Epoch 43/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0974 - acc: 0.8765Epoch 00042: val_acc did not improve\n",
      "63/63 [==============================] - 22s - loss: 1.0978 - acc: 0.8757 - val_loss: 0.7572 - val_acc: 0.8895\n",
      "Epoch 44/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1083 - acc: 0.8737Epoch 00043: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.1079 - acc: 0.8735 - val_loss: 0.7854 - val_acc: 0.8706\n",
      "Epoch 45/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0998 - acc: 0.8824Epoch 00044: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0999 - acc: 0.8824 - val_loss: 0.7717 - val_acc: 0.8760\n",
      "Epoch 46/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1057 - acc: 0.8807Epoch 00045: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1059 - acc: 0.8808 - val_loss: 0.8088 - val_acc: 0.8760\n",
      "Epoch 47/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0909 - acc: 0.8812Epoch 00046: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0909 - acc: 0.8810 - val_loss: 0.8441 - val_acc: 0.8410\n",
      "Epoch 48/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1058 - acc: 0.8770Epoch 00047: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1059 - acc: 0.8772 - val_loss: 0.7837 - val_acc: 0.8733\n",
      "Epoch 49/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0986 - acc: 0.8753Epoch 00048: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0992 - acc: 0.8757 - val_loss: 0.7929 - val_acc: 0.8760\n",
      "Epoch 50/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1049 - acc: 0.8784Epoch 00049: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1050 - acc: 0.8792 - val_loss: 0.8304 - val_acc: 0.8706\n",
      "Epoch 51/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1027 - acc: 0.8782Epoch 00050: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1022 - acc: 0.8780 - val_loss: 0.8274 - val_acc: 0.8706\n",
      "Epoch 52/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0918 - acc: 0.8771Epoch 00051: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0930 - acc: 0.8769 - val_loss: 0.7989 - val_acc: 0.8760\n",
      "Epoch 53/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0923 - acc: 0.8778Epoch 00052: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0930 - acc: 0.8769 - val_loss: 0.8097 - val_acc: 0.8679\n",
      "Epoch 54/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0985 - acc: 0.8770Epoch 00053: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0976 - acc: 0.8782 - val_loss: 0.7668 - val_acc: 0.8841\n",
      "Epoch 55/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0922 - acc: 0.8732Epoch 00054: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0930 - acc: 0.8725 - val_loss: 0.7693 - val_acc: 0.8814\n",
      "Epoch 56/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0961 - acc: 0.8749Epoch 00055: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0952 - acc: 0.8755 - val_loss: 0.7484 - val_acc: 0.8841\n",
      "Epoch 57/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1039 - acc: 0.8739Epoch 00056: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1031 - acc: 0.8745 - val_loss: 0.7660 - val_acc: 0.8814\n",
      "Epoch 58/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1050 - acc: 0.8833Epoch 00057: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1042 - acc: 0.8842 - val_loss: 0.7365 - val_acc: 0.8976\n",
      "Epoch 59/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1091 - acc: 0.8684Epoch 00058: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1085 - acc: 0.8689 - val_loss: 0.7665 - val_acc: 0.8895\n",
      "Epoch 60/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1020 - acc: 0.8759Epoch 00059: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.1016 - acc: 0.8759 - val_loss: 0.7589 - val_acc: 0.8787\n",
      "Epoch 61/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0941 - acc: 0.8761Epoch 00060: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0934 - acc: 0.8765 - val_loss: 0.7575 - val_acc: 0.8868\n",
      "Epoch 62/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0872 - acc: 0.8817Epoch 00061: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0874 - acc: 0.8817 - val_loss: 0.7923 - val_acc: 0.8679\n",
      "Epoch 63/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0876 - acc: 0.8812Epoch 00062: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0882 - acc: 0.8813 - val_loss: 0.7953 - val_acc: 0.8733\n",
      "Epoch 64/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0935 - acc: 0.8794Epoch 00063: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0939 - acc: 0.8796 - val_loss: 0.7813 - val_acc: 0.8652\n",
      "Epoch 65/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0840 - acc: 0.8802Epoch 00064: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0841 - acc: 0.8803 - val_loss: 0.7840 - val_acc: 0.8760\n",
      "Epoch 66/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0919 - acc: 0.8794Epoch 00065: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 19s - loss: 1.0928 - acc: 0.8796 - val_loss: 0.7345 - val_acc: 0.8814\n",
      "Epoch 67/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.1006 - acc: 0.8765Epoch 00066: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0998 - acc: 0.8769 - val_loss: 0.7549 - val_acc: 0.8895\n",
      "Epoch 68/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0810 - acc: 0.8750Epoch 00067: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0802 - acc: 0.8751 - val_loss: 0.8015 - val_acc: 0.8706\n",
      "Epoch 69/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0858 - acc: 0.8765Epoch 00068: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0848 - acc: 0.8771 - val_loss: 0.7860 - val_acc: 0.8760\n",
      "Epoch 70/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0943 - acc: 0.8759Epoch 00069: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0952 - acc: 0.8759 - val_loss: 0.7203 - val_acc: 0.8868\n",
      "Epoch 71/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0831 - acc: 0.8729Epoch 00070: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0841 - acc: 0.8733 - val_loss: 0.7296 - val_acc: 0.8895\n",
      "Epoch 72/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0751 - acc: 0.8831Epoch 00071: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0752 - acc: 0.8836 - val_loss: 0.7399 - val_acc: 0.8949\n",
      "Epoch 73/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0893 - acc: 0.8837Epoch 00072: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0891 - acc: 0.8837 - val_loss: 0.8104 - val_acc: 0.8598\n",
      "(8162, 40, 345, 1)\n",
      "(8162, 41)\n",
      "(371, 40, 345, 1)\n",
      "(371, 41)\n",
      "Epoch 1/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0642 - acc: 0.8621Epoch 00000: val_acc improved from -inf to 0.85175, saving model to model_full_resnet2_refine_co/semi_self_2_0.85175.h5\n",
      "63/63 [==============================] - 28s - loss: 1.0656 - acc: 0.8624 - val_loss: 0.8219 - val_acc: 0.8518\n",
      "Epoch 2/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0528 - acc: 0.8747Epoch 00001: val_acc improved from 0.85175 to 0.85984, saving model to model_full_resnet2_refine_co/semi_self_2_0.85984.h5\n",
      "63/63 [==============================] - 19s - loss: 1.0512 - acc: 0.8751 - val_loss: 0.7073 - val_acc: 0.8598\n",
      "Epoch 3/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0303 - acc: 0.8794Epoch 00002: val_acc improved from 0.85984 to 0.86523, saving model to model_full_resnet2_refine_co/semi_self_2_0.86523.h5\n",
      "63/63 [==============================] - 19s - loss: 1.0300 - acc: 0.8798 - val_loss: 0.7747 - val_acc: 0.8652\n",
      "Epoch 4/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0439 - acc: 0.8702Epoch 00003: val_acc improved from 0.86523 to 0.87062, saving model to model_full_resnet2_refine_co/semi_self_2_0.87062.h5\n",
      "63/63 [==============================] - 19s - loss: 1.0444 - acc: 0.8705 - val_loss: 0.7418 - val_acc: 0.8706\n",
      "Epoch 5/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0347 - acc: 0.8789Epoch 00004: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0350 - acc: 0.8795 - val_loss: 0.7196 - val_acc: 0.8625\n",
      "Epoch 6/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0273 - acc: 0.8827Epoch 00005: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0278 - acc: 0.8822 - val_loss: 0.7432 - val_acc: 0.8518\n",
      "Epoch 7/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0234 - acc: 0.8896Epoch 00006: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0230 - acc: 0.8903 - val_loss: 0.7399 - val_acc: 0.8652\n",
      "Epoch 8/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0223 - acc: 0.8868Epoch 00007: val_acc improved from 0.87062 to 0.87332, saving model to model_full_resnet2_refine_co/semi_self_2_0.87332.h5\n",
      "63/63 [==============================] - 19s - loss: 1.0226 - acc: 0.8872 - val_loss: 0.6914 - val_acc: 0.8733\n",
      "Epoch 9/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0342 - acc: 0.8770Epoch 00008: val_acc improved from 0.87332 to 0.89488, saving model to model_full_resnet2_refine_co/semi_self_2_0.89488.h5\n",
      "63/63 [==============================] - 19s - loss: 1.0343 - acc: 0.8774 - val_loss: 0.6760 - val_acc: 0.8949\n",
      "Epoch 10/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0151 - acc: 0.8866Epoch 00009: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0148 - acc: 0.8872 - val_loss: 0.7617 - val_acc: 0.8625\n",
      "Epoch 11/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0192 - acc: 0.8853Epoch 00010: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0202 - acc: 0.8848 - val_loss: 0.7536 - val_acc: 0.8625\n",
      "Epoch 12/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0251 - acc: 0.8782Epoch 00011: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0249 - acc: 0.8781 - val_loss: 0.7323 - val_acc: 0.8679\n",
      "Epoch 13/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0213 - acc: 0.8846Epoch 00012: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0213 - acc: 0.8850 - val_loss: 0.7450 - val_acc: 0.8706\n",
      "Epoch 14/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0208 - acc: 0.8853Epoch 00013: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0192 - acc: 0.8859 - val_loss: 0.6941 - val_acc: 0.8814\n",
      "Epoch 15/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0152 - acc: 0.8836Epoch 00014: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0150 - acc: 0.8844 - val_loss: 0.7358 - val_acc: 0.8760\n",
      "Epoch 16/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0145 - acc: 0.8799Epoch 00015: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0148 - acc: 0.8796 - val_loss: 0.7486 - val_acc: 0.8760\n",
      "Epoch 17/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0142 - acc: 0.8876Epoch 00016: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0129 - acc: 0.8873 - val_loss: 0.7410 - val_acc: 0.8652\n",
      "Epoch 18/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0173 - acc: 0.8813Epoch 00017: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0171 - acc: 0.8808 - val_loss: 0.7307 - val_acc: 0.8868\n",
      "Epoch 19/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0211 - acc: 0.8818Epoch 00018: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0211 - acc: 0.8811 - val_loss: 0.7114 - val_acc: 0.8841\n",
      "Epoch 20/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0090 - acc: 0.8880Epoch 00019: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 1.0082 - acc: 0.8880 - val_loss: 0.7731 - val_acc: 0.8733\n",
      "Epoch 21/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0177 - acc: 0.8843Epoch 00020: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.0175 - acc: 0.8850 - val_loss: 0.7834 - val_acc: 0.8652\n",
      "Epoch 22/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0043 - acc: 0.8872Epoch 00021: val_acc did not improve\n",
      "63/63 [==============================] - 23s - loss: 1.0042 - acc: 0.8874 - val_loss: 0.7416 - val_acc: 0.8760\n",
      "Epoch 23/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0069 - acc: 0.8881Epoch 00022: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0073 - acc: 0.8879 - val_loss: 0.7384 - val_acc: 0.8571\n",
      "Epoch 24/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0152 - acc: 0.8895Epoch 00023: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0153 - acc: 0.8893 - val_loss: 0.7534 - val_acc: 0.8814\n",
      "Epoch 25/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/63 [============================>.] - ETA: 0s - loss: 1.0170 - acc: 0.8817Epoch 00024: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.0174 - acc: 0.8822 - val_loss: 0.7042 - val_acc: 0.8814\n",
      "Epoch 26/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0126 - acc: 0.8880Epoch 00025: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0118 - acc: 0.8880 - val_loss: 0.7108 - val_acc: 0.8760\n",
      "Epoch 27/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0062 - acc: 0.8889Epoch 00026: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0055 - acc: 0.8890 - val_loss: 0.6980 - val_acc: 0.8760\n",
      "Epoch 28/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0066 - acc: 0.8875Epoch 00027: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0060 - acc: 0.8876 - val_loss: 0.7385 - val_acc: 0.8652\n",
      "Epoch 29/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0098 - acc: 0.8839Epoch 00028: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0099 - acc: 0.8842 - val_loss: 0.6976 - val_acc: 0.8787\n",
      "Epoch 30/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0073 - acc: 0.8896Epoch 00029: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0066 - acc: 0.8903 - val_loss: 0.7622 - val_acc: 0.8733\n",
      "Epoch 31/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0057 - acc: 0.8910Epoch 00030: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0060 - acc: 0.8916 - val_loss: 0.7078 - val_acc: 0.8814\n",
      "Epoch 32/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0042 - acc: 0.8880Epoch 00031: val_acc improved from 0.89488 to 0.89757, saving model to model_full_resnet2_refine_co/semi_self_2_0.89757.h5\n",
      "63/63 [==============================] - 19s - loss: 1.0053 - acc: 0.8875 - val_loss: 0.7123 - val_acc: 0.8976\n",
      "Epoch 33/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0086 - acc: 0.8855Epoch 00032: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.0090 - acc: 0.8854 - val_loss: 0.7327 - val_acc: 0.8706\n",
      "Epoch 34/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0129 - acc: 0.8813Epoch 00033: val_acc did not improve\n",
      "63/63 [==============================] - 23s - loss: 1.0137 - acc: 0.8816 - val_loss: 0.7389 - val_acc: 0.8760\n",
      "Epoch 35/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0100 - acc: 0.8887Epoch 00034: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 1.0102 - acc: 0.8881 - val_loss: 0.7284 - val_acc: 0.8814\n",
      "Epoch 36/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0062 - acc: 0.8884Epoch 00035: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 1.0070 - acc: 0.8875 - val_loss: 0.7669 - val_acc: 0.8706\n",
      "Epoch 37/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9985 - acc: 0.8875Epoch 00036: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 0.9986 - acc: 0.8873 - val_loss: 0.7147 - val_acc: 0.8706\n",
      "Epoch 38/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0020 - acc: 0.8895Epoch 00037: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 1.0028 - acc: 0.8891 - val_loss: 0.7023 - val_acc: 0.8841\n",
      "Epoch 39/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0050 - acc: 0.8824Epoch 00038: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 1.0047 - acc: 0.8827 - val_loss: 0.7379 - val_acc: 0.8679\n",
      "Epoch 40/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9929 - acc: 0.8896Epoch 00039: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 0.9937 - acc: 0.8903 - val_loss: 0.7935 - val_acc: 0.8652\n",
      "Epoch 41/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9965 - acc: 0.8904Epoch 00040: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 0.9970 - acc: 0.8904 - val_loss: 0.7118 - val_acc: 0.8895\n",
      "Epoch 42/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0011 - acc: 0.8892Epoch 00041: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 1.0014 - acc: 0.8896 - val_loss: 0.7451 - val_acc: 0.8706\n",
      "Epoch 43/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0042 - acc: 0.8887Epoch 00042: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 1.0038 - acc: 0.8889 - val_loss: 0.7687 - val_acc: 0.8706\n",
      "Epoch 44/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0095 - acc: 0.8834Epoch 00043: val_acc did not improve\n",
      "63/63 [==============================] - 22s - loss: 1.0087 - acc: 0.8824 - val_loss: 0.7159 - val_acc: 0.8841\n",
      "Epoch 45/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9916 - acc: 0.8911Epoch 00044: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 0.9909 - acc: 0.8921 - val_loss: 0.7781 - val_acc: 0.8571\n",
      "Epoch 46/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0019 - acc: 0.8944Epoch 00045: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 1.0011 - acc: 0.8938 - val_loss: 0.7379 - val_acc: 0.8733\n",
      "Epoch 47/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0027 - acc: 0.8824Epoch 00046: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0033 - acc: 0.8824 - val_loss: 0.7173 - val_acc: 0.8733\n",
      "Epoch 48/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0042 - acc: 0.8809Epoch 00047: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.0043 - acc: 0.8808 - val_loss: 0.7687 - val_acc: 0.8706\n",
      "Epoch 49/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0002 - acc: 0.8901Epoch 00048: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.0009 - acc: 0.8894 - val_loss: 0.7378 - val_acc: 0.8760\n",
      "Epoch 50/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0058 - acc: 0.8881Epoch 00049: val_acc did not improve\n",
      "63/63 [==============================] - 20s - loss: 1.0066 - acc: 0.8876 - val_loss: 0.7348 - val_acc: 0.8679\n",
      "Epoch 51/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9951 - acc: 0.8910Epoch 00050: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 0.9954 - acc: 0.8911 - val_loss: 0.7598 - val_acc: 0.8652\n",
      "Epoch 52/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9883 - acc: 0.8945Epoch 00051: val_acc did not improve\n",
      "63/63 [==============================] - 22s - loss: 0.9894 - acc: 0.8943 - val_loss: 0.8625 - val_acc: 0.8544\n",
      "Epoch 53/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9983 - acc: 0.8887Epoch 00052: val_acc did not improve\n",
      "63/63 [==============================] - 22s - loss: 0.9982 - acc: 0.8885 - val_loss: 0.7534 - val_acc: 0.8733\n",
      "Epoch 54/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9922 - acc: 0.8930Epoch 00053: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 0.9932 - acc: 0.8927 - val_loss: 0.7415 - val_acc: 0.8652\n",
      "Epoch 55/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9923 - acc: 0.8871Epoch 00054: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 0.9915 - acc: 0.8879 - val_loss: 0.7522 - val_acc: 0.8571\n",
      "Epoch 56/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9940 - acc: 0.8856Epoch 00055: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 0.9938 - acc: 0.8864 - val_loss: 0.7527 - val_acc: 0.8652\n",
      "Epoch 57/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9973 - acc: 0.8839Epoch 00056: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 0.9959 - acc: 0.8848 - val_loss: 0.7333 - val_acc: 0.8733\n",
      "Epoch 58/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0081 - acc: 0.8843Epoch 00057: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 19s - loss: 1.0084 - acc: 0.8844 - val_loss: 0.7185 - val_acc: 0.8733\n",
      "Epoch 59/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0074 - acc: 0.8832Epoch 00058: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0082 - acc: 0.8829 - val_loss: 0.7568 - val_acc: 0.8598\n",
      "Epoch 60/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0034 - acc: 0.8831Epoch 00059: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0032 - acc: 0.8828 - val_loss: 0.7364 - val_acc: 0.8760\n",
      "Epoch 61/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9965 - acc: 0.8925Epoch 00060: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 0.9970 - acc: 0.8925 - val_loss: 0.7048 - val_acc: 0.8760\n",
      "Epoch 62/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.0028 - acc: 0.8861Epoch 00061: val_acc did not improve\n",
      "63/63 [==============================] - 19s - loss: 1.0011 - acc: 0.8872 - val_loss: 0.6912 - val_acc: 0.8814\n",
      "Epoch 63/10000\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.9944 - acc: 0.8887Epoch 00062: val_acc did not improve\n",
      "63/63 [==============================] - 21s - loss: 0.9950 - acc: 0.8879 - val_loss: 0.6963 - val_acc: 0.8733\n",
      "(8162, 40, 345, 1)\n",
      "(8162, 41)\n",
      "(371, 40, 345, 1)\n",
      "(371, 41)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-24b32ca7a43c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mheight_shift_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mhorizontal_flip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mpreprocessing_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_random_eraser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Trainset's boundaries.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     return _methods._amin(a, axis=axis,\n\u001b[0;32m-> 2420\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = 'model_full_resnet2'\n",
    "refine_path = 'model_full_resnet2_refine_co'\n",
    "\n",
    "all_x = np.concatenate( (np.load('data/mfcc/X_train.npy') , np.load('data/X_test.npy')))\n",
    "\n",
    "if not os.path.exists(refine_path):\n",
    "    os.mkdir(refine_path)\n",
    "\n",
    "for i in range(1,11):\n",
    "    X_train = np.load('data/ten_fold_data/X_train_{}.npy'.format(i)) \n",
    "    Y_train = np.load('data/ten_fold_data/Y_train_{}.npy'.format(i)) \n",
    "    X_test = np.load('data/ten_fold_data/X_valid_{}.npy'.format(i))\n",
    "    Y_test = np.load('data/ten_fold_data/Y_valid_{}.npy'.format(i))\n",
    "    \n",
    "    X_train = np.append(X_train,X_semi , axis=0)\n",
    "    Y_train = np.append(Y_train,Y_semi , axis=0)\n",
    "    \n",
    "    X_train , Y_train = shuffle(X_train, Y_train, random_state=5)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y_test.shape)\n",
    "    \n",
    "    model = load_model(join(model_path,'best_{}.h5'.format(i)))\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(join(refine_path , 'semi_self_%d_{val_acc:.5f}.h5'%i), monitor='val_acc', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=30)\n",
    "    callbacks_list = [checkpoint, early]\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=get_random_eraser(v_l=np.min(all_x), v_h=np.max(all_x)) # Trainset's boundaries.\n",
    "    )\n",
    "    \n",
    "    mygenerator = MixupGenerator(X_train, Y_train, alpha=1.0, batch_size=128, datagen=datagen)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=Adam(lr=0.0001),\n",
    "             metrics=['accuracy'])\n",
    "    # mixup\n",
    "    history = model.fit_generator(mygenerator(),\n",
    "                    steps_per_epoch= X_train.shape[0] // 128,\n",
    "                    epochs=10000,\n",
    "                    validation_data=(X_test,Y_test), callbacks=callbacks_list)\n",
    "    # normalize\n",
    "#     history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), callbacks=callbacks_list,\n",
    "#                         batch_size=32, epochs=10000)\n",
    "\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
